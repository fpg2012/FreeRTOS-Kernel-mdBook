<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title></title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title"></h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="1-preface"><a class="header" href="#1-preface">1 Preface</a></h1>
<h2 id="11-multitasking-in-small-embedded-systems"><a class="header" href="#11-multitasking-in-small-embedded-systems">1.1 Multitasking in Small Embedded Systems</a></h2>
<h3 id="111-about-the-freertos-kernel"><a class="header" href="#111-about-the-freertos-kernel">1.1.1 About the FreeRTOS Kernel</a></h3>
<p>FreeRTOS is a collection of C libraries comprised of a real-time kernel
and a set of modular libraries that implement complementary
functionality.</p>
<p>Richard Barry originally developed FreeRTOS around 2003. Real-Time
Engineers Ltd, Richard's company, continued FreeRTOS development in
close partnership with the world's leading chip companies until Amazon
Web Services (AWS) took stewardship of FreeRTOS 2016. Richard now
continues his work on FreeRTOS as a senior principal engineer within the
AWS IoT team.  FreeRTOS is MIT licensed open source code, available for
any purpose.  You don't have to be an AWS customer to benefit from AWS's
stewardship!</p>
<p>The FreeRTOS kernel is ideally suited to deeply embedded real-time
applications that run on microcontrollers or small microprocessors. This
type of application typically includes a mix of both hard and soft
real-time requirements.</p>
<p>Soft real-time requirements state a time deadline—but breaching the
deadline would not render the system useless. For example, responding to
keystrokes too slowly might make a system seem annoyingly unresponsive
without actually making it unusable.</p>
<p>Hard real-time requirements state a time deadline—and breaching the
deadline would result in absolute failure of the system. For example, a
driver's airbag has the potential to do more harm than good if it
responded to crash sensor inputs too slowly.</p>
<p>The FreeRTOS kernel is a real-time kernel (or real-time scheduler) that
enables applications built on FreeRTOS to meet their hard real-time
requirements. It enables applications to be organized as a collection of
independent threads of execution. For example, on a processor that has
only one core, only a single thread of execution can execute at any
one time. The kernel decides which thread to execute by examining the
priority assigned to each thread by the application designer. In the
simplest case, the application designer could assign higher priorities
to threads that implement hard real-time requirements and lower
priorities to threads that implement soft real-time requirements.
Allocating priorities in that way would ensure hard real-time threads
always execute ahead of soft real-time threads, but priority assignment
decisions are not always that simplistic.</p>
<p>Do not be concerned if you do not fully understand the concepts in the
previous paragraph yet. The following chapters provide a detailed
explanation, with many examples, to help you understand how to use a
real-time kernel, and FreeRTOS in particular.</p>
<h3 id="112-value-proposition"><a class="header" href="#112-value-proposition">1.1.2 Value Proposition</a></h3>
<p>The unprecedented global success of the FreeRTOS kernel comes from its
compelling value proposition; FreeRTOS is professionally developed,
strictly quality controlled, robust, supported, does not contain any
intellectual property ownership ambiguity, and is truly free to use in
commercial applications without any requirement to expose your
proprietary source code. Further, AWS's stewardship provides a global
presence, expert security event response procedures, a large and diverse
development team, expertise in formal verification, pen testing, memory
safety proofs, and long-term
support – all while maintaining FreeRTOS as a hardware, development
tool, and cloud service-neutral open-source project. FreeRTOS
development is transparent and community-driven in GitHub, and does not
require any special tools or development practices.</p>
<p>You can take a product to market using FreeRTOS without even telling us,
let alone paying any fees, and thousands of companies do just that. If
at any time you would like to receive additional backup, or if your
legal team requires additional written guarantees or indemnification,
then our strategic partners provide simple low-cost commercial license
options. Peace of mind comes with the knowledge that you can opt to take
the commercial route whenever you choose.</p>
<h3 id="113-a-note-about-terminology"><a class="header" href="#113-a-note-about-terminology">1.1.3 A Note About Terminology</a></h3>
<p>In FreeRTOS, each thread of execution is called a 'task'. There is no
consensus on terminology within the embedded community, but I prefer
'task' to 'thread,' as thread can have a more specific meaning in some
fields of application.</p>
<h3 id="114-why-use-an-rtos"><a class="header" href="#114-why-use-an-rtos">1.1.4 Why Use an RTOS?</a></h3>
<p>There are many well-established techniques for writing good embedded
software without using a multithreading kernel. If the system under
development is simple, then these techniques might provide the most
appropriate solution. Using a kernel would likely be preferable in more
complex cases, but where the crossover point occurs will always be
subjective.</p>
<p>As already described, task prioritization can help ensure an application
meets its processing deadlines, but a kernel can bring other less
obvious benefits. Some of these are listed very briefly below.</p>
<ul>
<li>
<p>Abstracting away timing information</p>
<p>The RTOS is responsible for execution timing and provides a time-related
API to the application. That allows the structure of the application
code to be more straightforward and the overall code size to be smaller.</p>
</li>
<li>
<p>Maintainability/Extensibility</p>
<p>Abstracting away timing details results in fewer interdependencies
between modules and allows the software to evolve in a controlled and
predictable way. Also, the kernel is responsible for the timing, so
application performance is less susceptible to changes in the underlying
hardware.</p>
</li>
<li>
<p>Modularity</p>
<p>Tasks are independent modules, each of which should have a well-defined
purpose.</p>
</li>
<li>
<p>Team development</p>
<p>Tasks should also have well-defined interfaces, allowing easier
team development.</p>
</li>
<li>
<p>Easier testing</p>
<p>Tasks that are well-defined independent modules with clean interfaces
are easier to test in isolation.</p>
</li>
<li>
<p>Code reuse</p>
<p>Code designed with greater modularity and fewer interdependencies is
easier to reuse.</p>
</li>
<li>
<p>Improved efficiency</p>
<p>Application code that uses an RTOS can be completely event-driven. No
processing time needs to be wasted by polling for events that
have not occurred.</p>
<p>Countering the efficiency gained from being event driven is the need to process the RTOS tick
interrupt and switch execution from one task to another. However,
applications that don't use an RTOS normally include some form of tick
interrupt anyway.</p>
</li>
<li>
<p>Idle time</p>
<p>The automatically created Idle task executes when there are no
application tasks that require processing. The Idle task can measure
spare processing capacity, perform background checks, or place the
processor into a low-power mode.</p>
</li>
<li>
<p>Power Management</p>
<p>The efficiency gains that result from using an RTOS allow the processor to
spend more time in a low power mode.</p>
<p>Power consumption can be decreased significantly by placing the
processor into a low power state each time the Idle task runs. FreeRTOS
also has a special tick-less mode. Using the tick-less mode allows the
processor to enter a lower power mode than would otherwise be possible
and remain in the low power mode for longer.</p>
</li>
<li>
<p>Flexible interrupt handling</p>
<p>Interrupt handlers can be kept very short by deferring processing to
either a task created by the application writer or the automatically
created RTOS daemon task (also known as the timer task).</p>
</li>
<li>
<p>Mixed processing requirements</p>
<p>Simple design patterns can achieve a mix of periodic, continuous, and
event-driven processing within an application. In addition, hard and
soft real-time requirements can be met by selecting appropriate task and
interrupt priorities.</p>
</li>
</ul>
<h3 id="115-freertos-kernel-features"><a class="header" href="#115-freertos-kernel-features">1.1.5 FreeRTOS Kernel Features</a></h3>
<p>The FreeRTOS kernel has the following standard features:</p>
<ul>
<li>Pre-emptive or co-operative operation</li>
<li>Optional time-slicing</li>
<li>Very flexible task priority assignment</li>
<li>Flexible, fast and light-weight task notification mechanisms</li>
<li>Queues</li>
<li>Binary semaphores</li>
<li>Counting semaphores</li>
<li>Mutexes</li>
<li>Recursive mutexes</li>
<li>Software timers</li>
<li>Event groups</li>
<li>Stream buffers</li>
<li>Message buffers</li>
<li>Co-routines (deprecated)</li>
<li>Tick hook functions</li>
<li>Idle hook functions</li>
<li>Stack overflow checking</li>
<li>Trace macros</li>
<li>Task run-time statistics gathering</li>
<li>Optional commercial licensing and support</li>
<li>Full interrupt nesting model (for some architectures)</li>
<li>A tick-less capability for extreme low power applications (for some architectures)</li>
<li>Memory Protection Unit support for isolating tasks and increasing application safety (for some architectures)</li>
<li>Software managed interrupt stack when appropriate (this can help save RAM)</li>
<li>The ability to create RTOS objects using either statically or
dynamically allocated memory</li>
</ul>
<h3 id="116-licensing-and-the-freertos-openrtos-and-safertos-family"><a class="header" href="#116-licensing-and-the-freertos-openrtos-and-safertos-family">1.1.6 Licensing, and The FreeRTOS, OpenRTOS, and SafeRTOS Family</a></h3>
<p>The <strong>FreeRTOS</strong> MIT open source license is designed to ensure:</p>
<ul>
<li>
<p>FreeRTOS can be used in commercial applications.</p>
</li>
<li>
<p>FreeRTOS itself remains freely available to everybody.</p>
</li>
<li>
<p>FreeRTOS users retain ownership of their intellectual property.</p>
</li>
</ul>
<p>See <a href="https://www.FreeRTOS.org/license">https://www.FreeRTOS.org/license</a> for the latest open source
license information.</p>
<p><strong>OpenRTOS</strong> is a commercially licensed version of FreeRTOS provided
under license from Amazon Web Services by a third party.</p>
<p><strong>SafeRTOS</strong> shares the same usage model as FreeRTOS, but has been
developed in accordance with the practices, procedures, and processes
necessary to claim compliance with various internationally recognized
safety related standards.</p>
<h2 id="12-included-source-files-and-projects"><a class="header" href="#12-included-source-files-and-projects">1.2 Included Source Files and Projects</a></h2>
<h3 id="121-obtaining-the-examples-that-accompany-this-book"><a class="header" href="#121-obtaining-the-examples-that-accompany-this-book">1.2.1 Obtaining the Examples that Accompany this Book</a></h3>
<p>The zip file available for download from <a href="https://www.FreeRTOS.org/Documentation/code">https://www.FreeRTOS.org/Documentation/code</a>
contains all the source code, pre-configured project files, and
instructions necessary to build and execute the examples presented in
this book. Note the zip file will not necessarily contain the most
recent version of FreeRTOS.</p>
<p>The screenshots included in this book show the examples executing in a
Microsoft Windows environment, using the FreeRTOS Windows port. The
project that uses the FreeRTOS Windows port is pre-configured to build
using the free Community edition of Visual Studio, available from
<a href="https://www.visualstudio.com/">https://www.visualstudio.com/</a>. Note that while the FreeRTOS Windows
port provides a convenient evaluation, test, and development platform,
it does <em>not</em> provide true real-time behavior.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h1>
<h2 id="1-preface-1"><a class="header" href="#1-preface-1"><a href="ch01.html#1-preface">1 Preface</a></a></h2>
<ul>
<li><a href="ch01.html#11-multitasking-in-small-embedded-systems">1.1 Multitasking in Small Embedded Systems</a>
<ul>
<li><a href="ch01.html#111-about-the-freertos-kernel">1.1.1 About the FreeRTOS Kernel</a></li>
<li><a href="ch01.html#112-value-proposition">1.1.2 Value Proposition</a></li>
<li><a href="ch01.html#113-a-note-about-terminology">1.1.3 A Note About Terminology</a></li>
<li><a href="ch01.html#114-why-use-an-rtos">1.1.4 Why Use an RTOS?</a></li>
<li><a href="ch01.html#115-freertos-kernel-features">1.1.5 FreeRTOS Kernel Features</a></li>
<li><a href="ch01.html#116-licensing-and-the-freertos-openrtos-and-safertos-family">1.1.6 Licensing, and The FreeRTOS, OpenRTOS, and SafeRTOS Family</a></li>
</ul>
</li>
<li><a href="ch01.html#12-included-source-files-and-projects">1.2 Included Source Files and Projects</a>
<ul>
<li><a href="ch01.html#121-obtaining-the-examples-that-accompany-this-book">1.2.1 Obtaining the Examples that Accompany this Book</a></li>
</ul>
</li>
</ul>
<h2 id="2-the-freertos-kernel-distribution"><a class="header" href="#2-the-freertos-kernel-distribution"><a href="ch02.html#2-the-freertos-kernel-distribution">2 The FreeRTOS Kernel Distribution</a></a></h2>
<ul>
<li><a href="ch02.html#21-introduction">2.1 Introduction</a></li>
<li><a href="ch02.html#22-understanding-the-freertos-distribution">2.2 Understanding the FreeRTOS Distribution</a>
<ul>
<li><a href="ch02.html#221-definition-freertos-port">2.2.1 Definition: FreeRTOS Port</a></li>
<li><a href="ch02.html#222-building-freertos">2.2.2 Building FreeRTOS</a></li>
<li><a href="ch02.html#223-freertosconfigh">2.2.3 FreeRTOSConfig.h</a></li>
<li><a href="ch02.html#224-official-distributions">2.2.4 Official Distributions</a></li>
<li><a href="ch02.html#225-freertos-source-files-common-to-all-ports">2.2.5 FreeRTOS Source Files Common to All Ports</a></li>
<li><a href="ch02.html#226-freertos-source-files-specific-to-a-port">2.2.6 FreeRTOS Source Files Specific to a Port</a></li>
<li><a href="ch02.html#227-include-paths">2.2.7 Include Paths</a></li>
<li><a href="ch02.html#228-header-files">2.2.8 Header Files</a></li>
</ul>
</li>
<li><a href="ch02.html#23-demo-applications">2.3 Demo Applications</a></li>
<li><a href="ch02.html#24-creating-a-freertos-project">2.4 Creating a FreeRTOS Project</a>
<ul>
<li><a href="ch02.html#241-adapting-one-of-the-supplied-demo-projects">2.4.1 Adapting One of the Supplied Demo Projects</a></li>
<li><a href="ch02.html#242-creating-a-new-project-from-scratch">2.4.2 Creating a New Project from Scratch</a></li>
</ul>
</li>
<li><a href="ch02.html#25-data-types-and-coding-style-guide">2.5 Data Types and Coding Style Guide</a>
<ul>
<li><a href="ch02.html#251-data-types">2.5.1 Data Types</a></li>
<li><a href="ch02.html#252-variable-names">2.5.2 Variable Names</a></li>
<li><a href="ch02.html#253-function-names">2.5.3 Function Names</a></li>
<li><a href="ch02.html#254-formatting">2.5.4 Formatting</a></li>
<li><a href="ch02.html#255-macro-names">2.5.5 Macro Names</a></li>
<li><a href="ch02.html#256-rationale-for-excessive-type-casting">2.5.6 Rationale for Excessive Type Casting</a></li>
</ul>
</li>
</ul>
<h2 id="3-heap-memory-management"><a class="header" href="#3-heap-memory-management"><a href="ch03.html#3-heap-memory-management">3 Heap Memory Management</a></a></h2>
<ul>
<li><a href="ch03.html#31-introduction">3.1 Introduction</a>
<ul>
<li><a href="ch03.html#311-prerequisites">3.1.1 Prerequisites</a></li>
<li><a href="ch03.html#312-scope">3.1.2 Scope</a></li>
<li><a href="ch03.html#313-switching-between-static-and-dynamic-memory-allocation">3.1.3 Switching Between Static and Dynamic Memory Allocation</a></li>
<li><a href="ch03.html#314-using-dynamic-memory-allocation">3.1.4 Using Dynamic Memory Allocation</a></li>
<li><a href="ch03.html#315-options-for-dynamic-memory-allocation">3.1.5 Options for Dynamic Memory Allocation</a></li>
</ul>
</li>
<li><a href="ch03.html#32-example-memory-allocation-schemes">3.2 Example Memory Allocation Schemes</a>
<ul>
<li><a href="ch03.html#321-heap_1">3.2.1 Heap_1</a></li>
<li><a href="ch03.html#322-heap_2">3.2.2 Heap_2</a></li>
<li><a href="ch03.html#323-heap_3">3.2.3 Heap_3</a></li>
<li><a href="ch03.html#324-heap_4">3.2.4 Heap_4</a></li>
<li><a href="ch03.html#325-heap_5">3.2.5 Heap_5</a></li>
<li><a href="ch03.html#326-initialising-heap_5-the-vportdefineheapregions-api-function">3.2.6 Initialising heap_5: The vPortDefineHeapRegions() API Function</a></li>
</ul>
</li>
<li><a href="ch03.html#33-heap-related-utility-functions-and-macros">3.3 Heap Related Utility Functions and Macros</a>
<ul>
<li><a href="ch03.html#331-defining-the-heap-start-address">3.3.1 Defining the Heap Start Address</a></li>
<li><a href="ch03.html#332-the-xportgetfreeheapsize-api-function">3.3.2 The xPortGetFreeHeapSize() API Function</a></li>
<li><a href="ch03.html#333-the-xportgetminimumeverfreeheapsize-api-function">3.3.3 The xPortGetMinimumEverFreeHeapSize() API Function</a></li>
<li><a href="ch03.html#334-the-vportgetheapstats-api-function">3.3.4 The vPortGetHeapStats() API Function</a></li>
<li><a href="ch03.html#335-collecting-per-task-heap-usage-statistics">3.3.5 Collecting Per-task Heap Usage Statistics</a></li>
<li><a href="ch03.html#336-malloc-failed-hook-functions">3.3.6 Malloc Failed Hook Functions</a></li>
<li><a href="ch03.html#337-placing-task-stacks-in-fast-memory">3.3.7 Placing Task Stacks in Fast Memory</a></li>
</ul>
</li>
<li><a href="ch03.html#34-using-static-memory-allocation">3.4 Using Static Memory Allocation</a>
<ul>
<li><a href="ch03.html#341-enabling-static-memory-allocation">3.4.1 Enabling Static Memory Allocation</a></li>
<li><a href="ch03.html#342-static-internal-kernel-memory">3.4.2 Static Internal Kernel Memory</a>
<ul>
<li><a href="ch03.html#3421-vapplicationgettimertaskmemory">3.4.2.1 vApplicationGetTimerTaskMemory</a></li>
<li><a href="ch03.html#3422-vapplicationgetidletaskmemory">3.4.2.2 vApplicationGetIdleTaskMemory</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="4-task-management"><a class="header" href="#4-task-management"><a href="ch04.html#4-task-management">4 Task Management</a></a></h2>
<ul>
<li><a href="ch04.html#41-introduction">4.1 Introduction</a>
<ul>
<li><a href="ch04.html#411-scope">4.1.1 Scope</a></li>
</ul>
</li>
<li><a href="ch04.html#42-task-functions">4.2 Task Functions</a></li>
<li><a href="ch04.html#43-top-level-task-states">4.3 Top Level Task States</a></li>
<li><a href="ch04.html#44-task-creation">4.4 Task Creation</a>
<ul>
<li><a href="ch04.html#441-the-xtaskcreate-api-function">4.4.1 The xTaskCreate() API Function</a></li>
</ul>
</li>
<li><a href="ch04.html#45-task-priorities">4.5 Task Priorities</a>
<ul>
<li><a href="ch04.html#451-generic-scheduler">Generic Scheduler</a></li>
<li><a href="ch04.html#452-architecture-optimized-scheduler">Architecture-Optimized Scheduler</a></li>
</ul>
</li>
<li><a href="ch04.html#46-time-measurement-and-the-tick-interrupt">4.6 Time Measurement and the Tick Interrupt</a></li>
<li><a href="ch04.html#47-expanding-the-not-running-state">4.7 Expanding the <em>Not Running</em> State</a>
<ul>
<li><a href="ch04.html#471-the-blocked-state">4.7.1 The <em>Blocked</em> State</a></li>
<li><a href="ch04.html#472-the-suspended-state">4.7.2 The <em>Suspended</em> State</a></li>
<li><a href="ch04.html#473-the-ready-state">4.7.3 The Ready State</a></li>
<li><a href="ch04.html#474-completing-the-state-transition-diagram">4.7.4 Completing the State Transition Diagram</a></li>
<li><a href="ch04.html#475-the-vtaskdelayuntil-api-function">4.7.5 The vTaskDelayUntil() API Function</a></li>
</ul>
</li>
<li><a href="ch04.html#48-the-idle-task-and-the-idle-task-hook">4.8 The Idle Task and the Idle Task Hook</a>
<ul>
<li><a href="ch04.html#481-idle-task-hook-functions">4.8.1 Idle Task Hook Functions</a></li>
<li><a href="ch04.html#482-limitations-on-the-implementation-of-idle-task-hook-functions">4.8.2 Limitations on the Implementation of Idle Task Hook Functions</a></li>
</ul>
</li>
<li><a href="ch04.html#49-changing-the-priority-of-a-task">4.9 Changing the Priority of a Task</a>
<ul>
<li><a href="ch04.html#491-the-vtaskpriorityset-api-function">4.9.1 The vTaskPrioritySet() API Function</a></li>
<li><a href="ch04.html#492-the-uxtaskpriorityget-api-function">4.9.2 The uxTaskPriorityGet() API Function</a></li>
</ul>
</li>
<li><a href="ch04.html#410-deleting-a-task">4.10 Deleting a Task</a>
<ul>
<li><a href="ch04.html#4101-the-vtaskdelete-api-function">4.10.1 The vTaskDelete() API Function</a></li>
</ul>
</li>
<li><a href="ch04.html#411-thread-local-storage-and-reentrancy">4.11 Thread Local Storage and Reentrancy</a>
<ul>
<li><a href="ch04.html#4111-c-runtime-thread-local-storage-implementations">4.11.1 C Runtime Thread Local Storage Implementations</a></li>
<li><a href="ch04.html#4112-custom-c-runtime-thread-local-storage">4.11.2 Custom C Runtime Thread Local Storage</a></li>
<li><a href="ch04.html#4113-application-thread-local-storage">4.11.3 Application Thread Local Storage</a></li>
</ul>
</li>
<li><a href="ch04.html#412-scheduling-algorithms">4.12 Scheduling Algorithms</a>
<ul>
<li><a href="ch04.html#4121-a-recap-of-task-states-and-events">4.12.1 A Recap of Task States and Events</a></li>
<li><a href="ch04.html#4122-selecting-the-scheduling-algorithm">4.12.2 Selecting the Scheduling Algorithm</a></li>
<li><a href="ch04.html#4123-prioritized-preemptive-scheduling-with-time-slicing">4.12.3 Prioritized Preemptive Scheduling with Time Slicing</a></li>
<li><a href="ch04.html#4124-prioritized-preemptive-scheduling-without-time-slicing">4.12.4 Prioritized Preemptive Scheduling without Time Slicing</a></li>
<li><a href="ch04.html#4125-cooperative-scheduling">4.12.5 Cooperative Scheduling</a></li>
</ul>
</li>
</ul>
<h2 id="5-queue-management"><a class="header" href="#5-queue-management"><a href="ch05.html#5-queue-management">5 Queue Management</a></a></h2>
<ul>
<li><a href="ch05.html#51-introduction">5.1 Introduction</a>
<ul>
<li><a href="ch05.html#511-scope">5.1.1 Scope</a></li>
</ul>
</li>
<li><a href="ch05.html#52-characteristics-of-a-queue">5.2 Characteristics of a Queue</a>
<ul>
<li><a href="ch05.html#521-data-storage">5.2.1 Data Storage</a></li>
<li><a href="ch05.html#522-access-by-multiple-tasks">5.2.2 Access by Multiple Tasks</a></li>
<li><a href="ch05.html#523-blocking-on-queue-reads">5.2.3 Blocking on Queue Reads</a></li>
<li><a href="ch05.html#524-blocking-on-queue-writes">5.2.4 Blocking on Queue Writes</a></li>
<li><a href="ch05.html#525-blocking-on-multiple-queues">5.2.5 Blocking on Multiple Queues</a></li>
<li><a href="ch05.html#526-creating-queues-statically-allocated-and-dynamically-allocated-queues">5.2.6 Creating Queues: Statically Allocated and Dynamically Allocated Queues</a></li>
</ul>
</li>
<li><a href="ch05.html#53-using-a-queue">5.3 Using a Queue</a>
<ul>
<li><a href="ch05.html#531-the-xqueuecreate-api-function">5.3.1 The xQueueCreate() API Function</a></li>
<li><a href="ch05.html#532-the-xqueuesendtoback-and-xqueuesendtofront-api-functions">5.3.2 The xQueueSendToBack() and xQueueSendToFront() API Functions</a></li>
<li><a href="ch05.html#533-the-xqueuereceive-api-function">5.3.3 The xQueueReceive() API Function</a></li>
<li><a href="ch05.html#534-the-uxqueuemessageswaiting-api-function">5.3.4 The uxQueueMessagesWaiting() API Function</a></li>
</ul>
</li>
<li><a href="ch05.html#54-receiving-data-from-multiple-sources">5.4 Receiving Data From Multiple Sources</a></li>
<li><a href="ch05.html#55-working-with-large-or-variable-sized-data">5.5 Working with Large or Variable Sized Data</a>
<ul>
<li><a href="ch05.html#551-queuing-pointers">5.5.1 Queuing Pointers</a></li>
<li><a href="ch05.html#552-using-a-queue-to-send-different-types-and-lengths-of-data9">5.5.2 Using a Queue to Send Different Types and Lengths of Data[^9]</a></li>
</ul>
</li>
<li><a href="ch05.html#56-receiving-from-multiple-queues">5.6 Receiving From Multiple Queues</a>
<ul>
<li><a href="ch05.html#561-queue-sets">5.6.1 Queue Sets</a></li>
<li><a href="ch05.html#562-the-xqueuecreateset-api-function">5.6.2 The xQueueCreateSet() API Function</a></li>
<li><a href="ch05.html#563-the-xqueueaddtoset-api-function">5.6.3 The xQueueAddToSet() API Function</a></li>
<li><a href="ch05.html#564-the-xqueueselectfromset-api-function">5.6.4 The xQueueSelectFromSet() API Function</a></li>
<li><a href="ch05.html#565-more-realistic-queue-set-use-cases">5.6.5 More Realistic Queue Set Use Cases</a></li>
</ul>
</li>
<li><a href="ch05.html#57-using-a-queue-to-create-a-mailbox">5.7 Using a Queue to Create a Mailbox</a>
<ul>
<li><a href="ch05.html#571-the-xqueueoverwrite-api-function">5.7.1 The xQueueOverwrite() API Function</a></li>
<li><a href="ch05.html#572-the-xqueuepeek-api-function">5.7.2 The xQueuePeek() API Function</a></li>
</ul>
</li>
</ul>
<h2 id="6-software-timer-management"><a class="header" href="#6-software-timer-management"><a href="ch06.html#6-software-timer-management">6 Software Timer Management</a></a></h2>
<ul>
<li><a href="ch06.html#61-chapter-introduction-and-scope">6.1 Chapter Introduction and Scope</a>
<ul>
<li><a href="ch06.html#611-scope">6.1.1 Scope</a></li>
</ul>
</li>
<li><a href="ch06.html#62-software-timer-callback-functions">6.2 Software Timer Callback Functions</a></li>
<li><a href="ch06.html#63-attributes-and-states-of-a-software-timer">6.3 Attributes and States of a Software Timer</a>
<ul>
<li><a href="ch06.html#631-period-of-a-software-timer">6.3.1 Period of a Software Timer</a></li>
<li><a href="ch06.html#632-one-shot-and-auto-reload-timers">6.3.2 One-shot and Auto-reload Timers</a></li>
<li><a href="ch06.html#633-software-timer-states">6.3.3 Software Timer States</a></li>
</ul>
</li>
<li><a href="ch06.html#64-the-context-of-a-software-timer">6.4 The Context of a Software Timer</a>
<ul>
<li><a href="ch06.html#641-the-rtos-daemon-timer-service-task">6.4.1 The RTOS Daemon (Timer Service) Task</a></li>
<li><a href="ch06.html#642-the-timer-command-queue">6.4.2 The Timer Command Queue</a></li>
<li><a href="ch06.html#643-daemon-task-scheduling">6.4.3 Daemon Task Scheduling</a></li>
</ul>
</li>
<li><a href="ch06.html#65-creating-and-starting-a-software-timer">6.5 Creating and Starting a Software Timer</a>
<ul>
<li><a href="ch06.html#651-the-xtimercreate-api-function">6.5.1 The xTimerCreate() API Function</a></li>
<li><a href="ch06.html#652-the-xtimerstart-api-function">6.5.2 The xTimerStart() API Function</a></li>
</ul>
</li>
<li><a href="ch06.html#66-the-timer-id">6.6 The Timer ID</a>
<ul>
<li><a href="ch06.html#661-the-vtimersettimerid-api-function">6.6.1 The vTimerSetTimerID() API Function</a></li>
<li><a href="ch06.html#662-the-pvtimergettimerid-api-function">6.6.2 The pvTimerGetTimerID() API Function</a></li>
</ul>
</li>
<li><a href="ch06.html#67-changing-the-period-of-a-timer">6.7 Changing the Period of a Timer</a>
<ul>
<li><a href="ch06.html#671-the-xtimerchangeperiod-api-function">6.7.1 The xTimerChangePeriod() API Function</a></li>
</ul>
</li>
<li><a href="ch06.html#68-resetting-a-software-timer">6.8 Resetting a Software Timer</a>
<ul>
<li><a href="ch06.html#681-the-xtimerreset-api-function">6.8.1 The xTimerReset() API Function</a></li>
</ul>
</li>
</ul>
<h2 id="7-interrupt-management"><a class="header" href="#7-interrupt-management"><a href="ch07.html#7-interrupt-management">7 Interrupt Management</a></a></h2>
<ul>
<li><a href="ch07.html#71-introduction">7.1 Introduction</a>
<ul>
<li><a href="ch07.html#711-events">7.1.1 Events</a></li>
<li><a href="ch07.html#712-scope">7.1.2 Scope</a></li>
</ul>
</li>
<li><a href="ch07.html#72-using-the-freertos-api-from-an-isr">7.2 Using the FreeRTOS API from an ISR</a>
<ul>
<li><a href="ch07.html#721-the-interrupt-safe-api">7.2.1 The Interrupt Safe API</a></li>
<li><a href="ch07.html#722-the-benefits-of-using-a-separate-interrupt-safe-api">7.2.2 The Benefits of Using a Separate Interrupt Safe API</a></li>
<li><a href="ch07.html#723-the-disadvantages-of-using-a-separate-interrupt-safe-api">7.2.3 The Disadvantages of Using a Separate, Interrupt Safe API</a></li>
<li><a href="ch07.html#724-the-xhigherprioritytaskwoken-parameter">7.2.4 The xHigherPriorityTaskWoken Parameter</a></li>
<li><a href="ch07.html#725-the-portyield_from_isr-and-portend_switching_isr-macros">7.2.5 The portYIELD_FROM_ISR() and portEND_SWITCHING_ISR() Macros</a></li>
</ul>
</li>
<li><a href="ch07.html#73-deferred-interrupt-processing">7.3 Deferred Interrupt Processing</a></li>
<li><a href="ch07.html#74-binary-semaphores-used-for-synchronization">7.4 Binary Semaphores Used for Synchronization</a>
<ul>
<li><a href="ch07.html#741-the-xsemaphorecreatebinary-api-function">7.4.1 The xSemaphoreCreateBinary() API Function</a></li>
<li><a href="ch07.html#742-the-xsemaphoretake-api-function">7.4.2 The xSemaphoreTake() API Function</a></li>
<li><a href="ch07.html#743-the-xsemaphoregivefromisr-api-function">7.4.3 The xSemaphoreGiveFromISR() API Function</a></li>
<li><a href="ch07.html#744-improving-the-implementation-of-the-task-used-in-example-71">7.4.4 Improving the Implementation of the Task Used in Example 7.1</a></li>
</ul>
</li>
<li><a href="ch07.html#75-counting-semaphores">7.5 Counting Semaphores</a>
<ul>
<li><a href="ch07.html#751-the-xsemaphorecreatecounting-api-function">7.5.1 The xSemaphoreCreateCounting() API Function</a></li>
</ul>
</li>
<li><a href="ch07.html#76-deferring-work-to-the-rtos-daemon-task">7.6 Deferring Work to the RTOS Daemon Task</a>
<ul>
<li><a href="ch07.html#761-the-xtimerpendfunctioncallfromisr-api-function">7.6.1 The xTimerPendFunctionCallFromISR() API Function</a></li>
</ul>
</li>
<li><a href="ch07.html#77-using-queues-within-an-interrupt-service-routine">7.7 Using Queues within an Interrupt Service Routine</a>
<ul>
<li><a href="ch07.html#771-the-xqueuesendtofrontfromisr-and-xqueuesendtobackfromisr-api-functions">7.7.1 The xQueueSendToFrontFromISR() and xQueueSendToBackFromISR() API Functions</a></li>
<li><a href="ch07.html#772-considerations-when-using-a-queue-from-an-isr">7.7.2 Considerations When Using a Queue From an ISR</a></li>
</ul>
</li>
<li><a href="ch07.html#78-interrupt-nesting">7.8 Interrupt Nesting</a>
<ul>
<li><a href="ch07.html#781-a-note-to-arm-cortex-m22-and-arm-gic-users">7.8.1 A Note to ARM Cortex-M[^22] and ARM GIC Users</a></li>
</ul>
</li>
</ul>
<h2 id="8-resource-management"><a class="header" href="#8-resource-management"><a href="ch08.html#8-resource-management">8 Resource Management</a></a></h2>
<ul>
<li><a href="ch08.html#81-chapter-introduction-and-scope">8.1 Chapter Introduction and Scope</a>
<ul>
<li><a href="ch08.html#811-mutual-exclusion">8.1.1 Mutual Exclusion</a></li>
<li><a href="ch08.html#812-scope">8.1.2 Scope</a></li>
</ul>
</li>
<li><a href="ch08.html#82-critical-sections-and-suspending-the-scheduler">8.2 Critical Sections and Suspending the Scheduler</a>
<ul>
<li><a href="ch08.html#821-basic-critical-sections">8.2.1 Basic Critical Sections</a></li>
<li><a href="ch08.html#822-suspending-or-locking-the-scheduler">8.2.2 Suspending (or Locking) the Scheduler</a></li>
<li><a href="ch08.html#823-the-vtasksuspendall-api-function">8.2.3 The vTaskSuspendAll() API Function</a></li>
<li><a href="ch08.html#824-the-xtaskresumeall-api-function">8.2.4 The xTaskResumeAll() API Function</a></li>
</ul>
</li>
<li><a href="ch08.html#83-mutexes-and-binary-semaphores">8.3 Mutexes (and Binary Semaphores)</a>
<ul>
<li><a href="ch08.html#831-the-xsemaphorecreatemutex-api-function">8.3.1 The xSemaphoreCreateMutex() API Function</a></li>
<li><a href="ch08.html#832-priority-inversion">8.3.2 Priority Inversion</a></li>
<li><a href="ch08.html#833-priority-inheritance">8.3.3 Priority Inheritance</a></li>
<li><a href="ch08.html#834-deadlock-or-deadly-embrace">8.3.4 Deadlock (or Deadly Embrace)</a></li>
<li><a href="ch08.html#835-recursive-mutexes">8.3.5 Recursive Mutexes</a></li>
<li><a href="ch08.html#836-mutexes-and-task-scheduling">8.3.6 Mutexes and Task Scheduling</a></li>
</ul>
</li>
<li><a href="ch08.html#84-gatekeeper-tasks">8.4 Gatekeeper Tasks</a>
<ul>
<li><a href="ch08.html#841-re-writing-vprintstring-to-use-a-gatekeeper-task">8.4.1 Re-writing vPrintString() to use a gatekeeper task</a></li>
</ul>
</li>
</ul>
<h2 id="9-event-groups"><a class="header" href="#9-event-groups"><a href="ch09.html#9-event-groups">9 Event Groups</a></a></h2>
<ul>
<li><a href="ch09.html#91-chapter-introduction-and-scope">9.1 Chapter Introduction and Scope</a>
<ul>
<li><a href="ch09.html#911-scope">9.1.1 Scope</a></li>
</ul>
</li>
<li><a href="ch09.html#92-characteristics-of-an-event-group">9.2 Characteristics of an Event Group</a>
<ul>
<li><a href="ch09.html#921-event-groups-event-flags-and-event-bits">9.2.1 Event Groups, Event Flags and Event Bits</a></li>
<li><a href="ch09.html#922-more-about-the-eventbits_t-data-type">9.2.2 More About the EventBits_t Data Type</a></li>
<li><a href="ch09.html#923-access-by-multiple-tasks">9.2.3 Access by Multiple Tasks</a></li>
<li><a href="ch09.html#924-a-practical-example-of-using-an-event-group">9.2.4 A Practical Example of Using an Event Group</a></li>
</ul>
</li>
<li><a href="ch09.html#93-event-management-using-event-groups">9.3 Event Management Using Event Groups</a>
<ul>
<li><a href="ch09.html#931-the-xeventgroupcreate-api-function">9.3.1 The xEventGroupCreate() API Function</a></li>
<li><a href="ch09.html#932-the-xeventgroupsetbits-api-function">9.3.2 The xEventGroupSetBits() API Function</a></li>
<li><a href="ch09.html#933-the-xeventgroupsetbitsfromisr-api-function">9.3.3 The xEventGroupSetBitsFromISR() API Function</a></li>
<li><a href="ch09.html#934-the-xeventgroupwaitbits-api-function">9.3.4 The xEventGroupWaitBits() API Function</a></li>
<li><a href="ch09.html#935-the-xeventgroupgetstaticbuffer-api-function">9.3.5 The xEventGroupGetStaticBuffer() API Function</a></li>
</ul>
</li>
<li><a href="ch09.html#94-task-synchronization-using-an-event-group">9.4 Task Synchronization Using an Event Group</a>
<ul>
<li><a href="ch09.html#941-the-xeventgroupsync-api-function">9.4.1 The xEventGroupSync() API Function</a></li>
</ul>
</li>
</ul>
<h2 id="10-task-notifications"><a class="header" href="#10-task-notifications"><a href="ch10.html#10-task-notifications">10 Task Notifications</a></a></h2>
<ul>
<li><a href="ch10.html#101-introduction">10.1 Introduction</a>
<ul>
<li><a href="ch10.html#1011-communicating-through-intermediary-objects">10.1.1 Communicating Through Intermediary Objects</a></li>
<li><a href="ch10.html#1012-task-notificationsdirect-to-task-communication">10.1.2 Task Notifications—Direct to Task Communication</a></li>
<li><a href="ch10.html#1013-scope">10.1.3 Scope</a></li>
</ul>
</li>
<li><a href="ch10.html#102-task-notifications-benefits-and-limitations">10.2 Task Notifications; Benefits and Limitations</a>
<ul>
<li><a href="ch10.html#1021-performance-benefits-of-task-notifications">10.2.1 Performance Benefits of Task Notifications</a></li>
<li><a href="ch10.html#1022-ram-footprint-benefits-of-task-notifications">10.2.2 RAM Footprint Benefits of Task Notifications</a></li>
<li><a href="ch10.html#1023-limitations-of-task-notifications">10.2.3 Limitations of Task Notifications</a></li>
</ul>
</li>
<li><a href="ch10.html#103-using-task-notifications">10.3 Using Task Notifications</a>
<ul>
<li><a href="ch10.html#1031-task-notification-api-options">10.3.1 Task Notification API Options</a>
<ul>
<li><a href="ch10.html#10311-the-complete-list-of-api-functions-sup27sup">10.3.1.1 The complete list of API functions <sup>27</sup></a></li>
</ul>
</li>
<li><a href="ch10.html#1032-the-xtasknotifygive-api-functions">10.3.2 The xTaskNotifyGive() API Functions</a></li>
<li><a href="ch10.html#1033-the-vtasknotifygivefromisr-api-function">10.3.3 The vTaskNotifyGiveFromISR() API Function</a></li>
<li><a href="ch10.html#1034-the-ultasknotifytake-api-function">10.3.4 The ulTaskNotifyTake() API Function</a></li>
<li><a href="ch10.html#1035-the-xtasknotify-and-xtasknotifyfromisr-api-functions">10.3.5 The xTaskNotify() and xTaskNotifyFromISR() API Functions</a></li>
<li><a href="ch10.html#1036-the-xtasknotifywait-api-function">10.3.6 The xTaskNotifyWait() API Function</a></li>
<li><a href="ch10.html#1037-task-notifications-used-in-peripheral-device-drivers-uart-example">10.3.7 Task Notifications Used in Peripheral Device Drivers: UART Example</a></li>
<li><a href="ch10.html#1038-task-notifications-used-in-peripheral-device-drivers-adc-example">10.3.8 Task Notifications Used in Peripheral Device Drivers: ADC Example</a></li>
<li><a href="ch10.html#1039-task-notifications-used-directly-within-an-application">10.3.9 Task Notifications Used Directly Within an Application</a></li>
</ul>
</li>
</ul>
<h2 id="11-low-power-support"><a class="header" href="#11-low-power-support"><a href="ch11.html#11-low-power-support">11 Low Power Support</a></a></h2>
<ul>
<li><a href="ch11.html#111-power-saving-introduction">11.1 Power Saving Introduction</a></li>
<li><a href="ch11.html#112-freertos-sleep-modes">11.2 FreeRTOS Sleep Modes</a></li>
<li><a href="ch11.html#113-functions-and-enabling-built-in-tickless-idle-functionality">11.3 Functions and Enabling Built-in Tickless Idle Functionality</a>
<ul>
<li><a href="ch11.html#1131-the-portsuppress_ticks_and_sleep-macro">11.3.1 The portSUPPRESS_TICKS_AND_SLEEP() Macro</a></li>
<li><a href="ch11.html#1132-the-vportsuppressticksandsleep-function">11.3.2 The vPortSuppressTicksAndSleep Function</a></li>
<li><a href="ch11.html#1133-the-etaskconfirmsleepmodestatus-function">11.3.3 The eTaskConfirmSleepModeStatus Function</a></li>
<li><a href="ch11.html#1134-the-configpre_sleep_processing-configuration">11.3.4 The configPRE_SLEEP_PROCESSING configuration</a></li>
<li><a href="ch11.html#1135-the-configpost_sleep_processing-configuration">11.3.5 The configPOST_SLEEP_PROCESSING configuration</a></li>
</ul>
</li>
<li><a href="ch11.html#114-implementing-portsuppress_ticks_and_sleep-macro">11.4 Implementing portSUPPRESS_TICKS_AND_SLEEP() Macro</a></li>
<li><a href="ch11.html#115-idle-task-hook-function">11.5 Idle Task Hook Function</a></li>
</ul>
<h2 id="12-developer-support"><a class="header" href="#12-developer-support"><a href="ch12.html#12-developer-support">12 Developer Support</a></a></h2>
<ul>
<li><a href="ch12.html#121-introduction">12.1 Introduction </a></li>
<li><a href="ch12.html#122-configassert">12.2 configASSERT()</a>
<ul>
<li><a href="ch12.html#1221-example-configassert-definitions">12.2.1 Example configASSERT() definitions</a></li>
</ul>
</li>
<li><a href="ch12.html#123-tracealyzer-for-freertos">12.3 Tracealyzer for FreeRTOS</a></li>
<li><a href="ch12.html#124-debug-related-hook-callback-functions">12.4 Debug Related Hook (Callback) Functions</a>
<ul>
<li><a href="ch12.html#1241-malloc-failed-hook">12.4.1 Malloc failed hook</a></li>
</ul>
</li>
<li><a href="ch12.html#125-viewing-run-time-and-task-state-information">12.5 Viewing Run-time and Task State Information</a>
<ul>
<li><a href="ch12.html#1251-task-run-time-statistics">12.5.1 Task Run-Time Statistics</a></li>
<li><a href="ch12.html#1252-the-run-time-statistics-clock">12.5.2 The Run-Time Statistics Clock</a></li>
<li><a href="ch12.html#1253-configuring-an-application-to-collect-run-time-statistics">12.5.3 Configuring an Application to Collect Run-Time Statistics</a></li>
<li><a href="ch12.html#1254-the-uxtaskgetsystemstate-api-function">12.5.4 The uxTaskGetSystemState() API Function</a></li>
<li><a href="ch12.html#1255-the-vtasklisttasks-helper-function">12.5.5 The vTaskListTasks() Helper Function</a></li>
<li><a href="ch12.html#1256-the-vtaskgetruntimestatistics-helper-function">12.5.6 The vTaskGetRunTimeStatistics() Helper Function</a></li>
<li><a href="ch12.html#1257-generating-and-displaying-run-time-statistics-a-worked-example">12.5.7 Generating and Displaying Run-Time Statistics, a Worked Example</a></li>
</ul>
</li>
<li><a href="ch12.html#126-trace-hook-macros">12.6 Trace Hook Macros</a>
<ul>
<li><a href="ch12.html#1261-available-trace-hook-macros">12.6.1 Available Trace Hook Macros</a></li>
<li><a href="ch12.html#1262-defining-trace-hook-macros">12.6.2 Defining Trace Hook Macros</a></li>
<li><a href="ch12.html#1263-freertos-aware-debugger-plug-ins">12.6.3 FreeRTOS Aware Debugger Plug-ins</a></li>
</ul>
</li>
</ul>
<h2 id="13-troubleshooting"><a class="header" href="#13-troubleshooting"><a href="ch13.html#13-troubleshooting">13 Troubleshooting</a></a></h2>
<ul>
<li><a href="ch13.html#131-chapter-introduction-and-scope">13.1 Chapter Introduction and Scope</a></li>
<li><a href="ch13.html#132-interrupt-priorities">13.2 Interrupt Priorities</a></li>
<li><a href="ch13.html#133-stack-overflow">13.3 Stack Overflow</a>
<ul>
<li><a href="ch13.html#1331-the-uxtaskgetstackhighwatermark-api-function">13.3.1 The uxTaskGetStackHighWaterMark() API Function</a></li>
<li><a href="ch13.html#1332-run-time-stack-checkingoverview">13.3.2 Run Time Stack Checking—Overview</a></li>
<li><a href="ch13.html#1333-run-time-stack-checkingmethod-1">13.3.3 Run Time Stack Checking—Method 1</a></li>
<li><a href="ch13.html#1334-run-time-stack-checkingmethod-2">13.3.4 Run Time Stack Checking—Method 2</a></li>
<li><a href="ch13.html#1334-run-time-stack-checkingmethod-3">13.3.4 Run Time Stack Checking—Method 3</a></li>
</ul>
</li>
<li><a href="ch13.html#134-use-of-printf-and-sprintf">13.4 Use of printf() and sprintf()</a>
<ul>
<li><a href="ch13.html#1341-printf-stdargc">13.4.1 Printf-stdarg.c</a></li>
</ul>
</li>
<li><a href="ch13.html#135-other-common-sources-of-error">13.5 Other Common Sources of Error</a>
<ul>
<li><a href="ch13.html#1351-symptom-adding-a-simple-task-to-a-demo-causes-the-demo-to-crash">13.5.1 Symptom: Adding a simple task to a demo causes the demo to crash</a></li>
<li><a href="ch13.html#1352-symptom-using-an-api-function-within-an-interrupt-causes-the-application-to-crash">13.5.2 Symptom: Using an API function within an interrupt causes the application to crash</a></li>
<li><a href="ch13.html#1353-symptom-sometimes-the-application-crashes-within-an-interrupt-service-routine">13.5.3 Symptom: Sometimes the application crashes within an interrupt service routine</a></li>
<li><a href="ch13.html#1354-symptom-the-scheduler-crashes-when-attempting-to-start-the-first-task">13.5.4 Symptom: The scheduler crashes when attempting to start the first task</a></li>
<li><a href="ch13.html#1355-symptom-interrupts-are-unexpectedly-left-disabled-or-critical-sections-do-not-nest-correctly">13.5.5 Symptom: Interrupts are unexpectedly left disabled, or critical sections do not nest correctly</a></li>
<li><a href="ch13.html#1356-symptom-the-application-crashes-even-before-the-scheduler-is-started">13.5.6 Symptom: The application crashes even before the scheduler is started</a></li>
<li><a href="ch13.html#1357-symptom-calling-api-functions-while-the-scheduler-is-suspended-or-from-inside-a-critical-section-causes-the-application-to-crash">13.5.7 Symptom: Calling API functions while the scheduler is suspended, or from inside a critical section, causes the application to crash</a></li>
</ul>
</li>
<li><a href="ch13.html#136-additional-debugging-steps">13.6 Additional Debugging Steps</a></li>
</ul>
<h2 id="examples"><a class="header" href="#examples">Examples:</a></h2>
<ul>
<li><a href="ch04.html#example4.1">Example 4.1 Creating tasks</a></li>
<li><a href="ch04.html#example4.2">Example 4.2 Using the task parameter</a></li>
<li><a href="ch04.html#example4.3">Example 4.3 Experimenting with priorities</a></li>
<li><a href="ch04.html#example4.4">Example 4.4 Using the <em>Blocked</em> state to create a delay</a></li>
<li><a href="ch04.html#example4.5">Example 4.5 Converting the example tasks to use vTaskDelayUntil()</a></li>
<li><a href="ch04.html#example4.6">Example 4.6 Combining blocking and non-blocking tasks</a></li>
<li><a href="ch04.html#example4.7">Example 4.7 Defining an idle task hook function</a></li>
<li><a href="ch04.html#example4.8">Example 4.8 Deleting tasks</a></li>
<li><a href="ch05.html#example5.1">Example 5.1 Blocking when receiving from a queue</a></li>
<li><a href="ch05.html#example5.2">Example 5.2 Blocking when sending to a queue, and sending structures on a queue</a></li>
<li><a href="ch05.html#example5.3">Example 5.3 Using a Queue Set</a></li>
<li><a href="ch06.html#example6.1">Example 6.1 Creating one-shot and auto-reload timers</a></li>
<li><a href="ch06.html#example6.2">Example 6.2 Using the callback function parameter and the software timer ID</a></li>
<li><a href="ch06.html#example6.3">Example 6.3 Resetting a software timer</a></li>
<li><a href="ch07.html#example7.1">Example 7.1 Using a binary semaphore to synchronize a task with an interrupt</a></li>
<li><a href="ch07.html#example7.2">Example 7.2 Using a counting semaphore to synchronize a task with an interrupt</a></li>
<li><a href="ch07.html#example7.3">Example 7.3 Centralized deferred interrupt processing</a></li>
<li><a href="ch07.html#example7.4">Example 7.4 Sending and receiving on a queue from within an interrupt</a></li>
<li><a href="ch08.html#example8.1">Example 8.1 Rewriting vPrintString() to use a semaphore</a></li>
<li><a href="ch08.html#example8.2">Example 8.2 The alternative implementation for print task</a></li>
<li><a href="ch09.html#example9.1">Example 9.1 Experimenting with event groups</a></li>
<li><a href="ch09.html#example9.2">Example 9.2 Synchronizing tasks</a></li>
<li><a href="ch10.html#example10.1">Example 10.1 Using a task notification in place of a semaphore, method 1</a></li>
<li><a href="ch10.html#example10.2">Example 10.2 Using a task notification in place of a semaphore, method 2</a></li>
</ul>
<h2 id="figures"><a class="header" href="#figures">Figures:</a></h2>
<ul>
<li><a href="ch02.html#fig2.1">Figure 2.1 Top level directories within the FreeRTOS distribution</a></li>
<li><a href="ch02.html#fig2.2">Figure 2.2 Core FreeRTOS source files within the FreeRTOS directory tree</a></li>
<li><a href="ch02.html#fig2.3">Figure 2.3 Port specific source files within the FreeRTOS directory tree</a></li>
<li><a href="ch02.html#fig2.4">Figure 2.4 The demo directory hierarchy</a></li>
<li><a href="ch03.html#fig3.1">Figure 3.1 RAM being allocated from the heap_1 array each time a task is created</a></li>
<li><a href="ch03.html#fig3.2">Figure 3.2 RAM being allocated and freed from the heap_2 array as tasks are created and deleted</a></li>
<li><a href="ch03.html#fig3.3">Figure 3.3 RAM being allocated and freed from the heap_4 array</a></li>
<li><a href="ch03.html#fig3.4">Figure 3.4 Memory Map</a></li>
<li><a href="ch04.html#fig4.1">Figure 4.1 Top level task states and transitions</a></li>
<li><a href="ch04.html#fig4.2">Figure 4.2 The output produced when executing Example 4.1</a></li>
<li><a href="ch04.html#fig4.3">Figure 4.3 The actual execution pattern of the two Example 4.1 tasks</a></li>
<li><a href="ch04.html#fig4.4">Figure 4.4 The execution sequence expanded to show the tick interrupt executing</a></li>
<li><a href="ch04.html#fig4.5">Figure 4.5 Running both tasks at different priorities</a></li>
<li><a href="ch04.html#fig4.6">Figure 4.6 The execution pattern when one task has a higher priority than the...</a></li>
<li><a href="ch04.html#fig4.7">Figure 4.7 Full task state machine</a></li>
<li><a href="ch04.html#fig4.8">Figure 4.8 The output produced when Example 4.4 is executed</a></li>
<li><a href="ch04.html#fig4.9">Figure 4.9 The execution sequence when the tasks use vTaskDelay() in place of the null loop</a></li>
<li><a href="ch04.html#fig4.10">Figure 4.10 Bold lines indicate the state transitions performed by the tasks...</a></li>
<li><a href="ch04.html#fig4.11">Figure 4.11 The output produced when Example 4.6 is executed</a></li>
<li><a href="ch04.html#fig4.12">Figure 4.12 The execution pattern of Example 4.6</a></li>
<li><a href="ch04.html#fig4.13">Figure 4.13 The output produced when Example 4.7 is executed</a></li>
<li><a href="ch04.html#fig4.14">Figure 4.14 The sequence of task execution when running Example 4.8</a></li>
<li><a href="ch04.html#fig4.15">Figure 4.15 The output produced when Example 4.8 is executed</a></li>
<li><a href="ch04.html#fig4.16">Figure 4.16 The output produced when Example 4.9 is executed</a></li>
<li><a href="ch04.html#fig4.17">Figure 4.17 The execution sequence for Example 4.9</a></li>
<li><a href="ch04.html#fig4.18">Figure 4.18 Execution pattern highlighting task prioritization and preemption...</a></li>
<li><a href="ch04.html#fig4.19">Figure 4.19 Execution pattern highlighting task prioritization and time slicing...</a></li>
<li><a href="ch04.html#fig4.20">Figure 4.20 The execution pattern for the same scenario as shown in Figure 4.19...</a></li>
<li><a href="ch04.html#fig4.21">Figure 4.21 Execution pattern that demonstrates how tasks of equal priority can...</a></li>
<li><a href="ch04.html#fig4.22">Figure 4.22 Execution pattern demonstrating the behavior of the cooperative scheduler</a></li>
<li><a href="ch05.html#fig5.1">Figure 5.1 An example sequence of writes to, and reads from a queue</a></li>
<li><a href="ch05.html#fig5.2">Figure 5.2 The output produced when Example 5.1 is executed</a></li>
<li><a href="ch05.html#fig5.3">Figure 5.3 The sequence of execution produced by Example 5.1</a></li>
<li><a href="ch05.html#fig5.4">Figure 5.4 An example scenario where structures are sent on a queue</a></li>
<li><a href="ch05.html#fig5.5">Figure 5.5 The output produced by Example 5.2</a></li>
<li><a href="ch05.html#fig5.6">Figure 5.6 The sequence of execution produced by Example 5.2</a></li>
<li><a href="ch05.html#fig5.7">Figure 5.7 The output produced when Example 5.3 is executed</a></li>
<li><a href="ch06.html#fig6.1">Figure 6.1 The difference in behavior between one-shot and auto-reload software timers</a></li>
<li><a href="ch06.html#fig6.2">Figure 6.2 Auto-reload software timer states and transitions</a></li>
<li><a href="ch06.html#fig6.3">Figure 6.3 One-shot software timer states and transitions</a></li>
<li><a href="ch06.html#fig6.4">Figure 6.4 The timer command queue being used by a software timer API function to communicate with the RTOS daemon task</a></li>
<li><a href="ch06.html#fig6.5">Figure 6.5 The execution pattern when the priority of a task calling xTimerStart() is above the priority of the daemon task</a></li>
<li><a href="ch06.html#fig6.6">Figure 6.6 The execution pattern when the priority of a task calling xTimerStart() is below the priority of the daemon task</a></li>
<li><a href="ch06.html#fig6.7">Figure 6.7 The output produced when Example 6.1 is executed</a></li>
<li><a href="ch06.html#fig6.8">Figure 6.8 The output produced when Example 6.2 is executed</a></li>
<li><a href="ch06.html#fig6.9">Figure 6.9 Starting and resetting a software timer that has a period of 6 ticks</a></li>
<li><a href="ch06.html#fig6.10">Figure 6.10 The output produced when Example 6.3 is executed</a></li>
<li><a href="ch07.html#fig7.1">Figure 7.1 Completing interrupt processing in a high priority task</a></li>
<li><a href="ch07.html#fig7.2">Figure 7.2 Using a binary semaphore to implement deferred interrupt processing</a></li>
<li><a href="ch07.html#fig7.3">Figure 7.3 Using a binary semaphore to synchronize a task with an interrupt</a></li>
<li><a href="ch07.html#fig7.4">Figure 7.4 The output produced when Example 7.1 is executed</a></li>
<li><a href="ch07.html#fig7.5">Figure 7.5 The sequence of execution when Example 7.1 is executed</a></li>
<li><a href="ch07.html#fig7.6">Figure 7.6 The scenario when one interrupt occurs before the task has finished processing the first event</a></li>
<li><a href="ch07.html#fig7.7">Figure 7.7 The scenario when two interrupts occur before the task has finished processing the first event</a></li>
<li><a href="ch07.html#fig7.8">Figure 7.8 Using a counting semaphore to </a></li>
<li><a href="ch07.html#fig7.9">Figure 7.9 The output produced when Example 7.2 is executed</a></li>
<li><a href="ch07.html#fig7.10">Figure 7.10 The output produced when Example 7.3 is executed</a></li>
<li><a href="ch07.html#fig7.11">Figure 7.11 The sequence of execution when Example 7.3 is executed</a></li>
<li><a href="ch07.html#fig7.12">Figure 7.12 The output produced when Example 7.4 is executed</a></li>
<li><a href="ch07.html#fig7.13">Figure 7.13 The sequence of execution produced by Example 7.4</a></li>
<li><a href="ch07.html#fig7.14">Figure 7.14 Constants affecting interrupt nesting behavior</a></li>
<li><a href="ch07.html#fig7.15">Figure 7.15 How a priority of binary 101 is stored by a Cortex-M microcontroller that implements four priority bits</a></li>
<li><a href="ch08.html#fig8.1">Figure 8.1 Mutual exclusion implemented using a mutex</a></li>
<li><a href="ch08.html#fig8.2">Figure 8.2 The output produced when Example 8.1 is executed</a></li>
<li><a href="ch08.html#fig8.3">Figure 8.3 A possible sequence of execution for Example 8.1</a></li>
<li><a href="ch08.html#fig8.4">Figure 8.4 A worst case priority inversion scenario</a></li>
<li><a href="ch08.html#fig8.5">Figure 8.5 Priority inheritance minimizing the effect of priority inversion</a></li>
<li><a href="ch08.html#fig8.6">Figure 8.6 A possible sequence of execution when tasks that have the same priority use the same mutex</a></li>
<li><a href="ch08.html#fig8.7">Figure 8.7 A sequence of execution that could occur if two instances of the task shown by Listing 8.15 are created at the same priority</a></li>
<li><a href="ch08.html#fig8.8">Figure 8.8 The output produced when Example 8.2 is executed</a></li>
<li><a href="ch09.html#fig9.1">Figure 9.1 Event flag to bit number mapping in a variable of type EventBits_t</a></li>
<li><a href="ch09.html#fig9.2">Figure 9.2 An event group in which only bits 1, 4 and 7 are set, and all the other event flags are clear, making the event group</a></li>
<li><a href="ch09.html#fig9.3">Figure 9.3 The output produced when Example 9.1 is executed with xWaitForAllBits set to pdFALSE</a></li>
<li><a href="ch09.html#fig9.4">Figure 9.4 The output produced when Example 9.1 is executed with xWaitForAllBits set to pdTRUE</a></li>
<li><a href="ch09.html#fig9.5">Figure 9.5 The output produced when Example 9.2 is executed</a></li>
<li><a href="ch10.html#fig10.1">Figure 10.1 A communication object being used to send an event from one task to another</a></li>
<li><a href="ch10.html#fig10.2">Figure 10.2 A task notification used to send an event directly from one task to another</a></li>
<li><a href="ch10.html#fig10.3">Figure 10.3 The output produced when Example 7.1 is executed</a></li>
<li><a href="ch10.html#fig10.4">Figure 10.4 The sequence of execution when Example 10.1 is executed</a></li>
<li><a href="ch10.html#fig10.5">Figure 10.5 The output produced when Example 10.2 is executed</a></li>
<li><a href="ch10.html#fig10.6">Figure 10.6 The communication paths from the application tasks to the cloud server, and back again</a></li>
<li><a href="ch12.html#fig12.1">Figure 12.1 FreeRTOS-Trace includes more than 20 interconnected views</a></li>
<li><a href="ch12.html#fig12.2">Figure 12.2 FreeRTOS-Trace main trace view - one of more than 20 interconnected trace views</a></li>
<li><a href="ch12.html#fig12.3">Figure 12.3 FreeRTOS-Trace CPU load view - one of more than 20 interconnected trace views</a></li>
<li><a href="ch12.html#fig12.4">Figure 12.4 FreeRTOS-Trace response time view - one of more than 20 interconnected trace views</a></li>
<li><a href="ch12.html#fig12.5">Figure 12.5 FreeRTOS-Trace user event plot view - one of more than 20 interconnected trace views</a></li>
<li><a href="ch12.html#fig12.6">Figure 12.6 FreeRTOS-Trace kernel object history view - one of more than 20 interconnected trace views</a></li>
<li><a href="ch12.html#fig12.7">Figure 12.7 Example output generated by vTaskListTasks()</a></li>
<li><a href="ch12.html#fig12.8">Figure 12.8 Example output generated by vTaskGetRunTimeStatistics()</a></li>
</ul>
<h2 id="listings"><a class="header" href="#listings">Listings:</a></h2>
<ul>
<li><a href="ch02.html#list2.1">Listing 2.1 The template for a new main() function</a></li>
<li><a href="ch03.html#list3.1">Listing 3.1 The vPortDefineHeapRegions() API function prototype</a></li>
<li><a href="ch03.html#list3.2">Listing 3.2 The HeapRegion_t structure</a></li>
<li><a href="ch03.html#list3.3">Listing 3.3 An array of HeapRegion_t structures that together describe the 3 regions of RAM in their entirety</a></li>
<li><a href="ch03.html#list3.4">Listing 3.4 An array of HeapRegion_t structures that describe all of RAM2, all of RAM3, but only part of RAM1</a></li>
<li><a href="ch03.html#list3.5">Listing 3.5 Using GCC syntax to declare the array that will be used by heap_4, and place the array in a memory section named .my_heap</a></li>
<li><a href="ch03.html#list3.6">Listing 3.6 Using IAR syntax to declare the array that will be used by heap_4, and place the array at the absolute address 0x20000000</a></li>
<li><a href="ch03.html#list3.7">Listing 3.7 The xPortGetFreeHeapSize() API function prototype</a></li>
<li><a href="ch03.html#list3.8">Listing 3.8 The xPortGetMinimumEverFreeHeapSize() API function prototype</a></li>
<li><a href="ch03.html#list3.9">Listing 3.9 The vPortGetHeapStatus() API function prototype</a></li>
<li><a href="ch03.html#list3.10">Listing 3.10 The HeapStatus_t() structure</a></li>
<li><a href="ch03.html#list3.11">Listing 3.11 The malloc failed hook function name and prototype</a></li>
<li><a href="ch03.html#list3.12">Listing 3.12 Mapping the pvPortMallocStack() and vPortFreeStack() macros to an application defined memory allcator</a></li>
<li><a href="ch03.html#list3.13">Listing 3.13 Typical implementation of vApplicationGetTimerTaskMemory</a></li>
<li><a href="ch03.html#list3.14">Listing 3.14 Typical implementation of vApplicationGetIdleTaskMemory</a></li>
<li><a href="ch04.html#list4.1">Listing 4.1 The task function prototype</a></li>
<li><a href="ch04.html#list4.2">Listing 4.2 The structure of a typical task function</a></li>
<li><a href="ch04.html#list4.3">Listing 4.3 The xTaskCreate() API function prototype</a></li>
<li><a href="ch04.html#list4.4">Listing 4.4 Implementation of the first task used in Example 4.1</a></li>
<li><a href="ch04.html#list4.5">Listing 4.5 Implementation of the second task used in Example 4.1</a></li>
<li><a href="ch04.html#list4.6">Listing 4.6 Starting the Example 4.1 tasks</a></li>
<li><a href="ch04.html#list4.7">Listing 4.7 Creating a task from within another task after the scheduler has started</a></li>
<li><a href="ch04.html#list4.8">Listing 4.8 The single task function used to create two tasks in Example 4.2</a></li>
<li><a href="ch04.html#list4.9">Listing 4.9 The main() function for Example 2</a></li>
<li><a href="ch04.html#list4.10">Listing 4.10 Using the pdMS_TO_TICKS() macro to convert 200 milliseconds...</a></li>
<li><a href="ch04.html#list4.11">Listing 4.11. Creating two tasks at different priorities</a></li>
<li><a href="ch04.html#list4.12">Listing 4.12 The vTaskDelay() API function prototype</a></li>
<li><a href="ch04.html#list4.13">Listing 4.13 The source code for the example task after replacing the null loop delay with a call...</a></li>
<li><a href="ch04.html#list4.14">Listing 4.14 vTaskDelayUntil() API function prototype</a></li>
<li><a href="ch04.html#list4.15">Listing 4.15 The implementation of the example task using vTaskDelayUntil()</a></li>
<li><a href="ch04.html#list4.16">Listing 4.16 The continuous processing task used in Example 4.6</a></li>
<li><a href="ch04.html#list4.17">Listing 4.17 The periodic task used in Example 4.6</a></li>
<li><a href="ch04.html#list4.18">Listing 4.18 The idle task hook function name and prototype</a></li>
<li><a href="ch04.html#list4.19">Listing 4.19 A very simple Idle hook function</a></li>
<li><a href="ch04.html#list4.20">Listing 4.20 The source code for the example task now prints out the ulIdleCycleCount value</a></li>
<li><a href="ch04.html#list4.21">Listing 4.21 The vTaskPrioritySet() API function prototype</a></li>
<li><a href="ch04.html#list4.22">Listing 4.22 The uxTaskPriorityGet() API function prototype</a></li>
<li><a href="ch04.html#list4.23">Listing 4.23 The implementation of Task 1 in Example 4.8</a></li>
<li><a href="ch04.html#list4.24">Listing 4.24 The implementation of Task 2 in Example 4.8</a></li>
<li><a href="ch04.html#list4.25">Listing 4.25 The implementation of main() for Example 4.8</a></li>
<li><a href="ch04.html#list4.26">Listing 4.26 The vTaskDelete() API function prototype</a></li>
<li><a href="ch04.html#list4.27">Listing 4.27 The implementation of main() for Example 4.9</a></li>
<li><a href="ch04.html#list4.28">Listing 4.28 The implementation of Task 1 for Example 4.9</a></li>
<li><a href="ch04.html#list4.29">Listing 4.29 The implementation of Task 2 for Example 4.9</a></li>
<li><a href="ch04.html#list4.30">Listing 4.30 Function prototypes of the Thread Local Storage Pointer API functions</a></li>
<li><a href="ch05.html#list5.1">Listing 5.1 The xQueueCreate() API function prototype</a></li>
<li><a href="ch05.html#list5.2">Listing 5.2 The xQueueSendToFront() API function prototype</a></li>
<li><a href="ch05.html#list5.3">Listing 5.3 The xQueueSendToBack() API function prototype</a></li>
<li><a href="ch05.html#list5.4">Listing 5.4 The xQueueReceive() API function prototype</a></li>
<li><a href="ch05.html#list5.5">Listing 5.5 The uxQueueMessagesWaiting() API function prototype</a></li>
<li><a href="ch05.html#list5.6">Listing 5.6 Implementation of the sending task used in Example 5.1</a></li>
<li><a href="ch05.html#list5.7">Listing 5.7  Implementation of the receiver task for Example 5.1</a></li>
<li><a href="ch05.html#list5.8">Listing 5.8 The implementation of main() in Example 5.1</a></li>
<li><a href="ch05.html#list5.9">Listing 5.9 The definition of the structure that is to be passed on a queue, plus the declaration of two variables for use by the example</a></li>
<li><a href="ch05.html#list5.10">Listing 5.10 The implementation of the sending task for Example 5.2</a></li>
<li><a href="ch05.html#list5.11">Listing 5.11 The definition of the receiving task for Example 5.2</a></li>
<li><a href="ch05.html#list5.12">Listing 5.12 The implementation of main() for Example 5.2</a></li>
<li><a href="ch05.html#list5.13">Listing 5.13 Creating a queue that holds pointers</a></li>
<li><a href="ch05.html#list5.14">Listing 5.14 Using a queue to send a pointer to a buffer</a></li>
<li><a href="ch05.html#list5.15">Listing 5.15 Using a queue to receive a pointer to a buffer</a></li>
<li><a href="ch05.html#list5.16">Listing 5.16 The structure used to send events to the TCP/IP stack task in FreeRTOS-TCP</a></li>
<li><a href="ch05.html#list5.17">Listing 5.17 Pseudo code showing how an IPStackEvent_t structure is used to send data received from the network to the TCP/IP task</a></li>
<li><a href="ch05.html#list5.18">Listing 5.18 Pseudo code showing how an IPStackEvent_t structure is used to send the handle of a socket that is accepting a connection to the TCP/IP task</a></li>
<li><a href="ch05.html#list5.19">Listing 5.19 Pseudo code showing how an IPStackEvent_t structure is used to send a network down event to the TCP/IP task</a></li>
<li><a href="ch05.html#list5.20">Listing 5.20 Pseudo code showing how an IPStackEvent_t structure is received and processed</a></li>
<li><a href="ch05.html#list5.21">Listing 5.21 The xQueueCreateSet() API function prototype</a></li>
<li><a href="ch05.html#list5.22">Listing 5.22 The xQueueAddToSet() API function prototype</a></li>
<li><a href="ch05.html#list5.23">Listing 5.23 The xQueueSelectFromSet() API function prototype</a></li>
<li><a href="ch05.html#list5.24">Listing 5.24  Implementation of main() for Example 5.3</a></li>
<li><a href="ch05.html#list5.25">Listing 5.25 The sending tasks used in Example 5.3</a></li>
<li><a href="ch05.html#list5.26">Listing 5.26 The receive task used in Example 5.3</a></li>
<li><a href="ch05.html#list5.27">Listing 5.27 Using a queue set that contains queues and semaphores</a></li>
<li><a href="ch05.html#list5.28">Listing 5.28 A queue being created for use as a mailbox</a></li>
<li><a href="ch05.html#list5.29">Listing 5.29 The xQueueOverwrite() API function prototype</a></li>
<li><a href="ch05.html#list5.30">Listing 5.30 Using the xQueueOverwrite() API function</a></li>
<li><a href="ch05.html#list5.31">Listing 5.31 The xQueuePeek() API function prototype</a></li>
<li><a href="ch05.html#list5.32">Listing 5.32 Using the xQueuePeek() API function</a></li>
<li><a href="ch06.html#list">Listing 6.1 The software timer callback function prototype</a></li>
<li><a href="ch06.html#list6.2">Listing 6.2 The xTimerDelete() API function prototype</a></li>
<li><a href="ch06.html#list6.3">Listing 6.3 The xTimerCreate() API function prototype</a></li>
<li><a href="ch06.html#list6.4">Listing 6.4 The xTimerStart() API function prototype</a></li>
<li><a href="ch06.html#list6.5">Listing 6.5 Creating and starting the timers used in Example 6.1</a></li>
<li><a href="ch06.html#list6.5">Listing 6.6 The callback function used by the one-shot timer in Example 6.1</a></li>
<li><a href="ch06.html#list6.7">Listing 6.7 The callback function used by the auto-reload timer in Example 6.1</a></li>
<li><a href="ch06.html#list6.8">Listing 6.8 The vTimerSetTimerID() API function prototype</a></li>
<li><a href="ch06.html#list6.9">Listing 6.9 The pvTimerGetTimerID() API function prototype</a></li>
<li><a href="ch06.html#list6.10">Listing 6.10 Creating the timers used in Example 6.2</a></li>
<li><a href="ch06.html#list6.11">Listing 6.11 The timer callback function used in Example 6.2</a></li>
<li><a href="ch06.html#list6.12">Listing 6.12 The xTimerChangePeriod() API function prototype</a></li>
<li><a href="ch06.html#list6.13">Listing 6.13 Using xTimerChangePeriod()</a></li>
<li><a href="ch06.html#list6.14">Listing 6.14 The xTimerReset() API function prototype</a></li>
<li><a href="ch06.html#list6.15">Listing 6.15 The callback function for the one-shot timer used in Example 6.3</a></li>
<li><a href="ch06.html#list6.16">Listing 6.16 The task used to reset the software timer in Example 6.3</a></li>
<li><a href="ch07.html#list7.1">Listing 7.1 The portEND_SWITCHING_ISR() macros</a></li>
<li><a href="ch07.html#list7.2">Listing 7.2 The portYIELD_FROM_ISR() macros</a></li>
<li><a href="ch07.html#list7.3">Listing 7.3 The xSemaphoreCreateBinary() API function prototype</a></li>
<li><a href="ch07.html#list7.4">Listing 7.4 The xSemaphoreTake() API function prototype</a></li>
<li><a href="ch07.html#list">Listing 7.5 The xSemaphoreGiveFromISR() API function prototype</a></li>
<li><a href="ch07.html#list7.6">Listing 7.6 Implementation of the task that periodically generates a software interrupt in Example 7.1</a></li>
<li><a href="ch07.html#list7.7.">Listing 7.7 The implementation of the task to which the interrupt processing is deferred (the task that...</a></li>
<li><a href="ch07.html#list7.8">Listing 7.8 The ISR for the software interrupt used in Example 7.1</a></li>
<li><a href="ch07.html#list7.9">Listing 7.9 The implementation of main() for Example 7.1</a></li>
<li><a href="ch07.html#list7.10">Listing 7.10 The recommended structure of a deferred interrupt processing task, using a UART receive...</a></li>
<li><a href="ch07.html#list7.11">Listing 7.11 The xSemaphoreCreateCounting() API function prototype</a></li>
<li><a href="ch07.html#list7.12">Listing 7.12 The call to xSemaphoreCreateCounting() used to create the counting semaphore in Example 7.2</a></li>
<li><a href="ch07.html#list7.13">Listing 7.13 The implementation of the interrupt service routine used by Example 7.2</a></li>
<li><a href="ch07.html#list7.14">Listing 7.14 The xTimerPendFunctionCallFromISR() API function prototype</a></li>
<li><a href="ch07.html#list7.15">Listing 7.15 The prototype to which a function passed in the xFunctionToPend parameter of xTimerPendFunctionCallFromISR()...</a></li>
<li><a href="ch07.html#list7.16">Listing 7.16 The software interrupt handler used in Example 7.3</a></li>
<li><a href="ch07.html#list7.17">Listing 7.17 The function that performs the processing necessitated by the interrupt in Example 7.3</a></li>
<li><a href="ch07.html#list7.18">Listing 7.18 The implementation of main() for Example 7.3</a></li>
<li><a href="ch07.html#list7.19">Listing 7.19 The xQueueSendToFrontFromISR() API function prototype</a></li>
<li><a href="ch07.html#list7.20">Listing 7.20 The xQueueSendToBackFromISR() API function prototype</a></li>
<li><a href="ch07.html#list7.21">Listing 7.21 The implementation of the task that writes to the queue in Example 7.4</a></li>
<li><a href="ch07.html#list7.22">Listing 7.22 The implementation of the interrupt service routine used by Example 7.4</a></li>
<li><a href="ch07.html#list7.23">Listing 7.23 The task that prints out the strings received from the interrupt service routine in Example 7.4</a></li>
<li><a href="ch07.html#list7.24">Listing 7.24 The main() function for Example 7.4</a></li>
<li><a href="ch08.html#list8.1">Listing 8.1 An example read, modify, write sequence</a></li>
<li><a href="ch08.html#list8.2">Listing 8.2 An example of a reentrant function</a></li>
<li><a href="ch08.html#list8.3">Listing 8.3 An example of a function that is not reentrant</a></li>
<li><a href="ch08.html#list8.4">Listing 8.4 Using a critical section to guard access to a register</a></li>
<li><a href="ch08.html#list8.5">Listing 8.5 A possible implementation of vPrintString()</a></li>
<li><a href="ch08.html#list8.6">Listing 8.6 Using a critical section in an interrupt service routine</a></li>
<li><a href="ch08.html#list8.7">Listing 8.7 The vTaskSuspendAll() API function prototype</a></li>
<li><a href="ch08.html#list8.8">Listing 8.8 The xTaskResumeAll() API function prototype</a></li>
<li><a href="ch08.html#list8.9">Listing 8.9 The implementation of vPrintString()</a></li>
<li><a href="ch08.html#list8.10">Listing 8.10 The xSemaphoreCreateMutex() API function prototype</a></li>
<li><a href="ch08.html#list8.11">Listing 8.11 The implementation of prvNewPrintString()</a></li>
<li><a href="ch08.html#list8.12">Listing 8.12 The implementation of prvPrintTask() for Example 8.1</a></li>
<li><a href="ch08.html#list8.13">Listing 8.13 The implementation of main() for Example 8.1</a></li>
<li><a href="ch08.html#list8.14">Listing 8.14 Creating and using a recursive mutex</a></li>
<li><a href="ch08.html#list8.15">Listing 8.15 A task that uses a mutex in a tight loop</a></li>
<li><a href="ch08.html#list8.16">Listing 8.16 Ensuring tasks that use a mutex in a loop receive a more equal amount of processing time...</a></li>
<li><a href="ch08.html#list8.17">Listing 8.17 The name and prototype for a tick hook function</a></li>
<li><a href="ch08.html#list8.18">Listing 8.18 The gatekeeper task</a></li>
<li><a href="ch08.html#list8.19">Listing 8.19 The print task implementation for Example 8.2</a></li>
<li><a href="ch08.html#list8.20">Listing 8.20 The tick hook implementation</a></li>
<li><a href="ch08.html#list8.21">Listing 8.21 The implementation of main() for Example 8.2</a></li>
<li><a href="ch09.html#list9.1">Listing 9.1 The xEventGroupCreate() API function prototype</a></li>
<li><a href="ch09.html#list9.2">Listing 9.2. The xEventGroupSetBits() API function prototype</a></li>
<li><a href="ch09.html#list9.3">Listing 9.3 The xEventGroupSetBitsFromISR() API function prototype</a></li>
<li><a href="ch09.html#list9.4">Listing 9.4 The xEventGroupWaitBits() API function prototype</a></li>
<li><a href="ch09.html#list9.5">Listing 9.5 The xEventGroupGetStaticBuffer() API function prototype</a></li>
<li><a href="ch09.html#list9.6">Listing 9.6 Event bit definitions used in Example 9.1</a></li>
<li><a href="ch09.html#list9.7">Listing 9.7 The task that sets two bits in the event group in Example 9.1</a></li>
<li><a href="ch09.html#list9.8">Listing 9.8 The ISR that sets bit 2 in the event group in Example 9.1</a></li>
<li><a href="ch09.html#list9.9">Listing 9.9 The task that blocks to wait for event bits to become set in Example 9.1</a></li>
<li><a href="ch09.html#list9.10">Listing 9.10 Creating the event group and tasks in Example 9.1</a></li>
<li><a href="ch09.html#list9.11">Listing 9.11 Pseudo code for two tasks that synchronize with each other to ensure a shared TCP socket...</a></li>
<li><a href="ch09.html#list9.12">Listing 9.12 The xEventGroupSync() API function prototype</a></li>
<li><a href="ch09.html#list9.13">Listing 9.13 The implementation of the task used in Example 9.2</a></li>
<li><a href="ch09.html#list9.14">Listing 9.14 The main() function used in Example 9.2</a></li>
<li><a href="ch10.html#list10.1">Listing 10.1 The xTaskNotifyGive() API function prototype</a></li>
<li><a href="ch10.html#list10.2">Listing 10.2 The vTaskNotifyGiveFromISR() API function prototype</a></li>
<li><a href="ch10.html#list10.3">Listing 10.3 The ulTaskNotifyTake() API function prototype</a></li>
<li><a href="ch10.html#list10.4">Listing 10.4 The implementation of the task to which the interrupt processing is deferred (the task that...</a></li>
<li><a href="ch10.html#list10.5">Listing 10.5 The implementation of the interrupt service routine used in Example 10.1</a></li>
<li><a href="ch10.html#list10.6">Listing 10.6 The implementation of the task to which the interrupt processing is deferred (the task...</a></li>
<li><a href="ch10.html#list10.7">Listing 10.7 The implementation of the interrupt service routine used in Example 10.2</a></li>
<li><a href="ch10.html#list10.8">Listing 10.8 Prototypes for the xTaskNotify() and xTaskNotifyFromISR() API functions</a></li>
<li><a href="ch10.html#list10.9">Listing 10.9 The xTaskNotifyWait() API function prototype</a></li>
<li><a href="ch10.html#list10.10">Listing 10.10 Pseudo code demonstrating how a binary semaphore can be used in a driver library transmit...</a></li>
<li><a href="ch10.html#list10.11">Listing 10.11 Pseudo code demonstrating how a task notification can be used in a driver library transmit...</a></li>
<li><a href="ch10.html#list10.12">Listing 10.12 Pseudo code demonstrating how a task notification can be used in a driver library receive...</a></li>
<li><a href="ch10.html#list10.13">Listing 10.13 Pseudo code demonstrating how a task notification can be used to pass a value to a task</a></li>
<li><a href="ch10.html#list10.14">Listing 10.14 The structure and data type sent on a queue to the server task</a></li>
<li><a href="ch10.html#list10.15">Listing 10.15 The Implementation of the Cloud Read API Function</a></li>
<li><a href="ch10.html#list10.16">Listing 10.16 The Server Task Processing a Read Request</a></li>
<li><a href="ch10.html#list10.17">Listing 10.17 The Implementation of the Cloud Write API Function</a></li>
<li><a href="ch10.html#list10.18">Listing 10.18 The Server Task Processing a Send Request</a></li>
<li><a href="ch11.html#list11.1">Listing 11.1 The prototype for the portSUPPRESS_TICKS_AND_SLEEP macro</a></li>
<li><a href="ch11.html#list11.2">Listing 11.2 The vPortSuppressTicksAndSleep API function prototype</a></li>
<li><a href="ch11.html#list11.3">Listing 11.3 The eTaskConfirmSleepModeStatus API function prototype</a></li>
<li><a href="ch11.html#list11.4">Listing 11.4 The prototype for the configPRE_SLEEP_PROCESSING macro</a></li>
<li><a href="ch11.html#list11.5">Listing 11.5 The prototype for the configPOST_SLEEP_PROCESSING macro</a></li>
<li><a href="ch11.html#list11.6">Listing 11.6 An example of a user defined implementation of portSUPPRESS_TICKS_AND_SLEEP()</a></li>
<li><a href="ch11.html#list11.7">Listing 11.7 The vApplicationIdleHook API function prototype</a></li>
<li><a href="ch12.html#list12.1">Listing 12.1 Using the standard C assert() macro to check pxMyPointer is not NULL</a></li>
<li><a href="ch12.html#list12.2">Listing 12.2 A simple configASSERT() definition useful when executing under the control of a debugger</a></li>
<li><a href="ch12.html#list12.3">Listing 12.3 A configASSERT() definition that records the source code line that failed an assertion</a></li>
<li><a href="ch12.html#list12.4">Listing 12.4 The uxTaskGetSystemState() API function prototype</a></li>
<li><a href="ch12.html#list12.5">Listing 12.5 The TaskStatus_t structure</a></li>
<li><a href="ch12.html#list12.6">Listing 12.6 The vTaskListTasks() API function prototype</a></li>
<li><a href="ch12.html#list12.7">Listing 12.7 The vTaskList() API function prototype</a></li>
<li><a href="ch12.html#list12.8">Listing 12.8 The vTaskGetRunTimeStatistics() API function prototype</a></li>
<li><a href="ch12.html#list12.9">Listing 12.9 The vTaskGetRunTimeStats() API function prototype</a></li>
<li><a href="ch12.html#list12.10">Listing 12.10 16-bit timer overflow interrupt handler used to count timer overflows</a></li>
<li><a href="ch12.html#list12.11">Listing 12.11 Macros added to FreeRTOSConfig.h to enable the collection of run-time statistics</a></li>
<li><a href="ch12.html#list12.12">Listing 12.12 The task that prints out the collected run-time statistics</a></li>
<li><a href="ch13.html#list13.1">Listing 13.1 The uxTaskGetStackHighWaterMark() API function prototype</a></li>
<li><a href="ch13.html#list13.2">Listing 13.2 The uxTaskGetStackHighWaterMark2() API function prototype</a></li>
<li><a href="ch13.html#list13.3">Listing 13.3 The stack overflow hook function prototype</a></li>
</ul>
<h2 id="tables"><a class="header" href="#tables">Tables:</a></h2>
<ul>
<li><a href="ch02.html#tbl1">Table 1 FreeRTOS source files to include in the project</a></li>
<li><a href="ch02.html#tbl2">Table 2 TickType_t data type and the configTICK_TYPE_WIDTH_IN_BITS configuration</a></li>
<li><a href="ch02.html#tbl3">Table 3 Macro prefixes</a></li>
<li><a href="ch02.html#tbl4">Table 4 Common macro definitions</a></li>
<li><a href="ch04.html#tbl5">Table 5 The FreeRTOSConfig.h settings to configure the kernel scheduling algorithms</a></li>
<li><a href="ch09.html#tbl6">Table 6 The Effect of the uxBitsToWaitFor and xWaitForAllBits Parameters</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="2-the-freertos-kernel-distribution-1"><a class="header" href="#2-the-freertos-kernel-distribution-1">2 The FreeRTOS Kernel Distribution</a></h1>
<h2 id="21-introduction"><a class="header" href="#21-introduction">2.1 Introduction</a></h2>
<p>To help users orientate themselves with the FreeRTOS kernel
files and directories, this chapter:</p>
<ul>
<li>Provides a top-level view of the FreeRTOS directory structure.</li>
<li>Describes the source files required by any particular FreeRTOS project.</li>
<li>Introduces the demo applications.</li>
<li>Provides information on how to create a new FreeRTOS project.</li>
</ul>
<p>The description here relates only to the official FreeRTOS distribution.
The examples that come with this book use a slightly different
organization.</p>
<h2 id="22-understanding-the-freertos-distribution"><a class="header" href="#22-understanding-the-freertos-distribution">2.2 Understanding the FreeRTOS Distribution</a></h2>
<h3 id="221-definition-freertos-port"><a class="header" href="#221-definition-freertos-port">2.2.1 Definition: FreeRTOS Port</a></h3>
<p>FreeRTOS can be built with approximately twenty different compilers and can
run on more than forty different processor architectures. Each supported
combination of compiler and processor is called a FreeRTOS port.</p>
<h3 id="222-building-freertos"><a class="header" href="#222-building-freertos">2.2.2 Building FreeRTOS</a></h3>
<p>FreeRTOS is a library that provides multi-tasking capabilities to what
would otherwise be a single-threaded, bare-metal application.</p>
<p>FreeRTOS is supplied as a set of C source files. Some source files are
common to all ports, while others are specific to a port. Building the
source files as part of your project makes the FreeRTOS API available to
your application. A demo application that can be used as a reference is
provided for each official FreeRTOS port. The demo application is
pre-configured to build the correct source files and include the correct
header files.</p>
<p>At the time of its creation, each demo application built 'out of the
box' with no compiler errors or warnings. Please use the FreeRTOS
support forums (<a href="https://forums.FreeRTOS.org">https://forums.FreeRTOS.org</a>) to let us know if
subsequent changes to the build tools mean that this is no longer the case.
Section 2.3 describes the demo applications.</p>
<h3 id="223-freertosconfigh"><a class="header" href="#223-freertosconfigh">2.2.3 FreeRTOSConfig.h</a></h3>
<p>Constants defined in a header file called FreeRTOSConfig.h configure the
kernel. Do not include FreeRTOSConfig.h directly in your source files!
Instead, include FreeRTOS.h, which will include FreeRTOSConfig.h at the
appropriate time.</p>
<p>FreeRTOSConfig.h is used to tailor the FreeRTOS kernel for use in a
specific application. For example, FreeRTOSConfig.h contains constants
such as <code>configUSE_PREEMPTION</code> which defines whether
FreeRTOS uses co-operative or pre-emptive scheduling<sup class="footnote-reference"><a href="#1">1</a></sup>.</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>Section 4.13 describes scheduling algorithms.</p>
</div>
<p>FreeRTOSConfig.h tailors FreeRTOS for a specific application, so it
should be located in a directory that is part of the application, not in
a directory that contains the FreeRTOS source code.</p>
<p>The main FreeRTOS distribution contains a demo application for every
FreeRTOS port, and every demo application has its own FreeRTOSConfig.h
file. It is recommended to start with, then adapt, the FreeRTOSConfig.h
used by the demo application provided for the FreeRTOS port you use
rather than create the file from scratch.</p>
<p>The FreeRTOS reference manual and <a href="https://www.freertos.org/a00110.html">https://www.freertos.org/a00110.html</a>
describe the constants that appear in FreeRTOSConfig.h. It is
not necessary to include all the constants in FreeRTOSConfig.h—many get a
default value if omitted.</p>
<h3 id="224-official-distributions"><a class="header" href="#224-official-distributions">2.2.4 Official Distributions</a></h3>
<p>Individual FreeRTOS libraries, including the kernel, are available from
their own Github repository and as a zip file archive. The ability to
obtain individual libraries is convenient when using FreeRTOS in
production code. However, it is better to download the main FreeRTOS
distribution to get started as that contains both libraries and example
projects.</p>
<p>The main distribution contains source code for all the FreeRTOS
libraries, all the FreeRTOS kernel ports, and project files for all the
FreeRTOS demo applications. Do not be put off by the number of files!
Applications only require a small subset.</p>
<p>Use <a href="https://github.com/FreeRTOS/FreeRTOS/releases/latest">https://github.com/FreeRTOS/FreeRTOS/releases/latest</a> to download a
zip file containing the latest distribution. Alternatively, use one of
the following Git commands to clone the main distribution from GitHub,
including individual libraries sub-moduled from their respective Git
repositories:</p>
<hr />
<pre><code>git clone https://github.com/FreeRTOS/FreeRTOS.git --recurse-submodules

git clone git@github.com:FreeRTOS/FreeRTOS.git --recurse-submodules
</code></pre>
<hr />
<p>Figure 2.1 shows the first and second-level directories of the FreeRTOS
distribution:</p>
<p><a name="fig2.1" title="Figure 2.1 Top level directories within the FreeRTOS distribution"></a></p>
<hr />
<pre><code>FreeRTOS
│ │
│ ├─Source  Contains the FreeRTOS kernel source files
│ │
│ └─Demo    Contains pre-configured and port specific FreeRTOS kernel demo projects
│
FreeRTOS-Plus
│
├─Source    Contains source code for other FreeRTOS and ecosystem libraries
│
└─Demo      Contains demo projects for other FreeRTOS and ecosystem libraries
</code></pre>
<p><em><strong>Figure 2.1</strong></em> <em>Top level directories within the FreeRTOS distribution</em></p>
<hr />
<p>The distribution only contains one copy of the FreeRTOS kernel source
files; all the demo projects expect to find the kernel source files in
the FreeRTOS/Source directory, and may not build if the directory
structure is changed.</p>
<h3 id="225-freertos-source-files-common-to-all-ports"><a class="header" href="#225-freertos-source-files-common-to-all-ports">2.2.5 FreeRTOS Source Files Common to All Ports</a></h3>
<p>tasks.c and list.c implement the core FreeRTOS kernel functionality and
are always required. They are located directly in the FreeRTOS/Source
directory, as shown in Figure 2.2. The same directory also contains the
following optional source files:</p>
<ul>
<li>
<p><strong>queue.c</strong></p>
<p>queue.c provides both queue and semaphore services, as described later
in this book. queue.c is nearly always required.</p>
</li>
<li>
<p><strong>timers.c</strong></p>
<p>timers.c provides software timer functionality, as described later in
this book. It only needs to be built if the application uses software
timers.</p>
</li>
<li>
<p><strong>event_groups.c</strong></p>
<p>event_groups.c provides event group functionality, as described later
in this book. It only needs to be built if the application uses event
groups.</p>
</li>
<li>
<p><strong>stream_buffer.c</strong></p>
<p>stream_buffer.c provides both stream buffer and message buffer
functionality, as described later in this book. It only needs to
be built if the application uses
stream or message buffers.</p>
</li>
<li>
<p><strong>croutine.c</strong></p>
<p>croutine.c implements the FreeRTOS co-routine functionality. It only
needs to be built if the application uses co-routines. Co-routines are
intended for use on very small microcontrollers, are rarely used now.
They are, therefore, no longer maintained, and their use is not
recommended for new designs. Co-routines are not described in this
book.</p>
</li>
</ul>
<p><a name="fig2.2" title="Figure 2.2 Core FreeRTOS source files within the FreeRTOS directory tree"></a></p>
<hr />
<pre><code>FreeRTOS
│
└─Source
    │
    ├─tasks.c         FreeRTOS source file - always required
    ├─list.c          FreeRTOS source file - always required
    ├─queue.c         FreeRTOS source file - nearly always required
    ├─timers.c        FreeRTOS source file - optional
    ├─event_groups.c  FreeRTOS source file – optional
    ├─stream_buffer.c FreeRTOS source file - optional
    └─croutine.c      FreeRTOS source file – optional and no longer maintained
</code></pre>
<p><em><strong>Figure 2.2</strong></em> <em>Core FreeRTOS source files within the FreeRTOS directory tree</em></p>
<hr />
<p>It is recognized that the file names used in the zip file distribution
may cause namespace clashes, as many projects will already use files
with the same names. Users can change the file names if necessary, but
the names cannot change in the distribution, as doing so will break
compatibility with existing users' projects as well as FreeRTOS-aware
development tools.</p>
<h3 id="226-freertos-source-files-specific-to-a-port"><a class="header" href="#226-freertos-source-files-specific-to-a-port">2.2.6 FreeRTOS Source Files Specific to a Port</a></h3>
<p>The FreeRTOS/Source/portable directory contains source files specific to a FreeRTOS
port. The portable directory is arranged as a hierarchy, first by
compiler, then by processor architecture. Figure 2.3 shows the hierarchy.</p>
<p>To run FreeRTOS on a processor with architecture '<em>architecture</em>' using
compiler '<em>compiler</em>', in addition to the core FreeRTOS source
files, you must also build the files located in the
FreeRTOS/Source/portable/[<em>compiler</em>]/[<em>architecture</em>] directory.</p>
<p>As described in Chapter 3, Heap Memory Management, FreeRTOS also
considers heap memory allocation to be part of the portable layer. If
<code>configSUPPORT_DYNAMIC_ALLOCATION</code> is set to 0, then do not include a heap
memory allocation scheme in your project.</p>
<p>FreeRTOS provides example heap allocation schemes in the
FreeRTOS/Source/portable/MemMang directory. If FreeRTOS is configured to
use dynamic memory allocation, it is necessary to either include one of
the heap implementation source files from that directory in your project, or
provide your own implementation.</p>
<blockquote>
<p><strong>! Do not include more than one of the example heap allocation implementations in your project.</strong></p>
</blockquote>
<p><a name="fig2.3" title="Figure 2.3 Port specific source files within the FreeRTOS directory tree"></a></p>
<hr />
<pre><code>FreeRTOS
│
└─Source
    │
    └─portable Directory containing all port specific source files
        │
        ├─MemMang Directory containing the alternative heap allocation source files
        │
        ├─[compiler 1] Directory containing port files specific to compiler 1
        │   │
        │   ├─[architecture 1] Contains files for the compiler 1 architecture 1 port
        │   ├─[architecture 2] Contains files for the compiler 1 architecture 2 port
        │   └─[architecture 3] Contains files for the compiler 1 architecture 3 port
        │
        └─[compiler 2] Directory containing port files specific to compiler 2
            │
            ├─[architecture 1] Contains files for the compiler 2 architecture 1 port
            ├─[architecture 2] Contains files for the compiler 2 architecture 2 port
            └─[etc.]
</code></pre>
<p><em><strong>Figure 2.3</strong></em> <em>Port specific source files within the FreeRTOS directory tree</em></p>
<hr />
<h3 id="227-include-paths"><a class="header" href="#227-include-paths">2.2.7 Include Paths</a></h3>
<p>FreeRTOS requires the inclusion of three directories in the compiler's
include path. These are:</p>
<ol>
<li>
<p>The path to the core FreeRTOS kernel header files, FreeRTOS/Source/include.</p>
</li>
<li>
<p>The path to the source files specific to the FreeRTOS port in use,
FreeRTOS/Source/portable/[<em>compiler</em>]/[<em>architecture</em>].</p>
</li>
<li>
<p>The path to the correct FreeRTOSConfig.h header file.</p>
</li>
</ol>
<h3 id="228-header-files"><a class="header" href="#228-header-files">2.2.8 Header Files</a></h3>
<p>A source file that uses the FreeRTOS API must include FreeRTOS.h,
followed by the header file that contains the prototype for the API
function—either task.h, queue.h, semphr.h, timers.h,
event_groups.h, stream_buffer.h, message_buffer.h or croutine.h. Do not
explicitly include any other FreeRTOS header files—FreeRTOS.h automatically includes
FreeRTOSConfig.h.</p>
<h2 id="23-demo-applications"><a class="header" href="#23-demo-applications">2.3 Demo Applications</a></h2>
<p>Each FreeRTOS port comes with at least one demo application that, at the
time of its creation, built 'out of the box' with no compiler errors or
warnings. Please use the FreeRTOS support forums
(<a href="https://forums.FreeRTOS.org">https://forums.FreeRTOS.org</a>) to let us know if subsequent changes to
the build tools mean that is no longer the case.</p>
<blockquote>
<p><strong>Cross Platform Support</strong>: FreeRTOS is developed and tested on Windows,
Linux and MacOS systems and with a variety of toolchains, both embedded and
traditional.  However, occasionally build errors can appear due to differences
of version or a missed test.  Please use the FreeRTOS support forum
(<a href="https://forums.FreeRTOS.org">https://forums.FreeRTOS.org</a>) to alert us of any such errors.</p>
</blockquote>
<p>Demo applications have several purposes:</p>
<ul>
<li>To provide an example of a working and pre-configured project, with
the correct files included, and the correct compiler options set.</li>
<li>To allow 'out of the box' experimentation with minimal setup or
prior knowledge.</li>
<li>To demonstrate how to use FreeRTOS APIs.</li>
<li>As a base from which real applications can be created.</li>
<li>To stress test the kernel's implementation.</li>
</ul>
<p>Each demo project is located in a unique sub-directory under the
FreeRTOS/Demo directory. The sub-directory's name indicates the port to
which the demo project relates.</p>
<p>The FreeRTOS.org website contains a page for each demo application. The
web page includes information on:</p>
<ul>
<li>How to locate the project file for the demo within the FreeRTOS directory
structure.</li>
<li>The hardware or emulator the project is configured to use.</li>
<li>How to set up the hardware to run the demo.</li>
<li>How to build the demo.</li>
<li>The demo's expected behaviour.</li>
</ul>
<p>All demo projects create a subset of the 'common demo tasks', the
implementations of which are in the FreeRTOS/Demo/Common/Minimal
directory. The common demo tasks exist to demonstrate how to use the
FreeRTOS API and test FreeRTOS kernel ports—they do not implement any
particular useful functionality.</p>
<p>Many demo projects can also be configured to create a simple 'blinky'
style starter project that typically creates two RTOS tasks and one
queue.</p>
<p>Every demo project includes a file called main.c that contains the
<code>main()</code> function, which creates the demo application tasks before starting
the FreeRTOS kernel. See the
comments within the individual main.c files for information specific to
that demo.</p>
<p><a name="fig2.4" title="Figure 2.4 The demo directory hierarchy"></a></p>
<hr />
<pre><code>FreeRTOS
    │
    └─Demo          Directory containing all the demo projects
        │
        ├─[Demo x]  Contains the project file that builds demo 'x'
        ├─[Demo y]  Contains the project file that builds demo 'y'
        ├─[Demo z]  Contains the project file that builds demo 'z'
        └─Common    Contains files that are built by all the demo applications
</code></pre>
<p><em><strong>Figure 2.4</strong></em> <em>The demo directory hierarchy</em></p>
<hr />
<h2 id="24-creating-a-freertos-project"><a class="header" href="#24-creating-a-freertos-project">2.4 Creating a FreeRTOS Project</a></h2>
<h3 id="241-adapting-one-of-the-supplied-demo-projects"><a class="header" href="#241-adapting-one-of-the-supplied-demo-projects">2.4.1 Adapting One of the Supplied Demo Projects</a></h3>
<p>Every FreeRTOS port comes with at least one pre-configured demo
application. It is recommended to create new projects by adapting one of
these existing projects to ensure the new project has the correct files
included, the correct interrupt handlers installed, and the correct
compiler options set.</p>
<p>To create a new application from an existing demo project:</p>
<ol>
<li>
<p>Open the supplied demo project and ensure it builds and executes as
expected.</p>
</li>
<li>
<p>Remove the source files that implement the demo tasks, which are
files located in the Demo/Common directory.</p>
</li>
<li>
<p>Delete all the function calls within <code>main()</code>, except
<code>prvSetupHardware()</code> and <code>vTaskStartScheduler()</code>, as shown in Listing 2.1.</p>
</li>
<li>
<p>Verify that the project still builds.</p>
</li>
</ol>
<p>When you follow these steps you create a project that includes the correct
FreeRTOS source files, but does not define any functionality.</p>
<p><a name="list2.1" title="Listing 2.1 The template for a new main() function"></a></p>
<pre><code class="language-c">int main( void )
{
    /* Perform any hardware setup necessary. */
    prvSetupHardware();

    /* --- APPLICATION TASKS CAN BE CREATED HERE --- */

    /* Start the created tasks running. */
    vTaskStartScheduler();

    /* Execution will only reach here if there was insufficient heap to
       start the scheduler. */
    for( ;; );
    return 0;
}
</code></pre>
<p><em><strong>Listing 2.1</strong></em> <em>The template for a new main() function</em></p>
<h3 id="242-creating-a-new-project-from-scratch"><a class="header" href="#242-creating-a-new-project-from-scratch">2.4.2 Creating a New Project from Scratch</a></h3>
<p>As already mentioned, it is recommended to create new projects from an
existing demo project. If this is not desirable, then use the following
procedure to create a new project:</p>
<ol>
<li>
<p>Using your chosen toolchain, create a new project that does not yet
include any FreeRTOS source files.</p>
</li>
<li>
<p>Ensure the new project builds, downloads to your target hardware,
and executes.</p>
</li>
<li>
<p>Only when you are sure you already have a working project, add the
FreeRTOS source files detailed in Table 1 to the project.</p>
</li>
<li>
<p>Copy the <code>FreeRTOSConfig.h</code> header file used by the demo project and
provided for the port in use into your new project directory.</p>
</li>
<li>
<p>Add the following directories to the path the project will search to
locate header files:</p>
<ul>
<li>FreeRTOS/Source/include</li>
<li>FreeRTOS/Source/portable/[<em>compiler</em>]/[<em>architecture</em>] (where
[<em>compiler</em>] and [<em>architecture</em>] are correct for your chosen port)</li>
<li>The directory containing the <code>FreeRTOSConfig.h</code> header file</li>
</ul>
</li>
<li>
<p>Copy the compiler settings from the relevant demo project.</p>
</li>
<li>
<p>Install any FreeRTOS interrupt handlers that might be necessary. Use
the web page that describes the port in use and the demo project
provided for the port in use as a reference.</p>
</li>
</ol>
<p><a name="tbl1" title="Table 1 FreeRTOS source files to include in the project"></a></p>
<hr />
<div class="table-wrapper"><table><thead><tr><th>File</th><th>Location</th></tr></thead><tbody>
<tr><td>tasks.c</td><td>FreeRTOS/Source</td></tr>
<tr><td>queue.c</td><td>FreeRTOS/Source</td></tr>
<tr><td>list.c</td><td>FreeRTOS/Source</td></tr>
<tr><td>timers.c</td><td>FreeRTOS/Source</td></tr>
<tr><td>event_groups.c</td><td>FreeRTOS/Source</td></tr>
<tr><td>stream_buffer.c</td><td>FreeRTOS/Source</td></tr>
<tr><td>All C and assembler files</td><td>FreeRTOS/Source/portable/[compiler]/[architecture]</td></tr>
<tr><td>heap_n.c</td><td>FreeRTOS/Source/portable/MemMang, where n is either 1, 2, 3, 4 or 5</td></tr>
</tbody></table>
</div>
<p><em><strong>Table 1</strong></em> <em>FreeRTOS source files to include in the project</em></p>
<hr />
<p><strong>Note on heap memory:</strong>
If <code>configSUPPORT_DYNAMIC_ALLOCATION</code> is 0 then do not include a heap memory
allocation scheme in your project. Else include a heap memory allocation scheme
in your project, either one of the heap_<em>n</em>.c files, or one provided by
yourself. Refer to Chapter 3, Heap Memory Management, for more information.</p>
<h2 id="25-data-types-and-coding-style-guide"><a class="header" href="#25-data-types-and-coding-style-guide">2.5 Data Types and Coding Style Guide</a></h2>
<h3 id="251-data-types"><a class="header" href="#251-data-types">2.5.1 Data Types</a></h3>
<p>Each port of FreeRTOS has a unique portmacro.h header file that contains
(amongst other things) definitions for two port-specific data types:
<code>TickType_t</code> and <code>BaseType_t</code>. The following list describes the macro or
typedef used and the actual type:</p>
<ul>
<li>
<p><code>TickType_t</code></p>
<p>FreeRTOS configures a periodic interrupt called the tick interrupt.</p>
<p>The number of tick interrupts that have occurred since the FreeRTOS
application started is called the <em>tick count</em>. The tick count is
used as a measure of time.</p>
<p>The time between two tick interrupts is called the <em>tick period</em>.
Times are specified as multiples of tick periods.</p>
<p><code>TickType_t</code> is the data type used to hold the tick count value, and to
specify times.</p>
<p><code>TickType_t</code> can be an unsigned 16-bit type, an unsigned 32-bit
type, or an unsigned 64-bit type, depending on the setting of <code>configTICK_TYPE_WIDTH_IN_BITS</code>
in FreeRTOSConfig.h. The setting of <code>configTICK_TYPE_WIDTH_IN_BITS</code> is architecture
dependent. FreeRTOS ports will also check if this setting is valid.</p>
<p>Using a 16-bit type can greatly improve efficiency on 8-bit and
16-bit architectures, but severely limits the maximum block time that
can be specified in FreeRTOS API calls. There is no reason to use a
16-bit <code>TickType_t</code> type on a 32-bit or 64-bit architecture.</p>
<p>Previous use of <code>configUSE_16_BIT_TICKS</code> has been replaced by <code>configTICK_TYPE_WIDTH_IN_BITS</code> to support
tick counts greater than 32-bits. New designs should use <code>configTICK_TYPE_WIDTH_IN_BITS</code>
instead of <code>configUSE_16_BIT_TICKS</code>.</p>
<p><a name="tbl2" title="Table 2 TickType_t data type and the configTICK_TYPE_WIDTH_IN_BITS configuration"></a></p>
<hr />
<div class="table-wrapper"><table><thead><tr><th>configTICK_TYPE_WIDTH_IN_BITS</th><th>8-bit architectures</th><th>16-bit architectures</th><th>32-bit architectures</th><th>64-bit architectures</th></tr></thead><tbody>
<tr><td>TICK_TYPE_WIDTH_16_BITS</td><td>uint16_t</td><td>uint16_t</td><td>uint16_t</td><td>N/A</td></tr>
<tr><td>TICK_TYPE_WIDTH_32_BITS</td><td>uint32_t</td><td>uint32_t</td><td>uint32_t</td><td>N/A</td></tr>
<tr><td>TICK_TYPE_WIDTH_64_BITS</td><td>N/A</td><td>N/A</td><td>uint64_t</td><td>uint64_t</td></tr>
</tbody></table>
</div>
<p><em><strong>Table 2</strong></em> <em>TickType_t data type and the configTICK_TYPE_WIDTH_IN_BITS configuration</em></p>
<hr />
</li>
<li>
<p><code>BaseType_t</code></p>
<p>This is always defined as the most efficient data type for the
architecture. Typically, this is a 64-bit type on a 64-bit architecture,
a 32-bit type on a 32-bit architecture, a 16-bit type on a 16-bit
architecture, and an 8-bit type on an 8-bit architecture.</p>
<p><code>BaseType_t</code> is generally used for return types that take only a very
limited range of values, and for <code>pdTRUE</code>/<code>pdFALSE</code> type Booleans.</p>
</li>
</ul>
<p><em>List of port specific data types used by FreeRTOS</em></p>
<h3 id="252-variable-names"><a class="header" href="#252-variable-names">2.5.2 Variable Names</a></h3>
<p>Variables are prefixed with their type: 'c' for <code>char</code>, 's' for <code>int16_t</code>
(short), 'l' for <code>int32_t</code> (long), and 'x' for <code>BaseType_t</code> and any other
non-standard types (structures, task handles, queue handles, etc.).</p>
<p>If a variable is unsigned, it is also prefixed with a 'u'. If a variable
is a pointer, it is also prefixed with a 'p'. For example, a variable of
type <code>uint8_t</code> will be prefixed with 'uc', and a variable of type pointer
to char (<code>char *</code>) will be prefixed with 'pc'.</p>
<h3 id="253-function-names"><a class="header" href="#253-function-names">2.5.3 Function Names</a></h3>
<p>Functions are prefixed with both the type they return and the file they
are defined within. For example:</p>
<ul>
<li>v<strong>Task</strong>PrioritySet() returns a <em>v</em>oid and is defined within <strong>tasks</strong>.c.</li>
<li>x<strong>Queue</strong>Receive() returns a variable of type <em>BaseType_t</em> and is defined within <strong>queue</strong>.c.</li>
<li>pv<strong>Timer</strong>GetTimerID() returns a <em>p</em>ointer to <em>v</em>oid and is defined within <strong>timers</strong>.c.</li>
</ul>
<p>File scope (private) functions are prefixed with 'prv'.</p>
<h3 id="254-formatting"><a class="header" href="#254-formatting">2.5.4 Formatting</a></h3>
<p>Tabs are used in some demo applications where one tab is always set to
equal four spaces. The kernel no longer uses tabs.</p>
<h3 id="255-macro-names"><a class="header" href="#255-macro-names">2.5.5 Macro Names</a></h3>
<p>Most macros are written in upper case, and prefixed with lower case
letters that indicate where the macro is defined. Table 3 provides a
list of prefixes.</p>
<p><a name="tbl3" title="Table 3 Macro prefixes"></a></p>
<hr />
<div class="table-wrapper"><table><thead><tr><th>Prefix</th><th>Location of macro definition</th></tr></thead><tbody>
<tr><td>port (for example, <code>portMAX_DELAY</code>)</td><td><code>portable.h</code> or <code>portmacro.h</code></td></tr>
<tr><td>task (for example, <code>taskENTER_CRITICAL()</code>)</td><td><code>task.h</code></td></tr>
<tr><td>pd (for example, <code>pdTRUE</code>)</td><td><code>projdefs.h</code></td></tr>
<tr><td>config (for example, <code>configUSE_PREEMPTION</code>)</td><td><code>FreeRTOSConfig.h</code></td></tr>
<tr><td>err (for example, <code>errQUEUE_FULL</code>)</td><td><code>projdefs.h</code></td></tr>
</tbody></table>
</div>
<p><em><strong>Table 3</strong></em> <em>Macro prefixes</em></p>
<hr />
<p>Note that the semaphore API is written almost entirely as a set of
macros, but follows the function naming convention, rather than the
macro naming convention.</p>
<p>The macros defined in Table 4 are used throughout the FreeRTOS source code.</p>
<p><a name="tbl4" title="Table 4 Common macro definitions"></a></p>
<hr />
<div class="table-wrapper"><table><thead><tr><th>Macro</th><th>Value</th></tr></thead><tbody>
<tr><td><code>pdTRUE</code></td><td>1</td></tr>
<tr><td><code>pdFALSE</code></td><td>0</td></tr>
<tr><td><code>pdPASS</code></td><td>1</td></tr>
<tr><td><code>pdFAIL</code></td><td>0</td></tr>
</tbody></table>
</div>
<p><em><strong>Table 4</strong></em> <em>Common macro definitions</em></p>
<hr />
<h3 id="256-rationale-for-excessive-type-casting"><a class="header" href="#256-rationale-for-excessive-type-casting">2.5.6 Rationale for Excessive Type Casting</a></h3>
<p>The FreeRTOS source code compiles with many different compilers, many of
which differ in how and when they generate warnings. In particular,
different compilers want casting used in different ways. As a result,
the FreeRTOS source code contains more type casting than would normally
be warranted.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="3-heap-memory-management-1"><a class="header" href="#3-heap-memory-management-1">3 Heap Memory Management</a></h1>
<h2 id="31-introduction"><a class="header" href="#31-introduction">3.1 Introduction</a></h2>
<h3 id="311-prerequisites"><a class="header" href="#311-prerequisites">3.1.1 Prerequisites</a></h3>
<p>Being a competent C programmer is a prerequisite for using FreeRTOS, so
this chapter assumes the reader is familiar with concepts such as:</p>
<ul>
<li>The different compiling and linking phases of building a C project.</li>
<li>What the stack and heap are.</li>
<li>The standard C library <code>malloc()</code> and <code>free()</code> functions.</li>
</ul>
<h3 id="312-scope"><a class="header" href="#312-scope">3.1.2 Scope</a></h3>
<p>This chapter covers:</p>
<ul>
<li>When FreeRTOS allocates RAM.</li>
<li>The five example memory allocation schemes supplied with FreeRTOS.</li>
<li>Which memory allocation scheme to select.</li>
</ul>
<h3 id="313-switching-between-static-and-dynamic-memory-allocation"><a class="header" href="#313-switching-between-static-and-dynamic-memory-allocation">3.1.3 Switching Between Static and Dynamic Memory Allocation</a></h3>
<p>The following chapters introduce kernel objects such as tasks, queues,
semaphores, and event groups. The RAM required to hold these objects can
be allocated statically at compile-time or dynamically at run time.
Dynamic allocation reduces design and planning effort, simplifies the
API, and minimizes the RAM footprint. Static allocation is more
deterministic, removes the need to handle memory allocation failures,
and removes the risk of heap fragmentation (where the heap has enough
free memory but not in one usable contiguous block).</p>
<p>The FreeRTOS API functions that create kernel objects using statically
allocated memory are only available when <code>configSUPPORT_STATIC_ALLOCATION</code>
is set to 1 in FreeRTOSConfig.h. The FreeRTOS API functions that create
kernel objects using dynamically allocated memory are only available
when <code>configSUPPORT_DYNAMIC_ALLOCATION</code> is either set to 1 or left
undefined in FreeRTOSConfig.h. It is valid to have both constants set to
1 simultaneously.</p>
<p>More information concerning <code>configSUPPORT_STATIC_ALLOCATION</code> is in
section 3.4 Using Static Memory Allocation.</p>
<h3 id="314-using-dynamic-memory-allocation"><a class="header" href="#314-using-dynamic-memory-allocation">3.1.4 Using Dynamic Memory Allocation</a></h3>
<p>Dynamic memory allocation is a C programming concept, not a concept
specific to either FreeRTOS or multitasking. It is relevant to FreeRTOS
because kernel objects can optionally be created using dynamically
allocated memory, and the general-purpose C library <code>malloc()</code> and <code>free()</code>
functions may not be suitable for one or more of the following reasons:</p>
<ul>
<li>They are not always available on small embedded systems.</li>
<li>Their implementation can be relatively large, taking up valuable
code space.</li>
<li>They are rarely thread-safe.</li>
<li>They are not deterministic; the amount of time taken to execute the
functions will differ from call to call.</li>
<li>They can suffer from fragmentation (where the heap has enough free
memory but not in one usable contiguous block).</li>
<li>They can complicate the linker configuration.</li>
<li>They can be the source of difficult to debug errors if the heap
space is allowed to grow into memory used by other variables.</li>
</ul>
<h3 id="315-options-for-dynamic-memory-allocation"><a class="header" href="#315-options-for-dynamic-memory-allocation">3.1.5 Options for Dynamic Memory Allocation</a></h3>
<p>Early versions of FreeRTOS used a memory pools allocation scheme, where
pools of different size memory blocks are pre-allocated at compile-time,
then returned by the memory allocation functions. Although block
allocation is common in real-time systems, it was removed from FreeRTOS
because its inefficient use of RAM in really small embedded systems led to
many support requests.</p>
<p>FreeRTOS now treats memory allocation as part of the portable layer
(instead of part of the core codebase). This is because different
embedded systems have different dynamic memory allocation and timing
requirements, so a single dynamic memory allocation algorithm will only
ever be appropriate for a subset of applications. Also, removing dynamic
memory allocation from the core codebase enables application writers to
provide their own specific implementations when appropriate.</p>
<p>When FreeRTOS requires RAM it calls <code>pvPortMalloc()</code> instead of <code>malloc()</code>.
Likewise, when FreeRTOS frees previously allocated RAM it calls
<code>vPortFree()</code> instead of <code>free()</code>. <code>pvPortMalloc()</code> has the same prototype as
the standard C library <code>malloc()</code> function, and <code>vPortFree()</code> has the same
prototype as the standard C library <code>free()</code> function.</p>
<p><code>pvPortMalloc()</code> and <code>vPortFree()</code> are public functions, so they can also be
called from application code.</p>
<p>FreeRTOS comes with five example implementations of <code>pvPortMalloc()</code> and
<code>vPortFree()</code>, which are all documented in this chapter. FreeRTOS
applications can use one of the example implementations or provide their
own.</p>
<p>The five examples are defined in the heap_1.c, heap_2.c, heap_3.c,
heap_4.c and heap_5.c source files respectively, all of which are
located in the FreeRTOS/Source/portable/MemMang directory.</p>
<h2 id="32-example-memory-allocation-schemes"><a class="header" href="#32-example-memory-allocation-schemes">3.2 Example Memory Allocation Schemes</a></h2>
<h3 id="321-heap_1"><a class="header" href="#321-heap_1">3.2.1 Heap_1</a></h3>
<p>It is common for small, dedicated embedded systems to only create tasks
and other kernel objects before starting the FreeRTOS scheduler. When
this is the case, memory only gets (dynamically) allocated by the kernel
before the application starts to perform any real-time functionality,
and the memory remains allocated for the application's lifetime. This
means the chosen allocation scheme does not have to consider the more
complex memory allocation issues, such as determinism and fragmentation,
and can instead prioritise attributes such as code size and simplicity.</p>
<p>Heap_1.c implements a very basic version of <code>pvPortMalloc()</code>, and does not
implement <code>vPortFree()</code>. Applications that never delete a task or other
kernel objects have the potential to use heap_1. Some commercially
critical and safety-critical systems that would otherwise prohibit the
use of dynamic memory allocation also have the potential to use heap_1.
Critical systems often prohibit dynamic memory allocation because of the
uncertainties associated with non-determinism, memory fragmentation, and
failed allocations. Heap_1 is always deterministic and cannot fragment
memory.</p>
<p>Heap_1's implementation of <code>pvPortMalloc()</code> simply subdivides a simple
<code>uint8_t</code> array called the FreeRTOS heap into smaller blocks each time
it's called. The FreeRTOSConfig.h constant <code>configTOTAL_HEAP_SIZE</code> sets
the size of the array in bytes. Implementing the heap as a statically
allocated array makes FreeRTOS appear to consume a lot of RAM because
the heap becomes part of the FreeRTOS data.</p>
<p>Each dynamically allocated task results in two calls to <code>pvPortMalloc()</code>.
The first allocates a task control block (TCB), and the second the
task's stack. Figure 3.1 demonstrates how heap_1 subdivides the simple
array as tasks get created.</p>
<p>Referring to Figure 3.1:</p>
<ul>
<li>
<p><strong>A</strong> shows the array before creating any tasks—the entire array is free.</p>
</li>
<li>
<p><strong>B</strong> shows the array after creating one task.</p>
</li>
<li>
<p><strong>C</strong> shows the array after creating three tasks.</p>
</li>
</ul>
<p><a name="fig3.1" title="Figure 3.1 RAM being allocated from the heap\_1 array each time a task is created"></a></p>
<hr />
<p><img src="media/image05.png" alt="" /><br />
<em><strong>Figure 3.1</strong></em> <em>RAM being allocated from the heap_1 array each time a task is created</em></p>
<hr />
<h3 id="322-heap_2"><a class="header" href="#322-heap_2">3.2.2 Heap_2</a></h3>
<p>Heap_2 is superseded by heap_4, which includes enhanced functionality.
Heap_2 is kept in the FreeRTOS distribution for backward compatibility
and is not recommended for new designs.</p>
<p>Heap_2.c also works by subdividing an array dimensioned by the
<code>configTOTAL_HEAP_SIZE</code> constant. It uses a best-fit algorithm to allocate
memory, and, unlike heap_1, it does implement <code>vPortFree()</code>. Again,
implementing the heap as a statically allocated array makes FreeRTOS
appear to consume a lot of RAM because the heap becomes part of the
FreeRTOS data.</p>
<p>The best-fit algorithm ensures that <code>pvPortMalloc()</code> uses the free block
of memory that is closest in size to the number of bytes requested. For
example, consider the scenario where:</p>
<ul>
<li>The heap contains three blocks of free memory that are 5 bytes, 25
bytes, and 100 bytes, respectively.</li>
<li><code>pvPortMalloc()</code> requests 20 bytes of RAM.</li>
</ul>
<p>The smallest free block of RAM into which the requested number of bytes
fits is the 25-byte block, so <code>pvPortMalloc()</code> splits the 25-byte block
into one block of 20 bytes and one block of 5 bytes before returning
a pointer to the 20-byte block<sup class="footnote-reference"><a href="#2">1</a></sup>. The new 5-byte block remains available
for future calls to <code>pvPortMalloc()</code>.</p>
<div class="footnote-definition" id="2"><sup class="footnote-definition-label">1</sup>
<p>This is an oversimplification, because heap_2 stores information
on the block sizes within the heap area, so the sum of the two split
blocks will actually be less than 25.</p>
</div>
<p>Unlike heap_4, heap_2 does not combine adjacent free blocks into a
single larger block, so it is more susceptible to fragmentation than
heap_4. However, fragmentation is not an issue if the allocated and
subsequently freed blocks are always the same size.</p>
<p><a name="fig3.2" title="Figure 3.2 RAM being allocated and freed from the heap\_2 array as tasks are created and deleted"></a></p>
<hr />
<p><img src="media/image06.png" alt="" /><br />
<em><strong>Figure 3.2</strong></em> <em>RAM being allocated and freed from the heap_2 array as tasks are created and deleted</em></p>
<hr />
<p>Figure 3.2 demonstrates how the best-fit algorithm works when a task is
created, deleted, and created again. Referring to Figure 3.2:</p>
<ul>
<li>
<p><strong>A</strong> shows the array after allocating three tasks. A large free
block remains at the top of the array.</p>
</li>
<li>
<p><strong>B</strong> shows the array after deleting one of the tasks. The large
free block at the top of the array remains. There are now also two
smaller free blocks that previously held the TCB and stack of the
deleted task.</p>
</li>
<li>
<p><strong>C</strong> shows the situation after creating another task. Creating
the task resulted in two calls to <code>pvPortMalloc()</code> from within the
<code>xTaskCreate()</code> API function, one to allocate a new TCB and the other
to allocate the task stack. Section 3.4 of this book describes
<code>xTaskCreate()</code>.</p>
<p>Every TCB is the same size, so the best-fit algorithm reuses the block
of RAM that held the TCB of the deleted task to hold the TCB of the
created task.</p>
<p>If the size of the stack allocated to the newly created task is the
same size as that allocated to the previously deleted task, then the
best-fit algorithm reuses the block of RAM that held the stack of the
deleted task to hold the stack of the created task.</p>
<p>The larger unallocated block at the top of the array remains
untouched.</p>
</li>
</ul>
<p>Heap_2 is not deterministic but is faster than most standard library
implementations of <code>malloc()</code> and <code>free()</code>.</p>
<h3 id="323-heap_3"><a class="header" href="#323-heap_3">3.2.3 Heap_3</a></h3>
<p>Heap_3.c uses the standard library <code>malloc()</code> and <code>free()</code> functions, so the
linker configuration defines the heap size, and the
<code>configTOTAL_HEAP_SIZE</code> constant is not used.</p>
<p>Heap_3 makes <code>malloc()</code> and <code>free()</code> thread-safe by temporarily suspending
the FreeRTOS scheduler for the duration of their execution. Chapter 8,
Resource Management, covers thread safety and scheduler suspension.</p>
<h3 id="324-heap_4"><a class="header" href="#324-heap_4">3.2.4 Heap_4</a></h3>
<p>Like heap_1 and heap_2, heap_4 works by subdividing an array into
smaller blocks. As before, the array is statically allocated and
dimensioned by <code>configTOTAL_HEAP_SIZE</code>, which makes FreeRTOS appear to use
a lot of RAM as the heap becomes part of the FreeRTOS data.</p>
<p>Heap_4 uses a first-fit algorithm to allocate memory. Unlike heap_2,
heap_4 combines (coalesces) adjacent free blocks of memory into a
single larger block, which minimizes the risk of memory fragmentation.</p>
<p>The first fit algorithm ensures <code>pvPortMalloc()</code> uses the first free block
of memory that is large enough to hold the number of bytes requested.
For example, consider the scenario where:</p>
<ul>
<li>The heap contains three blocks of free memory that, in the order in
which they appear in the array, are 5 bytes, 200 bytes, and 100
bytes, respectively.</li>
<li><code>pvPortMalloc()</code> requests 20 bytes of RAM.</li>
</ul>
<p>The first free block of RAM that the requested number of bytes fits is
the 200-byte block, so <code>pvPortMalloc()</code> splits the 200-byte block into one
block of 20 bytes and one of 180 bytes<sup class="footnote-reference"><a href="#3">2</a></sup>, before returning a pointer
to the 20-byte block. The new 180-byte block remains available to future
calls to <code>pvPortMalloc()</code>.</p>
<div class="footnote-definition" id="3"><sup class="footnote-definition-label">2</sup>
<p>This is an oversimplification, because heap_4 stores information
on the block sizes within the heap area, so the sum of the two split
blocks will actually be less than 200 bytes.</p>
</div>
<p>Heap_4 combines (coalesces) adjacent free blocks into a single larger
block, minimizing the risk of fragmentation, and making it suitable for
applications that repeatedly allocate and free different-sized blocks of
RAM.</p>
<p><a name="fig3.3" title="Figure 3.3 RAM being allocated and freed from the heap\_4 array"></a></p>
<hr />
<p><img src="media/image07.png" alt="" /><br />
<em><strong>Figure 3.3</strong></em> <em>RAM being allocated and freed from the heap_4 array</em></p>
<hr />
<p>Figure 3.3 demonstrates how the heap_4 first-fit algorithm with memory
coalescence works. Referring to Figure 3.3:</p>
<ul>
<li>
<p><strong>A</strong> shows the array after creating three tasks. A large free
block remains at the top of the array.</p>
</li>
<li>
<p><strong>B</strong> shows the array after deleting one of the tasks. The large
free block at the top of the array remains. There is now another
free block where the TCB and stack of the deleted task used to be.
Unlike in the heap_2 example, heap_4 merges the two memory blocks
that previously held the TCB and stack of the deleted task,
respectively, into a larger single free block.</p>
</li>
<li>
<p><strong>C</strong> shows the situation after creating a FreeRTOS queue.
Section 5.3 of this book describes the <code>xQueueCreate()</code> API function
used to allocate queues dynamically. <code>xQueueCreate()</code> calls
<code>pvPortMalloc()</code> to allocate the RAM used by the queue. As heap_4 uses
a first-fit algorithm, <code>pvPortMalloc()</code> allocates RAM from the first
free RAM block that is large enough to hold the queue, which in
Figure 3.3, was the RAM freed by deleting the task. The queue does not
consume all the RAM in the free block, so the block is split into
two, and the unused portion remains available to future calls to
<code>pvPortMalloc()</code>.</p>
</li>
<li>
<p><strong>D</strong> shows the situation after calling <code>pvPortMalloc()</code> directly
from application code, rather than indirectly by calling a FreeRTOS
API function. The user allocated block was small enough to fit in
the first free block, which was the block between the memory
allocated to the queue, and the memory allocated to the TCB
following it.</p>
<p>The memory freed by deleting the task has now split into three
separate blocks; the first block holds the queue, the second block
holds the user allocated memory, and the third block remains free.</p>
</li>
<li>
<p><strong>E</strong> shows the situation after deleting the queue, which
automatically frees the memory allocated to the deleted queue. There
is now free memory on either side of the user allocated block.</p>
</li>
<li>
<p><strong>F</strong> shows the situation after freeing the user allocated
memory. The memory previously used by the user allocated block has
been combined with the free memory on either side to create a larger
single free block.</p>
</li>
</ul>
<p>Heap_4 is not deterministic but is faster than most standard library
implementations of <code>malloc()</code> and <code>free()</code>.</p>
<h3 id="325-heap_5"><a class="header" href="#325-heap_5">3.2.5 Heap_5</a></h3>
<p>Heap_5 uses the same allocation algorithm as heap_4. Unlike heap_4,
which is limited to allocating memory from a single array, heap_5 can
combine memory from multiple separated memory spaces into a single heap.
Heap_5 is useful when the RAM provided by the system on which FreeRTOS
is running does not appear as a single contiguous (without space) block
in the system's memory map.</p>
<h3 id="326-initialising-heap_5-the-vportdefineheapregions-api-function"><a class="header" href="#326-initialising-heap_5-the-vportdefineheapregions-api-function">3.2.6 Initialising heap_5: The vPortDefineHeapRegions() API Function</a></h3>
<p><code>vPortDefineHeapRegions()</code> initialises heap_5 by specifying the start
address and size of each separate memory area that makes up the heap
managed by heap_5. Heap_5 is the only provided heap allocation scheme
that requires explicit initialisation and can't be used until after the
call to <code>vPortDefineHeapRegions()</code>. That means kernel objects, such as
tasks, queues, and semaphores, cannot be created dynamically until after
the call to <code>vPortDefineHeapRegions()</code>.</p>
<p><a name="list3.1" title="Listing 3.1 The vPortDefineHeapRegions() API function prototype"></a></p>
<pre><code class="language-c">void vPortDefineHeapRegions( const HeapRegion_t * const pxHeapRegions );
</code></pre>
<p><em><strong>Listing 3.1</strong></em> <em>The vPortDefineHeapRegions() API function prototype</em></p>
<p><code>vPortDefineHeapRegions()</code> takes an array of <code>HeapRegion_t</code> structures as
its only parameter. Each structure defines the start address and size of
a memory block that will become part of the heap—the whole array of
structures defines the entire heap space.</p>
<p><a name="list3.2" title="Listing 3.2 The HeapRegion\_t structure"></a></p>
<pre><code class="language-c">typedef struct HeapRegion
{
    /* The start address of a block of memory that will be part of the heap.*/
    uint8_t *pucStartAddress;

    /* The size of the block of memory in bytes. */
    size_t xSizeInBytes;

} HeapRegion_t;
</code></pre>
<p><em><strong>Listing 3.2</strong></em> <em>The HeapRegion_t structure</em></p>
<p><strong>Parameters:</strong></p>
<ul>
<li>
<p><code>pxHeapRegions</code></p>
<p>A pointer to the start of an array of <code>HeapRegion_t</code> structures.
Each structure defines the start address and size of a memory block that
will become part of the heap.</p>
<p>The <code>HeapRegion_t</code> structures in the array must be ordered by start
address; the <code>HeapRegion_t</code> structure that describes the memory area with
the lowest start address must be the first structure in the array, and
the <code>HeapRegion_t</code> structure that describes the memory area with the
highest start address must be the last structure in the array.</p>
<p>Mark the end of the array with a <code>HeapRegion_t</code> structure that has its
<code>pucStartAddress</code> member set to <code>NULL</code>.</p>
</li>
</ul>
<p>By way of example, consider the hypothetical memory map shown in Figure
3.4 <strong>A</strong> which contains three separate blocks of RAM: RAM1, RAM2
and RAM3. It is assumed executable code is placed in read-only memory,
which is not shown.</p>
<p><a name="fig3.4" title="Figure 3.4 Memory Map"></a></p>
<hr />
<p><img src="media/image08.png" alt="" /><br />
<em><strong>Figure 3.4</strong></em> <em>Memory Map</em></p>
<hr />
<p>Listing 3.3 shows an array of <code>HeapRegion_t</code> structures that together
describe the three blocks of RAM in their entirety.</p>
<p><a name="list3.3" title="Listing 3.3 An array of HeapRegion\_t structures that together describe the 3 regions of RAM in their entirety"></a></p>
<pre><code class="language-c">/* Define the start address and size of the three RAM regions. */
#define RAM1_START_ADDRESS ( ( uint8_t * ) 0x00010000 )
#define RAM1_SIZE ( 64 * 1024 )

#define RAM2_START_ADDRESS ( ( uint8_t * ) 0x00020000 )
#define RAM2_SIZE ( 32 * 1024 )

#define RAM3_START_ADDRESS ( ( uint8_t * ) 0x00030000 )
#define RAM3_SIZE ( 32 * 1024 )

/* Create an array of HeapRegion_t definitions, with an index for each
   of the three RAM regions, and terminate the array with a HeapRegion_t
   structure containing a NULL address. The HeapRegion_t structures must
   appear in start address order, with the structure that contains the
   lowest start address appearing first. */
const HeapRegion_t xHeapRegions[] =
{
    { RAM1_START_ADDRESS, RAM1_SIZE },
    { RAM2_START_ADDRESS, RAM2_SIZE },
    { RAM3_START_ADDRESS, RAM3_SIZE },
    { NULL,               0         } /* Marks the end of the array. */
};

int main( void )
{
    /* Initialize heap_5. */
    vPortDefineHeapRegions( xHeapRegions );

    /* Add application code here. */
}
</code></pre>
<p><em><strong>Listing 3.3</strong></em> <em>An array of HeapRegion_t structures that together describe the 3 regions of RAM in their entirety</em></p>
<p>Although Listing 3.3 correctly describes the RAM, it does not demonstrate a
usable example because it allocates all the RAM to the heap, leaving no
RAM free for use by other variables.</p>
<p>The linking phase of the build process allocates a RAM address to each
variable. The RAM available for use by the linker is normally described
by a linker configuration file, such as a linker script. In Figure 3.4
<strong>B</strong> it is assumed the linker script included information on
RAM1, but did not include information on RAM2 or RAM3. As a result, the
linker placed variables in RAM1, leaving only the portion of RAM1 above
address 0x0001nnnn available for use by heap_5. The actual value of
0x0001nnnn depends on the combined size of all the variables included in
the application. The linker has left all of RAM2 and all of RAM3 unused,
leaving the whole of RAM2 and the whole of RAM3 available for use by
heap_5.</p>
<p>The code shown in Listing 3.3 would cause the RAM allocated to heap_5
below address 0x0001nnnn to overlap the RAM used to hold variables.
If you set the start address of the first <code>HeapRegion_t</code> structure within the
<code>xHeapRegions[]</code> array to 0x0001nnnn, rather than a start address of
0x00010000, the heap will not overlap with RAM used by the linker.
However, that is not a recommended solution because:</p>
<ul>
<li>The start address might not be easy to determine.</li>
<li>The amount of RAM used by the linker might change in future builds,
which would make an update to the start address used in the
<code>HeapRegion_t</code> structure necessary.</li>
<li>The build tools will not know, and therefore cannot warn the
application writer, if the RAM used by the linker and the RAM used
by heap_5 overlap.</li>
</ul>
<p>Listing 3.4 demonstrates a more convenient and maintainable example. It
declares an array called <code>ucHeap</code>. <code>ucHeap</code> is a normal variable, so it
becomes part of the data allocated to RAM1 by the linker. The first
<code>HeapRegion_t</code> structure in the <code>xHeapRegions</code> array describes the start
address and size of <code>ucHeap</code>, so <code>ucHeap</code> becomes part of the memory managed
by heap_5. The size of <code>ucHeap</code> can be increased until the RAM used by the
linker consumes all of RAM1, as shown in Figure 3.4 <strong>C</strong>.</p>
<p><a name="list3.4" title="Listing 3.4 An array of HeapRegion\_t structures that describe all of RAM2, all of RAM3, but only part of RAM1"></a></p>
<pre><code class="language-c">/* Define the start address and size of the two RAM regions not used by
   the linker. */
#define RAM2_START_ADDRESS ( ( uint8_t * ) 0x00020000 )
#define RAM2_SIZE ( 32 * 1024 )

#define RAM3_START_ADDRESS ( ( uint8_t * ) 0x00030000 )
#define RAM3_SIZE ( 32 * 1024 )

/* Declare an array that will be part of the heap used by heap_5. The
   array will be placed in RAM1 by the linker. */
#define RAM1_HEAP_SIZE ( 30 * 1024 )
static uint8_t ucHeap[ RAM1_HEAP_SIZE ];

/* Create an array of HeapRegion_t definitions. Whereas in Listing 3.3 the
   first entry described all of RAM1, so heap_5 will have used all of
   RAM1, this time the first entry only describes the ucHeap array, so
   heap_5 will only use the part of RAM1 that contains the ucHeap array.
   The HeapRegion_t structures must still appear in start address order,
   with the structure that contains the lowest start address appearing first. */

const HeapRegion_t xHeapRegions[] =
{
    { ucHeap,             RAM1_HEAP_SIZE },
    { RAM2_START_ADDRESS, RAM2_SIZE },
    { RAM3_START_ADDRESS, RAM3_SIZE },
    { NULL,               0 }           /* Marks the end of the array. */
};
</code></pre>
<p><em><strong>Listing 3.4</strong></em> <em>An array of HeapRegion_t structures that describe all of RAM2, all of RAM3, but only part of RAM1</em></p>
<p>The advantages of the technique demonstrated in Listing 3.4 include:</p>
<ul>
<li>It is not necessary to use a hard-coded start address.</li>
<li>The address used in the <code>HeapRegion_t</code> structure will be set
automatically by the linker, so it will always be correct, even if the
amount of RAM used by the linker changes in future builds.</li>
<li>It is impossible for RAM allocated to heap_5 to overlap data placed
into RAM1 by the linker.</li>
<li>The application will not link if <code>ucHeap</code> is too big.</li>
</ul>
<h2 id="33-heap-related-utility-functions-and-macros"><a class="header" href="#33-heap-related-utility-functions-and-macros">3.3 Heap Related Utility Functions and Macros</a></h2>
<h3 id="331-defining-the-heap-start-address"><a class="header" href="#331-defining-the-heap-start-address">3.3.1 Defining the Heap Start Address</a></h3>
<p>Heap_1, heap_2 and heap_4 allocate memory from a statically allocated
array dimensioned by <code>configTOTAL_HEAP_SIZE</code>. This section refers to these
allocation schemes collectively as heap_n.</p>
<p>Sometimes the heap needs to be placed at a specific memory address. For
example, the stack allocated to a dynamically created task comes from
the heap, so it might be necessary to locate the heap in fast internal
memory rather than slow external memory. (See the sub-section Placing
Task Stacks in Fast Memory below for another method of allocating task
stacks in fast memory). The <code>configAPPLICATION_ALLOCATED_HEAP</code>
compile-time configuration constant enables the application to declare
the array in place of the declaration that would otherwise be in the
heap_n.c source file. Declaring the array in the application code
enables the application writer to specify its start address.</p>
<p>If <code>configAPPLICATION_ALLOCATED_HEAP</code> is set to 1 in FreeRTOSConfig.h,
the application that uses FreeRTOS must allocate a <code>uint8_t</code> array
called <code>ucHeap</code> and dimensioned by the <code>configTOTAL_HEAP_SIZE</code> constant.</p>
<p>The syntax required to place a variable at a specific memory address is
dependent on the compiler in use, so refer to your compiler's
documentation. Examples for two compilers follow:</p>
<ul>
<li>Listing 3.5 shows the syntax required by the GCC compiler to declare
the array and place the array in a memory section called <code>.my_heap</code>.</li>
<li>Listing 3.6 shows the syntax required by the IAR compiler to declare
the array and place the array at the absolute memory address
0x20000000.</li>
</ul>
<p><a name="list3.5" title="Listing 3.5 Using GCC syntax to declare the array that will be used by heap\_4, and place the array in a memory section named .my\_heap"></a></p>
<pre><code class="language-c">uint8_t ucHeap[ configTOTAL_HEAP_SIZE ] __attribute__ ( ( section( ".my_heap" ) ) );
</code></pre>
<p><em><strong>Listing 3.5</strong></em> <em>Using GCC syntax to declare the array that will be used by heap_4, and place the array in a memory section named .my_heap</em></p>
<p><a name="list3.6" title="Listing 3.6 Using IAR syntax to declare the array that will be used by heap\_4, and place the array at the absolute address 0x20000000"></a></p>
<pre><code class="language-c">uint8_t ucHeap[ configTOTAL_HEAP_SIZE ] @ 0x20000000;
</code></pre>
<p><em><strong>Listing 3.6</strong></em> <em>Using IAR syntax to declare the array that will be used by heap_4, and place the array at the absolute address 0x20000000</em></p>
<h3 id="332-the-xportgetfreeheapsize-api-function"><a class="header" href="#332-the-xportgetfreeheapsize-api-function">3.3.2 The xPortGetFreeHeapSize() API Function</a></h3>
<p>The <code>xPortGetFreeHeapSize()</code> API function returns the number of free bytes
in the heap at the time the function is called. It does not provide
information on heap fragmentation.</p>
<p><code>xPortGetFreeHeapSize()</code> is not implemented for heap_3.</p>
<p><a name="list3.7" title="Listing 3.7 The xPortGetFreeHeapSize() API function prototype"></a></p>
<pre><code class="language-c">size_t xPortGetFreeHeapSize( void );
</code></pre>
<p><em><strong>Listing 3.7</strong></em> <em>The xPortGetFreeHeapSize() API function prototype</em></p>
<p><strong>Return value:</strong></p>
<ul>
<li><code>xPortGetFreeHeapSize()</code> returns the number of bytes that remain unallocated in the heap at
the time it is called.</li>
</ul>
<h3 id="333-the-xportgetminimumeverfreeheapsize-api-function"><a class="header" href="#333-the-xportgetminimumeverfreeheapsize-api-function">3.3.3 The xPortGetMinimumEverFreeHeapSize() API Function</a></h3>
<p>The <code>xPortGetMinimumEverFreeHeapSize()</code> API function returns the minimum
number of unallocated bytes that have ever existed in the heap since the
FreeRTOS application started executing.</p>
<p>The value returned by <code>xPortGetMinimumEverFreeHeapSize()</code> indicates how
close the application has ever come to running out of heap space. For
example, if <code>xPortGetMinimumEverFreeHeapSize()</code> returns 200, then, at some
time since the application started executing, it came within 200 bytes
of running out of heap space.</p>
<p><code>xPortGetMinimumEverFreeHeapSize()</code> can also be used to optimise the heap
size. For example, if <code>xPortGetMinimumEverFreeHeapSize()</code> returns 2000
after executing the code that you know has the highest heap usage,
<code>configTOTAL_HEAP_SIZE</code> can be reduced by up to 2000 bytes.</p>
<p><code>xPortGetMinimumEverFreeHeapSize()</code> is only implemented in heap_4 and heap_5.</p>
<p><a name="list3.8" title="Listing 3.8 The xPortGetMinimumEverFreeHeapSize() API function prototype"></a></p>
<pre><code class="language-c">size_t xPortGetMinimumEverFreeHeapSize( void );
</code></pre>
<p><em><strong>Listing 3.8</strong></em> <em>The xPortGetMinimumEverFreeHeapSize() API function prototype</em></p>
<p><strong>Return value:</strong></p>
<ul>
<li><code>xPortGetMinimumEverFreeHeapSize()</code> returns the minimum number of unallocated
bytes that existed in the heap since the FreeRTOS application started executing.</li>
</ul>
<h3 id="334-the-vportgetheapstats-api-function"><a class="header" href="#334-the-vportgetheapstats-api-function">3.3.4 The vPortGetHeapStats() API Function</a></h3>
<p>Heap_4 and heap_5 implement <code>vPortGetHeapStats()</code>, which completes the
<code>HeapStats_t</code> structure pass by reference as the function's only parameter.</p>
<p>Listing 3.9 shows the <code>vPortGetHeapStats()</code> function prototype. Listing 3.10
shows the <code>HeapStats_t</code> structure members.</p>
<p><a name="list3.9" title="Listing 3.9 The vPortGetHeapStatus() API function prototype"></a></p>
<pre><code class="language-c">void vPortGetHeapStats( HeapStats_t *xHeapStats );
</code></pre>
<p><em><strong>Listing 3.9</strong></em> <em>The vPortGetHeapStatus() API function prototype</em></p>
<p><a name="list3.10" title="Listing 3.10 The HeapStatus\_t() structure"></a></p>
<pre><code class="language-c">/* Prototype of the vPortGetHeapStats() function. */
void vPortGetHeapStats( HeapStats_t *xHeapStats );

/* Definition of the HeapStats_t structure. All sizes specified in bytes. */
typedef struct xHeapStats
{
    /* The total heap size currently available - this is the sum of all the
       free blocks, not the largest available block. */
    size_t xAvailableHeapSpaceInBytes;

    /* The size of the largest free block within the heap at the time
       vPortGetHeapStats() is called. */
    size_t xSizeOfLargestFreeBlockInBytes;

    /* The size of the smallest free block within the heap at the time
       vPortGetHeapStats() is called. */
    size_t xSizeOfSmallestFreeBlockInBytes;

    /* The number of free memory blocks within the heap at the time
       vPortGetHeapStats() is called. */
    size_t xNumberOfFreeBlocks;

    /* The minimum amount of total free memory (sum of all free blocks)
       there has been in the heap since the system booted. */
    size_t xMinimumEverFreeBytesRemaining;

    /* The number of calls to pvPortMalloc() that have returned a valid
       memory block. */
    size_t xNumberOfSuccessfulAllocations;

    /* The number of calls to vPortFree() that has successfully freed a
       block of memory. */
    size_t xNumberOfSuccessfulFrees;
} HeapStats_t;
</code></pre>
<p><em><strong>Listing 3.10</strong></em> <em>The HeapStatus_t() structure</em></p>
<h3 id="335-collecting-per-task-heap-usage-statistics"><a class="header" href="#335-collecting-per-task-heap-usage-statistics">3.3.5 Collecting Per-task Heap Usage Statistics</a></h3>
<p>The <code>vTaskGetInfo()</code> API function, documented in section TBD-RB of this
book, populates a <code>TaskStatus_t</code> structure with information about a task.
If the <code>configTRACK_TASK_MEMORY_ALLOCATIONS</code> compile-time constant is set
to 1 in FreeRTOSConfig.h, the structure includes the following additional
information:</p>
<ul>
<li>The number of times the task called <code>pvPortMalloc()</code>.</li>
<li>The number of times the task called <code>vPortFree()</code>.</li>
<li>The number of heap bytes allocated by the task that have not yet
been freed by any task at the time <code>vTaskGetInfo()</code> was called.</li>
<li>The maximum amount of heap memory allocated by the task at any given
time since the task started.</li>
</ul>
<h3 id="336-malloc-failed-hook-functions"><a class="header" href="#336-malloc-failed-hook-functions">3.3.6 Malloc Failed Hook Functions</a></h3>
<p>Like the standard library <code>malloc()</code> function, <code>pvPortMalloc()</code> returns NULL
if it cannot allocate the requested amount of RAM. The malloc failed hook
(or callback) is an application-provided function that gets called if
<code>pvPortMalloc()</code> returns NULL. You must set <code>configUSE_MALLOC_FAILED_HOOK</code> to
1 in FreeRTOSConfig.h in order for the callback to occur. If the malloc failed
hook gets called inside a FreeRTOS API function that uses dynamic memory
allocation to create a kernel object, the object is not created.</p>
<p>If <code>configUSE_MALLOC_FAILED_HOOK</code> is set to 1 in FreeRTOSConfig.h, then
the application must provide a malloc failed hook function with the name
and prototype shown in Listing 3.11. The application can implement the
function in any way appropriate for the application. Many of the
provided FreeRTOS demo applications treat an allocation failure as a
fatal error, but that is not the best practice for production systems,
which should gracefully recover from allocation failures.</p>
<p><a name="list3.11" title="Listing 3.11 The malloc failed hook function name and prototype"></a></p>
<pre><code class="language-c">void vApplicationMallocFailedHook( void );
</code></pre>
<p><em><strong>Listing 3.11</strong></em> <em>The malloc failed hook function name and prototype</em></p>
<h3 id="337-placing-task-stacks-in-fast-memory"><a class="header" href="#337-placing-task-stacks-in-fast-memory">3.3.7 Placing Task Stacks in Fast Memory</a></h3>
<p>Because stacks are written to and read from at a high rate, they should
be placed in fast memory, but that might not be where you want the heap to
reside. FreeRTOS uses the <code>pvPortMallocStack()</code> and <code>vPortFreeStack()</code>
macros to optionally enable stacks that are allocated within the FreeRTOS API
code to have their own memory allocator. If you want the stack to come
from the heap managed by <code>pvPortMalloc()</code> then leave <code>pvPortMallocStack()</code>
and <code>vPortFreeStack()</code> undefined as they default to calling
<code>pvPortMalloc()</code> and <code>vPortFree()</code>, respectively. Otherwise, define the
macros to call application-provided functions as shown in Listing 3.12.</p>
<p><a name="list3.12" title="Listing 3.12 Mapping the pvPortMallocStack() and vPortFreeStack() macros to an application defined memory allcator"></a></p>
<pre><code class="language-c">/* Functions provided by the application writer than allocate and free 
   memory from a fast area of RAM. */

void *pvMallocFastMemory( size_t xWantedSize );

void vPortFreeFastMemory( void *pvBlockToFree );

/* Add the following to FreeRTOSConfig.h to map the pvPortMallocStack()
   and vPortFreeStack() macros to the functions that use fast memory. */

#define pvPortMallocStack( x ) pvMallocFastMemory( x )

#define vPortFreeStack( x ) vPortFreeFastMemory( x )
</code></pre>
<p><em><strong>Listing 3.12</strong></em> <em>Mapping the pvPortMallocStack() and vPortFreeStack() macros to an application defined memory allcator</em></p>
<h2 id="34-using-static-memory-allocation"><a class="header" href="#34-using-static-memory-allocation">3.4 Using Static Memory Allocation</a></h2>
<p>Section 3.1.4 lists some of the disadvantages that come with dynamic memory allocation. To avoid those issues, static
memory allocation allows the developer to explicity create every memory block needed by the application. This has the
following advantages:</p>
<ul>
<li>All required memory is known at compile time.</li>
<li>All memory is deterministic.</li>
</ul>
<p>There are other advantages, but with these advantages come a few complications. The main complication is the addition of a
few additional user functions to manage some kernel memory, and the second complication is the need to ensure all static
memory is declared in a suitable scope.</p>
<h3 id="341-enabling-static-memory-allocation"><a class="header" href="#341-enabling-static-memory-allocation">3.4.1 Enabling Static Memory Allocation</a></h3>
<p>Static memory allocation is enabled by setting <code>configSUPPORT_STATIC_ALLOCATION</code> to 1 in FreeRTOSConfig.h.  When this
configuration is enabled, the kernel enables all the <code>static</code> versions of the kernel functions. These are:</p>
<ul>
<li><code>xTaskCreateStatic</code></li>
<li><code>xEventGroupCreateStatic</code></li>
<li><code>xEventGroupGetStaticBuffer</code></li>
<li><code>xQueueGenericCreateStatic</code></li>
<li><code>xQueueGenericGetStaticBuffers</code></li>
<li><code>xQueueCreateMutexStatic</code>
<ul>
<li><em>if <code>configUSE_MUTEXES</code> is 1</em></li>
</ul>
</li>
<li><code>xQueueCreateCountingSemaphoreStatic</code>
<ul>
<li><em>if <code>configUSE_COUNTING_SEMAPHORES</code> is 1</em></li>
</ul>
</li>
<li><code>xStreamBufferGenericCreateStatic</code></li>
<li><code>xStreamBufferGetStaticBuffers</code></li>
<li><code>xTimerCreateStatic</code>
<ul>
<li><em>if <code>configUSE_TIMERS</code> is 1</em></li>
</ul>
</li>
<li><code>xTimerGetStaticBuffer</code>
<ul>
<li><em>if <code>configUSE_TIMERS</code> is 1</em></li>
</ul>
</li>
</ul>
<p>These functions will be explained in the appropriate chapters in this book.</p>
<h3 id="342-static-internal-kernel-memory"><a class="header" href="#342-static-internal-kernel-memory">3.4.2 Static Internal Kernel Memory</a></h3>
<p>When the static memory allocator is enabled, the idle task and the timer task (if enabled) will use static memory supplied
by user functions. These user functions are:</p>
<ul>
<li><code>vApplicationGetTimerTaskMemory</code>
<ul>
<li><em>if <code>configUSE_TIMERS</code> is 1</em></li>
</ul>
</li>
<li><code>vApplicationGetIdleTaskMemory</code></li>
</ul>
<h4 id="3421-vapplicationgettimertaskmemory"><a class="header" href="#3421-vapplicationgettimertaskmemory">3.4.2.1 vApplicationGetTimerTaskMemory</a></h4>
<p>If <code>configSUPPORT_STATIC_ALLOCATION</code> and <code>configUSE_TIMERS</code> are both enabled, the kernel will call <code>vApplicationGetTimerTaskMemory()</code>
to allow the application to create and return a memory buffer for the timer task TCB and the timer task stack. The function will
also return the size of the timer task stack. A suggested implementation of the timer task memory function is shown in listing 3.13.</p>
<p><a name="list3.13" title="Listing 3.13 Typical implementation of vApplicationGetTimerTaskMemory"></a></p>
<pre><code class="language-c">void vApplicationGetTimerTaskMemory( StaticTask_t **ppxTimerTaskTCBBuffer,
                                     StackType_t **ppxTimerTaskStackBuffer,
                                     uint32_t *pulTimerTaskStackSize )
{
  /* If the buffers to be provided to the Timer task are declared inside this
  function then they must be declared static - otherwise they will be allocated on
  the stack and hence would not exists after this function exits. */
  static StaticTask_t xTimerTaskTCB;
  static StackType_t uxTimerTaskStack[ configMINIMAL_STACK_SIZE ];

  /* Pass out a pointer to the StaticTask_t structure in which the Timer task's
  state will be stored. */
  *ppxTimerTaskTCBBuffer = &amp;xTimerTaskTCB;

  /* Pass out the array that will be used as the Timer task's stack. */
  *ppxTimerTaskStackBuffer = uxTimerTaskStack;

  /* Pass out the stack size of the array pointed to by *ppxTimerTaskStackBuffer.
  Note the stack size is a count of StackType_t */
  *pulTimerTaskStackSize = sizeof(uxTimerTaskStack) / sizeof(*uxTimerTaskStack);
}
</code></pre>
<p><em><strong>Listing 3.13</strong></em> <em>Typical implementation of vApplicationGetTimerTaskMemory</em></p>
<p>Since there is only a single timer task in any system including SMP, a valid solution to the timer task memory problem
is to allocate static buffers in the <code>vApplicationGetTimeTaskMemory()</code> function and return the buffer pointers to the kernel.</p>
<h4 id="3422-vapplicationgetidletaskmemory"><a class="header" href="#3422-vapplicationgetidletaskmemory">3.4.2.2 vApplicationGetIdleTaskMemory</a></h4>
<p>The idle task is run when a core runs out of scheduled work. The idle task performs some housekeeping and can also trigger
the user's <code>vTaskIdleHook()</code> if it is enabled.  In a symetric multiprocessing system (SMP) there are also non-housekeeping
idle tasks for each of the remaining cores, but these are statically allocated internally to <code>configMINIMUM_STACK_SIZE</code> bytes.</p>
<p>The <code>vApplicationGetIdleTaskMemory</code> function is called to allow the application to create the needed buffers for the "main"
idle task. Listing 3.14 shows a typical implementation of the <code>vApplicationIdleTaskMemory()</code> function using static local
variables to create the needed buffers.</p>
<p><a name="list3.14" title="Listing 3.14 Typical implementation of vApplicationGetIdleTaskMemory"></a></p>
<pre><code class="language-c">void vApplicationGetIdleTaskMemory( StaticTask_t **ppxIdleTaskTCBBuffer,
                                    StackType_t **ppxIdleTaskStackBuffer,
                                    uint32_t *pulIdleTaskStackSize )
{
  static StaticTask_t xIdleTaskTCB;
  static StackType_t uxIdleTaskStack[ configMINIMAL_STACK_SIZE ];

  *ppxIdleTaskTCBBuffer = &amp;xIdleTaskTCB;
  *ppxIdleTaskStackBuffer = uxIdleTaskStack;
  *pulIdleTaskStackSize = configMINIMAL_STACK_SIZE;
}
</code></pre>
<p><em><strong>Listing 3.14</strong></em> <em>Typical implementation of vApplicationGetIdleTaskMemory</em></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="4-task-management-1"><a class="header" href="#4-task-management-1">4 Task Management</a></h1>
<h2 id="41-introduction"><a class="header" href="#41-introduction">4.1 Introduction</a></h2>
<h3 id="411-scope"><a class="header" href="#411-scope">4.1.1 Scope</a></h3>
<p>This chapter covers:</p>
<ul>
<li>How FreeRTOS allocates processing time to each task in an application.</li>
<li>How FreeRTOS chooses which task should execute at any given time.</li>
<li>How the relative priority of each task affects system behavior.</li>
<li>The states that a task can exist in.</li>
</ul>
<p>This chapter also discusses:</p>
<ul>
<li>How to implement tasks.</li>
<li>How to create one or more instances of a task.</li>
<li>How to use the task parameter.</li>
<li>How to change the priority of a task that has already been created.</li>
<li>How to delete a task.</li>
<li>How to implement periodic processing using a task. (A later chapter
describes how to do the same using software timers.)</li>
<li>When the idle task will execute and how it can be used.</li>
</ul>
<p>The concepts presented in this chapter are fundamental to understanding
how to use FreeRTOS and how FreeRTOS applications behave. Therefore,
this is the most detailed chapter in the book.</p>
<h2 id="42-task-functions"><a class="header" href="#42-task-functions">4.2 Task Functions</a></h2>
<p>Tasks are implemented as C functions. Tasks must implement the expected function
prototype shown in Listing 4.1. which takes a void pointer parameter and returns
void.</p>
<p><a name="list4.1" title="Listing 4.1 The task function prototype"></a></p>
<pre><code class="language-c">void vATaskFunction( void * pvParameters );
</code></pre>
<p><em><strong>Listing 4.1</strong></em> <em>The task function prototype</em></p>
<p>Each task is a small program in its own right. It has an entry point,
will normally run forever in an infinite loop, and does not exit.
Listing 4.2 shows the structure of a typical task.</p>
<p>A FreeRTOS task must not be allowed to return from the function that implements
it in any way. It must not contain a 'return' statement and must
not be allowed to execute past the end of its implementing function.
If a task is no longer required, it should be explicitly deleted as
demonstrated in Listing 4.2.</p>
<p>A single task function definition can be used to create any number of
tasks where each created task is a separate execution instance. Each instance has
its own stack and thus its own copy of any automatic (stack) variables defined
within the task itself.</p>
<p><a name="list4.2" title="Listing 4.2 The structure of a typical task function"></a></p>
<pre><code class="language-c">void vATaskFunction( void * pvParameters )
{
    /*
     * Stack-allocated variables can be declared normally when inside a function.
     * Each instance of a task created using this example function will have its
     * own separate instance of lStackVariable allocated on the task's stack.
     */
    long lStackVariable = 0;

    /*
     * In contrast to stack allocated variables, variables declared with the `static`
     * keyword are allocated to a specific location in memory by the linker.
     * This means that all tasks calling vATaskFunction will share the same
     * instance of lStaticVariable.
     */
    static long lStaticVariable = 0;

    for( ;; )
    {
        /* The code to implement the task functionality will go here. */
    }

    /*
     * If the task implementation ever exits the above loop, then the task
     * must be deleted before reaching the end of its implementing function.
     * When NULL is passed as a parameter to the vTaskDelete() API function,
     * this indicates that the task to be deleted is the calling (this) task.
     */
    vTaskDelete( NULL );
}
</code></pre>
<p><em><strong>Listing 4.2</strong></em> <em>The structure of a typical task function</em></p>
<h2 id="43-top-level-task-states"><a class="header" href="#43-top-level-task-states">4.3 Top Level Task States</a></h2>
<p>An application may consist of many tasks. If the processor running the
application includes a single core, then only one task may be executing
at any given time. This implies that a task may exist in one of two
states: <em>Running</em> and <em>Not Running</em>. This simplistic model is considered
first. Later in this chapter we describe the several sub-states of the
<em>Not Running</em> state.</p>
<p>A task is in the <em>Running</em> state when the processor is executing that task's
code. When a task is in the <em>Not Running</em> state, the task is paused and its
state has been saved so that it may resume execution the next time the scheduler
decides it should enter the <em>Running</em> state. When a task resumes execution,
it does so from the instruction it was about to execute before it left the
<em>Running</em> state.</p>
<p><a name="fig4.1" title="Figure 4.1 Top level task states and transitions"></a></p>
<hr />
<p><img src="media/figure_4.1_top_level_task_states.png" alt="" /><br />
<em><strong>Figure 4.1</strong></em> <em>Top level task states and transitions</em></p>
<hr />
<p>A task transitioned from the <em>Not Running</em> state to the <em>Running</em> state is
said to have been "switched in" or "swapped in". Conversely, a task
transitioned from the <em>Running</em> state to the <em>Not Running</em> state is said to
have been "switched out" or "swapped out". The FreeRTOS scheduler is the
only entity that can switch a task in and out of the <em>Running</em> state.</p>
<h2 id="44-task-creation"><a class="header" href="#44-task-creation">4.4 Task Creation</a></h2>
<p>Six API functions may be used to create tasks:
<code>xTaskCreate()</code>,
<code>xTaskCreateStatic()</code>,
<code>xTaskCreateRestricted()</code>,
<code>xTaskCreateRestrictedStatic()</code>,
<code>xTaskCreateAffinitySet()</code>, and
<code>xTaskCreateStaticAffinitySet()</code></p>
<p>Each task requires two blocks of RAM: one to hold its Task Control Block (TCB)
and one to store its stack. FreeRTOS API functions with "Static" in their names
use pre-allocated blocks of RAM passed into the functions as parameters.
Conversely, API functions without "Static" in their names allocate the required
RAM dynamically at runtime from the system heap.</p>
<p>Some FreeRTOS ports support tasks running in a "restricted" or "unprivileged" mode.
FreeRTOS API functions with "Restricted" in their names create tasks that
execute with limited access to the system's memory. API functions without
"Restricted" in their names create tasks that execute in "privileged mode" and
have access to the system's entire memory map.</p>
<p>FreeRTOS ports that support Symmetric Multi Processing (SMP) allow different tasks
to run simultaneously on multiple cores of the same CPU. For these ports, you may
specify which core a task will run on by using functions with "Affinity" in the name.</p>
<p>The FreeRTOS task creation API functions are quite complex. Most examples in this
document use <code>xTaskCreate()</code> because it is the simplest of these functions.</p>
<h3 id="441-the-xtaskcreate-api-function"><a class="header" href="#441-the-xtaskcreate-api-function">4.4.1 The xTaskCreate() API Function</a></h3>
<p>Listing 4.3 shows the <code>xTaskCreate()</code> API function prototype.
<code>xTaskCreateStatic()</code> has two additional parameters that point to the
memory pre-allocated to hold the task's data structure and stack,
respectively. <a href="ch02.html#25-data-types-and-coding-style-guide">Section 2.5: Data Types and Coding Style Guide</a>
describes the data types and naming conventions used.</p>
<p><a name="list4.3" title="Listing 4.3 The xTaskCreate() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xTaskCreate( TaskFunction_t pvTaskCode,
                        const char * const pcName,
                        configSTACK_DEPTH_TYPE usStackDepth,
                        void * pvParameters,
                        UBaseType_t uxPriority,
                        TaskHandle_t * pxCreatedTask );
</code></pre>
<p><em><strong>Listing 4.3</strong></em> <em>The xTaskCreate() API function prototype</em></p>
<p><strong>xTaskCreate() Parameters and return value:</strong></p>
<ul>
<li>
<p><code>pvTaskCode</code></p>
<p>Tasks are simply C functions that never exit and, as such, are normally
implemented as an infinite loop. The <code>pvTaskCode</code> parameter is simply a
pointer to the function that implements the task (in effect, just the
function's name).</p>
</li>
<li>
<p><code>pcName</code></p>
<p>A descriptive name for the task. FreeRTOS does not use this in
any way and it is included purely as a debugging aid. Identifying a task by
a human-readable name is much simpler than identifying it by its handle.</p>
<p>The application-defined constant <code>configMAX_TASK_NAME_LEN</code> defines the
maximum length a task name can be, including the NULL terminator.
Supplying a longer string results in the string being truncated.</p>
</li>
<li>
<p><code>usStackDepth</code></p>
<p>Specifies the size of the stack to allocate for use by the task.
Use <code>xTaskCreateStatic()</code> instead of <code>xTaskCreate()</code> to use pre-allocated
memory instead of dynamically allocated memory.</p>
<p>Note the value specifies the number of words the stack can hold, not
the number of bytes. For example, if the stack is 32-bits wide and
<code>usStackDepth</code> is 128, then <code>xTaskCreate()</code> allocates 512 bytes of stack
space (128 * 4 bytes).</p>
<p><code>configSTACK_DEPTH_TYPE</code> is a macro that allows the application writer
to specify the data type used to hold stack sizes. <code>configSTACK_DEPTH_TYPE</code>
defaults to <code>uint16_t</code> if left undefined, so #define <code>configSTACK_DEPTH_TYPE</code>
to <code>unsigned long</code> or <code>size_t</code> in <code>FreeRTOSConfig.h</code> if the stack depth multiplied
by the stack width is greater than 65535 (the largest possible 16-bit number).</p>
<p><a href="ch13.html#133-stack-overflow">Section 13.3 Stack Overflow</a>, describes a
practical method of choosing an optimal stack size.</p>
</li>
<li>
<p><code>pvParameters</code></p>
<p>Functions that implement tasks accept a single void pointer (<code>void *</code>)
parameter. <code>pvParameters</code> is the value passed into the task using that
parameter.</p>
</li>
<li>
<p><code>uxPriority</code></p>
<p>Defines the task's priority. 0 is the lowest priority and
<code>(configMAX_PRIORITIES – 1)</code> is the highest priority. <a href="ch04.html#45-task-priorities">Section 4.5</a>
describes the user defined <code>configMAX_PRIORITIES</code> constant.</p>
<p>If a <code>uxPriority</code> greater than <code>(configMAX_PRIORITIES – 1)</code> is defined, it will
be capped to <code>(configMAX_PRIORITIES – 1)</code>.</p>
</li>
<li>
<p><code>pxCreatedTask</code></p>
<p>Pointer to a location to store a handle to the created task. This handle may
be used in future API calls to, for example, change the task's priority or delete
the task.</p>
<p><code>pxCreatedTask</code> is an optional parameter and may be set to NULL if the
task's handle is not required.</p>
</li>
<li>
<p>Return values</p>
<p>There are two possible return values:</p>
<ul>
<li>
<p><code>pdPASS</code></p>
<p>This indicates the task was created successfully.</p>
</li>
<li>
<p><code>pdFAIL</code></p>
<p>This indicates there was not enough heap memory available to create
the task. <a href="ch03.html#3-heap-memory-management">Chapter 3</a> provides more
information on heap memory management.</p>
</li>
</ul>
</li>
</ul>
<h2 id=""><a class="header" href="#"><a name="example4.1" title="Example 4.1 Creating tasks"></a></a></h2>
<p><em><strong>Example 4.1</strong></em> <em>Creating tasks</em></p>
<hr />
<p>The following example demonstrates the steps needed to create two simple tasks
and then start the newly created tasks. The tasks simply print out a string
periodically by using a crude busy loop to create the period delay. Both
tasks are created at the same priority and are identical except for the
string they print out—see Listing 4.4 and Listing 4.5 for their respective
implementations. See chapter 8 for warnings about using <code>printf()</code> in
tasks.</p>
<p><a name="list4.4" title="Listing 4.4 Implementation of the first task used in Example 4.1"></a></p>
<pre><code class="language-c">void vTask1( void * pvParameters )
{
    /* ulCount is declared volatile to ensure it is not optimized out. */
    volatile unsigned long ulCount;

    for( ;; )
    {
        /* Print out the name of the current task task. */
        vPrintLine( "Task 1 is running" );

        /* Delay for a period. */
        for( ulCount = 0; ulCount &lt; mainDELAY_LOOP_COUNT; ulCount++ )
        {
            /*
             * This loop is just a very crude delay implementation. There is
             * nothing to do in here. Later examples will replace this crude
             * loop with a proper delay/sleep function.
             */
        }
    }
}
</code></pre>
<p><em><strong>Listing 4.4</strong></em> <em>Implementation of the first task used in Example 4.1</em></p>
<p><a name="list4.5" title="Listing 4.5 Implementation of the second task used in Example 4.1"></a></p>
<pre><code class="language-c">void vTask2( void * pvParameters )
{
    /* ulCount is declared volatile to ensure it is not optimized out. */
    volatile unsigned long ulCount;

    /* As per most tasks, this task is implemented in an infinite loop. */
    for( ;; )
    {
        /* Print out the name of this task. */
        vPrintLine( "Task 2 is running" );

        /* Delay for a period. */
        for( ulCount = 0; ulCount &lt; mainDELAY_LOOP_COUNT; ulCount++ )
        {
            /*
             * This loop is just a very crude delay implementation. There is
             * nothing to do in here. Later examples will replace this crude
             * loop with a proper delay/sleep function.
             */
        }
    }
}
</code></pre>
<p><em><strong>Listing 4.5</strong></em> <em>Implementation of the second task used in Example 4.1</em></p>
<p>The main() function creates the tasks before starting the scheduler—see
Listing 4.6 for its implementation.</p>
<p><a name="list4.6" title="Listing 4.6 Starting the Example 4.1 tasks"></a></p>
<pre><code class="language-c">int main( void )
{
    /*
     * Variables declared here may no longer exist after starting the FreeRTOS
     * scheduler. Do not attempt to access variables declared on the stack used
     * by main() from tasks.
     */

    /*
     * Create one of the two tasks. Note that a real application should check
     * the return value of the xTaskCreate() call to ensure the task was
     * created successfully.
     */
    xTaskCreate( vTask1,  /* Pointer to the function that implements the task.*/
                 "Task 1",/* Text name for the task. */
                 1000,    /* Stack depth in words. */
                 NULL,    /* This example does not use the task parameter. */
                 1,       /* This task will run at priority 1. */
                 NULL );  /* This example does not use the task handle. */

    /* Create the other task in exactly the same way and at the same priority.*/
    xTaskCreate( vTask2, "Task 2", 1000, NULL, 1, NULL );

    /* Start the scheduler so the tasks start executing. */
    vTaskStartScheduler();

    /*
     * If all is well main() will not reach here because the scheduler will now
     * be running the created tasks. If main() does reach here then there was
     * not enough heap memory to create either the idle or timer tasks
     * (described later in this book). Chapter 3 provides more information on
     * heap memory management.
     */
    for( ;; );
}
</code></pre>
<p><em><strong>Listing 4.6</strong></em> <em>Starting the Example 4.1 tasks</em></p>
<p>Executing the example produces the output shown in Figure 4.2.</p>
<p><a name="fig4.2" title="Figure 4.2 The output produced when executing Example 4.1"></a></p>
<hr />
<pre><code class="language-console">C:\Temp&gt;rtosdemo
Task 1 is running
Task 2 is running
Task 1 is running
Task 2 is running
Task 1 is running
Task 2 is running
Task 1 is running
Task 2 is running
Task 1 is running
Task 2 is running
Task 1 is running
Task 2 is running
Task 1 is running
Task 2 is running
</code></pre>
<p><em><strong>Figure 4.2</strong></em> <em>The output produced when executing Example 4.1<sup class="footnote-reference"><a href="#4">1</a></sup></em></p>
<hr />
<div class="footnote-definition" id="4"><sup class="footnote-definition-label">1</sup>
<p>The screen shot shows each task printing out its message exactly
once before the next task executes. This is an artificial scenario
that results from using the FreeRTOS Windows simulator. The Windows
simulator is not truly real time. Also, writing to the Windows
console takes a relatively long time and results in a chain of
Windows system calls. Executing the same code on a genuine embedded
target with a fast and non-blocking print function may result in
each task printing its string many times before being switched out
to allow the other task to run.</p>
</div>
<p>Figure 4.2 shows the two tasks appearing to execute simultaneously;
however, both tasks execute on the same processor core, so that cannot
be the case. In reality, both tasks are rapidly entering and exiting the
<em>Running</em> state. Both tasks are running at the same priority and so share
time on the same processor core. Figure 4.3 shows their actual execution
pattern.</p>
<p>The arrow along the bottom of Figure 4.3 shows time passing from time t1
onwards. The colored lines show which task is executing at each point in
time—for example, Task 1 is executing between times t1 and t2.</p>
<p>Only one task can exist in the <em>Running</em> state at any one time. So, as one
task enters the <em>Running</em> state (the task is switched in), the other
enters the <em>Not Running</em> state (the task is switched out).</p>
<p><a name="fig4.3" title="Figure 4.3 The actual execution pattern of the two Example 4.1 tasks"></a></p>
<hr />
<p><img src="media/figure_4.3_example_4.1_execution_pattern.png" alt="" /><br />
<em><strong>Figure 4.3</strong></em> <em>The actual execution pattern of the two Example 4.1 tasks</em></p>
<hr />
<p>Example 4.1 created both tasks from within <code>main()</code>, prior to starting the
scheduler. It is also possible to create a task from within another
task. For example, Task 2 could have been created from within Task 1, as
shown by Listing 4.7.</p>
<p><a name="list4.7" title="Listing 4.7 Creating a task from within another task after the scheduler has started"></a></p>
<pre><code class="language-c">void vTask1( void * pvParameters )
{
    const char *pcTaskName = "Task 1 is running\r\n";
    volatile unsigned long ul; /* volatile to ensure ul is not optimized away. */

    /*
     * If this task code is executing then the scheduler must already have
     * been started. Create the other task before entering the infinite loop.
     */
    xTaskCreate( vTask2, "Task 2", 1000, NULL, 1, NULL );

    for( ;; )
    {
        /* Print out the name of this task. */
        vPrintLine( pcTaskName );

        /* Delay for a period. */
        for( ul = 0; ul &lt; mainDELAY_LOOP_COUNT; ul++ )
        {
            /*
             * This loop is just a very crude delay implementation. There is
             * nothing to do in here. Later examples will replace this crude
             * loop with a proper delay/sleep function.
             */
        }
    }
}
</code></pre>
<p><em><strong>Listing 4.7</strong></em> <em>Creating a task from within another task after the scheduler has started</em></p>
<h2 id="-1"><a class="header" href="#-1"><a name="example4.2" title="Example 4.2 Using the task parameter"></a></a></h2>
<p><em><strong>Example 4.2</strong></em> <em>Using the task parameter</em></p>
<hr />
<p>The two tasks created in Example 4.1 are almost identical, the only
difference between them is the text string they print out. If you create
two instances of a single task implementation, and use the task
parameter to pass the string into each instance, this would remove the
duplication.</p>
<p>Example 4.2 replaces the two task functions used in Example 4.1 with a
single task function called <code>vTaskFunction()</code>, as shown in Listing 4.8.
Note how the task parameter is cast to a <code>char *</code> to obtain the string
the task should print out.</p>
<p><a name="list4.8" title="Listing 4.8 The single task function used to create two tasks in Example 4.2"></a></p>
<pre><code class="language-c">void vTaskFunction( void * pvParameters )
{

    char *pcTaskName;
    volatile unsigned long ul; /* volatile to ensure ul is not optimized away. */

    /*
     * The string to print out is passed in via the parameter. Cast this to a
     * character pointer.
     */
    pcTaskName = ( char * ) pvParameters;

    /* As per most tasks, this task is implemented in an infinite loop. */
    for( ;; )
    {
        /* Print out the name of this task. */
        vPrintLine( pcTaskName );

        /* Delay for a period. */
        for( ul = 0; ul &lt; mainDELAY_LOOP_COUNT; ul++ )
        {
            /*
             * This loop is just a very crude delay implementation. There is
             * nothing to do in here. Later exercises will replace this crude
             * loop with a proper delay/sleep function.
             */
        }
    }
}
</code></pre>
<p><em><strong>Listing 4.8</strong></em> <em>The single task function used to create two tasks in Example 4.2</em></p>
<p>Listing 4.9 creates two instances of the task implemented by
<code>vTaskFunction()</code>, using the task's parameter to pass a different string
into each. Both tasks execute independently under the control of the
FreeRTOS scheduler and with their own stack, and so with their own copies of
the <code>pcTaskName</code> and <code>ul</code> variables.</p>
<p><a name="list4.9" title="Listing 4.9 The main() function for Example 2"></a></p>
<pre><code class="language-c">/*
 * Define the strings that will be passed in as the task parameters. These are
 * defined const and not on the stack used by main() to ensure they remain
 * valid when the tasks are executing.
 */
static const char * pcTextForTask1 = "Task 1 is running";
static const char * pcTextForTask2 = "Task 2 is running";

int main( void )
{
    /*
     * Variables declared here may no longer exist after starting the FreeRTOS
     * scheduler. Do not attempt to access variables declared on the stack used
     * by main() from tasks.
     */

    /* Create one of the two tasks. */
    xTaskCreate( vTaskFunction,             /* Pointer to the function that 
                                               implements the task. */
                 "Task 1",                  /* Text name for the task. This is to
                                               facilitate debugging only. */
                 1000,                      /* Stack depth - small microcontrollers
                                               will use much less stack than this.*/
                 ( void * ) pcTextForTask1, /* Pass the text to be printed into
                                               the task using the task parameter. */
                 1,                         /* This task will run at priority 1. */
                 NULL );                    /* The task handle is not used in
                                               this example. */

    /*
     * Create the other task in exactly the same way. Note this time that
     * multiple tasks are being created from the SAME task implementation
     * (vTaskFunction). Only the value passed in the parameter is different.
     * Two instances of the same task definition are being created.
     */
    xTaskCreate( vTaskFunction,
                 "Task 2",
                 1000,
                 ( void * ) pcTextForTask2,
                 1,
                 NULL );

    /* Start the scheduler so the tasks start executing. */
    vTaskStartScheduler();

    /*
     * If all is well main() will not reach here because the scheduler will
     * now be running the created tasks. If main() does reach here then there
     * was not enough heap memory to create either the idle or timer tasks
     * (described later in this book). Chapter 3 provides more information on
     * heap memory management.
     */
    for( ;; )
    {
    }
}
</code></pre>
<p><em><strong>Listing 4.9</strong></em> <em>The main() function for Example 2</em></p>
<p>The output from Example 4.2 is exactly as per that shown for example 1 in Figure
4.2.</p>
<h2 id="45-task-priorities"><a class="header" href="#45-task-priorities">4.5 Task Priorities</a></h2>
<p>The FreeRTOS scheduler always ensures the highest priority task that can
run is the task selected to enter the <em>Running</em> state. Tasks of equal
priority are transitioned into and out of the <em>Running</em> state in turn.</p>
<p>The <code>uxPriority</code> parameter of the API function used to create the task
gives the task its initial priority. The <code>vTaskPrioritySet()</code> API function
changes a task's priority after its creation.</p>
<p>The application-defined <code>configMAX_PRIORITIES</code> compile-time configuration
constant sets the number of available priorities. Low numeric priority
values denote low-priority tasks, with priority 0 being the lowest
priority possible—so valid priorities range from 0 to
<code>(configMAX_PRIORITIES – 1)</code>. Any number of tasks can share the same
priority.</p>
<p>The FreeRTOS scheduler has two implementations of the algorithm used to
select the <em>Running</em> state task and the maximum allowable value for
<code>configMAX_PRIORITIES</code> depends on the implementation used:</p>
<h3 id="451-generic-scheduler"><a class="header" href="#451-generic-scheduler">4.5.1 Generic Scheduler</a></h3>
<p>The generic scheduler is written in C and can be used with all FreeRTOS
architecture ports. It does not impose an upper limit on <code>configMAX_PRIORITEIS</code>.
In general, it is advisable to minimize <code>configMAX_PRIORITIES</code> because more
values require more RAM and will result in a longer worst-case execution time.</p>
<h3 id="452-architecture-optimized-scheduler"><a class="header" href="#452-architecture-optimized-scheduler">4.5.2 Architecture-Optimized Scheduler</a></h3>
<p>Architecture optimized implementations are written in architecture-specific
assembly code and are more performant than the generic c implementation, and the
worst-case execution time is the same for all <code>configMAX_PRIORITIES</code> values.</p>
<p>The architecture optimized implementation imposes a maximum value for
<code>configMAX_PRIORITIES</code> of 32 on 32-bit architectures and 64 on 64-bit
architectures. As with the generic method, it is advisable to keep
<code>configMAX_PRIORITIES</code> at the lowest value practical because higher
values require more RAM.</p>
<p>Set <code>configUSE_PORT_optimized_TASK_SELECTION</code> to 1 in FreeRTOSConfig.h to
use the architecture optimized implementation, or 0 to use the generic
implementation. Not all FreeRTOS ports have an architecture optimized
implementation. Those that do default
<code>configUSE_PORT_optimized_TASK_SELECTION</code> to 1 if it is left undefined.
Those that do not, default <code>configUSE_PORT_optimized_TASK_SELECTION</code> to 0
if it is left undefined.</p>
<h2 id="46-time-measurement-and-the-tick-interrupt"><a class="header" href="#46-time-measurement-and-the-tick-interrupt">4.6 Time Measurement and the Tick Interrupt</a></h2>
<p><a href="ch04.html#412-scheduling-algorithms">Section 4.12, Scheduling Algorithms</a>, describes an
optional feature called 'time slicing'. Time slicing was used in the examples
presented so far, and is the behavior observed in the output they produced.
In the examples, both tasks were created at the same priority, and both
tasks were always able to run. Therefore, each task executed for a 'time
slice', entering the <em>Running</em> state at the start of a time slice, and
exiting the <em>Running</em> state at the end of a time slice. In Figure 4.3, the
time between t1 and t2 equals a single time slice.</p>
<p>The scheduler executes at the end of each time slice to select the next
task to run<sup class="footnote-reference"><a href="#5">2</a></sup>. A periodic interrupt, called the 'tick interrupt', is
used for this purpose. The <code>configTICK_RATE_HZ</code> compile-time configuration
constant sets the frequency of the tick interrupt, and so also the
length of each time slice. For example, setting <code>configTICK_RATE_HZ</code> to
100 (Hz) results in each time slice lasting 10 milliseconds. The time
between two tick interrupts is called the 'tick period'—so one time
slice equals one tick period.</p>
<div class="footnote-definition" id="5"><sup class="footnote-definition-label">2</sup>
<p>It is important to note that the end of a time slice is not the
only place that the scheduler can select a new task to run. As we will
demonstrate throughout this book, the scheduler will also select
a new task to run immediately after the currently executing task
enters the <em>Blocked</em> state, or when an interrupt moves a higher
priority task into the <em>Ready</em> state.</p>
</div>
<p>Figure 4.4 expands on Figure 4.3 to also show the execution of the
scheduler. In Figure 4.4, the top line shows when the scheduler is
executing, and the thin arrows show the sequence of execution from a
task to the tick interrupt, then from the tick interrupt back to a
different task.</p>
<p>The optimal value for <code>configTICK_RATE_HZ</code> depends on the application,
although a value of 100 is typical.</p>
<p><a name="fig4.4" title="Figure 4.4 The execution sequence expanded to show the tick interrupt executing"></a></p>
<hr />
<p><img src="media/figure_4.4_expanded_execution_sequence_with_tick_interrupt.png" alt="" /><br />
<em><strong>Figure 4.4</strong></em> <em>The execution sequence expanded to show the tick interrupt executing</em></p>
<hr />
<p>FreeRTOS API calls specify time in multiples of tick periods, often
referred to simply as 'ticks'. The <code>pdMS_TO_TICKS()</code> macro converts a time
specified in milliseconds into a time specified in ticks. The resolution
available depends on the defined tick frequency, and <code>pdMS_TO_TICKS()</code>
cannot be used if the tick frequency is above 1KHz (if
<code>configTICK_RATE_HZ</code> is greater than 1000). Listing 4.10 shows how to use
<code>pdMS_TO_TICKS()</code> to convert a time specified as 200 milliseconds into an
equivalent time specified in ticks.</p>
<p><a name="list4.10" title="Listing 4.10 Using the pdMS\_TO\_TICKS() macro to convert 200 milliseconds..."></a></p>
<pre><code class="language-c">/*
 * pdMS_TO_TICKS() takes a time in milliseconds as its only parameter,
 * and evaluates to the equivalent time in tick periods. This example shows
 * xTimeInTicks being set to the number of tick periods that are equivalent
 * to 200 milliseconds.
 */
TickType_t xTimeInTicks = pdMS_TO_TICKS( 200 );
</code></pre>
<p><em><strong>Listing 4.10</strong></em> <em>Using the pdMS_TO_TICKS() macro to convert 200 milliseconds
into an equivalent time in tick periods</em></p>
<p>Using <code>pdMS_TO_TICKS()</code> to specify times in milliseconds, rather than
directly as ticks, ensures times specified within the application do not
change if the tick frequency is changed.</p>
<p>The 'tick count' is the total number of tick interrupts that have
occurred since the scheduler started, assuming the tick count has not
overflowed. User applications do not have to consider overflows when
specifying delay periods, as FreeRTOS manages time consistency
internally.</p>
<p><a href="ch04.html#412-scheduling-algorithms">Section 4.12: Scheduling Algorithms</a>
describes configuration constants which affect when the scheduler will
select a new task to run and when a tick interrupt will execute.</p>
<h2 id="-2"><a class="header" href="#-2"><a name="example4.3" title="Example 4.3 Experimenting with priorities"></a></a></h2>
<p><em><strong>Example 4.3</strong></em> <em>Experimenting with priorities</em></p>
<hr />
<p>The scheduler will always ensure the highest priority task that can run
is the task selected to enter the <em>Running</em> state. The examples so far
created two tasks at the same priority, so both entered and exited the
<em>Running</em> state in turn. This example looks at what happens when the tasks
have different priorities. Listing 4.11 shows the code used to create the
tasks, the first with priority 1, and the second with priority 2. The
single function that implements both tasks has not changed; it still
periodically prints a string, using a null loop to create a delay.</p>
<p><a name="list4.11" title="Listing 4.11. Creating two tasks at different priorities"></a></p>
<pre><code class="language-c">/*
 * Define the strings that will be passed in as the task parameters.
 * These are defined const and not on the stack to ensure they remain valid
 * when the tasks are executing.
 */
static const char * pcTextForTask1 = "Task 1 is running";
static const char * pcTextForTask2 = "Task 2 is running";

int main( void )
{
    /* Create the first task with a priority of 1. */
    xTaskCreate( vTaskFunction,             /* Task Function    */
                 "Task 1",                  /* Task Name        */
                 1000,                      /* Task Stack Depth */
                 ( void * ) pcTextForTask1, /* Task Parameter   */
                 1,                         /* Task Priority    */
                 NULL );

    /* Create the second task at a higher priority of 2. */
    xTaskCreate( vTaskFunction,             /* Task Function    */
                 "Task 2",                  /* Task Name        */
                 1000,                      /* Task Stack Depth */
                 ( void * ) pcTextForTask2, /* Task Parameter   */
                 2,                         /* Task Priority    */
                 NULL );

    /* Start the scheduler so the tasks start executing. */
    vTaskStartScheduler();

    /* Will not reach here. */
    return 0;
}
</code></pre>
<p><em><strong>Listing 4.11</strong></em> <em>Creating two tasks at different priorities</em></p>
<p>Figure 4.5 shows the output produced by Example 4.3.</p>
<p>The scheduler will always select the highest priority task that can run.
Task 2 has a higher priority than Task 1 and can always run; therefore,
the scheduler always selects Task 2, and Task 1 never executes. Task 1
is said to be 'starved' of processing time by Task 2—it can't print its
string because it is never in the <em>Running</em> state.</p>
<p><a name="fig4.5" title="Figure 4.5 Running both tasks at different priorities"></a></p>
<hr />
<pre><code class="language-console">C:\Temp&gt;rtosdemo
Task 2 is running
Task 2 is running
Task 2 is running
Task 2 is running
Task 2 is running
Task 2 is running
Task 2 is running
Task 2 is running
Task 2 is running
Task 2 is running
Task 2 is running
Task 2 is running
Task 2 is running
Task 2 is running
Task 2 is running
</code></pre>
<p><em><strong>Figure 4.5</strong></em> <em>Running both tasks at different priorities</em></p>
<hr />
<p>Task 2 can always run because it never has to wait for anything—it is
either cycling around a null loop or printing to the terminal.</p>
<p><a name="fig4.6" title="Figure 4.6 The execution pattern when one task has a higher priority than the..."></a></p>
<hr />
<p><img src="media/figure_4.6_execution_pattern_higher_priority_task.png" alt="" /><br />
<em><strong>Figure 4.6</strong></em> <em>The execution pattern when one task has a higher priority than the
other from Example 4.3</em></p>
<h2 id="47-expanding-the-not-running-state"><a class="header" href="#47-expanding-the-not-running-state">4.7 Expanding the <em>Not Running</em> State</a></h2>
<p>So far, the created tasks have always had processing to perform and have
never had to wait for anything—and since they never had to wait for anything,
they were always able to enter the <em>Running</em> state. Such 'continuous processing'
tasks have limited usefulness because they can only be created at the very lowest
priority. If they run at any other priority, they will prevent tasks of lower
priority from ever running at all.</p>
<p>To make these tasks useful, they must be re-written to be event-driven. An
event-driven task only has work (processing) to perform after an event
triggers it and cannot enter the <em>Running</em> state before that time.
The scheduler always selects the highest priority task that can run. If
a high-priority task cannot be selected because it is waiting for an
event, the scheduler must, instead, select a lower-priority task that
can run. Therefore, writing event-driven tasks means tasks can be
created at different priorities without the highest priority tasks
starving all the lower priority tasks of processing time.</p>
<h3 id="471-the-blocked-state"><a class="header" href="#471-the-blocked-state">4.7.1 The <em>Blocked</em> State</a></h3>
<p>A task waiting for an event is said to be in the 'Blocked' state, a
sub-state of the <em>Not Running</em> state.</p>
<p>Tasks can enter the <em>Blocked</em> state to wait for two different types of
events:</p>
<ol>
<li>
<p>Temporal (time-related) events— these events occur either when a delay period
expires or an absolute time is reached. For example, a task may
enter the <em>Blocked</em> state to wait for 10 milliseconds to pass.</p>
</li>
<li>
<p>Synchronization events— these events originate from another task
or interrupt. For example, a task may enter the <em>Blocked</em> state to
wait for data to arrive on a queue. Synchronization events cover a
broad range of event types.</p>
</li>
</ol>
<p>FreeRTOS queues, binary semaphores, counting semaphores, mutexes,
recursive mutexes, event groups, stream buffers, message buffers, and
direct to task notifications can all create synchronization events.
Later chapters cover most of these features.</p>
<p>A task can block on a synchronization event with a timeout, effectively
blocking on both types of event simultaneously. For example, a task may
choose to wait for a maximum of 10 milliseconds for data to arrive on a
queue. The task will leave the <em>Blocked</em> state if data arrives within 10
milliseconds or if 10 milliseconds pass without data arriving.</p>
<h3 id="472-the-suspended-state"><a class="header" href="#472-the-suspended-state">4.7.2 The <em>Suspended</em> State</a></h3>
<p><em>Suspended</em> is also a sub-state of <em>Not Running</em>. Tasks in the Suspended
state are not available to the scheduler. The only way to enter the
Suspended state is through a call to the <code>vTaskSuspend()</code> API function,
and the only way out is through a call to the <code>vTaskResume()</code> or
<code>xTaskResumeFromISR()</code> API functions. Most applications do not use the
Suspended state.</p>
<h3 id="473-the-ready-state"><a class="header" href="#473-the-ready-state">4.7.3 The Ready State</a></h3>
<p>Tasks that are in the <em>Not Running</em> state and are not <em>Blocked</em> or <em>Suspended</em>
are said to be in the <em>Ready</em> state. They can run, and are therefore 'ready' to
run, but are not currently in the <em>Running</em> state.</p>
<h3 id="474-completing-the-state-transition-diagram"><a class="header" href="#474-completing-the-state-transition-diagram">4.7.4 Completing the State Transition Diagram</a></h3>
<p>Figure 4.7 expands on the simplified state diagram to include all of the
<em>Not Running</em> sub-states described in this section. The tasks created in the
examples so far have not used the <em>Blocked</em> or <em>Suspended</em> states. They have
only transitioned between the <em>Ready</em> state and the <em>Running</em> state as shown by
the bold lines in Figure 4.7.</p>
<p><a name="fig4.7" title="Figure 4.7 Full task state machine"></a></p>
<hr />
<p><img src="media/figure_4.7_full_task_state_machine.png" alt="" /><br />
<em><strong>Figure 4.7</strong></em> <em>Full task state machine</em></p>
<hr />
<h2 id="-3"><a class="header" href="#-3"><a name="example4.4" title="Example 4.4 Using the Blocked state to create a delay"></a></a></h2>
<p><em><strong>Example 4.4</strong></em> *Using the <em>Blocked</em> state to create a delay</i></h3></p>
<hr />
<p>All the tasks created in the examples presented so far have been
'periodic'—they have delayed for a period and then printed out their string,
before delaying once more, and so on. The delay has been generated very
crudely using a null loop—the task polled an incrementing
loop counter until it reached a fixed value. Example 4.3 clearly
demonstrated the disadvantage of this method. The higher priority task
remained in the <em>Running</em> state while it executed the null loop,
'starving' the lower priority task of any processing time.</p>
<p>There are several other disadvantages to any form of polling, not least
of which is its inefficiency. During polling, the task does not really
have any work to do, but it still uses the maximum processing time, and so
wastes processor cycles. Example 4.4 corrects this behavior by replacing
the polling null loop with a call to the <code>vTaskDelay()</code> API function, whose
prototype is shown in Listing 4.12. The new task definition is
shown in Listing 4.13. Note that the <code>vTaskDelay()</code> API function is
available only when <code>INCLUDE_vTaskDelay</code> is set to 1 in FreeRTOSConfig.h.</p>
<p><code>vTaskDelay()</code> places the calling task into the <em>Blocked</em> state for a fixed
number of tick interrupts. The task does not use any processing time
while it is in the <em>Blocked</em> state, so the task only uses processing time
when there is actually work to be done.</p>
<p><a name="list4.12" title="Listing 4.12 The vTaskDelay() API function prototype"></a></p>
<pre><code class="language-c">void vTaskDelay( TickType_t xTicksToDelay );
</code></pre>
<p><em><strong>Listing 4.12</strong></em> <em>The vTaskDelay() API function prototype</em></p>
<p><strong>vTaskDelay parameters:</strong></p>
<ul>
<li>
<p><code>xTicksToDelay</code></p>
<p>The number of tick interrupts that the calling task will remain
in the <em>Blocked</em> state before being transitioned back into the Ready
state.</p>
<p>For example, if a task called <code>vTaskDelay( 100 )</code> when the tick count
was 10,000, then it would immediately enter the <em>Blocked</em> state, and
remain in the <em>Blocked</em> state until the tick count reached 10,100.</p>
<p>The macro <code>pdMS_TO_TICKS()</code> can be used to convert a time specified in
milliseconds into a time specified in ticks. For example, calling
<code>vTaskDelay( pdMS_TO_TICKS( 100 ) )</code> results in the calling task remaining
in the <em>Blocked</em> state for 100 milliseconds.</p>
</li>
</ul>
<p><a name="list4.13" title="Listing 4.13 The source code for the example task after replacing the null loop delay with a call..."></a></p>
<pre><code class="language-c">void vTaskFunction( void * pvParameters )
{
    char * pcTaskName;
    const TickType_t xDelay250ms = pdMS_TO_TICKS( 250 );

    /*
     * The string to print out is passed in via the parameter. Cast this to a
     * character pointer.
     */
    pcTaskName = ( char * ) pvParameters;

    /* As per most tasks, this task is implemented in an infinite loop. */
    for( ;; )
    {
        /* Print out the name of this task. */
        vPrintLine( pcTaskName );

        /*
         * Delay for a period. This time a call to vTaskDelay() is used which
         * places the task into the Blocked state until the delay period has
         * expired. The parameter takes a time specified in 'ticks', and the
         * pdMS_TO_TICKS() macro is used (where the xDelay250ms constant is
         * declared) to convert 250 milliseconds into an equivalent time in
         * ticks.
         */
        vTaskDelay( xDelay250ms );
    }
}
</code></pre>
<p><em><strong>Listing 4.13</strong></em> <em>The source code for the example task after replacing the null loop
delay with a call to vTaskDelay()</em></p>
<p>Even though the two tasks are still being created at different
priorities, both will now run. The output of Example 4.4, which is shown
in Figure 4.8, confirms the expected behavior.</p>
<p><a name="fig4.8" title="Figure 4.8 The output produced when Example 4.4 is executed"></a></p>
<hr />
<pre><code class="language-console">C:\Temp&gt;rtosdemo
Task 2 is running
Task 1 is running
Task 2 is running
Task 1 is running
Task 2 is running
Task 1 is running
Task 2 is running
Task 1 is running
Task 2 is running
Task 1 is running
Task 2 is running
Task 1 is running
Task 2 is running
Task 1 is running
Task 2 is running
Task 1 is running
</code></pre>
<p><em><strong>Figure 4.8</strong></em> <em>The output produced when Example 4.4 is executed</em></p>
<hr />
<p>The execution sequence shown in Figure 4.9 explains why both tasks run,
even though they are created at different priorities. The execution of
the scheduler itself is omitted for simplicity.</p>
<p>The idle task is created automatically when the scheduler is started, to
ensure there is always at least one task that can run (at least one task
in the <em>Ready</em> state). <a href="ch04.html#48-the-idle-task-and-the-idle-task-hook">Section 4.8: The Idle Task and the Idle Task Hook</a>
describes the Idle task in more detail.</p>
<p><a name="fig4.9" title="Figure 4.9 The execution sequence when the tasks use vTaskDelay() in place of the null loop"></a></p>
<hr />
<p><img src="media/figure_4.9_vTaskDelay_execution_sequence.png" alt="" /><br />
<em><strong>Figure 4.9</strong></em> <em>The execution sequence when the tasks use vTaskDelay() in place of
the null loop</em></p>
<hr />
<p>Only the implementation of the two tasks has changed, not their
functionality. Comparing Figure 4.9 with Figure 4.4 demonstrates clearly
that this functionality is being achieved in a much more efficient
manner.</p>
<p>Figure 4.4 shows the execution pattern when the tasks use a null loop to
create a delay and so are always able to run. As a result, they use one
hundred percent of the available processor time between them. Figure 4.9
shows the execution pattern when the tasks enter the <em>Blocked</em> state for
the entirety of their delay period. They use processor time only when they
actually have work that needs to be performed (in this case simply a
message to be printed out), and as a result only use a tiny fraction of
the available processing time.</p>
<p>In the scenario shown in Figure 4.9, each time the tasks leave the <em>Blocked</em> state
they execute for a fraction of a tick period before re-entering the
Blocked state. Most of the time there are no application tasks that can
run (no application tasks in the <em>Ready</em> state) and, therefore, no
application tasks that can be selected to enter the <em>Running</em> state. While
this is the case, the idle task runs. The amount of processing time
allocated to the idle is a measure of the spare processing capacity in
the system. Using an RTOS can significantly increase the spare
processing capacity simply by allowing an application to be completely
event driven.</p>
<p>The bold lines in Figure 4.10 show the transitions performed by the tasks
in Example 4.4, with each task now transitioning through the <em>Blocked</em> state
before being returned to the <em>Ready</em> state.</p>
<p><a name="fig4.10" title="Figure 4.10 Bold lines indicate the state transitions performed by the tasks..."></a></p>
<hr />
<p><img src="media/figure_4.10_example_4.4_state_machine.png" alt="" /><br />
<em><strong>Figure 4.10</strong></em> <em>Bold lines indicate the state transitions performed by the tasks
in Example 4.4</em></p>
<hr />
<h3 id="475-the-vtaskdelayuntil-api-function"><a class="header" href="#475-the-vtaskdelayuntil-api-function">4.7.5 The vTaskDelayUntil() API Function</a></h3>
<p><code>vTaskDelayUntil()</code> is similar to <code>vTaskDelay()</code>. As just demonstrated, the
<code>vTaskDelay()</code> parameter specifies the number of tick interrupts that
should occur between a task calling <code>vTaskDelay()</code>, and the same task once
again transitioning out of the <em>Blocked</em> state. The length of time the
task remains in the blocked state is specified by the <code>vTaskDelay()</code>
parameter, but the time at which the task leaves the blocked state is
relative to the time at which <code>vTaskDelay()</code> was called.</p>
<p>The parameters to <code>vTaskDelayUntil()</code> specify, instead, the exact tick
count value at which the calling task should be moved from the Blocked
state into the <em>Ready</em> state. <code>vTaskDelayUntil()</code> is the API function to use
when a fixed execution period is required (where you want your task to
execute periodically with a fixed frequency), as the time at which the
calling task is unblocked is absolute, rather than relative to when the
function was called (as is the case with <code>vTaskDelay()</code>).</p>
<p><a name="list4.14" title="Listing 4.14 vTaskDelayUntil() API function prototype"></a></p>
<pre><code class="language-c">void vTaskDelayUntil( TickType_t * pxPreviousWakeTime,
                      TickType_t xTimeIncrement );
</code></pre>
<p><em><strong>Listing 4.14</strong></em> <em>vTaskDelayUntil() API function prototype</em></p>
<p><strong>vTaskDelayUntil() parameters</strong></p>
<ul>
<li>
<p><code>pxPreviousWakeTime</code></p>
<p>This parameter is named on the assumption that <code>vTaskDelayUntil()</code>
is being used to implement a task that executes periodically and with a
fixed frequency. In this case, <code>pxPreviousWakeTime</code> holds the time at
which the task last left the <em>Blocked</em> state (was 'woken' up). This time
is used as a reference point to calculate the time at which the task
should next leave the <em>Blocked</em> state.</p>
<p>The variable pointed to by <code>pxPreviousWakeTime</code> is updated
automatically in the <code>vTaskDelayUntil()</code> function; it would not
normally be modified by the application code, but must be initialized to
the current tick count before its first use. Listing 4.15 demonstrates how
to initialise the variable.</p>
</li>
<li>
<p><code>xTimeIncrement</code></p>
<p>This parameter is also named on the assumption that
<code>vTaskDelayUntil()</code> is being used to implement a task that executes
periodically and with a fixed frequency that is set by the
<code>xTimeIncrement</code> value.</p>
<p><code>xTimeIncrement</code> is specified in 'ticks'. The macro <code>pdMS_TO_TICKS()</code> can
be used to convert a time specified in milliseconds into a time
specified in ticks.</p>
</li>
</ul>
<h2 id="-4"><a class="header" href="#-4"><a name="example4.5" title="Example 4.5 Converting the example tasks to use vTaskDelayUntil()"></a></a></h2>
<p><em><strong>Example 4.5</strong></em> <em>Converting the example tasks to use vTaskDelayUntil()</em></p>
<hr />
<p>The two tasks created in Example 4.4 are periodic tasks, but using
<code>vTaskDelay()</code> does not guarantee that the frequency at which they run is
fixed, as the time at which the tasks leave the <em>Blocked</em> state is
relative to when they call <code>vTaskDelay()</code>. Converting the tasks to use
<code>vTaskDelayUntil()</code> instead of <code>vTaskDelay()</code> solves this potential problem.</p>
<p><a name="list4.15" title="Listing 4.15 The implementation of the example task using vTaskDelayUntil()"></a></p>
<pre><code class="language-c">void vTaskFunction( void * pvParameters )
{
    char * pcTaskName;
    TickType_t xLastWakeTime;

    /* 
     * The string to print out is passed in via the parameter. Cast this to a
     * character pointer. 
     */
    pcTaskName = ( char * ) pvParameters;

    /* 
     * The xLastWakeTime variable needs to be initialized with the current tick
     * count. Note that this is the only time the variable is written to
     * explicitly. After this xLastWakeTime is automatically updated within
     * vTaskDelayUntil(). 
     */
    xLastWakeTime = xTaskGetTickCount();

    /* As per most tasks, this task is implemented in an infinite loop. */
    for( ;; )
    {
        /* Print out the name of this task. */
        vPrintLine( pcTaskName );

        /* 
         * This task should execute every 250 milliseconds exactly. As per
         * the vTaskDelay() function, time is measured in ticks, and the
         * pdMS_TO_TICKS() macro is used to convert milliseconds into ticks.
         * xLastWakeTime is automatically updated within vTaskDelayUntil(), so
         * is not explicitly updated by the task. 
         */
        vTaskDelayUntil( &amp;xLastWakeTime, pdMS_TO_TICKS( 250 ) );
    }
}
</code></pre>
<p><em><strong>Listing 4.15</strong></em> <em>The implementation of the example task using vTaskDelayUntil()</em></p>
<p>The output produced by Example 4.5 is exactly as per that shown for Example 4.4
in Figure 4.8.</p>
<h2 id="-5"><a class="header" href="#-5"><a name="example4.6" title="Example 4.6 Combining blocking and non-blocking tasks"></a></a></h2>
<p><em><strong>Example 4.6</strong></em> <em>Combining blocking and non-blocking tasks</em></p>
<hr />
<p>The previous examples examined the behavior of both polling and blocking
tasks in isolation. This example re-enforces what we have already said regarding
the expected system behavior and demonstrates the execution sequence when the
two schemes are combined, as follows:</p>
<ol>
<li>
<p>Two tasks are created at priority 1. These do nothing other than continuously
print out a string.</p>
<p>These tasks never make API function calls that could cause them to enter the
<em>Blocked</em> state, so are always in either the Ready or the <em>Running</em> state.
Tasks of this nature are called 'continuous processing' tasks, as they always
have work to do (albeit rather trivial work, in this case).
Listing 4.16 shows the source code for the continuous processing tasks.</p>
</li>
<li>
<p>A third task is then created at priority 2, which is above the priority of
the other two tasks. The third task also just prints out a string, but this
time periodically, so it uses the <code>vTaskDelayUntil()</code> API function to place
itself into the <em>Blocked</em> state between each print iteration.</p>
</li>
</ol>
<p>Listing 4.17 shows the source code of the periodic task.</p>
<p><a name="list4.16" title="Listing 4.16 The continuous processing task used in Example 4.6"></a></p>
<pre><code class="language-c">void vContinuousProcessingTask( void * pvParameters )
{
    char * pcTaskName;

    /* 
     * The string to print out is passed in via the parameter. Cast this to a
     * character pointer. 
     */
    pcTaskName = ( char * ) pvParameters;

    /* As per most tasks, this task is implemented in an infinite loop. */
    for( ;; )
    {
        /* 
         * Print out the name of this task. This task just does this repeatedly
         * without ever blocking or delaying. 
         */
        vPrintLine( pcTaskName );
    }
}
</code></pre>
<p><em><strong>Listing 4.16</strong></em> <em>The continuous processing task used in Example 4.6</em></p>
<p><a name="list4.17" title="Listing 4.17 The periodic task used in Example 4.6"></a></p>
<pre><code class="language-c">void vPeriodicTask( void * pvParameters )
{
    TickType_t xLastWakeTime;

    const TickType_t xDelay3ms = pdMS_TO_TICKS( 3 );

    /*
     * The xLastWakeTime variable needs to be initialized with the current tick
     * count. Note that this is the only time the variable is explicitly
     * written to. After this xLastWakeTime is managed automatically by the
     * vTaskDelayUntil() API function.
     */
    xLastWakeTime = xTaskGetTickCount();

    /* As per most tasks, this task is implemented in an infinite loop. */
    for( ;; )
    {
        /* Print out the name of this task. */
        vPrintLine( "Periodic task is running" );

        /* 
         * The task should execute every 3 milliseconds exactly – see the
         * declaration of xDelay3ms in this function. 
         */
        vTaskDelayUntil( &amp;xLastWakeTime, xDelay3ms );
    }
}
</code></pre>
<p><em><strong>Listing 4.17</strong></em> <em>The periodic task used in Example 4.6</em></p>
<p>Figure 4.11 shows the output produced by Example 4.6, with an explanation of the
observed behavior given by the execution sequence shown in Figure 4.12.</p>
<p><a name="fig4.11" title="Figure 4.11 The output produced when Example 4.6 is executed"></a></p>
<hr />
<pre><code class="language-console">Continuous task 2 running
Continuous task 2 running
Periodic task is running
Continuous task 1 running
Continuous task 1 running
Continuous task 1 running
Continuous task 1 running
Continuous task 1 running
Continuous task 2 running
Continuous task 2 running
Continuous task 2 running
Continuous task 2 running
Continuous task 2 running
Continuous task 1 running
Continuous task 1 running
Continuous task 1 running
Continuous task 1 running
Continuous task 1 running
Continuous task 1 running
Continuous task 1 running
Continuous task 1 running
Continuous task 1 running
Periodic task is running
Continuous task 2 running
Continuous task 2 running
</code></pre>
<p><em><strong>Figure 4.11</strong></em> <em>The output produced when Example 4.6 is executed</em></p>
<hr />
<p><a name="fig4.12" title="Figure 4.12 The execution pattern of Example 4.6"></a></p>
<hr />
<p><img src="media/figure_4.11_example_4.6_execution_pattern.png" alt="" /><br />
<em><strong>Figure 4.12</strong></em> <em>The execution pattern of Example 4.6</em></p>
<hr />
<h2 id="48-the-idle-task-and-the-idle-task-hook"><a class="header" href="#48-the-idle-task-and-the-idle-task-hook">4.8 The Idle Task and the Idle Task Hook</a></h2>
<p>The tasks created in Example 4.4 spend most of their time in the Blocked
state. While in this state, they are not able to run, so they cannot be
selected by the scheduler.</p>
<p>There must always be at least one task that can enter the Running
state<sup class="footnote-reference"><a href="#6">3</a></sup>. To ensure this is the case, the scheduler automatically
creates an Idle task when <code>vTaskStartScheduler()</code> is called. The idle task
does very little more than sit in a loop, so, like the tasks in the first
examples, it is always able to run.</p>
<div class="footnote-definition" id="6"><sup class="footnote-definition-label">3</sup>
<p>This is the case even when the special low power features of
FreeRTOS are being used, in which case the microcontroller on which
FreeRTOS is executing will be placed into a low power mode if none
of the tasks created by the application are able to execute.</p>
</div>
<p>The idle task has the lowest possible priority (priority zero), to
ensure it never prevents a higher priority application task from
entering the <em>Running</em> state. However, there is nothing to prevent
application designers from creating tasks at, and therefore that share, the idle
task priority, if desired. The <code>configIDLE_SHOULD_YIELD</code> compile time
configuration constant in <code>FreeRTOSConfig.h</code> can be used to prevent the
Idle task from consuming processing time that would be more productively
allocated to applications tasks that also have a priority of 0. Section
4.12, Scheduling Algorithms, describes <code>configIDLE_SHOULD_YIELD</code>.</p>
<p>Running at the lowest priority ensures the Idle task is transitioned out
of the <em>Running</em> state as soon as a higher priority task enters the Ready
state. This can be seen at time <strong>tn</strong> in Figure 4.9, where the Idle task is
immediately swapped out to allow Task 2 to execute at the instant Task 2
leaves the <em>Blocked</em> state. Task 2 is said to have preempted the idle
task. Preemption occurs automatically, and without the knowledge of the
task being preempted.</p>
<blockquote>
<p><em>Note: If a task uses the <code>vTaskDelete()</code> API function to delete itself
then it is essential that the Idle task is not starved of processing time.
This is because the Idle task is responsible for cleaning up kernel
resources used by tasks that deleted themselves.</em></p>
</blockquote>
<h3 id="481-idle-task-hook-functions"><a class="header" href="#481-idle-task-hook-functions">4.8.1 Idle Task Hook Functions</a></h3>
<p>It is possible to add application specific functionality directly into
the idle task through the use of an idle hook (or idle callback)
function, which is a function that is called automatically by the idle task once
per iteration of the idle task loop.</p>
<p>Common uses for the Idle task hook include:</p>
<ul>
<li>
<p>Executing low priority, background, or continuous processing
functionality without the RAM overhead of creating application tasks
for the purpose.</p>
</li>
<li>
<p>Measuring the amount of spare processing capacity. (The idle task
will run only when all higher priority application tasks have no
work to perform; so measuring the amount of processing time
allocated to the idle task provides a clear indication of spare
processing time.)</p>
</li>
<li>
<p>Placing the processor into a low power mode, providing an easy and
automatic method of saving power whenever there is no application
processing to be performed (although the achievable power saving is
less than that achieved by tick-less idle mode).</p>
</li>
</ul>
<h3 id="482-limitations-on-the-implementation-of-idle-task-hook-functions"><a class="header" href="#482-limitations-on-the-implementation-of-idle-task-hook-functions">4.8.2 Limitations on the Implementation of Idle Task Hook Functions</a></h3>
<p>Idle task hook functions must adhere to the following rules.</p>
<ul>
<li>
<p>An Idle task hook function must never attempt to block or suspend itself.</p>
<p><em>Note: Blocking the idle task in any way could cause a scenario where
no tasks are available to enter the <em>Running</em> state.</em></p>
</li>
<li>
<p>If an application task uses the <code>vTaskDelete()</code> API function
to delete itself, then the Idle task hook must always return to its
caller within a reasonable time period. This is because the Idle
task is responsible for cleaning up kernel resources allocated to
tasks that delete themselves. If the idle task remains permanently
in the Idle hook function, then this clean-up cannot occur.</p>
</li>
</ul>
<p>Idle task hook functions must have the name and prototype shown in Listing 4.18.</p>
<p><a name="list4.18" title="Listing 4.18 The idle task hook function name and prototype"></a></p>
<pre><code class="language-c">void vApplicationIdleHook( void );
</code></pre>
<p><em><strong>Listing 4.18</strong></em> <em>The idle task hook function name and prototype</em></p>
<h2 id="-6"><a class="header" href="#-6"><a name="example4.7" title="Example 4.7 Defining an idle task hook function"></a></a></h2>
<p><em><strong>Example 4.7</strong></em> *Defining an idle task hook function</i></h3></p>
<hr />
<p>The use of blocking <code>vTaskDelay()</code> API calls in Example 4.4 created a lot of
idle time, that is, time when the Idle task executes because both application
tasks are in the <em>Blocked</em> state. Example 4.7 makes use of this idle time
through the addition of an Idle hook function, the source for which is
shown in Listing 4.19.</p>
<p><a name="list4.19" title="Listing 4.19 A very simple Idle hook function"></a></p>
<pre><code class="language-c">/* Declare a variable that will be incremented by the hook function.  */
volatile unsigned long ulIdleCycleCount = 0UL;

/*
 * Idle hook functions MUST be called vApplicationIdleHook(), take no
 * parameters, and return void.
 */
void vApplicationIdleHook( void )
{
    /* This hook function does nothing but increment a counter. */
    ulIdleCycleCount++;
}
</code></pre>
<p><em><strong>Listing 4.19</strong></em> <em>A very simple Idle hook function</em></p>
<p><code>configUSE_IDLE_HOOK</code> must be set to 1 in FreeRTOSConfig.h for the idle hook function
to get called.</p>
<p>The function that implements the created tasks is modified slightly to
print out the <code>ulIdleCycleCount</code> value, as shown in Listing 4.20.</p>
<p><a name="list4.20" title="Listing 4.20 The source code for the example task now prints out the ulIdleCycleCount value"></a></p>
<pre><code class="language-c">void vTaskFunction( void * pvParameters )
{
    char * pcTaskName;
    const TickType_t xDelay250ms = pdMS_TO_TICKS( 250 );

    /*
     * The string to print out is passed in via the parameter. Cast this to
     * a character pointer.
     */
    pcTaskName = ( char * ) pvParameters;

    /* As per most tasks, this task is implemented in an infinite loop. */
    for( ;; )
    {
        /*
         * Print out the name of this task AND the number of times
         * ulIdleCycleCount has been incremented.
         */
        vPrintLineAndNumber( pcTaskName, ulIdleCycleCount );

        /* Delay for a period of 250 milliseconds. */
        vTaskDelay( xDelay250ms );
    }
}
</code></pre>
<p><em><strong>Listing 4.20</strong></em> <em>The source code for the example task now prints out the
ulIdleCycleCount value</em></p>
<p>Figure 4.13 shows the output produced by Example 4.7. It can be seen that
the idle task hook function executes approximately 4 million times
between each iteration of the application tasks (the number of
iterations depends on the hardware speed).</p>
<p><a name="fig4.13" title="Figure 4.13 The output produced when Example 4.7 is executed"></a></p>
<hr />
<pre><code class="language-console">C:\Temp&gt;rtosdemo
Task 2 is running
ulIdleCycleCount = 0
Task 1 is running
ulIdleCycleCount = 0
Task 2 is running
ulIdleCycleCount = 3869504
Task 1 is running
ulIdleCycleCount = 3869504
Task 2 is running
ulIdleCycleCount = 8564623
Task 1 is running
ulIdleCycleCount = 8564623
Task 2 is running
ulIdleCycleCount = 13181489
Task 1 is running
ulIdleCycleCount = 13181489
Task 2 is running
ulIdleCycleCount = 17838406
Task 1 is running
ulIdleCycleCount = 17838406
Task 2 is running
</code></pre>
<p><em><strong>Figure 4.13</strong></em> <em>The output produced when Example 4.7 is executed</em></p>
<hr />
<h2 id="49-changing-the-priority-of-a-task"><a class="header" href="#49-changing-the-priority-of-a-task">4.9 Changing the Priority of a Task</a></h2>
<h3 id="491-the-vtaskpriorityset-api-function"><a class="header" href="#491-the-vtaskpriorityset-api-function">4.9.1 The vTaskPrioritySet() API Function</a></h3>
<p>The <code>vTaskPrioritySet()</code> API function changes the priority of a task after
the scheduler has been started. The <code>vTaskPrioritySet()</code> API function is
only available when <code>INCLUDE_vTaskPrioritySet</code> is set to 1 in
FreeRTOSConfig.h.</p>
<p><a name="list4.21" title="Listing 4.21 The vTaskPrioritySet() API function prototype"></a></p>
<pre><code class="language-c">void vTaskPrioritySet( TaskHandle_t xTask, 
                       UBaseType_t uxNewPriority );
</code></pre>
<p><em><strong>Listing 4.21</strong></em> <em>The vTaskPrioritySet() API function prototype</em></p>
<p><strong>vTaskPrioritySet() parameters</strong></p>
<ul>
<li>
<p><code>pxTask</code></p>
<p>The handle of the task whose priority is being modified (the
subject task). See the <code>pxCreatedTask</code> parameter of the <code>xTaskCreate()</code> API
function, or the return value of the <code>xTaskCreateStatic()</code> API function,
for information on obtaining handles to tasks.</p>
<p>A task can change its own priority by passing NULL in place of a
valid task handle.</p>
</li>
<li>
<p><code>uxNewPriority</code></p>
<p>The priority to which the subject task is to be set. This is capped
automatically to the maximum available priority of <code>(configMAX_PRIORITIES – 1)</code>,
where <code>configMAX_PRIORITIES</code> is a compile time constant set in the
FreeRTOSConfig.h header file.</p>
</li>
</ul>
<h3 id="492-the-uxtaskpriorityget-api-function"><a class="header" href="#492-the-uxtaskpriorityget-api-function">4.9.2 The uxTaskPriorityGet() API Function</a></h3>
<p>The <code>uxTaskPriorityGet()</code> API function returns the priority of a task. The
<code>uxTaskPriorityGet()</code> API function is only available when
<code>INCLUDE_uxTaskPriorityGet</code> is set to 1 in FreeRTOSConfig.h.</p>
<p><a name="list4.22" title="Listing 4.22 The uxTaskPriorityGet() API function prototype"></a></p>
<pre><code class="language-c">UBaseType_t uxTaskPriorityGet( TaskHandle_t xTask );
</code></pre>
<p><em><strong>Listing 4.22</strong></em> <em>The uxTaskPriorityGet() API function prototype</em></p>
<p><strong>uxTaskPriorityGet() parameters and return value</strong></p>
<ul>
<li>
<p><code>pxTask</code></p>
<p>The handle of the task whose priority is being queried (the
subject task). See the <code>pxCreatedTask</code> parameter of the <code>xTaskCreate()</code> API
function for information on how to obtain handles to tasks.</p>
<p>A task can query its own priority by passing NULL in place of a valid
task handle.</p>
</li>
<li>
<p>Return value</p>
<p>The priority currently assigned to the task being queried.</p>
</li>
</ul>
<h2 id="-7"><a class="header" href="#-7"><a name="example4.8" title="Example 4.8 Changing task priorities"></a></a></h2>
<p><em><strong>Example 4.8</strong></em> <em>Changing task priorities</em></p>
<hr />
<p>The scheduler always selects the highest <em>Ready</em> state task as the task to
enter the <em>Running</em> state. Example 4.8 demonstrates this by using the
<code>vTaskPrioritySet()</code> API function to change the priority of two tasks
relative to each other.</p>
<p>Example 4.8 creates two tasks at two different priorities. Neither task
makes any API function calls that could cause it to enter the Blocked
state, so both are always in either the <em>Ready</em> state or the Running
state. Therefore, the task with the highest relative priority will
always be the task selected by the scheduler to be in the <em>Running</em> state.</p>
<p>Example 4.8 behaves as follows:</p>
<ol>
<li>
<p>Task 1 (Listing 4.23) is created with the highest priority, so it is
guaranteed to run first. Task 1 prints out a couple of strings
before raising the priority of Task 2 (Listing 4.24) above its own
priority.</p>
</li>
<li>
<p>Task 2 starts to run (enters the <em>Running</em> state) as soon as it has
the highest relative priority. Only one task can be in the Running
state at any one time, so when Task 2 is in the <em>Running</em> state, Task
1 is in the <em>Ready</em> state.</p>
</li>
<li>
<p>Task 2 prints out a message before setting its own priority back
down to below that of Task 1.</p>
</li>
<li>
<p>When Task 2 sets its priority back down, then Task 1 is once again the
highest priority task, so Task 1 re-enters the <em>Running</em> state,
forcing Task 2 back into the <em>Ready</em> state.</p>
</li>
</ol>
<p><a name="list4.23" title="Listing 4.23 The implementation of Task 1 in Example 4.8"></a></p>
<pre><code class="language-c">void vTask1( void * pvParameters )
{
    UBaseType_t uxPriority;

    /* 
     * This task will always run before Task 2 as it is created with the higher
     * priority. Neither Task 1 nor Task 2 ever block so both will always be in
     * either the Running or the Ready state.
     */

    /*
     * Query the priority at which this task is running - passing in NULL means
     * "return the calling task's priority".
     */
    uxPriority = uxTaskPriorityGet( NULL );

    for( ;; )
    {
        /* Print out the name of this task. */
        vPrintLine( "Task 1 is running" );

        /*
         * Setting the Task 2 priority above the Task 1 priority will cause
         * Task 2 to immediately start running (as then Task 2 will have the
         * higher priority of the two created tasks). Note the use of the
         * handle to task 2 (xTask2Handle) in the call to vTaskPrioritySet().
         * Listing 4.25 shows how the handle was obtained.
         */
        vPrintLine( "About to raise the Task 2 priority" );
        vTaskPrioritySet( xTask2Handle, ( uxPriority + 1 ) );

        /*
         * Task 1 will only run when it has a priority higher than Task 2.
         * Therefore, for this task to reach this point, Task 2 must already
         * have executed and set its priority back down to below the priority
         * of this task.
         */
    }
}
</code></pre>
<p><em><strong>Listing 4.23</strong></em> <em>The implementation of Task 1 in Example 4.8</em></p>
<p><a name="list4.24" title="Listing 4.24 The implementation of Task 2 in Example 4.8"></a></p>
<pre><code class="language-c">void vTask2( void * pvParameters )
{
    UBaseType_t uxPriority;

    /*
     * Task 1 will always run before this task as Task 1 is created with the
     * higher priority. Neither Task 1 nor Task 2 ever block so will always be
     * in either the Running or the Ready state.
     *
     * Query the priority at which this task is running - passing in NULL means
     * "return the calling task's priority".
     */
    uxPriority = uxTaskPriorityGet( NULL );

    for( ;; )
    {
        /*
         * For this task to reach this point Task 1 must have already run and
         * set the priority of this task higher than its own.
         */

         /* Print out the name of this task. */
        vPrintLine( "Task 2 is running" );

        /*
         * Set the priority of this task back down to its original value.
         * Passing in NULL as the task handle means "change the priority of the
         * calling task". Setting the priority below that of Task 1 will cause
         * Task 1 to immediately start running again – preempting this task.
         */
        vPrintLine( "About to lower the Task 2 priority" );
        vTaskPrioritySet( NULL, ( uxPriority - 2 ) );
    }
}
</code></pre>
<p><em><strong>Listing 4.24</strong></em> <em>The implementation of Task 2 in Example 4.8</em></p>
<p>Each task can both query and set its own priority by using NULL in place
of a valid task handle. A task handle is only required when a task
wishes to reference a task other than itself, such as when Task 1
changes the priority of Task 2. To allow Task 1 to do this, the Task 2
handle is obtained and saved when Task 2 is created, as highlighted in
the comments in Listing 4.25.</p>
<p><a name="list4.25" title="Listing 4.25 The implementation of main() for Example 4.8"></a></p>
<pre><code class="language-c">/* Declare a variable that is used to hold the handle of Task 2. */
TaskHandle_t xTask2Handle = NULL;

int main( void )
{
    /*
     * Create the first task at priority 2. The task parameter is not used
     * and set to NULL. The task handle is also not used so is also set to
     * NULL.
     */
    xTaskCreate( vTask1, "Task 1", 1000, NULL, 2, NULL );
    /* The task is created at priority 2 ______^. */

    /*
     * Create the second task at priority 1 - which is lower than the priority
     * given to Task 1. Again the task parameter is not used so is set to NULL-
     * BUT this time the task handle is required so the address of xTask2Handle
     * is passed in the last parameter.
     */
    xTaskCreate( vTask2, "Task 2", 1000, NULL, 1, &amp;xTask2Handle );
    /* The task handle is the last parameter _____^^^^^^^^^^^^^ */

    /* Start the scheduler so the tasks start executing. */
    vTaskStartScheduler();

    /*
     * If all is well main() will not reach here because the scheduler will
     * now be running the created tasks. If main() does reach here then there
     * was not enough heap memory to create either the idle or timer tasks
     * (described later in this book). Chapter 2 provides more information on
     * heap memory management.
     */
    for( ;; )
    {
    }
}
</code></pre>
<p><em><strong>Listing 4.25</strong></em> <em>The implementation of main() for Example 4.8</em></p>
<p>Figure 4.14 demonstrates the sequence in which the tasks in Example 4.8
execute, and the resultant output is shown in Figure 4.15.</p>
<p><a name="fig4.14" title="Figure 4.14 The sequence of task execution when running Example 4.8"></a></p>
<hr />
<p><img src="media/figure_4.14_example_4.8_execution_sequence.png" alt="" /><br />
<em><strong>Figure 4.14</strong></em> <em>The sequence of task execution when running Example 4.8</em></p>
<hr />
<p><a name="fig4.15" title="Figure 4.15 The output produced when Example 4.8 is executed"></a></p>
<hr />
<pre><code class="language-console">Task1 is running
About to raise the Task2 priority
Task2 is running
About to lower the Task2 priority
Task1 is running
About to raise the Task2 priority
Task2 is running
About to lower the Task2 priority
Task1 is running
About to raise the Task2 priority
Task2 is running
About to lower the Task2 priority
Task1 is running
</code></pre>
<p><em><strong>Figure 4.15</strong></em> <em>The output produced when Example 4.8 is executed</em></p>
<hr />
<h2 id="410-deleting-a-task"><a class="header" href="#410-deleting-a-task">4.10 Deleting a Task</a></h2>
<h3 id="4101-the-vtaskdelete-api-function"><a class="header" href="#4101-the-vtaskdelete-api-function">4.10.1 The vTaskDelete() API Function</a></h3>
<p>The <code>vTaskDelete()</code> API function deletes a task. The <code>vTaskDelete()</code> API
function is only available when <code>INCLUDE_vTaskDelete</code> is set to 1 in
FreeRTOSConfig.h.</p>
<p>It is not good practice to continuously create and delete tasks at run
time, so consider other design options, such as re-using tasks, if you
find yourself needing this function.</p>
<p>Deleted tasks no longer exist and cannot enter the <em>Running</em> state again.</p>
<p>If a task that was created using dynamic memory allocation later deletes itself,
the Idle task is responsible for freeing the memory allocated for use, such as
the deleted task's data structure and stack. So it is important that
applications do not completely starve the Idle task of all processing
time when this is the case.</p>
<blockquote>
<p><em>Note: Only memory allocated to a task by the kernel itself is freed
automatically when the task is deleted. Any memory or other resource
that was allocated during the implementation of the task must be freed explicitly
if it is no longer needed.</em></p>
</blockquote>
<p><a name="list4.26" title="Listing 4.26 The vTaskDelete() API function prototype"></a></p>
<pre><code class="language-c">void vTaskDelete( TaskHandle_t xTaskToDelete );
</code></pre>
<p><em><strong>Listing 4.26</strong></em> <em>The vTaskDelete() API function prototype</em></p>
<p><strong>vTaskDelete() parameters</strong></p>
<ul>
<li>
<p><code>pxTaskToDelete</code></p>
<p>The handle of the task that is to be deleted (the subject
task). See the <code>pxCreatedTask</code> parameter of the <code>xTaskCreate()</code> API function,
and the return value of the <code>xTaskCreateStatic()</code> API function, for
information on obtaining handles to tasks.</p>
<p>A task can delete itself by passing NULL in place of a valid task
handle.</p>
</li>
</ul>
<h2 id="-8"><a class="header" href="#-8"><a name="example4.9" title="Example 4.9 Deleting tasks"></a></a></h2>
<p><em><strong>Example 4.9</strong></em> <em>Deleting tasks</em></p>
<hr />
<p>This is a very simple example that behaves as follows.</p>
<ol>
<li>
<p>Task 1 is created by <code>main()</code> with priority 1. When it runs, it
creates Task 2 at priority 2. Task 2 is now the highest priority
task, so it starts to execute immediately. Listing 4.27 shows the
source code for <code>main()</code>. Listing 4.28 shows the source code for Task 1.</p>
</li>
<li>
<p>Task 2 does nothing other than delete itself. It could delete itself
by passing NULL to <code>vTaskDelete()</code> but instead, for demonstration
purposes, it uses its own task handle. Listing 4.29 shows the source
code for Task 2.</p>
</li>
<li>
<p>When Task 2 has been deleted, Task 1 is again the highest priority
task, so it continues executing—at which point it calls <code>vTaskDelay()</code> to
block for a short period.</p>
</li>
<li>
<p>The Idle task executes while Task 1 is in the blocked state and
frees the memory that was allocated to the now deleted Task 2.</p>
</li>
<li>
<p>When Task 1 leaves the blocked state it again becomes the highest
priority <em>Ready</em> state task and so preempts the Idle task. When it
enters the <em>Running</em> state it creates Task 2 again, and so it goes on.</p>
</li>
</ol>
<p><a name="list4.27" title="Listing 4.27 The implementation of main() for Example 4.9"></a></p>
<pre><code class="language-c">int main( void )
{
    /* Create the first task at priority 1. */
    xTaskCreate( vTask1, "Task 1", 1000, NULL, 1, NULL );

    /* Start the scheduler so the task starts executing. */
    vTaskStartScheduler();

    /* main() should never reach here as the scheduler has been started. */
    for( ;; )
    {
    }
}
</code></pre>
<p><em><strong>Listing 4.27</strong></em> <em>The implementation of main() for Example 4.9</em></p>
<hr />
<p><a name="list4.28" title="Listing 4.28 The implementation of Task 1 for Example 4.9"></a></p>
<pre><code class="language-c">TaskHandle_t xTask2Handle = NULL;

void vTask1( void * pvParameters )
{
    const TickType_t xDelay100ms = pdMS_TO_TICKS( 100UL );

    for( ;; )
    {
        /* Print out the name of this task. */
        vPrintLine( "Task 1 is running" );

        /*
         * Create task 2 at a higher priority.
         * Pass the address of xTask2Handle as the pxCreatedTask parameter so
         * that xTaskCreate write the resulting task handle to that variable.
         */
        xTaskCreate( vTask2, "Task 2", 1000, NULL, 2, &amp;xTask2Handle );

        /*
         * Task 2 has/had the higher priority. For Task 1 to reach here, Task 2
         * must have already executed and deleted itself.
         */
        vTaskDelay( xDelay100ms );
    }
}
</code></pre>
<p><em><strong>Listing 4.28</strong></em> <em>The implementation of Task 1 for Example 4.9</em></p>
<p><a name="list4.29" title="Listing 4.29 The implementation of Task 2 for Example 4.9"></a></p>
<pre><code class="language-c">void vTask2( void * pvParameters )
{
    /*
     * Task 2 immediately deletes itself upon starting.
     * To do this it could call vTaskDelete() using NULL as the parameter.
     * For demonstration purposes, it instead calls vTaskDelete() with its own
     * task handle.
     */
    vPrintLine( "Task 2 is running and about to delete itself" );
    vTaskDelete( xTask2Handle );
}
</code></pre>
<p><em><strong>Listing 4.29</strong></em> <em>The implementation of Task 2 for Example 4.9</em></p>
<p><a name="fig4.16" title="Figure 4.16 The output produced when Example 4.9 is executed"></a></p>
<hr />
<pre><code class="language-console">C:\Temp&gt;rtosdemo
Task1 is running
Task2 is running and about to delete itself
Task1 is running
Task2 is running and about to delete itself
Task1 is running
Task2 is running and about to delete itself
Task1 is running
Task2 is running and about to delete itself
Task1 is running
Task2 is running and about to delete itself
Task1 is running
Task2 is running and about to delete itself
Task1 is running
Task2 is running and about to delete itself
Task1 is running
Task2 is running and about to delete itself
</code></pre>
<p><em><strong>Figure 4.16</strong></em> <em>The output produced when Example 4.9 is executed</em></p>
<hr />
<p><a name="fig4.17" title="Figure 4.17 The execution sequence for Example 4.9"></a></p>
<hr />
<p><img src="media/figure_4.17_example_4.9_execution_sequence.png" alt="" /><br />
<em><strong>Figure 4.17</strong></em> <em>The execution sequence for Example 4.9</em></p>
<hr />
<h2 id="411-thread-local-storage-and-reentrancy"><a class="header" href="#411-thread-local-storage-and-reentrancy">4.11 Thread Local Storage and Reentrancy</a></h2>
<p>Thread Local Storage allows an application developer to store arbitrary data in
the Task Control Block of each task. This feature is most commonly used to store
data which would normally be stored in a global variable by non-reentrant functions.</p>
<p>A reentrant function is a function which can safely run from multiple threads
without any side effects. When non-reentrant functions are used in a
multi-threaded environment without thread local storage, special care must be
taken to check the out of band results of these function calls from within a
critical section. Excessive use of critical sections degrades RTOS performance,
so Thread Local Storage is often preferred over the use of critical sections.</p>
<p>By far the most common use of Thread Local Storage is the <code>errno</code> global used
in the ISO C standard used by the C standard library and POSIX systems.
The <code>errno</code> global is used to provide an extended result or error code for
common standard library functions such as strtof and strtol.</p>
<h3 id="4111-c-runtime-thread-local-storage-implementations"><a class="header" href="#4111-c-runtime-thread-local-storage-implementations">4.11.1 C Runtime Thread Local Storage Implementations</a></h3>
<p>Most embedded libc implementations provide APIs to ensure that non-reentrant
functions can work correctly in a multi-threaded environment. FreeRTOS includes
support for the reentrancy APIs of two commonly used open-source libraries:
<a href="https://sourceware.org/newlib/">newlib</a> and
<a href="https://github.com/picolibc/picolibc">picolibc</a>.
These pre-built C Runtime Thread Local Storage implementations can be enabled by
by defining the respective macro listed below in their project's FreeRTOSConfig.h
file.</p>
<ul>
<li><code>configUSE_NEWLIB_REENTRANT</code> for <a href="https://sourceware.org/newlib/">newlib</a></li>
<li><code>configUSE_PICOLIBC_TLS</code> for <a href="https://github.com/picolibc/picolibc">picolibc</a></li>
</ul>
<h3 id="4112-custom-c-runtime-thread-local-storage"><a class="header" href="#4112-custom-c-runtime-thread-local-storage">4.11.2 Custom C Runtime Thread Local Storage</a></h3>
<p>Application developers may implement thread local storage by defining the following
macros in their FreeRTOSConfig.h file:</p>
<ul>
<li>
<p>Define <code>configUSE_C_RUNTIME_TLS_SUPPORT</code> to 1 to enable C Runtime Thread
Local Storage support.</p>
</li>
<li>
<p>Define <code>configTLS_BLOCK_TYPE</code> to the c type which should be used for storing
C Runtime Thread Local Storage data.</p>
</li>
<li>
<p>Define <code>configINIT_TLS_BLOCK</code> to the c code which should be run when initializing
the C Runtime Thread Local Storage block.</p>
</li>
<li>
<p>Define <code>configSET_TLS_BLOCK</code> to the c code which should be run when switching
in a new task</p>
</li>
<li>
<p>Define <code>configDEINIT_TLS_BLOCK</code> to the c code which should be run when de-initializing
the C Runtime Thread Local Storage block.</p>
</li>
</ul>
<h3 id="4113-application-thread-local-storage"><a class="header" href="#4113-application-thread-local-storage">4.11.3 Application Thread Local Storage</a></h3>
<p>In addition to C Runtime Thread Local Storage, application developers may also
define a set of application specific pointers to be included in the task control
block. This feature is enabled by setting <code>configNUM_THREAD_LOCAL_STORAGE_POINTERS</code>
to a non-zero number in the project's FreeRTOSConfig.h file.
The <code>vTaskSetThreadLocalStoragePointer</code> and <code>pvTaskGetThreadLocalStoragePointer</code>
functions defined in Listing 4.30 may be used respectively to set and get the
value of each thread local storage pointer at runtime.</p>
<p><a name="list4.30" title="Listing 4.30 Function prototypes of the Thread Local Storage Pointer API functions"></a></p>
<pre><code class="language-c">void * pvTaskGetThreadLocalStoragePointer( TaskHandle_t xTaskToQuery,
                                           BaseType_t xIndex )

void vTaskSetThreadLocalStoragePointer( TaskHandle_t xTaskToSet,
                                        BaseType_t xIndex,
                                        void * pvValue );
</code></pre>
<p><em><strong>Listing 4.30</strong></em> <em>Function prototypes of the Thread Local Storage Pointer API functions</em></p>
<h2 id="412-scheduling-algorithms"><a class="header" href="#412-scheduling-algorithms">4.12 Scheduling Algorithms</a></h2>
<h3 id="4121-a-recap-of-task-states-and-events"><a class="header" href="#4121-a-recap-of-task-states-and-events">4.12.1 A Recap of Task States and Events</a></h3>
<p>The task that is actually running (using processing time) is in the
<em>Running</em> state. On a single core processor there can only be one task in
the <em>Running</em> state at any given time. It is also possible to run FreeRTOS
on more than one core (asymmetric multiprocessing, or AMP), or have
FreeRTOS schedule tasks across multiple cores (symmetric
multiprocessing, or SMP). Neither of those scenarios are described here.</p>
<p>Tasks that are not actually running, but are not in either the Blocked
state or the <em>Suspended</em> state, are in the <em>Ready</em> state. Tasks in the Ready
state are available to be selected by the scheduler as the task to enter
the <em>Running</em> state. The scheduler will always choose the highest priority
Ready state task to enter the <em>Running</em> state.</p>
<p>Tasks can wait in the <em>Blocked</em> state for an event and they are automatically
moved back to the <em>Ready</em> state when the event occurs. Temporal events
occur at a particular time, for example, when a block time expires, and
are normally used to implement periodic or timeout behavior.
Synchronization events occur when a task or interrupt service routine
sends information using a task notification, queue, event group, message
buffer, stream buffer, or one of the many types of semaphore. They are
generally used to signal asynchronous activity, such as data arriving at
a peripheral.</p>
<h3 id="4122-selecting-the-scheduling-algorithm"><a class="header" href="#4122-selecting-the-scheduling-algorithm">4.12.2 Selecting the Scheduling Algorithm</a></h3>
<p>The scheduling algorithm is the software routine that decides which
<em>Ready</em> state task to transition into the <em>Running</em> state.</p>
<p>All the examples so far have used the same scheduling algorithm, but the
algorithm can be changed using the <code>configUSE_PREEMPTION</code> and
<code>configUSE_TIME_SLICING</code> configuration constants. Both constants are
defined in FreeRTOSConfig.h.</p>
<p>A third configuration constant, <code>configUSE_TICKLESS_IDLE</code>, also affects
the scheduling algorithm, as its use can result in the tick interrupt
being turned off completely for extended periods.
<code>configUSE_TICKLESS_IDLE</code> is an advanced option provided specifically for
use in applications that must minimize their power consumption.
The descriptions provided in this section assume <code>configUSE_TICKLESS_IDLE</code>
is set to 0, which is the default setting if the constant is left
undefined.</p>
<p>In all possible single core configurations the FreeRTOS scheduler
selects tasks that share a priority in turn. This 'take it in turn'
policy is often referred to as 'Round Robin Scheduling'. A Round Robin
scheduling algorithm does not guarantee time is shared equally between
tasks of equal priority, only that <em>Ready</em> state tasks of equal priority
enter the <em>Running</em> state in turn.</p>
<p><a name="tbl5" title="Table 5 The FreeRTOSConfig.h settings to configure the kernel scheduling algorithms"></a></p>
<hr />
<div class="table-wrapper"><table><thead><tr><th>Scheduling Algorithm</th><th>Prioritized</th><th><code>configUSE_PREEMPTION</code></th><th><code>configUSE_TIME_SLICING</code></th></tr></thead><tbody>
<tr><td>Preemptive With Time Slicing</td><td>Yes</td><td>1</td><td>1</td></tr>
<tr><td>Preemptive Without Time Slicing</td><td>Yes</td><td>1</td><td>0</td></tr>
<tr><td>Co-Operative</td><td>No</td><td>0</td><td>Any</td></tr>
</tbody></table>
</div>
<p><em><strong>Table 5</strong></em> <em>The FreeRTOSConfig.h settings to configure the kernel scheduling algorithms</em></p>
<hr />
<h3 id="4123-prioritized-preemptive-scheduling-with-time-slicing"><a class="header" href="#4123-prioritized-preemptive-scheduling-with-time-slicing">4.12.3 Prioritized Preemptive Scheduling with Time Slicing</a></h3>
<p>The configuration shown in the Table 5 sets the FreeRTOS scheduler to use a
scheduling algorithm called 'Fixed Priority Preemptive Scheduling with
Time Slicing', which is the scheduling algorithm used by most small RTOS
applications, and the algorithm used by all the examples presented in
this book so far. The next table provides a description of the terminology
used in the algorithm's name.</p>
<p><strong>An explanation of the terms used to describe the scheduling policy:</strong></p>
<ul>
<li>
<p>Fixed Priority</p>
<p>Scheduling algorithms described as 'Fixed Priority' do not change the priority
assigned to the tasks being scheduled, but also do not prevent the tasks
themselves from changing their own priority or that of other tasks.</p>
</li>
<li>
<p>Preemptive</p>
<p>Preemptive scheduling algorithms will immediately 'preempt' the <em>Running</em> state
task if a task that has a priority higher than the <em>Running</em> state task enters
the <em>Ready</em> state. Being preempted means being involuntarily moved out of the
<em>Running</em> state and into the <em>Ready</em> state (without explicitly yielding or
blocking) to allow a different task to enter the <em>Running</em> state. Task preemption
can occur at any time, not just in the RTOS tick interrupt.</p>
</li>
<li>
<p>Time Slicing</p>
<p>Time slicing is used to share processing time between tasks of equal priority,
even when the tasks do not explicitly yield or enter the <em>Blocked</em> state.
Scheduling algorithms described as using <em>Time Slicing</em> select a new task to
enter the <em>Running</em> state at the end of each time slice if there are other <em>Ready</em>
state tasks that have the same priority as the Running task. A time slice is equal
to the time between two RTOS tick interrupts.</p>
</li>
</ul>
<p>Figure 4.18 and Figure 4.19 demonstrate how tasks are scheduled when a fixed
priority preemptive scheduling with time slicing algorithm is used.
Figure 4.18 shows the sequence in which tasks are selected to enter the
<em>Running</em> state when all the tasks in an application have a unique
priority. Figure 4.19 shows the sequence in which tasks are selected to
enter the <em>Running</em> state when two tasks in an application share a
priority.</p>
<p><a name="fig4.18" title="Figure 4.18 Execution pattern highlighting task prioritization and preemption..."></a></p>
<hr />
<p><img src="media/figure_4.18_preemption_execution_pattern.png" alt="" /><br />
<em><strong>Figure 4.18</strong></em> <em>Execution pattern highlighting task prioritization and preemption
in a hypothetical application in which each task has been assigned a unique
priority</em></p>
<hr />
<p>Referring to Figure 4.18:</p>
<ul>
<li>
<p>Idle Task</p>
<p>The idle task is running at the lowest priority, so it gets preempted
every time a higher priority task enters the <em>Ready</em> state, for example, at
times t3, t5 and t9.</p>
</li>
<li>
<p>Task 3</p>
<p>Task 3 is an event-driven task that executes with a relatively low
priority, but above the Idle priority. It spends most of its time in the
<em>Blocked</em> state waiting for its event of interest, transitioning from the
<em>Blocked</em> state to the <em>Ready</em> state each time the event occurs. All
FreeRTOS inter-task communication mechanisms (task notifications,
queues, semaphores, event groups, etc.) can be used to signal events and
unblock tasks in this way.</p>
<p>Events occur at times t3 and t5, and also somewhere between t9 and t12.
The events occurring at times t3 and t5 are processed immediately because, at
these times, Task 3 is the highest priority task that is able to run.
The event that occurs somewhere between times t9 and t12 is not
processed until t12 because, until then, the higher priority tasks Task
1 and Task 2 are still executing. It is only at time t12 that both Task
1 and Task 2 are in the <em>Blocked</em> state, making Task 3 the highest
priority <em>Ready</em> state task.</p>
</li>
<li>
<p>Task 2</p>
<p>Task 2 is a periodic task that executes at a priority above the priority
of Task 3, but below the priority of Task 1. The task's period interval
means Task 2 wants to execute at times t1, t6, and t9.</p>
<p>At time t6, Task 3 is in the <em>Running</em> state, but Task 2 has the higher
relative priority so preempts Task 3 and starts executing immediately.
Task 2 completes its processing and re-enters the <em>Blocked</em> state at time
t7, at which point Task 3 can re-enter the <em>Running</em> state to complete its
processing. Task 3 itself Blocks at time t8.</p>
</li>
<li>
<p>Task 1</p>
<p>Task 1 is also an event-driven task. It executes with the highest
priority of all, so can preempt any other task in the system. The only
Task 1 event shown occurs at time t10, at which time Task 1 preempts
Task 2. Task 2 can complete its processing only after Task 1 has
re-entered the <em>Blocked</em> state at time t11.</p>
</li>
</ul>
<p><a name="fig4.19" title="Figure 4.19 Execution pattern highlighting task prioritization and time slicing..."></a></p>
<hr />
<p><img src="media/figure_4.19_time_slicing_execution_pattern.png" alt="" /><br />
<em><strong>Figure 4.19</strong></em> <em>Execution pattern highlighting task prioritization and time slicing
in a hypothetical application in which two tasks run at the same priority</em></p>
<hr />
<p>Referring to Figure 4.19:</p>
<ul>
<li>
<p>The Idle Task and Task 2</p>
<p>The Idle task and Task 2 are both continuous processing tasks, and both
have a priority of 0 (the lowest possible priority). The scheduler only
allocates processing time to the priority 0 tasks when there are no
higher priority tasks that are able to run, and shares the time that is
allocated to the priority 0 tasks by time slicing. A new time slice
starts on each tick interrupt, which in Figure 4.19 occurs at times t1, t2,
t3, t4, t5, t8, t9, t10 and t11.</p>
<p>The Idle task and Task 2 enter the <em>Running</em> state in turn, which can
result in both tasks being in the <em>Running</em> state for part of the same
time slice, as happens between time t5 and time t8.</p>
</li>
<li>
<p>Task 1</p>
<p>The priority of Task 1 is higher than the Idle priority. Task 1 is an
event driven task that spends most of its time in the <em>Blocked</em> state
waiting for its event of interest, transitioning from the <em>Blocked</em> state
to the <em>Ready</em> state each time the event occurs.</p>
<p>The event of interest occurs at time t6. At t6 Task 1 becomes the
highest priority task that is able to run, and therefore Task 1
preempts the Idle task part way through a time slice. Processing of the
event completes at time t7, at which point Task 1 re-enters the Blocked
state.</p>
</li>
</ul>
<p>Figure 4.19 shows the Idle task sharing processing time with a task
created by the application writer. Allocating that much processing time
to the Idle task might not be desirable if the Idle priority tasks
created by the application writer have work to do, but the Idle task
does not. The <code>configIDLE_SHOULD_YIELD</code> compile time configuration
constant can be used to change how the Idle task is scheduled:</p>
<ul>
<li>
<p>If <code>configIDLE_SHOULD_YIELD</code> is set to 0 then the Idle task remains in
the <em>Running</em> state for the entirety of its time slice, unless it is
preempted by a higher priority task.</p>
</li>
<li>
<p>If <code>configIDLE_SHOULD_YIELD</code> is set to 1 then the Idle task yields
(voluntarily gives up whatever remains of its allocated time slice)
on each iteration of its loop if there are other Idle priority tasks
in the <em>Ready</em> state.</p>
</li>
</ul>
<p>The execution pattern shown in Figure 4.19 is what would be observed when
<code>configIDLE_SHOULD_YIELD</code> is set to 0. The execution pattern shown in
Figure 4.20 is what would be observed in the same scenario when
<code>configIDLE_SHOULD_YIELD</code> is set to 1.</p>
<p><a name="fig4.20" title="Figure 4.20 The execution pattern for the same scenario as shown in Figure 4.19..."></a></p>
<hr />
<p><img src="media/figure_4.20_time_slicing_with_yield_execution_pattern.png" alt="" /><br />
<em><strong>Figure 4.20</strong></em> <em>The execution pattern for the same scenario as shown in Figure 4.19,
but this time with <code>configIDLE_SHOULD_YIELD</code> set to 1</em></p>
<hr />
<p>Figure 4.20 also shows that when <code>configIDLE_SHOULD_YIELD</code> is set to 1, the
task selected to enter the <em>Running</em> state after the Idle task does not
execute for an entire time slice, but instead executes for whatever
remains of the time slice during which the Idle task yielded.</p>
<h3 id="4124-prioritized-preemptive-scheduling-without-time-slicing"><a class="header" href="#4124-prioritized-preemptive-scheduling-without-time-slicing">4.12.4 Prioritized Preemptive Scheduling without Time Slicing</a></h3>
<p>Prioritized Preemptive Scheduling without time slicing maintains the
same task selection and preemption algorithms as described in the
previous section, but does not use time slicing to share processing time
between tasks of equal priority.</p>
<p>The Table 5 shows the FreeRTOSConfig.h settings that configure the FreeRTOS
scheduler to use prioritized preemptive scheduling without time slicing.</p>
<p>As was demonstrated in Figure 4.19, if time slicing is used, and there is
more than one ready state task at the highest priority that is able to
run, then the scheduler selects a new task to enter the <em>Running</em> state
during each RTOS tick interrupt (a tick interrupt marking the end of a
time slice). If time slicing is not used, then the scheduler only
selects a new task to enter the <em>Running</em> state when either:</p>
<ul>
<li>
<p>A higher priority task enters the <em>Ready</em> state.</p>
</li>
<li>
<p>The task in the <em>Running</em> state enters the <em>Blocked</em> or <em>Suspended</em> state.</p>
</li>
</ul>
<p>There are fewer task context switches when time slicing is not used than
when time slicing is used. Therefore, turning time slicing off results
in a reduction in the scheduler's processing overhead. However, turning
time slicing off can also result in tasks of equal priority receiving
greatly different amounts of processing time, a scenario demonstrated by
Figure 4.21. For this reason, running the scheduler without time slicing
is considered an advanced technique that should only be used by
experienced users.</p>
<p><a name="fig4.21" title="Figure 4.21 Execution pattern that demonstrates how tasks of equal priority can..."></a></p>
<hr />
<p><img src="media/figure_4.21_equal_priority_without_time_slicing_execution_pattern.png" alt="" /><br />
<em><strong>Figure 4.21</strong></em> <em>Execution pattern that demonstrates how tasks of equal priority can
receive hugely different amounts of processing time when time slicing is not used</em></p>
<hr />
<p>Referring to Figure 4.21, which assumes <code>configIDLE_SHOULD_YIELD</code> is set to 0:</p>
<ul>
<li>
<p>Tick Interrupts</p>
<p>Tick interrupts occur at times t1, t2, t3, t4, t5, t8, t11, t12 and
t13.</p>
</li>
<li>
<p>Task 1</p>
<p>Task 1 is a high priority event driven task that spends most of its
time in the <em>Blocked</em> state waiting for its event of interest. Task 1
transitions from the <em>Blocked</em> state to the <em>Ready</em> state (and
subsequently, as it is the highest priority <em>Ready</em> state task, on into
the <em>Running</em> state) each time the event occurs. Figure 4.21 shows Task 1
processing an event between times t6 and t7, then again between times
t9 and t10.</p>
</li>
<li>
<p>The Idle Task and Task 2</p>
<p>The Idle task and Task 2 are both continuous processing tasks, and both
have a priority of 0 (the idle priority). Continuous processing tasks do
not enter the <em>Blocked</em> state.</p>
<p>Time slicing is not being used, so an idle priority task that is in the
<em>Running</em> state will remain in the <em>Running</em> state until it is preempted by
the higher priority Task 1.</p>
<p>In Figure 4.21 the Idle task starts running at time t1, and remains in the
<em>Running</em> state until it is preempted by Task 1 at time t6, which is more
than four complete tick periods after it entered the <em>Running</em> state.</p>
<p>Task 2 starts running at time t7, which is when Task 1 re-enters the
<em>Blocked</em> state to wait for another event. Task 2 remains in the Running
state until it too is preempted by Task 1 at time t9, which is less than
one tick period after it entered the <em>Running</em> state.</p>
<p>At time t10 the Idle task re-enters the <em>Running</em> state, despite having
already received more than four times more processing time than Task 2.</p>
</li>
</ul>
<h3 id="4125-cooperative-scheduling"><a class="header" href="#4125-cooperative-scheduling">4.12.5 Cooperative Scheduling</a></h3>
<p>This book focuses on preemptive scheduling, but FreeRTOS can also use
cooperative scheduling. The Table 5 shows the FreeRTOSConfig.h settings
that configure the FreeRTOS scheduler to use cooperative scheduling.</p>
<p>When using the cooperative scheduler (and therefore assuming
application-provided interrupt service routines do not explicitly
request context switches) a context switch only occurs when the Running
state task enters the <em>Blocked</em> state, or the <em>Running</em> state task explicitly
yields (manually requests a re-schedule) by calling <code>taskYIELD()</code>. Tasks
are never preempted, so time slicing cannot be used.</p>
<p>Figure 4.22 demonstrates the behavior of the cooperative scheduler. The
horizontal dashed lines in Figure 4.22 show when a task is in the Ready
state.</p>
<p><a name="fig4.22" title="Figure 4.22 Execution pattern demonstrating the behavior of the cooperative scheduler"></a></p>
<hr />
<p><img src="media/figure_4.22_cooperative_scheduler_execution_pattern.png" alt="" /><br />
<em><strong>Figure 4.22</strong></em> <em>Execution pattern demonstrating the behavior of the cooperative scheduler</em></p>
<hr />
<p>Referring to Figure 4.22:</p>
<ul>
<li>
<p>Task 1</p>
<p>Task 1 has the highest priority. It starts in the <em>Blocked</em> state,
waiting for a semaphore.</p>
<p>At time t3, an interrupt gives the semaphore, causing Task 1 to leave
the <em>Blocked</em> state and enter the <em>Ready</em> state (giving semaphores from
interrupts is covered in Chapter 6).</p>
<p>At time t3, Task 1 is the highest priority <em>Ready</em> state task, and if the
preemptive scheduler had been used Task 1 would become the Running
state task. However, as the cooperative scheduler is being used, Task
1 remains in the <em>Ready</em> state until time t4, which is when the Running
state task calls <code>taskYIELD()</code>.</p>
</li>
<li>
<p>Task 2</p>
<p>The priority of Task 2 is between that of Task 1 and Task 3. It starts
in the <em>Blocked</em> state, waiting for a message that is sent to it by Task
3 at time t2.</p>
<p>At time t2, Task 2 is the highest priority <em>Ready</em> state task, and if the
preemptive scheduler had been used Task 2 would become the Running
state task. However, as the cooperative scheduler is being used, Task
2 remains in the <em>Ready</em> state until the <em>Running</em> state task either
enters the <em>Blocked</em> state or calls <code>taskYIELD()</code>.</p>
<p>The <em>Running</em> state task calls <code>taskYIELD()</code> at time t4, but by then Task
1 is the highest priority <em>Ready</em> state task, so Task 2 does not
actually become the <em>Running</em> state task until Task 1 re-enters the
<em>Blocked</em> state at time t5.</p>
<p>At time t6, Task 2 re-enters the <em>Blocked</em> state to wait for the next
message, at which point Task 3 is once again the highest priority
<em>Ready</em> state task.</p>
</li>
</ul>
<p>In a multi-tasking application the application writer must take care
that a resource is not accessed by more than one task simultaneously, as
simultaneous access could corrupt the resource. As an example, consider
the following scenario in which the accessed resource is a UART (serial
port). Two tasks write strings to the UART; Task 1 writes
"abcdefghijklmnop", and Task 2 writes "123456789":</p>
<ol>
<li>
<p>Task 1 is in the <em>Running</em> state and starts to write its string. It
writes "abcdefg" to the UART, but leaves the <em>Running</em> state before
writing any further characters.</p>
</li>
<li>
<p>Task 2 enters the <em>Running</em> state and writes "123456789" to the UART,
before leaving the <em>Running</em> state.</p>
</li>
<li>
<p>Task 1 re-enters the <em>Running</em> state and writes the remaining
characters of its string to the UART.</p>
</li>
</ol>
<p>In that scenario, what is actually written to the UART is
"abcdefg123456789hijklmnop". The string written by Task 1 has not been
written to the UART in an unbroken sequence as intended, but instead it
has been corrupted, because the string written to the UART by Task 2
appears within it.</p>
<p>Using the cooperative scheduler normally makes it easier to avoid
problems caused by simultaneous access than when using the preemptive
scheduler<sup class="footnote-reference"><a href="#7">4</a></sup>:</p>
<div class="footnote-definition" id="7"><sup class="footnote-definition-label">4</sup>
<p>Methods of safely sharing resources between tasks are covered
later in this book. Resources provided by FreeRTOS itself, such as
queues and semaphores, are always safe to share between tasks.</p>
</div>
<ul>
<li>
<p>When you use the preemptive scheduler the <em>Running</em> state task can be
preempted at any time, including when a resource it is sharing with
another task is in an inconsistent state. As just demonstrated by
the UART example, leaving a resource in an inconsistent state can
result in data corruption.</p>
</li>
<li>
<p>When you use the cooperative scheduler you control when a switch to
another task occurs. You can, therefore, ensure a switch to another
task does not occur while a resource is in an inconsistent state.</p>
</li>
<li>
<p>In the above UART example, you can ensure Task 1 does not leave the
<em>Running</em> state until after writing its entire string to the UART
and, in doing so, remove the possibility of the string being corrupted by the
activities of another task.</p>
</li>
</ul>
<p>As demonstrated in Figure 4.22, using the cooperative scheduler makes
systems less responsive than when using the preemptive scheduler:</p>
<ul>
<li>
<p>When using the preemptive scheduler, the scheduler starts running a
task immediately when the task becomes the highest priority <em>Ready</em>
state task. This is often essential in real-time systems which must
respond to high priority events within a defined time period.</p>
</li>
<li>
<p>When using the cooperative scheduler, a switch to a task that has
become the highest priority <em>Ready</em> state task is not performed until
the <em>Running</em> state task enters the <em>Blocked</em> state or calls
<code>taskYIELD()</code>.</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="5-queue-management-1"><a class="header" href="#5-queue-management-1">5 Queue Management</a></h1>
<h2 id="51-introduction"><a class="header" href="#51-introduction">5.1 Introduction</a></h2>
<p>'Queues' provide a task-to-task, task-to-interrupt, and
interrupt-to-task communication mechanism.</p>
<h3 id="511-scope"><a class="header" href="#511-scope">5.1.1 Scope</a></h3>
<p>This chapter covers:</p>
<ul>
<li>How to create a queue.</li>
<li>How a queue manages the data it contains.</li>
<li>How to send data to a queue.</li>
<li>How to receive data from a queue.</li>
<li>What it means to block on a queue.</li>
<li>How to block on multiple queues.</li>
<li>How to overwrite data in a queue.</li>
<li>How to clear a queue.</li>
<li>The effect of task priorities when writing to and reading from a queue.</li>
</ul>
<p>This chapter only covers task-to-task communication. Chapter 7 covers
task-to-interrupt and interrupt-to-task communication.</p>
<h2 id="52-characteristics-of-a-queue"><a class="header" href="#52-characteristics-of-a-queue">5.2 Characteristics of a Queue</a></h2>
<h3 id="521-data-storage"><a class="header" href="#521-data-storage">5.2.1 Data Storage</a></h3>
<p>A queue can hold a finite number of fixed size data items<sup class="footnote-reference"><a href="#8">1</a></sup>. The
maximum number of items a queue can hold is called its 'length'. Both
the length and the size of each data item are set when the queue is
created.</p>
<div class="footnote-definition" id="8"><sup class="footnote-definition-label">1</sup>
<p>FreeRTOS message buffers, described in chapter TBD, provide a
lighter weight alternative to queues that hold variable length
messages.</p>
</div>
<p>Queues are normally used as First In First Out (FIFO) buffers, where
data is written to the end (tail) of the queue and removed from the
front (head) of the queue. Figure 5.1 demonstrates data being written to
and read from a queue that is being used as a FIFO. It is also possible
to write to the front of a queue, and to overwrite data that is already
at the front of a queue.</p>
<p><a name="fig5.1" title="Figure 5.1 An example sequence of writes to, and reads from a queue"></a></p>
<hr />
<p><img src="media/image31.png" alt="" /><br />
<em><strong>Figure 5.1</strong></em> <em>An example sequence of writes to, and reads from a queue</em></p>
<hr />
<p>There are two ways in which queue behaviour can be implemented:</p>
<ol>
<li>
<p>Queue by copy</p>
<p>Queuing by copy means the data sent to the queue is copied byte for
byte into the queue.</p>
</li>
<li>
<p>Queue by reference</p>
<p>Queuing by reference means the queue only holds pointers to the data
sent to the queue, not the data itself.</p>
</li>
</ol>
<p>FreeRTOS uses the queue by copy method because it is both more
powerful and simpler to use than queueing by reference because:</p>
<ul>
<li>
<p>Queuing by copy does not prevent the queue from also being used to
queue by reference. For example, when the size of the data being
queued makes it impractical to copy the data into the queue, then a
pointer to the data can be copied into the queue instead.</p>
</li>
<li>
<p>A stack variable can be sent directly to a queue, even though the
variable will not exist after the function in which it is declared
has exited.</p>
</li>
<li>
<p>Data can be sent to a queue without first allocating a buffer to
hold the data—you then copy the data into the allocated buffer
and queue a reference to the buffer.</p>
</li>
<li>
<p>The sending task can immediately re-use the variable or buffer that
was sent to the queue.</p>
</li>
<li>
<p>The sending task and the receiving task are completely
de-coupled; an application designer does not need to concern
themself with which task 'owns' the data, or which task is
responsible for releasing the data.</p>
</li>
<li>
<p>The RTOS takes complete responsibility for allocating the memory
used to store data.</p>
</li>
<li>
<p>Memory protected systems restrict access to RAM, in which case
queueing by reference can only be accomplished if the sending and
receiving tasks can both access the referenced data. Queuing by copy
allows data to pass across memory protection boundaries.</p>
</li>
</ul>
<h3 id="522-access-by-multiple-tasks"><a class="header" href="#522-access-by-multiple-tasks">5.2.2 Access by Multiple Tasks</a></h3>
<p>Queues are objects in their own right and can be accessed by any task
or ISR that knows of their existence. Any number of tasks can write to
the same queue, and any number of tasks can read from the same queue. In
practice, it is very common for a queue to have multiple writers, but
much less common for a queue to have multiple readers.</p>
<h3 id="523-blocking-on-queue-reads"><a class="header" href="#523-blocking-on-queue-reads">5.2.3 Blocking on Queue Reads</a></h3>
<p>When a task attempts to read from a queue, it can optionally specify a
'block' time. This is the time the task is kept in the Blocked state to
wait for data to become available from the queue, if the queue
is already empty. A task that is in the Blocked state waiting for data
to become available from a queue is automatically moved to the Ready
state when another task or interrupt places data into the queue. The
task will also be moved automatically from the Blocked state to the
Ready state if the specified block time expires before data becomes
available.</p>
<p>Queues can have multiple readers, so it is possible for a single queue
to have more than one task blocked on it waiting for data. When this is
the case, only one task is unblocked when data becomes available. The
task that is unblocked is always the highest priority task that is
waiting for data. If two or more blocked tasks have equal priority, then the
task that is unblocked is the one that has been waiting the longest.</p>
<h3 id="524-blocking-on-queue-writes"><a class="header" href="#524-blocking-on-queue-writes">5.2.4 Blocking on Queue Writes</a></h3>
<p>Just as it can when reading from a queue, a task can optionally specify a block
time when writing to a queue. In this case, the block time is the
maximum time the task will be held in the Blocked state to wait for
space to become available on the queue, should the queue already be
full.</p>
<p>Queues can have multiple writers, so it is possible for a full queue to
have more than one task blocked on it waiting to complete a send
operation. When this is the case, only one task is unblocked when space
on the queue becomes available. The task that is unblocked is always the
highest priority task that is waiting for space. If two or more blocked tasks
have equal priority, then the task that is unblocked is the one that has been
waiting the longest.</p>
<h3 id="525-blocking-on-multiple-queues"><a class="header" href="#525-blocking-on-multiple-queues">5.2.5 Blocking on Multiple Queues</a></h3>
<p>Queues can be grouped into sets, allowing a task to enter the Blocked
state to wait for data to become available on any of the queues in the
set. Section 5.6, Receiving From Multiple Queues, demonstrates queue
sets.</p>
<h3 id="526-creating-queues-statically-allocated-and-dynamically-allocated-queues"><a class="header" href="#526-creating-queues-statically-allocated-and-dynamically-allocated-queues">5.2.6 Creating Queues: Statically Allocated and Dynamically Allocated Queues</a></h3>
<p>Queues are referenced by handles, which are variables of type
<code>QueueHandle_t</code>. A queue must be explicitly created before it can be used.</p>
<p>Two API functions create queues: <code>xQueueCreate()</code>, <code>xQueueCreateStatic()</code>.</p>
<p>Each queue requires two blocks of RAM, the first to hold its data
structure, and the second to hold queued data. <code>xQueueCreate()</code> allocates
the required RAM from the heap (dynamically). <code>xQueueCreateStatic()</code> uses
pre-allocated RAM passed into the function as parameters.</p>
<h2 id="53-using-a-queue"><a class="header" href="#53-using-a-queue">5.3 Using a Queue</a></h2>
<h3 id="531-the-xqueuecreate-api-function"><a class="header" href="#531-the-xqueuecreate-api-function">5.3.1 The xQueueCreate() API Function</a></h3>
<p>Listing 5.1 shows the <code>xQueueCreate()</code> function prototype.
<code>xQueueCreateStatic()</code> has two additional parameters that point to the
memory pre-allocated to hold the queue's data structure and data storage
area, respectively.</p>
<p><a name="list5.1" title="Listing 5.1 The xQueueCreate() API function prototype"></a></p>
<pre><code class="language-c">QueueHandle_t xQueueCreate( UBaseType_t uxQueueLength, UBaseType_t uxItemSize );
</code></pre>
<p><em><strong>Listing 5.1</strong></em> <em>The xQueueCreate() API function prototype</em></p>
<p><strong>xQueueCreate() parameters and return value:</strong></p>
<ul>
<li>
<p><code>uxQueueLength</code></p>
<p>The maximum number of items that the queue being created can hold at
any one time.</p>
</li>
<li>
<p><code>uxItemSize</code></p>
<p>The size in bytes of each data item that can be stored in the queue.</p>
</li>
<li>
<p>Return value</p>
<p>If NULL is returned, then the queue cannot be created because
there is insufficient heap memory available for FreeRTOS to allocate the
queue data structures and storage area. Chapter 2 provides more
information on the FreeRTOS heap.</p>
<p>If a non-NULL value is returned then the queue was created
successfully and the returned value is the handle to the created
queue.</p>
</li>
</ul>
<p><code>xQueueReset()</code> is an API function that restores a previously created queue
to its original empty state.</p>
<h3 id="532-the-xqueuesendtoback-and-xqueuesendtofront-api-functions"><a class="header" href="#532-the-xqueuesendtoback-and-xqueuesendtofront-api-functions">5.3.2 The xQueueSendToBack() and xQueueSendToFront() API Functions</a></h3>
<p>As might be expected, <code>xQueueSendToBack()</code> sends data to the back (tail)
of a queue, and <code>xQueueSendToFront()</code> sends data to the front (head) of a
queue.</p>
<p><code>xQueueSend()</code> is equivalent to, and exactly the same as,
<code>xQueueSendToBack()</code>.</p>
<blockquote>
<p><em>Note: Never call <code>xQueueSendToFront()</code> or <code>xQueueSendToBack()</code> from an
interrupt service routine. The interrupt-safe versions
<code>xQueueSendToFrontFromISR()</code> and <code>xQueueSendToBackFromISR()</code> should be used
in their place. These are described in Chapter 7.</em></p>
</blockquote>
<p><a name="list5.2" title="Listing 5.2 The xQueueSendToFront() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xQueueSendToFront( QueueHandle_t xQueue,
                              const void * pvItemToQueue,
                              TickType_t xTicksToWait );
</code></pre>
<p><em><strong>Listing 5.2</strong></em> <em>The xQueueSendToFront() API function prototype</em></p>
<p><a name="list5.3" title="Listing 5.3 The xQueueSendToBack() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xQueueSendToBack( QueueHandle_t xQueue,
                             const void * pvItemToQueue,
                             TickType_t xTicksToWait );
</code></pre>
<p><em><strong>Listing 5.3</strong></em> <em>The xQueueSendToBack() API function prototype</em></p>
<p><strong>xQueueSendToFront() and xQueueSendToBack() function parameters and return value</strong></p>
<ul>
<li>
<p><code>xQueue</code></p>
<p>The handle of the queue to which the data is being sent (written).
The queue handle will have been returned from the call to <code>xQueueCreate()</code>
or <code>xQueueCreateStatic()</code> which are used to create the queue.</p>
</li>
<li>
<p><code>pvItemToQueue</code></p>
<p>A pointer to the data to be copied into the queue.</p>
<p>The size of each item the queue can hold is set when the queue is
created, so that many bytes are copied from <code>pvItemToQueue</code> into the queue
storage area.</p>
</li>
<li>
<p><code>xTicksToWait</code></p>
<p>The maximum amount of time the task should remain in the Blocked
state to wait for space to become available on the queue, should the
queue already be full.</p>
<p>Both <code>xQueueSendToFront()</code> and <code>xQueueSendToBack()</code> will return
immediately if <code>xTicksToWait</code> is zero and the queue is already full.</p>
<p>The block time is specified in tick periods, so the absolute time it
represents is dependent on the tick frequency. The macro <code>pdMS_TO_TICKS()</code>
can be used to convert a time specified in milliseconds into a time
specified in ticks.</p>
<p>Setting <code>xTicksToWait</code> to <code>portMAX_DELAY</code> will cause the task to wait
indefinitely (without timing out), provided <code>INCLUDE_vTaskSuspend</code> is set
to 1 in FreeRTOSConfig.h.</p>
</li>
<li>
<p>Return value</p>
<p>There are two possible return values:</p>
<ul>
<li>
<p><code>pdPASS</code></p>
<p><code>pdPASS</code> is returned when data was successfully sent to the queue.</p>
<p>If a block time was specified (<code>xTicksToWait</code> was not zero), then it is
possible the calling task was placed into the Blocked state to wait for
space to become available in the queue before the function returned,
but data was successfully written to the queue before the block time
expired.</p>
</li>
<li>
<p><code>errQUEUE_FULL</code> (same value as <code>pdFAIL</code>)</p>
<p><code>errQUEUE_FULL</code> is returned if data could not be written to the queue
because the queue was already full.</p>
<p>If a block time was specified (<code>xTicksToWait</code> was not zero) then the
calling task will have been placed into the Blocked state to wait for
another task or interrupt to make space in the queue, but the specified
block time expired before that happened.</p>
</li>
</ul>
</li>
</ul>
<h3 id="533-the-xqueuereceive-api-function"><a class="header" href="#533-the-xqueuereceive-api-function">5.3.3 The xQueueReceive() API Function</a></h3>
<p><code>xQueueReceive()</code> receives (reads) an item from a queue. The received item
is removed from the queue.</p>
<blockquote>
<p><em>Note: Never call <code>xQueueReceive()</code> from an interrupt service routine. The
interrupt-safe <code>xQueueReceiveFromISR()</code> API function is described in
Chapter 7.</em></p>
</blockquote>
<p><a name="list5.4" title="Listing 5.4 The xQueueReceive() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xQueueReceive( QueueHandle_t xQueue,
                          void * const pvBuffer,
                          TickType_t xTicksToWait );
</code></pre>
<p><em><strong>Listing 5.4</strong></em> <em>The xQueueReceive() API function prototype</em></p>
<p><strong>xQueueReceive() function parameters and return values</strong></p>
<ul>
<li>
<p><code>xQueue</code></p>
<p>The handle of the queue from which the data is being received
(read). The queue handle will have been returned from the call to
<code>xQueueCreate()</code> or <code>xQueueCreateStatic()</code> used to create the queue.</p>
</li>
<li>
<p><code>pvBuffer</code></p>
<p>A pointer to the memory into which the received data will be copied.</p>
<p>The size of each data item that the queue holds is set when the queue
is created. The memory pointed to by <code>pvBuffer</code> must be at least large
enough to hold that many bytes.</p>
</li>
<li>
<p><code>xTicksToWait</code></p>
<p>The maximum amount of time the task should remain in the Blocked
state to wait for data to become available on the queue, if the
queue is already be empty.</p>
<p>If <code>xTicksToWait</code> is zero, then <code>xQueueReceive()</code> will return immediately
if the queue is already empty.</p>
<p>The block time is specified in tick periods, so the absolute time it
represents is dependent on the tick frequency. The macro <code>pdMS_TO_TICKS()</code>
can be used to convert a time specified in milliseconds into a time
specified in ticks.</p>
<p>Setting <code>xTicksToWait</code> to <code>portMAX_DELAY</code> will cause the task to wait
indefinitely (without timing out) provided <code>INCLUDE_vTaskSuspend</code> is set
to 1 in FreeRTOSConfig.h.</p>
</li>
<li>
<p>Return value</p>
<p>There are two possible return values:</p>
<ul>
<li>
<p><code>pdPASS</code></p>
<p><code>pdPASS</code> is returned when data was successfully read from the queue.</p>
<p>If a block time was specified (<code>xTicksToWait</code> was not zero), then it is
possible the calling task was placed into the Blocked state to wait for
data to become available on the queue, but data was successfully read
from the queue before the block time expired.</p></p>
</li>
<li>
<p><code>errQUEUE_EMPTY</code> (same value as <code>pdFAIL</code>)</p>
<p><code>errQUEUE_EMPTY</code> is returned if data cannot be read from the queue
because the queue is already empty.</p>
<p>If a block time was specified (<code>xTicksToWait</code> was not zero,) then the
calling task will have been placed into the Blocked state to wait for
another task or interrupt to send data to the queue, but the block time
expired before that happened.</p>
</li>
</ul>
</li>
</ul>
<h3 id="534-the-uxqueuemessageswaiting-api-function"><a class="header" href="#534-the-uxqueuemessageswaiting-api-function">5.3.4 The uxQueueMessagesWaiting() API Function</a></h3>
<p><code>uxQueueMessagesWaiting()</code> queries the number of items currently in a queue.</p>
<blockquote>
<p><em>Note: Never call <code>uxQueueMessagesWaiting()</code> from an interrupt service
routine. The interrupt-safe <code>uxQueueMessagesWaitingFromISR()</code> should be
used in its place.</em></p>
</blockquote>
<p><a name="list5.5" title="Listing 5.5 The uxQueueMessagesWaiting() API function prototype"></a></p>
<pre><code class="language-c">UBaseType_t uxQueueMessagesWaiting( QueueHandle_t xQueue );
</code></pre>
<p><em><strong>Listing 5.5</strong></em> <em>The uxQueueMessagesWaiting() API function prototype</em></p>
<p><strong>uxQueueMessagesWaiting() function parameters and return value</strong></p>
<ul>
<li>
<p><code>xQueue</code></p>
<p>The handle of the queue being queried. The queue handle will have
been returned from the call to <code>xQueueCreate()</code> or <code>xQueueCreateStatic()</code>
which are used to create the queue.</p>
</li>
<li>
<p>Return value</p>
<p>The number of items currently in the queue being queried. If zero is returned,
then the queue is empty.</p>
</li>
</ul>
<h2 id="-9"><a class="header" href="#-9"><a name="example5.1" title="Example 5.1 Blocking when receiving from a queue"></a></a></h2>
<p><em><strong>Example 5.1</strong></em> <em>Blocking when receiving from a queue</em></p>
<hr />
<p>This example demonstrates creating a queue, sending data to the queue
from multiple tasks, and receiving data from the queue. The queue is
created to hold data items of type <code>int32_t</code>. The tasks that send to the
queue do not specify a block time, whereas the task that receives from
the queue does.</p>
<p>The tasks that send to the queue have a lower priority than the task
that receives from the queue. This means the queue should never contain
more than one item because, as soon as data is sent to the queue the
receiving task will unblock, pre-empt the sending task (because it has a
higher priority), and remove the data, leaving the queue empty once
again.</p>
<p>The example creates two instances of the task shown in Listing 5.6, one
that continuously writes the value 100 to the queue, and another that
continuously writes the value 200 to the same queue. The task parameter
is used to pass these values into each task instance.</p>
<p><a name="list5.6" title="Listing 5.6 Implementation of the sending task used in Example 5.1"></a></p>
<pre><code class="language-c">static void vSenderTask( void *pvParameters )
{

    int32_t lValueToSend;

    BaseType_t xStatus;

    /* Two instances of this task are created so the value that is sent to
       the queue is passed in via the task parameter - this way each instance 
       can use a different value. The queue was created to hold values of type 
       int32_t, so cast the parameter to the required type. */
    lValueToSend = ( int32_t ) pvParameters;

    /* As per most tasks, this task is implemented within an infinite loop. */
    for( ;; )
    {

        /* Send the value to the queue.

           The first parameter is the queue to which data is being sent. The
           queue was created before the scheduler was started, so before this 
           task started to execute.

           The second parameter is the address of the data to be sent, in this 
           case the address of lValueToSend.

           The third parameter is the Block time – the time the task should be 
           kept in the Blocked state to wait for space to become available on 
           the queue should the queue already be full. In this case a block 
           time is not specified because the queue should never contain more 
           than one item, and therefore never be full. */
        xStatus = xQueueSendToBack( xQueue, &amp;lValueToSend, 0 );

        if( xStatus != pdPASS )
        {
            /* The send operation could not complete because the queue was full-
               this must be an error as the queue should never contain more than
               one item! */
            vPrintString( "Could not send to the queue.\r\n" );
        }
    }
}
</code></pre>
<p><em><strong>Listing 5.6</strong></em> <em>Implementation of the sending task used in Example 5.1</em></p>
<p>Listing 5.7 shows the implementation of the task that receives data from
the queue. The receiving task specifies a block time of 100
milliseconds, then enters the Blocked state to wait for data to become
available. It leaves the Blocked state when either data is available on
the queue, or 100 milliseconds passes without data becoming available.
In this example, there are two tasks continuously writing to the queue
so the 100 milliseconds timeout never expires.</p>
<p><a name="list5.7" title="Listing 5.7  Implementation of the receiver task for Example 5.1"></a></p>
<pre><code class="language-c">static void vReceiverTask( void *pvParameters )
{
    /* Declare the variable that will hold the values received from the
       queue. */
    int32_t lReceivedValue;
    BaseType_t xStatus;
    const TickType_t xTicksToWait = pdMS_TO_TICKS( 100 );

    /* This task is also defined within an infinite loop. */
    for( ;; )
    {
        /* This call should always find the queue empty because this task will
           immediately remove any data that is written to the queue. */
        if( uxQueueMessagesWaiting( xQueue ) != 0 )
        {
            vPrintString( "Queue should have been empty!\r\n" );
        }

        /* Receive data from the queue.

           The first parameter is the queue from which data is to be received.
           The queue is created before the scheduler is started, and therefore
           before this task runs for the first time.

           The second parameter is the buffer into which the received data will
           be placed. In this case the buffer is simply the address of a 
           variable that has the required size to hold the received data.

           The last parameter is the block time – the maximum amount of time 
           that the task will remain in the Blocked state to wait for data to 
           be available should the queue already be empty. */
        xStatus = xQueueReceive( xQueue, &amp;lReceivedValue, xTicksToWait );

        if( xStatus == pdPASS )
        {
            /* Data was successfully received from the queue, print out the
               received value. */
            vPrintStringAndNumber( "Received = ", lReceivedValue );
        }
        else
        {
            /* Data was not received from the queue even after waiting for 
               100ms. This must be an error as the sending tasks are free 
               running and will be continuously writing to the queue. */
            vPrintString( "Could not receive from the queue.\r\n" );
        }
    }
}
</code></pre>
<p><em><strong>Listing 5.7</strong></em>  <em>Implementation of the receiver task for Example 5.1</em></p>
<p>Listing 5.8 contains the definition of the <code>main()</code> function. This simply
creates the queue and the three tasks before starting the scheduler. The
queue is created to hold a maximum of five <code>int32_t</code> values, even though
the relative task priorities mean the queue will never hold more than
one item at a time.</p>
<p><a name="list5.8" title="Listing 5.8 The implementation of main() in Example 5.1"></a></p>
<pre><code class="language-c">/* Declare a variable of type QueueHandle_t. This is used to store the
   handle to the queue that is accessed by all three tasks. */
QueueHandle_t xQueue;

int main( void )
{
    /* The queue is created to hold a maximum of 5 values, each of which is
       large enough to hold a variable of type int32_t. */
    xQueue = xQueueCreate( 5, sizeof( int32_t ) );

    if( xQueue != NULL )
    {
        /* Create two instances of the task that will send to the queue. The
           task parameter is used to pass the value that the task will write 
           to the queue, so one task will continuously write 100 to the queue 
           while the other task will continuously write 200 to the queue. Both
           tasks are created at priority 1. */
        xTaskCreate( vSenderTask, "Sender1", 1000, ( void * ) 100, 1, NULL );
        xTaskCreate( vSenderTask, "Sender2", 1000, ( void * ) 200, 1, NULL );

        /* Create the task that will read from the queue. The task is created
           with priority 2, so above the priority of the sender tasks. */
        xTaskCreate( vReceiverTask, "Receiver", 1000, NULL, 2, NULL );

        /* Start the scheduler so the created tasks start executing. */
        vTaskStartScheduler();
    }
    else
    {
        /* The queue could not be created. */
    }

    /* If all is well then main() will never reach here as the scheduler will
       now be running the tasks. If main() does reach here then it is likely
       that there was insufficient FreeRTOS heap memory available for the idle 
       task to be created. Chapter 3 provides more information on heap memory 
       management. */
    for( ;; );
}
</code></pre>
<p><em><strong>Listing 5.8</strong></em> <em>The implementation of main() in Example 5.1</em></p>
<p>Figure 5.2 shows the output produced by Example 5.1.</p>
<p><a name="fig5.2" title="Figure 5.2 The output produced when Example 5.1 is executed"></a></p>
<hr />
<p><img src="media/image32.jpg" alt="" /><br />
<em><strong>Figure 5.2</strong></em> <em>The output produced when Example 5.1 is executed</em></p>
<hr />
<p>Figure 5.3 demonstrates the sequence of execution.</p>
<p><a name="fig5.3" title="Figure 5.3 The sequence of execution produced by Example 5.1"></a></p>
<hr />
<p><img src="media/image33.png" alt="" /><br />
<em><strong>Figure 5.3</strong></em> <em>The sequence of execution produced by Example 5.1</em></p>
<hr />
<h2 id="54-receiving-data-from-multiple-sources"><a class="header" href="#54-receiving-data-from-multiple-sources">5.4 Receiving Data From Multiple Sources</a></h2>
<p>It is common in FreeRTOS designs for a task to receive data from more
than one source. The receiving task needs to know where the data came
from to determine what to do with it. An easy design pattern to achieve
that uses a single queue to transfer structures that contain both the
data value and data source, as demonstrated in Figure 5.4.</p>
<p><a name="fig5.4" title="Figure 5.4 An example scenario where structures are sent on a queue"></a></p>
<hr />
<p><img src="media/image34.png" alt="" /><br />
<em><strong>Figure 5.4</strong></em> <em>An example scenario where structures are sent on a queue</em></p>
<hr />
<p>Referring to Figure 5.4:</p>
<ul>
<li>
<p>The created queue holds structures of type <code>Data_t</code>. The structure
allows both a data value and an enumerated type indicating what the
data means to be sent to the queue in one message.</p>
</li>
<li>
<p>A central Controller task performs the primary system function. This
has to react to inputs and changes to the system state communicated
to it on the queue.</p>
</li>
<li>
<p>A CAN bus task is used to encapsulate the CAN bus interfacing
functionality. When the CAN bus task has received and decoded a
message, it sends the already decoded message to the Controller task
in a <code>Data_t</code> structure. The <code>eDataID</code> member of the transferred
structure tells the Controller task what the data is. In the case
shown here, it is a motor speed value. The <code>lDataValue</code> member of the
transferred structure tells the Controller task the actual motor
speed value.</p>
</li>
<li>
<p>A Human Machine Interface (HMI) task is used to encapsulate all the
HMI functionality. The machine operator can probably input commands
and query values in a number of ways that have to be detected and
interpreted within the HMI task. When a new command is input, the
HMI task sends the command to the Controller task in a <code>Data_t</code>
structure. The <code>eDataID</code> member of the transferred structure tells the
Controller task what the data is. In the case shown here, it is a new
set point value. The <code>lDataValue</code> member of the transferred structure
tells the Controller task the actual set point value.</p>
</li>
</ul>
<p>Chapter (RB-TBD) shows how to extend this design pattern such that
the controller task can reply directly to the task that queued a structure.</p>
<h2 id="-10"><a class="header" href="#-10"><a name="example5.2" title="Example 5.2 Blocking when sending to a queue, and sending structures on a queue"></a></a></h2>
<p><em><strong>Example 5.2</strong></em> <em>Blocking when sending to a queue, and sending structures on a queue</em></p>
<hr />
<p>Example 5.2 is similar to Example 5.1, but with reversed task priorities,
so the receiving task has a lower priority than the sending tasks. Also,
the created queue holds structures rather than integers.</p>
<p>Listing 5.9 shows the definition of the structure used by Example 5.2.</p>
<p><a name="list5.9" title="Listing 5.9 The definition of the structure that is to be passed on a queue, plus the declaration of two variables for use by the example"></a></p>
<pre><code class="language-c">/* Define an enumerated type used to identify the source of the data. */
typedef enum
{
    eSender1,
    eSender2
} DataSource_t;

/* Define the structure type that will be passed on the queue. */
typedef struct
{
    uint8_t ucValue;
    DataSource_t eDataSource;
} Data_t;

/* Declare two variables of type Data_t that will be passed on the queue. */
static const Data_t xStructsToSend[ 2 ] =
{
    { 100, eSender1 }, /* Used by Sender1. */
    { 200, eSender2 }  /* Used by Sender2. */
};
</code></pre>
<p><em><strong>Listing 5.9</strong></em> <em>The definition of the structure that is to be passed on a queue, plus the declaration of two variables for use by the example</em></p>
<p>In Example 5.1, the receiving task has the highest priority, so the queue
never contains more than one item. This happens because the receiving task
pre-empts the sending tasks as soon as data is placed into the queue.
In Example 5.2, the sending tasks have the higher priority, so the queue
will normally be full. This is because, as soon as the receiving task
removes an item from the queue, it is pre-empted by one of the sending
tasks which then immediately re-fills the queue. The sending task then
re-enters the Blocked state to wait for space to become available on the
queue again.</p>
<p>Listing 5.10 shows the implementation of the sending task. The sending
task specifies a block time of 100 milliseconds, so it enters the
Blocked state to wait for space to become available each time the queue
becomes full. It leaves the Blocked state when either space is available
on the queue, or 100 milliseconds passes without space becoming
available. In this example, the receiving tasks continuously make space
in the queue, so the 100 milliseconds timeout never expires.</p>
<p><a name="list5.10" title="Listing 5.10 The implementation of the sending task for Example 5.2"></a></p>
<pre><code class="language-c">static void vSenderTask( void *pvParameters )
{
    BaseType_t xStatus;
    const TickType_t xTicksToWait = pdMS_TO_TICKS( 100 );

    /* As per most tasks, this task is implemented within an infinite loop. */
    for( ;; )
    {
        /* Send to the queue.

           The second parameter is the address of the structure being sent. The
           address is passed in as the task parameter so pvParameters is used
           directly.

           The third parameter is the Block time - the time the task should be 
           kept in the Blocked state to wait for space to become available on 
           the queue if the queue is already full. A block time is specified 
           because the sending tasks have a higher priority than the receiving 
           task so the queue is expected to become full. The receiving task 
           will remove items from the queue when both sending tasks are in the 
           Blocked state. */
        xStatus = xQueueSendToBack( xQueue, pvParameters, xTicksToWait );

        if( xStatus != pdPASS )
        {
            /* The send operation could not complete, even after waiting for 
               100ms. This must be an error as the receiving task should make 
               space in the queue as soon as both sending tasks are in the 
               Blocked state. */
            vPrintString( "Could not send to the queue.\r\n" );
        }
    }
}
</code></pre>
<p><em><strong>Listing 5.10</strong></em> <em>The implementation of the sending task for Example 5.2</em></p>
<p>The receiving task has the lowest priority so it only runs only when both
sending tasks are in the Blocked state. The sending tasks only enter the
Blocked state when the queue is full, so the receiving task will only
execute when the queue is already full. Therefore, it always expects to
receive data even when it does not specify a block time.</p>
<p>Listing 5.11 shows the implementation of the receiving task.</p>
<p><a name="list5.11" title="Listing 5.11 The definition of the receiving task for Example 5.2"></a></p>
<pre><code class="language-c">static void vReceiverTask( void *pvParameters )
{
    /* Declare the structure that will hold the values received from the
       queue. */
    Data_t xReceivedStructure;
    BaseType_t xStatus;

    /* This task is also defined within an infinite loop. */
    for( ;; )
    {
        /* Because it has the lowest priority this task will only run when the
           sending tasks are in the Blocked state. The sending tasks will only
           enter the Blocked state when the queue is full so this task always 
           expects the number of items in the queue to be equal to the queue 
           length, which is 3 in this case. */
        if( uxQueueMessagesWaiting( xQueue ) != 3 )
        {
            vPrintString( "Queue should have been full!\r\n" );
        }

        /* Receive from the queue.

           The second parameter is the buffer into which the received data will
           be placed. In this case the buffer is simply the address of a 
           variable that has the required size to hold the received structure.

           The last parameter is the block time - the maximum amount of time 
           that the task will remain in the Blocked state to wait for data to 
           be available if the queue is already empty. In this case a block 
           time is not necessary because this task will only run when the 
           queue is full. */
        xStatus = xQueueReceive( xQueue, &amp;xReceivedStructure, 0 );

        if( xStatus == pdPASS )
        {
            /* Data was successfully received from the queue, print out the
               received value and the source of the value. */
            if( xReceivedStructure.eDataSource == eSender1 )
            {
                vPrintStringAndNumber( "From Sender 1 = ", 
                                       xReceivedStructure.ucValue );
            }
            else
            {
                vPrintStringAndNumber( "From Sender 2 = ", 
                                       xReceivedStructure.ucValue );
            }
        }
        else
        {
            /* Nothing was received from the queue. This must be an error as 
               this task should only run when the queue is full. */
            vPrintString( "Could not receive from the queue.\r\n" );
        }
    }
}
</code></pre>
<p><em><strong>Listing 5.11</strong></em> <em>The definition of the receiving task for Example 5.2</em></p>
<p><code>main()</code> changes only slightly from the previous example. The queue is
created to hold three <code>Data_t</code> structures, and the priorities of the
sending and receiving tasks are reversed. Listing 5.12 shows the
implementation of <code>main()</code>.</p>
<p><a name="list5.12" title="Listing 5.12 The implementation of main() for Example 5.2"></a></p>
<pre><code class="language-c">int main( void )
{
    /* The queue is created to hold a maximum of 3 structures of type Data_t. */
    xQueue = xQueueCreate( 3, sizeof( Data_t ) );

    if( xQueue != NULL )
    {
        /* Create two instances of the task that will write to the queue. The
           parameter is used to pass the structure that the task will write to
           the queue, so one task will continuously send xStructsToSend[ 0 ]
           to the queue while the other task will continuously send 
           xStructsToSend[ 1 ]. Both tasks are created at priority 2, which is
           above the priority of the receiver. */
        xTaskCreate( vSenderTask, "Sender1", 1000, &amp;( xStructsToSend[ 0 ] ),
                     2, NULL );
        xTaskCreate( vSenderTask, "Sender2", 1000, &amp;( xStructsToSend[ 1 ] ),
                     2, NULL );

        /* Create the task that will read from the queue. The task is created
           with priority 1, so below the priority of the sender tasks. */
        xTaskCreate( vReceiverTask, "Receiver", 1000, NULL, 1, NULL );

        /* Start the scheduler so the created tasks start executing. */
        vTaskStartScheduler();
    }
    else
    {
        /* The queue could not be created. */
    }

    /* If all is well then main() will never reach here as the scheduler will
       now be running the tasks. If main() does reach here then it is likely
       that there was insufficient heap memory available for the idle task to 
       be created. Chapter 3 provides more information on heap memory 
       management. */
    for( ;; );
}
</code></pre>
<p><em><strong>Listing 5.12</strong></em> <em>The implementation of main() for Example 5.2</em></p>
<p>Figure 5.5 shows the output produced by Example 5.2.</p>
<p><a name="fig5.5" title="Figure 5.5 The output produced by Example 5.2"></a></p>
<hr />
<p><img src="media/image35.jpg" alt="" /><br />
<em><strong>Figure 5.5</strong></em> <em>The output produced by Example 5.2</em></p>
<hr />
<p>Figure 5.6 demonstrates the sequence of execution that results from
having the priority of the sending tasks above the priority of the
receiving task. Given below is a further explanation of Figure 5.6, and
description on why the first four messages originate from the same task.</p>
<p><a name="fig5.6" title="Figure 5.6 The sequence of execution produced by Example 5.2"></a></p>
<hr />
<p><img src="media/image36.png" alt="" /><br />
<em><strong>Figure 5.6</strong></em> <em>The sequence of execution produced by Example 5.2</em></p>
<hr />
<p><strong>Key to Figure 5.6</strong></p>
<ul>
<li>
<p>t1</p>
<p>Task Sender 1 executes and sends 3 data items to the queue.</p>
</li>
<li>
<p>t2</p>
<p>The queue is full so Sender 1 enters the Blocked state to wait for
its next send to complete. Task Sender 2 is now the highest priority
task that can run, so it enters the Running state.</p>
</li>
<li>
<p>t3</p>
<p>Task Sender 2 finds the queue is already full, so it enters the Blocked
state to wait for its first send to complete. Task Receiver is now the
highest priority task that can run, so it enters the Running state.</p>
</li>
<li>
<p>t4</p>
<p>Two tasks that have a priority higher than the receiving task's
priority are waiting for space to become available on the queue,
resulting in task Receiver being pre-empted as soon as it has removed
one item from the queue. Tasks Sender 1 and Sender 2 have the same
priority, so the scheduler selects the task that has been waiting the
longest as the task that will enter the Running state—in this case that
is task Sender 1.</p>
</li>
<li>
<p>t5</p>
<p>Task Sender 1 sends another data item to the queue. There was
only one space in the queue, so task Sender 1 enters the Blocked state
to wait for its next send to complete. Task Receiver is again the
highest priority task that can run so it enters the Running state.</p>
<p>Task Sender 1 has now sent four items to the queue, and task Sender 2
is still waiting to send its first item to the queue.</p>
</li>
<li>
<p>t6</p>
<p>Two tasks that have a priority higher than the receiving task's
priority are waiting for space to become available on the queue, so task
Receiver is pre-empted as soon as it has removed one item from the
queue. This time Sender 2 has been waiting longer than Sender 1, so
Sender 2 enters the Running state.</p>
</li>
<li>
<p>t7</p>
<p>Task Sender 2 sends a data item to the queue. There was only one
space in the queue so Sender 2 enters the Blocked state to wait for its
next send to complete. Both tasks Sender 1 and Sender 2 are waiting for
space to become available on the queue, so task Receiver is the only
task that can enter the Running state.</p>
</li>
</ul>
<h2 id="55-working-with-large-or-variable-sized-data"><a class="header" href="#55-working-with-large-or-variable-sized-data">5.5 Working with Large or Variable Sized Data</a></h2>
<h3 id="551-queuing-pointers"><a class="header" href="#551-queuing-pointers">5.5.1 Queuing Pointers</a></h3>
<p>If the size of the data stored in the queue is large, then it is
preferable to use the queue to transfer pointers to the data, rather
than copy the data itself into and out of the queue byte by byte.
Transferring pointers is more efficient in both processing time and the
amount of RAM required to create the queue. However, when queuing
pointers, extreme care must be taken to ensure that:</p>
<ul>
<li>
<p>The owner of the RAM being pointed to is clearly defined.</p>
<p>When sharing memory between tasks via a pointer, it is essential to
ensure both tasks do not modify the memory contents simultaneously, or
take any other action that could cause the memory contents to be invalid
or inconsistent. Ideally, only the sending task should be permitted to
access the memory before the pointer is sent to the queue, and only the
receiving task should be permitted to access the memory after the
pointer has been received from the queue.</p>
</li>
<li>
<p>The RAM being pointed to remains valid.</p>
<p>If the memory being pointed to was allocated dynamically, or obtained
from a pool of pre-allocated buffers, then exactly one task should be
responsible for freeing the memory. No tasks should attempt to access
the memory after it has been freed.</p>
<p>A pointer should never be used to access data that has been allocated on
a task stack. The data will not be valid after the stack frame has
changed.</p>
</li>
</ul>
<p>By way of example, Listings 5.13, 5.14 and 5.15 demonstrate how
to use a queue to send a pointer to a buffer from one task to another:</p>
<ul>
<li>
<p>Listing 5.13 creates a queue that can hold up to 5 pointers.</p>
</li>
<li>
<p>Listing 5.14 allocates a buffer, writes a string to the buffer, then
sends a pointer to the buffer to the queue.</p>
</li>
<li>
<p>Listing 5.15 receives a pointer to a buffer from the queue, then
prints the string contained in the buffer.</p>
</li>
</ul>
<p><a name="list5.13" title="Listing 5.13 Creating a queue that holds pointers"></a></p>
<pre><code class="language-c">/* Declare a variable of type QueueHandle_t to hold the handle of the
   queue being created. */
QueueHandle_t xPointerQueue;

/* Create a queue that can hold a maximum of 5 pointers, in this case
   character pointers. */
xPointerQueue = xQueueCreate( 5, sizeof( char * ) );
</code></pre>
<p><em><strong>Listing 5.13</strong></em> <em>Creating a queue that holds pointers</em></p>
<p><a name="list5.14" title="Listing 5.14 Using a queue to send a pointer to a buffer"></a></p>
<pre><code class="language-c">/* A task that obtains a buffer, writes a string to the buffer, then
   sends the address of the buffer to the queue created in Listing 5.13. */
void vStringSendingTask( void *pvParameters )
{
    char *pcStringToSend;
    const size_t xMaxStringLength = 50;
    BaseType_t xStringNumber = 0;

    for( ;; )
    {
        /* Obtain a buffer that is at least xMaxStringLength characters big.
           The implementation of prvGetBuffer() is not shown – it might obtain
           the buffer from a pool of pre-allocated buffers, or just allocate 
           the buffer dynamically. */
        pcStringToSend = ( char * ) prvGetBuffer( xMaxStringLength );

        /* Write a string into the buffer. */
        snprintf( pcStringToSend, xMaxStringLength, "String number %d\r\n",
                  xStringNumber );

        /* Increment the counter so the string is different on each iteration
           of this task. */
        xStringNumber++;

        /* Send the address of the buffer to the queue that was created in
           Listing 5.13. The address of the buffer is stored in the 
           pcStringToSend variable.*/
        xQueueSend( xPointerQueue,   /* The handle of the queue. */
                    &amp;pcStringToSend, /* The address of the pointer that points
                                        to the buffer. */
                    portMAX_DELAY );
    }
}
</code></pre>
<p><em><strong>Listing 5.14</strong></em> <em>Using a queue to send a pointer to a buffer</em></p>
<p><a name="list5.15" title="Listing 5.15 Using a queue to receive a pointer to a buffer"></a></p>
<pre><code class="language-c">/* A task that receives the address of a buffer from the queue created
   in Listing 5.13, and written to in Listing 5.14. The buffer contains a
   string, which is printed out. */

void vStringReceivingTask( void *pvParameters )
{
    char *pcReceivedString;

    for( ;; )
    {
        /* Receive the address of a buffer. */
        xQueueReceive( xPointerQueue,     /* The handle of the queue. */
                       &amp;pcReceivedString, /* Store the buffer's address in 
                                             pcReceivedString. */
                       portMAX_DELAY );

        /* The buffer holds a string, print it out. */
        vPrintString( pcReceivedString );

        /* The buffer is not required any more - release it so it can be freed,
           or re-used. */
        prvReleaseBuffer( pcReceivedString );
    }
}
</code></pre>
<p><em><strong>Listing 5.15</strong></em> <em>Using a queue to receive a pointer to a buffer</em></p>
<h3 id="552-using-a-queue-to-send-different-types-and-lengths-of-data2"><a class="header" href="#552-using-a-queue-to-send-different-types-and-lengths-of-data2">5.5.2 Using a Queue to Send Different Types and Lengths of Data<sup class="footnote-reference"><a href="#9">2</a></sup></a></h3>
<div class="footnote-definition" id="9"><sup class="footnote-definition-label">2</sup>
<p>FreeRTOS message buffers are a lighter weight alternative to
queues that hold variable length data.</p>
</div>
<p>Previous sections of this book demonstrated two powerful design
patterns; sending structures to a queue, and sending pointers to a
queue. Combining those techniques allows a task to use a single queue to
receive any data type from any data source. The implementation of the
FreeRTOS+TCP TCP/IP stack provides a practical example of how this is
achieved.</p>
<p>The TCP/IP stack, which runs in its own task, must process events from
many different sources. Different event types are associated with
different types and lengths of data. <code>IPStackEvent_t</code> structures describe
all events that occur outside of the TCP/IP task, and are sent to the
TCP/IP task on a queue. Listing 5.16 shows the <code>IPStackEvent_t</code> structure.
The <code>pvData</code> member of the <code>IPStackEvent_t</code> structure is a pointer that can
be used to hold a value directly, or point to a buffer.</p>
<p><a name="list5.16" title="Listing 5.16 The structure used to send events to the TCP/IP stack task in FreeRTOS+TCP"></a></p>
<pre><code class="language-c">/* A subset of the enumerated types used in the TCP/IP stack to
   identify events. */
typedef enum
{
    eNetworkDownEvent = 0, /* The network interface has been lost, or needs
                              (re)connecting. */
    eNetworkRxEvent,       /* A packet has been received from the network. */
    eTCPAcceptEvent,       /* FreeRTOS_accept() called to accept or wait for a
                              new client. */

/* Other event types appear here but are not shown in this listing. */

} eIPEvent_t;

/* The structure that describes events, and is sent on a queue to the
   TCP/IP task. */
typedef struct IP_TASK_COMMANDS
{
    /* An enumerated type that identifies the event. See the eIPEvent_t
       definition above. */
    eIPEvent_t eEventType;

    /* A generic pointer that can hold a value, or point to a buffer. */
    void *pvData;

} IPStackEvent_t;
</code></pre>
<p><em><strong>Listing 5.16</strong></em> <em>The structure used to send events to the TCP/IP stack task in FreeRTOS+TCP</em></p>
<p>Example TCP/IP events, and their associated data, include:</p>
<ul>
<li>
<p><code>eNetworkRxEvent</code>: A packet of data was received from the network.</p>
<p>The network interface sends data received events to the TCP/IP task
using a structure of type <code>IPStackEvent_t</code>. The structure's <code>eEventType</code>
member is set to <code>eNetworkRxEvent</code>, and the structure's <code>pvData</code> member is
used to point to the buffer that contains the received data. Listing
59 shows a pseudo code example.</p>
<p><a name="list5.17" title="Listing 5.17 Pseudo code showing how an IPStackEvent_t structure is used to send data received from the network to the TCP/IP task"></a></p>
<pre><code class="language-c">void vSendRxDataToTheTCPTask( NetworkBufferDescriptor_t *pxRxedData )
{
    IPStackEvent_t xEventStruct;

    /* Complete the IPStackEvent_t structure. The received data is stored in
       pxRxedData. */
    xEventStruct.eEventType = eNetworkRxEvent;
    xEventStruct.pvData = ( void * ) pxRxedData;

    /* Send the IPStackEvent_t structure to the TCP/IP task. */
    xSendEventStructToIPTask( &amp;xEventStruct );
}
</code></pre>
<p><em><strong>Listing 5.17</strong></em> <em>Pseudo code showing how an IPStackEvent_t structure is used to send data received from the network to the TCP/IP task</em></p>
</li>
<li>
<p><code>eTCPAcceptEvent</code>: A socket is to accept, or wait for, a connection
from a client.</p>
<p>The task that called <code>FreeRTOS_accept()</code> sends accept events to the
TCP/IP task using a structure of type <code>IPStackEvent_t</code>. The structure's
<code>eEventType</code> member is set to <code>eTCPAcceptEvent</code>, and the structure's
<code>pvData</code> member is set to the handle of the socket that is accepting a
connection. Listing 5.18 shows a pseudo code example.</p>
<p><a name="list5.18" title="Listing 5.18 Pseudo code showing how an IPStackEvent_t structure is used to send the handle of a socket that is accepting a connection to the TCP/IP task"></a></p>
<pre><code class="language-c">void vSendAcceptRequestToTheTCPTask( Socket_t xSocket )
{
    IPStackEvent_t xEventStruct;

    /* Complete the IPStackEvent_t structure. */
    xEventStruct.eEventType = eTCPAcceptEvent;
    xEventStruct.pvData = ( void * ) xSocket;

    /* Send the IPStackEvent_t structure to the TCP/IP task. */
    xSendEventStructToIPTask( &amp;xEventStruct );
}
</code></pre>
<p><em><strong>Listing 5.18</strong></em> <em>Pseudo code showing how an IPStackEvent_t structure is used to send the handle of a socket that is accepting a connection to the TCP/IP task</em></p>
</li>
<li>
<p><code>eNetworkDownEvent</code>: The network needs connecting, or re-connecting.</p>
<p>The network interface sends network down events to the TCP/IP task
using a structure of type <code>IPStackEvent_t</code>. The structure's <code>eEventType</code>
member is set to <code>eNetworkDownEvent</code>. Network down events are not
associated with any data, so the structure's <code>pvData</code> member is not
used. Listing 5.19 shows a pseudo code example.</p>
<p><a name="list5.19" title="Listing 5.19 Pseudo code showing how an IPStackEvent_t structure is used to send a network down event to the TCP/IP task"></a></p>
<pre><code class="language-c">void vSendNetworkDownEventToTheTCPTask( Socket_t xSocket )
{
    IPStackEvent_t xEventStruct;

    /* Complete the IPStackEvent_t structure. */
    xEventStruct.eEventType = eNetworkDownEvent;

    xEventStruct.pvData = NULL; /* Not used, but set to NULL for
                                   completeness. */

    /* Send the IPStackEvent_t structure to the TCP/IP task. */
    xSendEventStructToIPTask( &amp;xEventStruct );
}
</code></pre>
<p><em><strong>Listing 5.19</strong></em> <em>Pseudo code showing how an IPStackEvent_t structure is used to send a network down event to the TCP/IP task</em></p>
<p>Listing 5.20 shows the code that receives and processes these events
within the TCP/IP task. It can be seen that the <code>eEventType</code> member of the
<code>IPStackEvent_t</code> structures received from the queue is used to determine
how the <code>pvData</code> member is to be interpreted.</p>
<p><a name="list5.20" title="Listing 5.20 Pseudo code showing how an IPStackEvent_t structure is received and processed"></a></p>
<pre><code class="language-c">IPStackEvent_t xReceivedEvent;

/* Block on the network event queue until either an event is received, or 
   xNextIPSleep ticks pass without an event being received. eEventType is 
   set to eNoEvent in case the call to xQueueReceive() returns because it 
   timed out, rather than because an event was received. */
xReceivedEvent.eEventType = eNoEvent;
xQueueReceive( xNetworkEventQueue, &amp;xReceivedEvent, xNextIPSleep );

/* Which event was received, if any? */
switch( xReceivedEvent.eEventType )
{
    case eNetworkDownEvent :
         /* Attempt to (re)establish a connection. This event is not 
            associated with any data. */
         prvProcessNetworkDownEvent();
         break;

    case eNetworkRxEvent:
         /* The network interface has received a new packet. A pointer to the
            received data is stored in the pvData member of the received 
            IPStackEvent_t structure. Process the received data. */
         prvHandleEthernetPacket( ( NetworkBufferDescriptor_t * )
                                  ( xReceivedEvent.pvData ) );
         break;

    case eTCPAcceptEvent:
         /* The FreeRTOS_accept() API function was called. The handle of the
            socket that is accepting a connection is stored in the pvData 
            member of the received IPStackEvent_t structure. */
         xSocket = ( FreeRTOS_Socket_t * ) ( xReceivedEvent.pvData );
         xTCPCheckNewClient( xSocket );
         break;

    /* Other event types are processed in the same way, but are not shown
       here. */

}
</code></pre>
<p><em><strong>Listing 5.20</strong></em> <em>Pseudo code showing how an IPStackEvent_t structure is received and processed</em></p>
</li>
</ul>
<h2 id="56-receiving-from-multiple-queues"><a class="header" href="#56-receiving-from-multiple-queues">5.6 Receiving From Multiple Queues</a></h2>
<h3 id="561-queue-sets"><a class="header" href="#561-queue-sets">5.6.1 Queue Sets</a></h3>
<p>Often application designs require a single task to receive data of
different sizes, data with different meanings, and data from different
sources. The previous section demonstrated how to do this in a neat and
efficient way using a single queue that receives structures. However,
sometimes an application's designer is working with constraints that
limit their design choices, necessitating the use of a separate queue
for some data sources. For example, third party code being integrated
into a design might assume the presence of a dedicated queue. In such
cases a 'queue set' can be used.</p>
<p>Queue sets allow a task to receive data from more than one queue without
the task polling each queue in turn to determine which, if any, contains
data.</p>
<p>A design that uses a queue set to receive data from multiple sources is
less neat, and less efficient, than a design that achieves the same
functionality using a single queue that receives structures. For that
reason, it is recommended to only use queue sets if design constraints
make their use absolutely necessary.</p>
<p>The following sections describe how to use a queue set by:</p>
<ul>
<li>
<p>Creating a queue set.</p>
</li>
<li>
<p>Adding queues to the set.</p>
<p>Semaphores can also be added to a queue set. Semaphores are described later in this book.</p>
</li>
<li>
<p>Reading from the queue set to determine which queues within the set contain data.</p>
<p>When a queue that is a member of a set receives data, the handle of
the receiving queue is sent to the queue set, and returned when a
task calls a function that reads from the queue set. Therefore, if a
queue handle is returned from a queue set, then the queue referenced
by the handle is known to contain data, and the task can then read
from that queue directly.</p>
<blockquote>
<p><em>Note: If a queue is a member of a queue set then you must read from
the queue each time its handle is received from the queue set, and you
must not read from the queue before its handle is received from the
queue set.</em></p>
</blockquote>
</li>
</ul>
<p>Queue set functionality is enabled by setting the <code>configUSE_QUEUE_SETS</code>
compile time configuration constant to 1 in FreeRTOSConfig.h.</p>
<h3 id="562-the-xqueuecreateset-api-function"><a class="header" href="#562-the-xqueuecreateset-api-function">5.6.2 The xQueueCreateSet() API Function</a></h3>
<p>A queue set must be explicitly created before it can be used. At the
time of writing there is no implementation of <code>xQueueCreateSetStatic()</code>.
However queue sets are themselves queues, so it is possible to create a
set using pre-allocated memory by using a specially crafted call to
<code>xQueueCreateStatic()</code>.</p>
<p>Queues sets are referenced by handles, which are variables of type
<code>QueueSetHandle_t</code>. The <code>xQueueCreateSet()</code> API function creates a queue set
and returns a <code>QueueSetHandle_t</code> that references the created queue set.</p>
<p><a name="list5.21" title="Listing 5.21 The xQueueCreateSet() API function prototype"></a></p>
<pre><code class="language-c">QueueSetHandle_t xQueueCreateSet( const UBaseType_t uxEventQueueLength);
</code></pre>
<p><em><strong>Listing 5.21</strong></em> <em>The xQueueCreateSet() API function prototype</em></p>
<p><strong>xQueueCreateSet() parameters and return value</strong></p>
<ul>
<li>
<p><code>uxEventQueueLength</code></p>
<p>When a queue that is a member of a queue set receives data, the
handle of the receiving queue is sent to the queue set.
<code>uxEventQueueLength</code> defines the maximum number of queue handles the queue
set being created can hold at any one time.</p>
<p>Queue handles are only sent to a queue set when a queue within the
set receives data. A queue cannot receive data if it is full, so no
queue handles can be sent to the queue set if all the queues in the set
are full. Therefore, the maximum number of items the queue set will ever
have to hold at one time is the sum of the lengths of every queue in the
set.</p>
<p>As an example, if there are three empty queues in the set, and each
queue has a length of five, then in total the queues in the set can
receive fifteen items (three queues multiplied by five items each)
before all the queues in the set are full. In that example
<code>uxEventQueueLength</code> must be set to fifteen to guarantee the queue set can
receive every item sent to it.</p>
<p>Semaphores can also be added to a queue set. Semaphores are covered
later in this book. For the purposes of calculating the necessary
<code>uxEventQueueLength</code>, the length of a binary semaphore is one, the length
of a mutex is one, and the length of a counting semaphore is given by
the semaphore's maximum count value.</p>
<p>As another example, if a queue set will contain a queue that has a
length of three, and a binary semaphore (which has a length of one),
<code>uxEventQueueLength</code> must be set to four (three plus one).</p>
</li>
<li>
<p>Return Value</p>
<p>If NULL is returned, then the queue set cannot be created because
there is insufficient heap memory available for FreeRTOS to allocate the
queue set data structures and storage area. Chapter 3 provides more
information on the FreeRTOS heap.</p>
<p>If a non-NULL value is returned then the queue set was created
successfully and the returned value is the handle to the created queue set.</p>
</li>
</ul>
<h3 id="563-the-xqueueaddtoset-api-function"><a class="header" href="#563-the-xqueueaddtoset-api-function">5.6.3 The xQueueAddToSet() API Function</a></h3>
<p><code>xQueueAddToSet()</code> adds a queue or semaphore to a queue set. Semaphores
are described later in this book.</p>
<p><a name="list5.22" title="Listing 5.22 The xQueueAddToSet() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xQueueAddToSet( QueueSetMemberHandle_t xQueueOrSemaphore,
                           QueueSetHandle_t xQueueSet );
</code></pre>
<p><em><strong>Listing 5.22</strong></em> <em>The xQueueAddToSet() API function prototype</em></p>
<p><strong>xQueueAddToSet() parameters and return value</strong></p>
<ul>
<li>
<p><code>xQueueOrSemaphore</code></p>
<p>The handle of the queue or semaphore that is being added to the queue set.</p>
<p>Queue handles and semaphore handles can both be cast to the <code>QueueSetMemberHandle_t</code> type.</p>
</li>
<li>
<p><code>xQueueSet</code></p>
<p>The handle of the queue set to which the queue or semaphore is being added.</p>
</li>
<li>
<p>Return Value</p>
<p>There are two possible return values:</p>
<ol>
<li>
<p><code>pdPASS</code></p>
<p>This indicates the queue set was created successfully.</p>
</li>
<li>
<p><code>pdFAIL</code></p>
<p>This indicates the queue or semaphore could not be added to the queue set.</p>
</li>
</ol>
<p>Queues and binary semaphores can only be added to a set when they are
empty. Counting semaphores can only be added to a set when their count
is zero. Queues and semaphores can only be a member of one set at a time.</p>
</li>
</ul>
<h3 id="564-the-xqueueselectfromset-api-function"><a class="header" href="#564-the-xqueueselectfromset-api-function">5.6.4 The xQueueSelectFromSet() API Function</a></h3>
<p><code>xQueueSelectFromSet()</code> reads a queue handle from the queue set.</p>
<p>When a queue or semaphore that is a member of a set receives data, the
handle of the receiving queue or semaphore is sent to the queue set, and
returned when a task calls <code>xQueueSelectFromSet()</code>. If a handle is
returned from a call to <code>xQueueSelectFromSet()</code> then the queue or
semaphore referenced by the handle is known to contain data and the
calling task must then read from the queue or semaphore directly.</p>
<blockquote>
<p><em>Note: Do not read data from a queue or semaphore that is a member of a
set unless the handle of the queue or semaphore has first been returned
from a call to <code>xQueueSelectFromSet()</code>. Only read one item from a queue or
semaphore each time the queue handle or semaphore handle is returned
from a call to <code>xQueueSelectFromSet()</code>.</em></p>
</blockquote>
<p><a name="list5.23" title="Listing 5.23 The xQueueSelectFromSet() API function prototype"></a></p>
<pre><code class="language-c">QueueSetMemberHandle_t xQueueSelectFromSet( QueueSetHandle_t xQueueSet,
                                            const TickType_t xTicksToWait );
</code></pre>
<p><em><strong>Listing 5.23</strong></em> <em>The xQueueSelectFromSet() API function prototype</em></p>
<p><strong>xQueueSelectFromSet() parameters and return value</strong></p>
<ul>
<li>
<p><code>xQueueSet</code></p>
<p>The handle of the queue set from which a queue handle or semaphore
handle is being received (read). The queue set handle will have been
returned from the call to <code>xQueueCreateSet()</code> used to create the queue
set.</p>
</li>
<li>
<p><code>xTicksToWait</code></p>
<p>The maximum amount of time the calling task should remain in the
Blocked state to wait to receive a queue or semaphore handle from the
queue set, if all the queues and semaphore in the set are empty.</p>
<p>If <code>xTicksToWait</code> is zero then <code>xQueueSelectFromSet()</code> will return
immediately if all the queues and semaphores in the set are empty.</p>
<p>The block time is specified in tick periods, so the absolute time it
represents is dependent on the tick frequency. The macro <code>pdMS_TO_TICKS()</code>
can be used to convert a time specified in milliseconds to a time
specified in ticks.</p>
<p>Setting <code>xTicksToWait</code> to <code>portMAX_DELAY</code> will cause the task to wait
indefinitely (without timing out) provided <code>INCLUDE_vTaskSuspend</code> is set
to 1 in FreeRTOSConfig.h.</p>
</li>
<li>
<p>Return Value</p>
<p>A return value that is not NULL will be the handle of a queue or
semaphore that is known to contain data. If a block time was specified
(<code>xTicksToWait</code> was not zero), then it is possible the calling task was
placed into the Blocked state to wait for data to become available from
a queue or semaphore in the set, but a handle was successfully read from
the queue set before the block time expired. Handles are returned as a
<code>QueueSetMemberHandle_t</code> type, which can be cast to either a <code>QueueHandle_t</code>
type or <code>SemaphoreHandle_t</code> type.</p>
<p>If the return value is NULL then a handle could not be read from the
queue set. If a block time was specified (<code>xTicksToWait</code> was not zero)
then the calling task was placed in the Blocked state to
wait for another task or interrupt to send data to a queue or semaphore
in the set, but the block time expired before that happened.</p>
</li>
</ul>
<h2 id="-11"><a class="header" href="#-11"><a name="example5.3" title="Example 5.3 Using a Queue Set"></a></a></h2>
<p><em><strong>Example 5.3</strong></em> *Using a Queue Set</i></h3></p>
<hr />
<p>This example creates two sending tasks and one receiving task. The
sending tasks send data to the receiving task on two separate queues,
one queue for each task. The two queues are added to a queue set, and
the receiving task reads from the queue set to determine which of the
two queues contain data.</p>
<p>The tasks, queues, and the queue set are all created in <code>main()</code>—see
Listing 5.24 for its implementation.</p>
<p><a name="list5.24" title="Listing 5.24  Implementation of main() for Example 5.3"></a></p>
<pre><code class="language-c">/* Declare two variables of type QueueHandle_t. Both queues are added
   to the same queue set. */
static QueueHandle_t xQueue1 = NULL, xQueue2 = NULL;

/* Declare a variable of type QueueSetHandle_t. This is the queue set
   to which the two queues are added. */
static QueueSetHandle_t xQueueSet = NULL;

int main( void )
{
    /* Create the two queues, both of which send character pointers. The 
       priority of the receiving task is above the priority of the sending 
       tasks, so the queues will never have more than one item in them at 
       any one time*/
    xQueue1 = xQueueCreate( 1, sizeof( char * ) );
    xQueue2 = xQueueCreate( 1, sizeof( char * ) );

    /* Create the queue set. Two queues will be added to the set, each of
       which can contain 1 item, so the maximum number of queue handles the 
       queue set will ever have to hold at one time is 2 (2 queues multiplied 
       by 1 item per queue). */
    xQueueSet = xQueueCreateSet( 1 * 2 );

    /* Add the two queues to the set. */
    xQueueAddToSet( xQueue1, xQueueSet );
    xQueueAddToSet( xQueue2, xQueueSet );

    /* Create the tasks that send to the queues. */
    xTaskCreate( vSenderTask1, "Sender1", 1000, NULL, 1, NULL );
    xTaskCreate( vSenderTask2, "Sender2", 1000, NULL, 1, NULL );

    /* Create the task that reads from the queue set to determine which of
       the two queues contain data. */
    xTaskCreate( vReceiverTask, "Receiver", 1000, NULL, 2, NULL );

    /* Start the scheduler so the created tasks start executing. */
    vTaskStartScheduler();

    /* As normal, vTaskStartScheduler() should not return, so the following
       lines will never execute. */
    for( ;; );
    return 0;
}
</code></pre>
<p><em><strong>Listing 5.24</strong></em> <em>Implementation of main() for Example 5.3</em></p>
<p>The first sending task uses <code>xQueue1</code> to send a character pointer to the
receiving task every 100 milliseconds. The second sending task uses
<code>xQueue2</code> to send a character pointer to the receiving task every 200
milliseconds. The character pointers point to a string that identifies
the sending task. Listing 5.25 shows the implementation of both tasks.</p>
<p><a name="list5.25" title="Listing 5.25 The sending tasks used in Example 5.3"></a></p>
<pre><code class="language-c">void vSenderTask1( void *pvParameters )
{
    const TickType_t xBlockTime = pdMS_TO_TICKS( 100 );
    const char * const pcMessage = "Message from vSenderTask1\r\n";

    /* As per most tasks, this task is implemented within an infinite loop. */

    for( ;; )
    {

        /* Block for 100ms. */
        vTaskDelay( xBlockTime );

        /* Send this task's string to xQueue1. It is not necessary to use a
           block time, even though the queue can only hold one item. This is 
           because the priority of the task that reads from the queue is 
           higher than the priority of this task; as soon as this task writes 
           to the queue it will be pre-empted by the task that reads from the 
           queue, so the queue will already be empty again by the time the 
           call to xQueueSend() returns. The block time is set to 0. */
        xQueueSend( xQueue1, &amp;pcMessage, 0 );
    }
}

/*-----------------------------------------------------------*/

void vSenderTask2( void *pvParameters )
{
    const TickType_t xBlockTime = pdMS_TO_TICKS( 200 );
    const char * const pcMessage = "Message from vSenderTask2\r\n";

    /* As per most tasks, this task is implemented within an infinite loop. */
    for( ;; )
    {
        /* Block for 200ms. */
        vTaskDelay( xBlockTime );

        /* Send this task's string to xQueue2. It is not necessary to use a
           block time, even though the queue can only hold one item. This is 
           because the priority of the task that reads from the queue is 
           higher than the priority of this task; as soon as this task writes 
           to the queue it will be pre-empted by the task that reads from the 
           queue, so the queue will already be empty again by the time the 
           call to xQueueSend() returns. The block time is set to 0. */
        xQueueSend( xQueue2, &amp;pcMessage, 0 );
    }
}
</code></pre>
<p><em><strong>Listing 5.25</strong></em> <em>The sending tasks used in Example 5.3</em></p>
<p>The queues written to by the sending tasks are members of the same queue
set. Each time a task sends to one of the queues, the handle of the
queue is sent to the queue set. The receiving task calls
<code>xQueueSelectFromSet()</code> to read the queue handles from the queue set.
After the receiving task receives a queue handle from the set, it knows
the queue referenced by the received handle contains data, so it reads the
data from the queue directly. The data it reads from the queue is a
pointer to a string, which the receiving task prints out.</p>
<p>If a call to <code>xQueueSelectFromSet()</code> times out, it returns NULL. In Example
5.3, <code>xQueueSelectFromSet()</code> is called with an indefinite block time, so it
will never time out, and can only return a valid queue handle.
Therefore, the receiving task does not need to check to see if
<code>xQueueSelectFromSet()</code> returned NULL before using the returned value.</p>
<p><code>xQueueSelectFromSet()</code> only returns a queue handle if the queue
referenced by the handle contains data, so it is not necessary to use a
block time when reading from the queue.</p>
<p>Listing 5.26 shows the implementation of the receive task.</p>
<p><a name="list5.26" title="Listing 5.26 The receive task used in Example 5.3"></a></p>
<pre><code class="language-c">void vReceiverTask( void *pvParameters )
{
    QueueHandle_t xQueueThatContainsData;
    char *pcReceivedString;

    /* As per most tasks, this task is implemented within an infinite loop. */
    for( ;; )
    {
        /* Block on the queue set to wait for one of the queues in the set to
           contain data. Cast the QueueSetMemberHandle_t value returned from
           xQueueSelectFromSet() to a QueueHandle_t, as it is known all the 
           members of the set are queues (the queue set does not contain any 
           semaphores). */
        xQueueThatContainsData = ( QueueHandle_t ) xQueueSelectFromSet(
                                                     xQueueSet, portMAX_DELAY );

        /* An indefinite block time was used when reading from the queue set,
           so xQueueSelectFromSet() will not have returned unless one of the 
           queues in the set contained data, and xQueueThatContainsData cannot
           be NULL. Read from the queue. It is not necessary to specify a 
           block time because it is known the queue contains data. The block 
           time is set to 0. */
        xQueueReceive( xQueueThatContainsData, &amp;pcReceivedString, 0 );

        /* Print the string received from the queue. */
        vPrintString( pcReceivedString );
    }
}
</code></pre>
<p><em><strong>Listing 5.26</strong></em> <em>The receive task used in Example 5.3</em></p>
<p>Figure 5.7 shows the output produced by Example 5.3. It can be seen that
the receiving task receives strings from both sending tasks. The block
time used by <code>vSenderTask1()</code> is half of the block time used by
<code>vSenderTask2()</code>, which causes the strings sent by <code>vSenderTask1()</code> to print out
twice as often as those sent by <code>vSenderTask2()</code>.</p>
<p><a name="fig5.7" title="Figure 5.7 The output produced when Example 5.3 is executed"></a></p>
<hr />
<p><img src="media/image37.jpg" alt="" /><br />
<em><strong>Figure 5.7</strong></em> <em>The output produced when Example 5.3 is executed</em></p>
<hr />
<h3 id="565-more-realistic-queue-set-use-cases"><a class="header" href="#565-more-realistic-queue-set-use-cases">5.6.5 More Realistic Queue Set Use Cases</a></h3>
<p>Example 5.3 demonstrated a very simplistic case; the queue set only
contained queues, and the two queues it contained were both used to send
a character pointer. In a real application, a queue set might contain
both queues and semaphores, and the queues might not all hold the same
data type. When this is the case, it is necessary to test the value
returned by <code>xQueueSelectFromSet()</code>, before using the returned value.
Listing 5.27 demonstrates how to use the value returned from
<code>xQueueSelectFromSet()</code> when the set has the following members:</p>
<ul>
<li>A binary semaphore.</li>
<li>A queue from which character pointers are read.</li>
<li>A queue from which <code>uint32_t</code> values are read.</li>
</ul>
<p>Listing 5.27 assumes the queues and semaphore have already been created
and added to the queue set.</p>
<p><a name="list5.27" title="Listing 5.27 Using a queue set that contains queues and semaphores"></a></p>
<pre><code class="language-c">/* The handle of the queue from which character pointers are received. */
QueueHandle_t xCharPointerQueue;

/* The handle of the queue from which uint32_t values are received. */
QueueHandle_t xUint32tQueue;

/* The handle of the binary semaphore. */
SemaphoreHandle_t xBinarySemaphore;

/* The queue set to which the two queues and the binary semaphore belong. */
QueueSetHandle_t xQueueSet;

void vAMoreRealisticReceiverTask( void *pvParameters )
{
    QueueSetMemberHandle_t xHandle;
    char *pcReceivedString;
    uint32_t ulRecievedValue;
    const TickType_t xDelay100ms = pdMS_TO_TICKS( 100 );

    for( ;; )
    {
        /* Block on the queue set for a maximum of 100ms to wait for one of the
           members of the set to contain data. */
        xHandle = xQueueSelectFromSet( xQueueSet, xDelay100ms );

        /* Test the value returned from xQueueSelectFromSet(). If the returned
           value is NULL then the call to xQueueSelectFromSet() timed out. If 
           the returned value is not NULL then the returned value will be the 
           handle of one of the set's members. The QueueSetMemberHandle_t 
           value can be cast to either a QueueHandle_t or a SemaphoreHandle_t.
           Whether an explicit cast is required depends on the compiler. */

        if( xHandle == NULL )
        {
            /* The call to xQueueSelectFromSet() timed out. */
        }
        else if( xHandle == ( QueueSetMemberHandle_t ) xCharPointerQueue )
        {
            /* The call to xQueueSelectFromSet() returned the handle of the 
               queue that receives character pointers. Read from the queue. 
               The queue is known to contain data, so a block time of 0 is 
               used. */
            xQueueReceive( xCharPointerQueue, &amp;pcReceivedString, 0 );

            /* The received character pointer can be processed here... */
        }
        else if( xHandle == ( QueueSetMemberHandle_t ) xUint32tQueue )
        {
            /* The call to xQueueSelectFromSet() returned the handle of the 
               queue that receives uint32_t types. Read from the queue. The 
               queue is known to contain data, so a block time of 0 is used. */
            xQueueReceive(xUint32tQueue, &amp;ulRecievedValue, 0 );

            /* The received value can be processed here... */
        }
        else if( xHandle == ( QueueSetMemberHandle_t ) xBinarySemaphore )
        {
            /* The call to xQueueSelectFromSet() returned the handle of the 
               binary semaphore. Take the semaphore now. The semaphore is 
               known to be available so a block time of 0 is used. */
            xSemaphoreTake( xBinarySemaphore, 0 );

            /* Whatever processing is necessary when the semaphore is taken 
               can be performed here... */
        }
    }
}
</code></pre>
<p><em><strong>Listing 5.27</strong></em> <em>Using a queue set that contains queues and semaphores</em></p>
<h2 id="57-using-a-queue-to-create-a-mailbox"><a class="header" href="#57-using-a-queue-to-create-a-mailbox">5.7 Using a Queue to Create a Mailbox</a></h2>
<p>There is no consensus on terminology within the embedded community, and
'mailbox' will mean different things in different RTOSes. In this book,
the term mailbox is used to refer to a queue that has a length of one. A
queue may be described as a mailbox because of the way it is used in
the application, rather than because it has a functional difference to a
queue:</p>
<ul>
<li>
<p>A queue is used to send data from one task to another task, or from
an interrupt service routine to a task. The sender places an item in
the queue, and the receiver removes the item from the queue. The
data passes through the queue from the sender to the receiver.</p>
</li>
<li>
<p>A mailbox is used to hold data that can be read by any task, or any
interrupt service routine. The data does not pass through the
mailbox, but instead remains in the mailbox until it is overwritten.
The sender overwrites the value in the mailbox. The receiver reads
the value from the mailbox, but does not remove the value from the
mailbox.</p>
</li>
</ul>
<p>This chapter describes two queue API functions that enable a queue to be
used as a mailbox.</p>
<p>Listing 5.28 shows how a queue is created for use as a mailbox.</p>
<p><a name="list5.28" title="Listing 5.28 A queue being created for use as a mailbox"></a></p>
<pre><code class="language-c">/* A mailbox can hold a fixed size data item. The size of the data item is set
   when the mailbox (queue) is created. In this example the mailbox is created 
   to hold an Example_t structure. Example_t includes a time stamp to allow the
   data held in the mailbox to note the time at which the mailbox was last 
   updated. The time stamp used in this example is for demonstration purposes 
   only - a mailbox can hold any data the application writer wants, and the 
   data does not need to include a time stamp. */
typedef struct xExampleStructure
{
    TickType_t xTimeStamp;
    uint32_t ulValue;
} Example_t;

/* A mailbox is a queue, so its handle is stored in a variable of type
   QueueHandle_t. */
QueueHandle_t xMailbox;

void vAFunction( void )
{
    /* Create the queue that is going to be used as a mailbox. The queue has 
       a length of 1 to allow it to be used with the xQueueOverwrite() API 
       function, which is described below. */
    xMailbox = xQueueCreate( 1, sizeof( Example_t ) );
}
</code></pre>
<p><em><strong>Listing 5.28</strong></em> <em>A queue being created for use as a mailbox</em></p>
<h3 id="571-the-xqueueoverwrite-api-function"><a class="header" href="#571-the-xqueueoverwrite-api-function">5.7.1 The xQueueOverwrite() API Function</a></h3>
<p>Like the <code>xQueueSendToBack()</code> API function, the <code>xQueueOverwrite()</code> API
function sends data to a queue. Unlike <code>xQueueSendToBack()</code>, if the queue
is already full, then <code>xQueueOverwrite()</code> overwrites data that is already
in the queue.</p>
<p><code>xQueueOverwrite()</code> must only be used with queues that have a length of
one. The overwrite mode will always write to the front of the queue and
update the front of queue pointer, but it will not update the messages
waiting.  If <code>configASSERT</code> is defined, an assert will occur if the queue
has a length &gt; 1.</p>
<blockquote>
<p><em>Note: Never call <code>xQueueOverwrite()</code> from an interrupt service routine.
The interrupt-safe version <code>xQueueOverwriteFromISR()</code> should be used in
its place.</em></p>
</blockquote>
<p><a name="list5.29" title="Listing 5.29 The xQueueOverwrite() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xQueueOverwrite( QueueHandle_t xQueue, const void * pvItemToQueue );
</code></pre>
<p><em><strong>Listing 5.29</strong></em> <em>The xQueueOverwrite() API function prototype</em></p>
<p><strong>xQueueOverwrite() parameters and return value</strong></p>
<ul>
<li>
<p><code>xQueue</code></p>
<p>The handle of the queue to which the data is being sent (written). The queue handle
will have been returned from the call to <code>xQueueCreate()</code> or <code>xQueueCreateStatic()</code>
used to create the queue.</p>
</li>
<li>
<p><code>pvItemToQueue</code></p>
<p>A pointer to the data to be copied into the queue.</p>
<p>The size of each item that the queue can hold is set when the queue is
created, so this many bytes will be copied from <code>pvItemToQueue</code> into the
queue storage area.</p>
</li>
<li>
<p>Return value</p>
<p><code>xQueueOverwrite()</code> writes to the queue even when the queue is full,
so <code>pdPASS</code> is the only possible return value.</p>
</li>
</ul>
<p>Listing 5.30 shows how <code>xQueueOverwrite()</code> is used to write to the mailbox
(queue) created in Listing 5.28.</p>
<p><a name="list5.30" title="Listing 5.30 Using the xQueueOverwrite() API function"></a></p>
<pre><code class="language-c">void vUpdateMailbox( uint32_t ulNewValue )
{
    /* Example_t was defined in Listing 5.28. */
    Example_t xData;

    /* Write the new data into the Example_t structure.*/
    xData.ulValue = ulNewValue;

    /* Use the RTOS tick count as the time stamp stored in the Example_t
       structure. */
    xData.xTimeStamp = xTaskGetTickCount();

    /* Send the structure to the mailbox - overwriting any data that is 
       already in the mailbox. */
    xQueueOverwrite( xMailbox, &amp;xData );
}
</code></pre>
<p><em><strong>Listing 5.30</strong></em> <em>Using the xQueueOverwrite() API function</em></p>
<h3 id="572-the-xqueuepeek-api-function"><a class="header" href="#572-the-xqueuepeek-api-function">5.7.2 The xQueuePeek() API Function</a></h3>
<p><code>xQueuePeek()</code> receives (reads) an item from a queue <em>without</em> removing
the item from the queue. <code>xQueuePeek()</code> receives data from the head of the
queue without modifying the data stored in the queue, or the order in
which data is stored in the queue.</p>
<blockquote>
<p><em>Note: Never call <code>xQueuePeek()</code> from an interrupt service routine. The
interrupt-safe version <code>xQueuePeekFromISR()</code> should be used in its place.</em></p>
</blockquote>
<p><em><code>xQueuePeek()</code> has the same function parameters and return value as
<code>xQueueReceive()</code>.</em></p>
<p><a name="list5.31" title="Listing 5.31 The xQueuePeek() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xQueuePeek( QueueHandle_t xQueue,
                       void * const pvBuffer,
                       TickType_t xTicksToWait );
</code></pre>
<p><em><strong>Listing 5.31</strong></em> <em>The xQueuePeek() API function prototype</em></p>
<p>Listing 5.32 shows <code>xQueuePeek()</code> being used to receive the item posted to
the mailbox (queue) in Listing 5.30.</p>
<p><a name="list5.32" title="Listing 5.32 Using the xQueuePeek() API function"></a></p>
<pre><code class="language-c">BaseType_t vReadMailbox( Example_t *pxData )
{
    TickType_t xPreviousTimeStamp;
    BaseType_t xDataUpdated;

    /* This function updates an Example_t structure with the latest value
       received from the mailbox. Record the time stamp already contained in 
       *pxData before it gets overwritten by the new data. */
    xPreviousTimeStamp = pxData-&gt;xTimeStamp;

    /* Update the Example_t structure pointed to by pxData with the data
       contained in the mailbox. If xQueueReceive() was used here then the 
       mailbox would be left empty, and the data could not then be read by 
       any other tasks. Using xQueuePeek() instead of xQueueReceive() ensures 
       the data remains in the mailbox.

       A block time is specified, so the calling task will be placed in the
       Blocked state to wait for the mailbox to contain data should the mailbox
       be empty. An infinite block time is used, so it is not necessary to 
       check the value returned from xQueuePeek(), as xQueuePeek() will only 
       return when data is available. */
    xQueuePeek( xMailbox, pxData, portMAX_DELAY );

    /* Return pdTRUE if the value read from the mailbox has been updated since
       this function was last called. Otherwise return pdFALSE. */
    if( pxData-&gt;xTimeStamp &gt; xPreviousTimeStamp )
    {
        xDataUpdated = pdTRUE;
    }
    else
    {
        xDataUpdated = pdFALSE;
    }

    return xDataUpdated;
}
</code></pre>
<p><em><strong>Listing 5.32</strong></em> <em>Using the xQueuePeek() API function</em></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="6-software-timer-management-1"><a class="header" href="#6-software-timer-management-1">6 Software Timer Management</a></h1>
<h2 id="61-chapter-introduction-and-scope"><a class="header" href="#61-chapter-introduction-and-scope">6.1 Chapter Introduction and Scope</a></h2>
<p>Software timers are used to schedule the execution of a function at a
set time in the future, or periodically with a fixed frequency. The
function executed by the software timer is called the software timer's
callback function.</p>
<p>Software timers are implemented by, and are under the control of, the
FreeRTOS kernel. They do not require hardware support, and are not
related to hardware timers or hardware counters.</p>
<p>Note that, in line with the FreeRTOS philosophy of using innovative
design to ensure maximum efficiency, software timers do not use any
processing time unless a software timer callback function is actually
executing.</p>
<p>Software timer functionality is optional. To include software timer
functionality:</p>
<ol>
<li>
<p>Build the FreeRTOS source file FreeRTOS/Source/timers.c as part of
your project.</p>
</li>
<li>
<p>Define the constants detailed below in the application's FreeRTOSConfig.h header file :</p>
</li>
</ol>
<ul>
<li>
<p><code>configUSE_TIMERS</code></p>
<p>Set <code>configUSE_TIMERS</code> to 1 in FreeRTOSConfig.h.</p>
</li>
<li>
<p><code>configTIMER_TASK_PRIORITY</code></p>
<p>Sets the priority of the timer service task between 0 and ( <code>configMAX_PRIORITIES</code> - 1 ).</p>
</li>
<li>
<p><code>configTIMER_QUEUE_LENGTH</code></p>
<p>Sets the maximum number of unprocessed commands that the timer command queue can hold at any one time.</p>
</li>
<li>
<p><code>configTIMER_TASK_STACK_DEPTH</code></p>
<p>Sets the size of the stack (in words, not bytes) allocated to the timer service task.</p>
</li>
</ul>
<h3 id="611-scope"><a class="header" href="#611-scope">6.1.1 Scope</a></h3>
<p>This chapter covers:</p>
<ul>
<li>The characteristics of a software timer compared to the
characteristics of a task.</li>
<li>The RTOS daemon task.</li>
<li>The timer command queue.</li>
<li>The difference between a one shot software timer and a periodic
software timer.</li>
<li>How to create, start, reset and change the period of a software timer.</li>
</ul>
<h2 id="62-software-timer-callback-functions"><a class="header" href="#62-software-timer-callback-functions">6.2 Software Timer Callback Functions</a></h2>
<p>Software timer callback functions are implemented as C functions. The
only thing special about them is their prototype, which must return
void, and take a handle to a software timer as its only parameter. The
callback function prototype is demonstrated by Listing 6.1.</p>
<p><a name="list" title="Listing 6.1 The software timer callback function prototype"></a></p>
<pre><code class="language-c">void ATimerCallback( TimerHandle_t xTimer );
</code></pre>
<p><em><strong>Listing 6.1</strong></em> <em>The software timer callback function prototype</em></p>
<p>Software timer callback functions execute from start to finish, and exit
in the normal way. They should be kept short, and must not enter the
Blocked state.</p>
<blockquote>
<p><em>Note: As will be seen, software timer callback functions execute in the
context of a task that is created automatically when the FreeRTOS
scheduler is started. Therefore, it is essential that software timer
callback functions never call FreeRTOS API functions that will result in
the calling task entering the Blocked state. It is ok to call functions
such as <code>xQueueReceive()</code>, but only if the function's <code>xTicksToWait</code>
parameter (which specifies the function's block time) is set to 0. It is
not ok to call functions such as <code>vTaskDelay()</code>, as calling <code>vTaskDelay()</code>
will always place the calling task into the Blocked state.</em></p>
</blockquote>
<h2 id="63-attributes-and-states-of-a-software-timer"><a class="header" href="#63-attributes-and-states-of-a-software-timer">6.3 Attributes and States of a Software Timer</a></h2>
<h3 id="631-period-of-a-software-timer"><a class="header" href="#631-period-of-a-software-timer">6.3.1 Period of a Software Timer</a></h3>
<p>A software timer's 'period' is the time between the software timer being
started, and the software timer's callback function executing.</p>
<h3 id="632-one-shot-and-auto-reload-timers"><a class="header" href="#632-one-shot-and-auto-reload-timers">6.3.2 One-shot and Auto-reload Timers</a></h3>
<p>There are two types of software timer:</p>
<ol>
<li>
<p>One-shot timers</p>
<p>Once started, a one-shot timer will execute its callback function
once only. A one-shot timer can be restarted manually, but will not
restart itself.</p>
</li>
<li>
<p>Auto-reload timers</p>
<p>Once started, an auto-reload timer will re-start itself each time it
expires, resulting in periodic execution of its callback function.</p>
</li>
</ol>
<p>Figure 6.1 shows the difference in behavior between a one-shot timer and
an auto-reload timer. The dashed vertical lines mark the times at which
a tick interrupt occurs.</p>
<p><a name="fig6.1" title="Figure 6.1 The difference in behavior between one-shot and auto-reload software timers"></a></p>
<hr />
<p><img src="media/image38.png" alt="" /><br />
<em><strong>Figure 6.1</strong></em> <em>The difference in behavior between one-shot and auto-reload software timers</em></p>
<hr />
<p>Referring to Figure 6.1:</p>
<ul>
<li>
<p>Timer 1</p>
<p>Timer 1 is a one-shot timer that has a period of 6 ticks. It is
started at time t1, so its callback function executes 6 ticks later,
at time t7. As timer 1 is a one-shot timer, its callback function does
not execute again.</p>
</li>
<li>
<p>Timer 2</p>
<p>Timer 2 is an auto-reload timer that has a period of 5 ticks. It is
started at time t1, so its callback function executes every 5 ticks
after time t1. In Figure 6.1 this is at times t6, t11 and t16.</p>
</li>
</ul>
<h3 id="633-software-timer-states"><a class="header" href="#633-software-timer-states">6.3.3 Software Timer States</a></h3>
<p>A software timer can be in one of the following two states:</p>
<ul>
<li>
<p>Dormant</p>
<p>A Dormant software timer exists, and can be referenced by its handle,
but is not running, so its callback functions will not execute.</p>
</li>
<li>
<p>Running</p>
<p>A Running software timer will execute its callback function after a
time equal to its period has elapsed since the software timer entered
the Running state, or since the software timer was last reset.</p>
</li>
</ul>
<p>Figure 6.2 and Figure 6.3 show the possible transitions between the
Dormant and Running states for an auto-reload timer and a one-shot timer
respectively. The key difference between the two diagrams is the state
entered after the timer has expired; the auto-reload timer executes its
callback function then re-enters the Running state, the one-shot timer
executes its callback function then enters the Dormant state.</p>
<p><a name="fig6.2" title="Figure 6.2 Auto-reload software timer states and transitions"></a>
<a name="fig6.3" title="Figure 6.3 One-shot software timer states and transitions"></a></p>
<hr />
<p><img src="media/image39.png" alt="" /><br />
<em><strong>Figure 6.2</strong></em> <em>Auto-reload software timer states and transitions</em></p>
<p><img src="media/image40.png" alt="" /><br />
<em><strong>Figure 6.3</strong></em> <em>One-shot software timer states and transitions</em></p>
<hr />
<p>The <code>xTimerDelete()</code> API function deletes a timer. A timer can be deleted
at any time. The function prototype is demonstrated by Listing 6.2.</p>
<p><a name="list6.2" title="Listing 6.2 The xTimerDelete() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xTimerDelete( TimerHandle_t xTimer, TickType_t xTicksToWait );
</code></pre>
<p><em><strong>Listing 6.2</strong></em> <em>The xTimerDelete() API function prototype</em></p>
<p><strong>xTimerDelete() parameters and return value</strong></p>
<ul>
<li>
<p><code>xTimer</code></p>
<p>The handle of the timer being deleted.</p>
</li>
<li>
<p><code>xTicksToWait</code></p>
<p>Specifies the time, in ticks, that the calling task should be held
in the Blocked state to wait for the delete command to be successfully
sent to the timer command queue, should the queue already be full when
xTimerDelete() was called.  xTicksToWait is ignored if xTimerDelete()
is called before the scheduler is started.</p>
</li>
<li>
<p>Return value</p>
<p>There are two possible return values:</p>
<ul>
<li>
<p><code>pdPASS</code></p>
<p><code>pdPASS</code> will be returned if the command was successfully sent to the
timer command queue.</p>
</li>
<li>
<p><code>pdFAIL</code></p>
<p><code>pdFAIL</code> will be returned if the delete command could not be sent to
the timer command queue even after xBlockTime ticks had passed.</p>
</li>
</ul>
</li>
</ul>
<h2 id="64-the-context-of-a-software-timer"><a class="header" href="#64-the-context-of-a-software-timer">6.4 The Context of a Software Timer</a></h2>
<h3 id="641-the-rtos-daemon-timer-service-task"><a class="header" href="#641-the-rtos-daemon-timer-service-task">6.4.1 The RTOS Daemon (Timer Service) Task</a></h3>
<p>All software timer callback functions execute in the context of the same
RTOS daemon (or 'timer service') task<sup class="footnote-reference"><a href="#10">1</a></sup>.</p>
<div class="footnote-definition" id="10"><sup class="footnote-definition-label">1</sup>
<p>The task used to be called the 'timer service task', because
originally it was only used to execute software timer callback
functions. Now the same task is used for other purposes too, so it
is known by the more generic name of the 'RTOS daemon task'.</p>
</div>
<p>The daemon task is a standard FreeRTOS task that is created
automatically when the scheduler is started. Its priority and stack size
are set by the <code>configTIMER_TASK_PRIORITY</code> and
<code>configTIMER_TASK_STACK_DEPTH</code> compile time configuration constants
respectively. Both constants are defined within FreeRTOSConfig.h.</p>
<p>Software timer callback functions must not call FreeRTOS API functions
that will result in the calling task entering the Blocked state, as to
do so will result in the daemon task entering the Blocked state.</p>
<h3 id="642-the-timer-command-queue"><a class="header" href="#642-the-timer-command-queue">6.4.2 The Timer Command Queue</a></h3>
<p>Software timer API functions send commands from the calling task to the
daemon task on a queue called the 'timer command queue'. This is shown
in Figure 6.4. Examples of commands include 'start a timer', 'stop a
timer' and 'reset a timer'.</p>
<p>The timer command queue is a standard FreeRTOS queue that is created
automatically when the scheduler is started. The length of the timer
command queue is set by the <code>configTIMER_QUEUE_LENGTH</code> compile time
configuration constant in FreeRTOSConfig.h.</p>
<p><a name="fig6.4" title="Figure 6.4 The timer command queue being used by a software timer API function to communicate with the RTOS daemon task"></a></p>
<hr />
<p><img src="media/image41.png" alt="" /><br />
<em><strong>Figure 6.4</strong></em> <em>The timer command queue being used by a software timer API function to communicate with the RTOS daemon task</em></p>
<hr />
<h3 id="643-daemon-task-scheduling"><a class="header" href="#643-daemon-task-scheduling">6.4.3 Daemon Task Scheduling</a></h3>
<p>The daemon task is scheduled like any other FreeRTOS task; it will only
process commands, or execute timer callback functions, when it is the
highest priority task that is able to run. Figure 6.5 and Figure 6.6
demonstrate how the <code>configTIMER_TASK_PRIORITY</code> setting affects the
execution pattern.</p>
<p>Figure 6.5 shows the execution pattern when the priority of the daemon
task is below the priority of a task that calls the <code>xTimerStart()</code> API
function.</p>
<p><a name="fig6.5" title="Figure 6.5 The execution pattern when the priority of a task calling xTimerStart() is above the priority of the daemon task"></a></p>
<hr />
<p><img src="media/image42.png" alt="" /><br />
<em><strong>Figure 6.5</strong></em> <em>The execution pattern when the priority of a task calling xTimerStart() is above the priority of the daemon task</em></p>
<hr />
<p>Referring to Figure 6.5, in which the priority of Task 1 is higher than
the priority of the daemon task, and the priority of the daemon task is
higher than the priority of the Idle task:</p>
<ol>
<li>
<p>At time t1</p>
<p>Task 1 is in the Running state, and the daemon task is in the
Blocked state.</p>
<p>The daemon task will leave the Blocked state if a command is sent to
the timer command queue, in which case it will process the command,
or if a software timer expires, in which case it will execute the
software timer's callback function.</p>
</li>
<li>
<p>At time t2</p>
<p>Task 1 calls <code>xTimerStart()</code>.</p>
<p><code>xTimerStart()</code> sends a command to the timer command queue, causing
the daemon task to leave the Blocked state. The priority of Task 1
is higher than the priority of the daemon task, so the daemon task
does not pre-empt Task 1.</p>
<p>Task 1 is still in the Running state, and the daemon task has left
the Blocked state and entered the Ready state.</p>
</li>
<li>
<p>At time t3</p>
<p>Task 1 completes executing the <code>xTimerStart()</code> API function. Task 1
executed <code>xTimerStart()</code> from the start of the function to the end of
the function, without leaving the Running state.</p>
</li>
<li>
<p>At time t4</p>
<p>Task 1 calls an API function that results in it entering the Blocked
state. The daemon task is now the highest priority task in the Ready
state, so the scheduler selects the daemon task as the task to enter
the Running state. The daemon task then starts to process the
command sent to the timer command queue by Task 1.</p>
<blockquote>
<p><em>Note: The time at which the software timer being started will
expire is calculated from the time the 'start a timer' command was
sent to the timer command queue—it is not calculated from the time
the daemon task received the 'start a timer' command from the timer
command queue.</em></p>
</blockquote>
</li>
<li>
<p>At time t5</p>
<p>The daemon task has completed processing the command sent to it by
Task 1, and attempts to receive more data from the timer command
queue. The timer command queue is empty, so the daemon task
re-enters the Blocked state. The daemon task will leave the Blocked
state again if a command is sent to the timer command queue, or if a
software timer expires.</p>
<p>The Idle task is now the highest priority task in the Ready state,
so the scheduler selects the Idle task as the task to enter the
Running state.</p>
</li>
</ol>
<p>Figure 6.6 shows a similar scenario to that shown by Figure 6.5, but this
time the priority of the daemon task is above the priority of the task
that calls <code>xTimerStart()</code>.</p>
<p><a name="fig6.6" title="Figure 6.6 The execution pattern when the priority of a task calling xTimerStart() is below the priority of the daemon task"></a></p>
<hr />
<p><img src="media/image43.png" alt="" /><br />
<em><strong>Figure 6.6</strong></em> <em>The execution pattern when the priority of a task calling xTimerStart() is below the priority of the daemon task</em></p>
<hr />
<p>Referring to Figure 6.6, in which the priority of the daemon task is
higher than the priority of Task 1, and the priority of the Task 1 is
higher than the priority of the Idle task:</p>
<ol>
<li>
<p>At time t1</p>
<p>As before, Task 1 is in the Running state, and the daemon task is in
the Blocked state.</p>
</li>
<li>
<p>At time t2</p>
<p>Task 1 calls <code>xTimerStart()</code>.</p>
<p><code>xTimerStart()</code> sends a command to the timer command queue, causing
the daemon task to leave the Blocked state. The priority of the
daemon task is higher than the priority of Task 1, so the scheduler
selects the daemon task as the task to enter the Running state.</p>
<p>Task 1 was pre-empted by the daemon task before it had completed
executing the <code>xTimerStart()</code> function, and is now in the Ready state.</p>
<p>The daemon task starts to process the command sent to the timer
command queue by Task 1.</p>
</li>
<li>
<p>At time t3</p>
<p>The daemon task has completed processing the command sent to it by
Task 1, and attempts to receive more data from the timer command
queue. The timer command queue is empty, so the daemon task
re-enters the Blocked state.</p>
<p>Task 1 is now the highest priority task in the Ready state, so the
scheduler selects Task 1 as the task to enter the Running state.</p>
</li>
<li>
<p>At time t4</p>
<p>Task 1 was pre-empted by the daemon task before it had completed
executing the <code>xTimerStart()</code> function, and only exits (returns from)
<code>xTimerStart()</code> after it has re-entered the Running state.</p>
</li>
<li>
<p>At time t5</p>
<p>Task 1 calls an API function that results in it entering the Blocked
state. The Idle task is now the highest priority task in the Ready
state, so the scheduler selects the Idle task as the task to enter
the Running state.</p>
</li>
</ol>
<p>In the scenario shown by Figure 6.5, time passed between Task 1 sending a
command to the timer command queue, and the daemon task receiving and
processing the command. In the scenario shown by Figure 6.6, the daemon
task had received and processed the command sent to it by Task 1 before
Task 1 returned from the function that sent the command.</p>
<p>Commands sent to the timer command queue contain a time stamp. The time
stamp is used to account for any time that passes between a command
being sent by an application task, and the same command being processed
by the daemon task. For example, if a 'start a timer' command is sent to
start a timer that has a period of 10 ticks, the time stamp is used to
ensure the timer being started expires 10 ticks after the command was
sent, not 10 ticks after the command was processed by the daemon task.</p>
<h2 id="65-creating-and-starting-a-software-timer"><a class="header" href="#65-creating-and-starting-a-software-timer">6.5 Creating and Starting a Software Timer</a></h2>
<h3 id="651-the-xtimercreate-api-function"><a class="header" href="#651-the-xtimercreate-api-function">6.5.1 The xTimerCreate() API Function</a></h3>
<p>FreeRTOS also includes the <code>xTimerCreateStatic()</code> function, which
allocates the memory required to create a timer statically at compile
time: A software timer must be explicitly created before it can be used.</p>
<p>Software timers are referenced by variables of type <code>TimerHandle_t</code>.
<code>xTimerCreate()</code> is used to create a software timer and returns a
<code>TimerHandle_t</code> to reference the software timer it creates. Software
timers are created in the Dormant state.</p>
<p>Software timers can be created before the scheduler is running, or from
a task after the scheduler has been started.</p>
<p><a href="ch02.html#25-data-types-and-coding-style-guide">Section 2.5: Data Types and Coding Style Guide</a> describes the data types and naming conventions used.</p>
<p><a name="list6.3" title="Listing 6.3 The xTimerCreate() API function prototype"></a></p>
<pre><code class="language-c">TimerHandle_t xTimerCreate( const char * const pcTimerName,
                            const TickType_t xTimerPeriodInTicks,
                            const BaseType_t xAutoReload,
                            void * const pvTimerID,
                            TimerCallbackFunction_t pxCallbackFunction );
</code></pre>
<p><em><strong>Listing 6.3</strong></em> <em>The xTimerCreate() API function prototype</em></p>
<p><strong>xTimerCreate() parameters and return value</strong></p>
<ul>
<li>
<p><code>pcTimerName</code></p>
<p>A descriptive name for the timer. This is not used by FreeRTOS in
any way. It is included purely as a debugging aid. Identifying a timer
by a human readable name is much simpler than attempting to identify it
by its handle.</p>
</li>
<li>
<p><code>xTimerPeriodInTicks</code></p>
<p>The timer's period specified in ticks. The <code>pdMS_TO_TICKS()</code> macro can
be used to convert a time specified in milliseconds into a time
specified in ticks. Cannot be 0.</p>
</li>
<li>
<p><code>xAutoReload</code></p>
<p>Set <code>xAutoReload</code> to <code>pdTRUE</code> to create an auto-reload timer. Set
<code>xAutoReload</code> to <code>pdFALSE</code> to create a one-shot timer.</p>
</li>
<li>
<p><code>pvTimerID</code></p>
<p>Each software timer has an ID value. The ID is a void pointer,
and can be used by the application writer for any purpose. The ID is
particularly useful when the same callback function is used by more than
one software timer, as it can be used to provide timer specific storage.
Use of a timer's ID is demonstrated in an example in this
chapter.</p>
<p><code>pvTimerID</code> sets an initial value for the ID of the task being created.</p>
</li>
<li>
<p><code>pxCallbackFunction</code></p>
<p>Software timer callback functions are simply C functions that
conform to the prototype shown in Listing 6.1. The <code>pxCallbackFunction</code>
parameter is a pointer to the function (in effect, just the function
name) to use as the callback function for the software timer being
created.</p>
</li>
<li>
<p>Return value</p>
<p>If NULL is returned, then the software timer cannot be created
because there is insufficient heap memory available for FreeRTOS to
allocate the necessary data structure.</p>
<p>If a non-NULL value is returned it indicates that the software timer has
been created successfully. The returned value is the handle of the
created timer.</p>
<p>Chapter 3 provides more information on heap memory management.</p>
</li>
</ul>
<h3 id="652-the-xtimerstart-api-function"><a class="header" href="#652-the-xtimerstart-api-function">6.5.2 The xTimerStart() API Function</a></h3>
<p><code>xTimerStart()</code> is used to start a software timer that is in the Dormant
state, or reset (re-start) a software timer that is in the Running
state. <code>xTimerStop()</code> is used to stop a software timer that is in the
Running state. Stopping a software timer is the same as transitioning
the timer into the Dormant state.</p>
<p><code>xTimerStart()</code> can be called before the scheduler is started, but when
this is done, the software timer will not actually start until the time
at which the scheduler starts.</p>
<blockquote>
<p><em>Note: Never call <code>xTimerStart()</code> from an interrupt service routine. The
interrupt-safe version <code>xTimerStartFromISR()</code> should be used in its
place.</em></p>
</blockquote>
<p><a name="list6.4" title="Listing 6.4 The xTimerStart() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xTimerStart( TimerHandle_t xTimer, TickType_t xTicksToWait );
</code></pre>
<p><em><strong>Listing 6.4</strong></em> <em>The xTimerStart() API function prototype</em></p>
<p><strong>xTimerStart() parameters and return value</strong></p>
<ul>
<li>
<p><code>xTimer</code></p>
<p>The handle of the software timer being started or reset. The handle
will have been returned from the call to <code>xTimerCreate()</code> used to create
the software timer.</p>
</li>
<li>
<p><code>xTicksToWait</code></p>
<p><code>xTimerStart()</code> uses the timer command queue to send the 'start a
timer' command to the daemon task. <code>xTicksToWait</code> specifies the maximum
amount of time the calling task should remain in the Blocked state to
wait for space to become available on the timer command queue, should
the queue already be full.</p>
<p><code>xTimerStart()</code> will return immediately if <code>xTicksToWait</code> is zero and the
timer command queue is already full.</p>
<p>The block time is specified in tick periods, so the absolute time it
represents is dependent on the tick frequency. The macro <code>pdMS_TO_TICKS()</code>
can be used to convert a time specified in milliseconds into a time
specified in ticks.</p>
<p>If <code>INCLUDE_vTaskSuspend</code> is set to 1 in <code>FreeRTOSConfig.h</code> then setting
<code>xTicksToWait</code> to <code>portMAX_DELAY</code> will result in the calling task remaining
in the Blocked state indefinitely (without a timeout) to wait for space
to become available in the timer command queue.</p>
<p>If <code>xTimerStart()</code> is called before the scheduler has been started then
the value of <code>xTicksToWait</code> is ignored, and <code>xTimerStart()</code> behaves as if
<code>xTicksToWait</code> had been set to zero.</p>
</li>
<li>
<p>Return value</p>
<p>There are two possible return values:</p>
<ul>
<li>
<p><code>pdPASS</code></p>
<p><code>pdPASS</code> will be returned only if the 'start a timer' command was
successfully sent to the timer command queue.</p>
<p>If the priority of the daemon task is above the priority of the task
that called <code>xTimerStart()</code>, then the scheduler will ensure the start
command is processed before <code>xTimerStart()</code> returns. This is because the
daemon task will pre-empt the task that called <code>xTimerStart()</code> as soon as
there is data in the timer command queue.</p>
<p>If a block time was specified (<code>xTicksToWait</code> was not zero), then it is
possible the calling task was placed into the Blocked state to wait for
space to become available in the timer command queue before the function
returned, but data was successfully written to the timer command queue
before the block time expired.</p>
</li>
<li>
<p><code>pdFAIL</code></p>
<p><code>pdFAIL</code> will be returned if the 'start a timer' command could not be
written to the timer command queue because the queue was already
full.</p>
<p>If a block time was specified (<code>xTicksToWait</code> was not zero) then the
calling task will have been placed into the Blocked state to wait for
the daemon task to make room in the timer command queue, but the
specified block time expired before that happened.</p>
</li>
</ul>
</li>
</ul>
<h2 id="-12"><a class="header" href="#-12"><a name="example6.1" title="Example 6.1 Creating one-shot and auto-reload timers"></a></a></h2>
<p><em><strong>Example 6.1</strong></em> <em>Creating one-shot and auto-reload timers</em></p>
<hr />
<p>This example creates and starts a one-shot timer and an auto-reload
timer—as shown in Listing 6.5.</p>
<p><a name="list6.5" title="Listing 6.5 Creating and starting the timers used in Example 6.1"></a></p>
<pre><code class="language-c">/* The periods assigned to the one-shot and auto-reload timers are 3.333 
   second and half a second respectively. */
#define mainONE_SHOT_TIMER_PERIOD pdMS_TO_TICKS( 3333 )
#define mainAUTO_RELOAD_TIMER_PERIOD pdMS_TO_TICKS( 500 )

int main( void )
{
    TimerHandle_t xAutoReloadTimer, xOneShotTimer;
    BaseType_t xTimer1Started, xTimer2Started;

    /* Create the one shot timer, storing the handle to the created timer in 
       xOneShotTimer. */
    xOneShotTimer = xTimerCreate(
        /* Text name for the software timer - not used by FreeRTOS. */
                                  "OneShot", 
        /* The software timer's period in ticks. */
                                   mainONE_SHOT_TIMER_PERIOD, 
        /* Setting uxAutoRealod to pdFALSE creates a one-shot software timer. */
                                   pdFALSE,
        /* This example does not use the timer id. */
                                   0,
        /* Callback function to be used by the software timer being created. */
                                   prvOneShotTimerCallback );

    /* Create the auto-reload timer, storing the handle to the created timer 
       in xAutoReloadTimer. */
    xAutoReloadTimer = xTimerCreate(
        /* Text name for the software timer - not used by FreeRTOS. */
                                     "AutoReload",
        /* The software timer's period in ticks. */
                                     mainAUTO_RELOAD_TIMER_PERIOD,
        /* Setting uxAutoRealod to pdTRUE creates an auto-reload timer. */
                                     pdTRUE,
        /* This example does not use the timer id. */
                                     0,
        /* Callback function to be used by the software timer being created. */
                                     prvAutoReloadTimerCallback );

    /* Check the software timers were created. */
    if( ( xOneShotTimer != NULL ) &amp;&amp; ( xAutoReloadTimer != NULL ) )
    {
        /* Start the software timers, using a block time of 0 (no block time).
           The scheduler has not been started yet so any block time specified 
           here would be ignored anyway. */
        xTimer1Started = xTimerStart( xOneShotTimer, 0 );
        xTimer2Started = xTimerStart( xAutoReloadTimer, 0 );

        /* The implementation of xTimerStart() uses the timer command queue,
           and xTimerStart() will fail if the timer command queue gets full. 
           The timer service task does not get created until the scheduler is 
           started, so all commands sent to the command queue will stay in the
           queue until after the scheduler has been started. Check both calls 
           to xTimerStart() passed. */
        if( ( xTimer1Started == pdPASS ) &amp;&amp; ( xTimer2Started == pdPASS ) )
        {
            /* Start the scheduler. */
            vTaskStartScheduler();
        }
    }

    /* As always, this line should not be reached. */
    for( ;; );
}
</code></pre>
<p><em><strong>Listing 6.5</strong></em> <em>Creating and starting the timers used in Example 6.1</em></p>
<p>The timers' callback functions just print a message each time they are
called. The implementation of the one-shot timer callback function is
shown in Listing 6.6. The implementation of the auto-reload timer
callback function is shown in Listing 6.7.</p>
<p><a name="list6.5" title="Listing 6.6 The callback function used by the one-shot timer in Example 6.1"></a></p>
<pre><code class="language-c">static void prvOneShotTimerCallback( TimerHandle_t xTimer )
{
    TickType_t xTimeNow;

    /* Obtain the current tick count. */
    xTimeNow = xTaskGetTickCount();

    /* Output a string to show the time at which the callback was executed. */
    vPrintStringAndNumber( "One-shot timer callback executing", xTimeNow );

    /* File scope variable. */
    ulCallCount++;
}
</code></pre>
<p><em><strong>Listing 6.6</strong></em> <em>The callback function used by the one-shot timer in Example 6.1</em></p>
<p><a name="list6.7" title="Listing 6.7 The callback function used by the auto-reload timer in Example 6.1"></a></p>
<pre><code class="language-c">static void prvAutoReloadTimerCallback( TimerHandle_t xTimer )
{
    TickType_t xTimeNow;

    /* Obtain the current tick count. */ 
    xTimeNow = xTaskGetTickCount();

    /* Output a string to show the time at which the callback was executed. */
    vPrintStringAndNumber( "Auto-reload timer callback executing", xTimeNow);

    ulCallCount++;
}
</code></pre>
<p><em><strong>Listing 6.7</strong></em> <em>The callback function used by the auto-reload timer in Example 6.1</em></p>
<p>Executing this example produces the output shown in Figure 6.7. Figure 6.7
shows the auto-reload timer's callback function executing with a fixed
period of 500 ticks (<code>mainAUTO_RELOAD_TIMER_PERIOD</code> is set to 500 in
Listing 6.5), and the one-shot timer's callback function executing only
once, when the tick count is 3333 (<code>mainONE_SHOT_TIMER_PERIOD</code> is set to
3333 in Listing 6.5).</p>
<p><a name="fig6.7" title="Figure 6.7 The output produced when Example 6.1 is executed"></a></p>
<hr />
<p><img src="media/image44.jpg" alt="" /><br />
<em><strong>Figure 6.7</strong></em> <em>The output produced when Example 6.1 is executed</em></p>
<hr />
<h2 id="66-the-timer-id"><a class="header" href="#66-the-timer-id">6.6 The Timer ID</a></h2>
<p>Each software timer has an ID, which is a tag value that can be used by
the application writer for any purpose. The ID is stored in a void
pointer (<code>void *</code>), so it can store an integer value directly, point to any
other object, or be used as a function pointer.</p>
<p>An initial value is assigned to the ID when the software timer is
created, after which the ID can be updated using the <code>vTimerSetTimerID()</code>
API function, and queried using the <code>pvTimerGetTimerID()</code> API function.</p>
<p>Unlike other software timer API functions, <code>vTimerSetTimerID()</code> and
<code>pvTimerGetTimerID()</code> access the software timer directly—they do not send
a command to the timer command queue.</p>
<h3 id="661-the-vtimersettimerid-api-function"><a class="header" href="#661-the-vtimersettimerid-api-function">6.6.1 The vTimerSetTimerID() API Function</a></h3>
<p><a name="list6.8" title="Listing 6.8 The vTimerSetTimerID() API function prototype"></a></p>
<pre><code class="language-c">void vTimerSetTimerID( const TimerHandle_t xTimer, void *pvNewID );
</code></pre>
<p><em><strong>Listing 6.8</strong></em> <em>The vTimerSetTimerID() API function prototype</em></p>
<p><strong>vTimerSetTimerID() parameters</strong></p>
<ul>
<li>
<p><code>xTimer</code></p>
<p>The handle of the software timer being updated with a new ID value.
The handle will have been returned from the call to <code>xTimerCreate()</code> used
to create the software timer.</p>
</li>
<li>
<p><code>pvNewID</code></p>
<p>The value to which the software timer's ID will be set.</p>
</li>
</ul>
<h3 id="662-the-pvtimergettimerid-api-function"><a class="header" href="#662-the-pvtimergettimerid-api-function">6.6.2 The pvTimerGetTimerID() API Function</a></h3>
<p><a name="list6.9" title="Listing 6.9 The pvTimerGetTimerID() API function prototype"></a></p>
<pre><code class="language-c">void *pvTimerGetTimerID( const TimerHandle_t xTimer );
</code></pre>
<p><em><strong>Listing 6.9</strong></em> <em>The pvTimerGetTimerID() API function prototype</em></p>
<p><strong>pvTimerGetTimerID() parameters and return value</strong></p>
<ul>
<li>
<p><code>xTimer</code></p>
<p>The handle of the software timer being queried. The handle will have
been returned from the call to <code>xTimerCreate()</code> used to create the
software timer.</p>
</li>
<li>
<p>Return value</p>
<p>The ID of the software timer being queried.</p>
</li>
</ul>
<h2 id="-13"><a class="header" href="#-13"><a name="example6.2" title="Example 6.2 Using the callback function parameter and the software timer ID"></a></a></h2>
<p><em><strong>Example 6.2</strong></em> <em>Using the callback function parameter and the software timer ID</em></p>
<hr />
<p>The same callback function can be assigned to more than one software
timer. When that is done, the callback function parameter is used to
determine which software timer expired.</p>
<p>Example 6.1 used two separate callback functions; one callback function
was used by the one-shot timer, and the other callback function was used
by the auto-reload timer. Example 6.2 creates similar functionality to
that created by Example 6.1, but assigns a single callback function to
both software timers.</p>
<p>The <code>main()</code> function used by Example 6.2 is almost identical to the <code>main()</code>
function used in Example 6.1. The only difference is where the software
timers are created. This difference is shown in Listing 6.10, where
<code>prvTimerCallback()</code> is used as the callback function for both timers.</p>
<p><a name="list6.10" title="Listing 6.10 Creating the timers used in Example 6.2"></a></p>
<pre><code class="language-c">/* Create the one shot timer software timer, storing the handle in 
   xOneShotTimer. */
xOneShotTimer = xTimerCreate( "OneShot",
                              mainONE_SHOT_TIMER_PERIOD,
                              pdFALSE, 
                              /* The timer's ID is initialized to NULL. */
                              NULL,
                              /* prvTimerCallback() is used by both timers. */
                              prvTimerCallback );

/* Create the auto-reload software timer, storing the handle in 
   xAutoReloadTimer */
xAutoReloadTimer = xTimerCreate( "AutoReload",
                                 mainAUTO_RELOAD_TIMER_PERIOD,
                                 pdTRUE, 
                                 /* The timer's ID is initialized to NULL. */
                                 NULL,
                                 /* prvTimerCallback() is used by both timers. */
                                 prvTimerCallback );
</code></pre>
<p><em><strong>Listing 6.10</strong></em> <em>Creating the timers used in Example 6.2</em></p>
<p><code>prvTimerCallback()</code> will execute when either timer expires. The
implementation of <code>prvTimerCallback()</code> uses the function's parameter to
determine if it was called because the one-shot timer expired, or
because the auto-reload timer expired.</p>
<p><code>prvTimerCallback()</code> also demonstrates how to use the software timer ID as
timer specific storage; each software timer keeps a count of the number
of times it has expired in its own ID, and the auto-reload timer uses
the count to stop itself the fifth time it executes.</p>
<p>The implementation of <code>prvTimerCallback()</code> is shown in Listing 6.9.</p>
<p><a name="list6.11" title="Listing 6.11 The timer callback function used in Example 6.2"></a></p>
<pre><code class="language-c">static void prvTimerCallback( TimerHandle_t xTimer )
{
    TickType_t xTimeNow;
    uint32_t ulExecutionCount;

    /* A count of the number of times this software timer has expired is 
       stored in the timer's ID. Obtain the ID, increment it, then save it as 
       the new ID value. The ID is a void pointer, so is cast to a uint32_t. */
    ulExecutionCount = ( uint32_t ) pvTimerGetTimerID( xTimer );
    ulExecutionCount++;
    vTimerSetTimerID( xTimer, ( void * ) ulExecutionCount );

    /* Obtain the current tick count. */
    xTimeNow = xTaskGetTickCount();

    /* The handle of the one-shot timer was stored in xOneShotTimer when the 
       timer was created. Compare the handle passed into this function with 
       xOneShotTimer to determine if it was the one-shot or auto-reload timer 
       that expired, then output a string to show the time at which the 
       callback was executed. */
    if( xTimer == xOneShotTimer )
    {
        vPrintStringAndNumber( "One-shot timer callback executing", xTimeNow );
    }
    else
    {
        /* xTimer did not equal xOneShotTimer, so it must have been the 
           auto-reload timer that expired. */
        vPrintStringAndNumber( "Auto-reload timer callback executing", xTimeNow);

        if( ulExecutionCount == 5 )
        {
            /* Stop the auto-reload timer after it has executed 5 times. This
               callback function executes in the context of the RTOS daemon 
               task so must not call any functions that might place the daemon
               task into the Blocked state. Therefore a block time of 0 is 
               used. */
            xTimerStop( xTimer, 0 );
        }
    }
}
</code></pre>
<p><em><strong>Listing 6.11</strong></em> <em>The timer callback function used in Example 6.2</em></p>
<p>The output produced by Example 6.2 is shown in Figure 6.8. It can be seen
that the auto-reload timer only executes five times.</p>
<p><a name="fig6.8" title="Figure 6.8 The output produced when Example 6.2 is executed"></a></p>
<hr />
<p><img src="media/image45.jpg" alt="" /><br />
<em><strong>Figure 6.8</strong></em> <em>The output produced when Example 6.2 is executed</em></p>
<hr />
<h2 id="67-changing-the-period-of-a-timer"><a class="header" href="#67-changing-the-period-of-a-timer">6.7 Changing the Period of a Timer</a></h2>
<p>Every official FreeRTOS port is provided with one or more example
projects. Most example projects are self-checking, and an LED is used to
give visual feedback of the project's status; if the self-checks have
always passed then the LED is toggled slowly, if a self-check has ever
failed then the LED is toggled quickly.</p>
<p>Some example projects perform the self-checks in a task, and use the
<code>vTaskDelay()</code> function to control the rate at which the LED toggles.
Other example projects perform the self-checks in a software timer
callback function, and use the timer's period to control the rate at
which the LED toggles.</p>
<h3 id="671-the-xtimerchangeperiod-api-function"><a class="header" href="#671-the-xtimerchangeperiod-api-function">6.7.1 The xTimerChangePeriod() API Function</a></h3>
<p>The period of a software timer is changed using the <code>xTimerChangePeriod()</code> function.</p>
<p>If <code>xTimerChangePeriod()</code> is used to change the period of a timer that is
already running, then the timer will use the new period value to
recalculate its expiry time. The recalculated expiry time is relative to
when <code>xTimerChangePeriod()</code> was called, not relative to when the timer was
originally started.</p>
<p>If <code>xTimerChangePeriod()</code> is used to change the period of a timer that is
in the Dormant state (a timer that is not running), then the timer will
calculate an expiry time, and transition to the Running state (the timer
will start running).</p>
<blockquote>
<p><em>Note: Never call <code>xTimerChangePeriod()</code> from an interrupt service
routine. The interrupt-safe version <code>xTimerChangePeriodFromISR()</code> should
be used in its place.</em></p>
</blockquote>
<p><a name="list6.12" title="Listing 6.12 The xTimerChangePeriod() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xTimerChangePeriod( TimerHandle_t xTimer,
                               TickType_t xNewPeriod,
                               TickType_t xTicksToWait );
</code></pre>
<p><em><strong>Listing 6.12</strong></em> <em>The xTimerChangePeriod() API function prototype</em></p>
<p><strong>xTimerChangePeriod() parameters and return value</strong></p>
<ul>
<li>
<p><code>xTimer</code></p>
<p>The handle of the software timer being updated with a new period
value. The handle will have been returned from the call to
<code>xTimerCreate()</code> used to create the software timer.</p>
</li>
<li>
<p><code>xTimerPeriodInTicks</code></p>
<p>The new period for the software timer, specified in ticks. The
<code>pdMS_TO_TICKS()</code> macro can be used to convert a time specified in
milliseconds into a time specified in ticks.</p>
</li>
<li>
<p><code>xTicksToWait</code></p>
<p><code>xTimerChangePeriod()</code> uses the timer command queue to send the
'change period' command to the daemon task. <code>xTicksToWait</code> specifies the
maximum amount of time the calling task should remain in the Blocked
state to wait for space to become available on the timer command queue,
if the queue is already full.</p>
<p><code>xTimerChangePeriod()</code> will return immediately if <code>xTicksToWait</code> is zero
and the timer command queue is already full.</p>
<p>The macro <code>pdMS_TO_TICKS()</code> can be used to convert a time specified in
milliseconds into a time specified in ticks.</p>
<p>If <code>INCLUDE_vTaskSuspend</code> is set to 1 in FreeRTOSConfig.h, then setting
<code>xTicksToWait</code> to <code>portMAX_DELAY</code> will result in the calling task remaining
in the Blocked state indefinitely (without a timeout) to wait for space
to become available in the timer command queue.</p>
<p>If <code>xTimerChangePeriod()</code> is called before the scheduler has been
started, then the value of <code>xTicksToWait</code> is ignored, and
<code>xTimerChangePeriod()</code> behaves as if <code>xTicksToWait</code> had been set to zero.</p>
</li>
<li>
<p>Returned value</p>
<p>There are two possible return values:</p>
<ul>
<li>
<p><code>pdPASS</code></p>
<p><code>pdPASS</code> will be returned only if data was successfully sent to the
timer command queue.</p>
<p>If a block time was specified (<code>xTicksToWait</code> was not zero), then it is
possible the calling task was placed into the Blocked state to wait for
space to become available in the timer command queue before the function
returned, but data was successfully written to the timer command queue
before the block time expired.</p>
</li>
<li>
<p><code>pdFAIL</code></p>
<p><code>pdFAIL</code> will be returned if the 'change period' command could not be
written to the timer command queue because the queue was already
full.</p>
<p>If a block time was specified (<code>xTicksToWait</code> was not zero) then the
calling task will have been placed into the Blocked state to wait for
the daemon task to make room in the queue, but the specified block time
expired before that happened.</p>
</li>
</ul>
</li>
</ul>
<p>Listing 6.13 shows how the FreeRTOS examples that include self-checking
functionality in a software timer callback function use
<code>xTimerChangePeriod()</code> to increase the rate at which an LED toggles if a
self-check fails. The software timer that performs the self-checks is
referred to as the 'check timer'.</p>
<p><a name="list6.13" title="Listing 6.13 Using xTimerChangePeriod()"></a></p>
<pre><code class="language-c">/* The check timer is created with a period of 3000 milliseconds, resulting 
   in the LED toggling every 3 seconds. If the self-checking functionality 
   detects an unexpected state, then the check timer's period is changed to 
   just 200 milliseconds, resulting in a much faster toggle rate. */
const TickType_t xHealthyTimerPeriod = pdMS_TO_TICKS( 3000 );
const TickType_t xErrorTimerPeriod = pdMS_TO_TICKS( 200 );

/* The callback function used by the check timer. */
static void prvCheckTimerCallbackFunction( TimerHandle_t xTimer )
{
    static BaseType_t xErrorDetected = pdFALSE;

    if( xErrorDetected == pdFALSE )
    {
        /* No errors have yet been detected. Run the self-checking function 
           again. The function asks each task created by the example to report
           its own status, and also checks that all the tasks are actually 
           still running (and so able to report their status correctly). */
        if( CheckTasksAreRunningWithoutError() == pdFAIL )
        {
            /* One or more tasks reported an unexpected status. An error might 
               have occurred. Reduce the check timer's period to increase the 
               rate at which this callback function executes, and in so doing 
               also increase the rate at which the LED is toggled. This 
               callback function is executing in the context of the RTOS daemon
               task, so a block time of 0 is used to ensure the Daemon task 
               never enters the Blocked state. */
            xTimerChangePeriod( 
                  xTimer,            /* The timer being updated */
                  xErrorTimerPeriod, /* The new period for the timer */
                  0 );               /* Do not block when sending this command */
        }

        /* Latch that an error has already been detected. */
        xErrorDetected = pdTRUE;
    }

    /* Toggle the LED. The rate at which the LED toggles will depend on how 
       often this function is called, which is determined by the period of the
       check timer. The timer's period will have been reduced from 3000ms to 
       just 200ms if CheckTasksAreRunningWithoutError() has ever returned 
       pdFAIL. */
    ToggleLED();
}
</code></pre>
<p><em><strong>Listing 6.13</strong></em> <em>Using xTimerChangePeriod()</em></p>
<h2 id="68-resetting-a-software-timer"><a class="header" href="#68-resetting-a-software-timer">6.8 Resetting a Software Timer</a></h2>
<p>Resetting a software timer means to re-start the timer; the timer's
expiry time is recalculated to be relative to when the timer was reset,
rather than when the timer was originally started. This is demonstrated
by Figure 6.9, which shows a timer that has a period of 6 being started,
then reset twice, before eventually expiring and executing its callback
function.</p>
<p><a name="fig6.9" title="Figure 6.9 Starting and resetting a software timer that has a period of 6 ticks"></a></p>
<hr />
<p><img src="media/image46.png" alt="" /><br />
<em><strong>Figure 6.9</strong></em> <em>Starting and resetting a software timer that has a period of 6 ticks</em></p>
<hr />
<p>Referring to Figure 6.9:</p>
<ul>
<li>
<p>Timer 1 is started at time t1. It has a period of 6, so the time at
which it will execute its callback function is originally calculated
to be t7, which is 6 ticks after it was started.</p>
</li>
<li>
<p>Timer 1 is reset before time t7 is reached, so before it had expired
and executed its callback function. Timer 1 is reset at time t5, so
the time at which it will execute its callback function is
re-calculated to be t11, which is 6 ticks after it was reset.</p>
</li>
<li>
<p>Timer 1 is reset again before time t11, so again before it had
expired and executed its callback function. Timer 1 is reset at time
t9, so the time at which it will execute its callback function is
re-calculated to be t15, which is 6 ticks after it was last reset.</p>
</li>
<li>
<p>Timer 1 is not reset again, so it expires at time t15, and its
callback function is executed accordingly.</p>
</li>
</ul>
<h3 id="681-the-xtimerreset-api-function"><a class="header" href="#681-the-xtimerreset-api-function">6.8.1 The xTimerReset() API Function</a></h3>
<p>A timer is reset using the <code>xTimerReset()</code> API function.</p>
<p><code>xTimerReset()</code> can also be used to start a timer that is in the Dormant state.</p>
<blockquote>
<p><em>Note: Never call <code>xTimerReset()</code> from an interrupt service routine. The
interrupt-safe version <code>xTimerResetFromISR()</code> should be used in its
place.</em></p>
</blockquote>
<p><a name="list6.14" title="Listing 6.14 The xTimerReset() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xTimerReset( TimerHandle_t xTimer, TickType_t xTicksToWait );
</code></pre>
<p><em><strong>Listing 6.14</strong></em> <em>The xTimerReset() API function prototype</em></p>
<p><strong>xTimerReset() parameters and return value</strong></p>
<ul>
<li>
<p><code>xTimer</code></p>
<p>The handle of the software timer being reset or started. The handle
will have been returned from the call to <code>xTimerCreate()</code> used to create
the software timer.</p>
</li>
<li>
<p><code>xTicksToWait</code></p>
<p><code>xTimerChangePeriod()</code> uses the timer command queue to send the
'reset' command to the daemon task. <code>xTicksToWait</code> specifies the maximum
amount of time the calling task should remain in the Blocked state to
wait for space to become available on the timer command queue, if
the queue is already full.</p>
<p><code>xTimerReset()</code> will return immediately if <code>xTicksToWait</code> is zero and the
timer command queue is already full.</p>
<p>If <code>INCLUDE_vTaskSuspend</code> is set to 1 in <code>FreeRTOSConfig.h</code> then setting
<code>xTicksToWait</code> to <code>portMAX_DELAY</code> will result in the calling task remaining
in the Blocked state indefinitely (without a timeout) to wait for space
to become available in the timer command queue.</p>
</li>
<li>
<p>Returned value</p>
<p>There are two possible return values:</p>
<ul>
<li>
<p><code>pdPASS</code></p>
<p><code>pdPASS</code> will be returned only if data was successfully sent to the
timer command queue.</p>
<p>If a block time was specified (<code>xTicksToWait</code> was not zero), then it is
possible the calling task was placed into the Blocked state to wait for
space to become available in the timer command queue before the function
returned, but data was successfully written to the timer command queue
before the block time expired.</p>
<p><code>pdFAIL</code></p>
<p><code>pdFAIL</code> will be returned if the 'reset' command could not be written
to the timer command queue because the queue was already full.</p>
<p>If a block time was specified (<code>xTicksToWait</code> was not zero) then the
calling task will have been placed into the Blocked state to wait for
the daemon task to make room in the queue, but the specified block time
expired before that happened.</p>
</li>
</ul>
</li>
</ul>
<h2 id="-14"><a class="header" href="#-14"><a name="example6.3" title="Example 6.3 Resetting a software timer"></a></a></h2>
<p><em><strong>Example 6.3</strong></em> <em>Resetting a software timer</em></p>
<hr />
<p>This example simulates the behavior of the backlight on a cell phone. The backlight:</p>
<ul>
<li>
<p>Turns on when a key is pressed.</p>
</li>
<li>
<p>Remains on provided further keys are pressed within a certain time period.</p>
</li>
<li>
<p>Automatically turns off if no key presses are made within a certain time period.</p>
</li>
</ul>
<p>A one-shot software timer is used to implement this behavior:</p>
<ul>
<li>
<p>The [simulated] backlight is turned on when a key is pressed, and
turned off in the software timer's callback function.</p>
</li>
<li>
<p>The software timer is reset each time a key is pressed.</p>
</li>
<li>
<p>The time period during which a key must be pressed to prevent the
backlight being turned off is therefore equal to the period of the
software timer; if the software timer is not reset by a key press
before the timer expires, then the timer's callback function
executes, and the backlight is turned off.</p>
</li>
</ul>
<p>The <code>xSimulatedBacklightOn</code> variable holds the backlight state.
<code>xSimulatedBacklightOn</code> is set to <code>pdTRUE</code> to indicate the backlight is on,
and <code>pdFALSE</code> to indicate the backlight is off.</p>
<p>The software timer callback function is shown in Listing 6.15.</p>
<p><a name="list6.15" title="Listing 6.15 The callback function for the one-shot timer used in Example 6.3"></a></p>
<pre><code class="language-c">static void prvBacklightTimerCallback( TimerHandle_t xTimer )
{
    TickType_t xTimeNow = xTaskGetTickCount();

    /* The backlight timer expired, turn the backlight off. */
    xSimulatedBacklightOn = pdFALSE;

    /* Print the time at which the backlight was turned off. */
    vPrintStringAndNumber(
            "Timer expired, turning backlight OFF at time\t\t", xTimeNow );
}
</code></pre>
<p><em><strong>Listing 6.15</strong></em> <em>The callback function for the one-shot timer used in Example 6.3</em></p>
<p>Example 6.3 creates a task to poll the keyboard<sup class="footnote-reference"><a href="#11">2</a></sup>. The task is shown
in Listing 6.16, but for the reasons described in the next paragraph,
Listing 6.16 is not intended to be representative of an optimal design.</p>
<div class="footnote-definition" id="11"><sup class="footnote-definition-label">2</sup>
<p>Printing to the Windows console, and reading keys from the
Windows console, both result in the execution of Windows system
calls. Windows system calls, including use of the Windows console,
disks, or TCP/IP stack, can adversely affect the behavior of the
FreeRTOS Windows port, and should normally be avoided.*</p>
</div>
<p>Using FreeRTOS allows your application to be event driven. Event driven
designs use processing time very efficiently, because processing time is
only used if an event has occurred, and processing time is not wasted
polling for events that have not occurred. Example 6.3 could not be made
event driven because it is not practical to process keyboard interrupts
when using the FreeRTOS Windows port, so the much less efficient polling
technique had to be used instead. If Listing 6.16 was an interrupt service
routine, then <code>xTimerResetFromISR()</code> would be used in place of
<code>xTimerReset()</code>.</p>
<p><a name="list6.16" title="Listing 6.16 The task used to reset the software timer in Example 6.3"></a></p>
<pre><code class="language-c">static void vKeyHitTask( void *pvParameters )
{
    const TickType_t xShortDelay = pdMS_TO_TICKS( 50 );
    TickType_t xTimeNow;

    vPrintString( "Press a key to turn the backlight on.\r\n" );

    /* Ideally an application would be event driven, and use an interrupt to 
       process key presses. It is not practical to use keyboard interrupts 
       when using the FreeRTOS Windows port, so this task is used to poll for 
       a key press. */
    for( ;; )
    {
        /* Has a key been pressed? */
        if( _kbhit() != 0 )
        {
            /* A key has been pressed. Record the time. */
            xTimeNow = xTaskGetTickCount();

            if( xSimulatedBacklightOn == pdFALSE )
            {

                /* The backlight was off, so turn it on and print the time at 
                   which it was turned on. */
                xSimulatedBacklightOn = pdTRUE;
                vPrintStringAndNumber(
                    "Key pressed, turning backlight ON at time\t\t", 
                    xTimeNow );
            }
            else
            {
                /* The backlight was already on, so print a message to say the
                   timer is about to be reset and the time at which it was 
                   reset. */
                vPrintStringAndNumber(
                    "Key pressed, resetting software timer at time\t\t", 
                    xTimeNow );
            }

            /* Reset the software timer. If the backlight was previously off, 
               then this call will start the timer. If the backlight was 
               previously on, then this call will restart the timer. A real 
               application may read key presses in an interrupt. If this 
               function was an interrupt service routine then 
               xTimerResetFromISR() must be used instead of xTimerReset(). */
            xTimerReset( xBacklightTimer, xShortDelay );

            /* Read and discard the key that was pressed – it is not required 
               by this simple example. */
            ( void ) _getch();
        }
    }
}
</code></pre>
<p><em><strong>Listing 6.16</strong></em> <em>The task used to reset the software timer in Example 6.3</em></p>
<p>The output produced when Example 6.3 is executed is shown in Figure 6.10.
With reference to Figure 6.10:</p>
<ul>
<li>
<p>The first key press occurred when the tick count was 812. At that
time the backlight was turned on, and the one-shot timer was
started.</p>
</li>
<li>
<p>Further key presses occurred when the tick count was 1813, 3114,
4015 and 5016. All of these key presses resulted in the timer being
reset before the timer had expired.</p>
</li>
<li>
<p>The timer expired when the tick count was 10016. At that time the
backlight was turned off.</p>
</li>
</ul>
<p><a name="fig6.10" title="Figure 6.10 The output produced when Example 6.3 is executed"></a></p>
<hr />
<p><img src="media/image47.jpg" alt="" /><br />
<em><strong>Figure 6.10</strong></em> <em>The output produced when Example 6.3 is executed</em></p>
<hr />
<p>It can be seen in Figure 6.10 that the timer had a period of 5000 ticks;
the backlight was turned off exactly 5000 ticks after a key was last
pressed, so 5000 ticks after the timer was last reset.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="7-interrupt-management-1"><a class="header" href="#7-interrupt-management-1">7 Interrupt Management</a></h1>
<h2 id="71-introduction"><a class="header" href="#71-introduction">7.1 Introduction</a></h2>
<h3 id="711-events"><a class="header" href="#711-events">7.1.1 Events</a></h3>
<p>Embedded real-time systems have to take actions in response to events
that originate from the environment. For example, a packet arriving on
an Ethernet peripheral (the event) might require passing it to a TCP/IP
stack for processing (the action). Non-trivial systems will have to
service events that originate from multiple sources, all of which will
have different processing overhead and response time requirements. In
each case, a judgment has to be made as to the best event processing
implementation strategy:</p>
<ul>
<li>
<p>How should the event be detected? Interrupts are normally used, but
inputs can also be polled.</p>
</li>
<li>
<p>When interrupts are used, how much processing should be performed
inside the interrupt service routine (ISR), and how much outside? It
is normally desirable to keep each ISR as short as possible.</p>
</li>
<li>
<p>How are events communicated to the main (non-ISR) code, and how can
this code be structured to best accommodate processing of
potentially asynchronous occurrences?</p>
</li>
</ul>
<p>FreeRTOS does not impose any specific event processing strategy on the
application designer, but does provide features that allow the chosen
strategy to be implemented in a simple and maintainable way.</p>
<p>It is important to draw a distinction between the priority of a task,
and the priority of an interrupt:</p>
<ul>
<li>
<p>A task is a software feature that is unrelated to the hardware on
which FreeRTOS is running. The priority of a task is assigned in
software by the application writer, and a software algorithm (the
scheduler) decides which task will be placed in the Running state.</p>
</li>
<li>
<p>Although written in software, an interrupt service routine is a
hardware feature because the hardware controls which interrupt
service routine will run, and when it will run. Tasks will only run
when there are no ISRs running, so the lowest priority interrupt
will interrupt the highest priority task, and there is no way for a
task to pre-empt an ISR.</p>
</li>
</ul>
<p>All architectures on which FreeRTOS will run are capable of processing
interrupts, but details relating to interrupt entry, and interrupt
priority assignment, vary between architectures.</p>
<h3 id="712-scope"><a class="header" href="#712-scope">7.1.2 Scope</a></h3>
<p>This chapter covers:</p>
<ul>
<li>Which FreeRTOS API functions can be used from within an interrupt
service routine.</li>
<li>Methods of deferring interrupt processing to a task.</li>
<li>How to create and use binary semaphores and counting semaphores.</li>
<li>The differences between binary and counting semaphores.</li>
<li>How to use a queue to pass data into and out of an interrupt service
routine.</li>
<li>The interrupt nesting model available with some FreeRTOS ports.</li>
</ul>
<h2 id="72-using-the-freertos-api-from-an-isr"><a class="header" href="#72-using-the-freertos-api-from-an-isr">7.2 Using the FreeRTOS API from an ISR</a></h2>
<h3 id="721-the-interrupt-safe-api"><a class="header" href="#721-the-interrupt-safe-api">7.2.1 The Interrupt Safe API</a></h3>
<p>Often it is necessary to use the functionality provided by a FreeRTOS
API function from an interrupt service routine (ISR), but many FreeRTOS
API functions perform actions that are not valid inside an ISR. The most
notable of these is placing the task that called the API function into
the Blocked state— if an API function is called from an ISR, then it is
not being called from a task, so there is no calling task that can be
placed into the Blocked state. FreeRTOS solves this problem by providing
two versions of some API functions; one version for use from tasks, and
one version for use from ISRs. Functions intended for use from ISRs have
"FromISR" appended to their name.</p>
<blockquote>
<p><em>Note: Never call a FreeRTOS API function that does not have "FromISR"
in its name from an ISR.</em></p>
</blockquote>
<h3 id="722-the-benefits-of-using-a-separate-interrupt-safe-api"><a class="header" href="#722-the-benefits-of-using-a-separate-interrupt-safe-api">7.2.2 The Benefits of Using a Separate Interrupt Safe API</a></h3>
<p>Having a separate API for use in interrupts allows task code to be more
efficient, ISR code to be more efficient, and interrupt entry to be
simpler. To see why, consider the alternative solution, which would have
been to provide a single version of each API function that could be
called from both a task and an ISR. If the same version of an API
function could be called from both a task and an ISR then:</p>
<ul>
<li>
<p>The API functions would need additional logic to determine if they
had been called from a task or an ISR. The additional logic would
introduce new paths through the function, making the functions
longer, more complex, and harder to test.</p>
</li>
<li>
<p>Some API function parameters would be obsolete when the function was
called from a task, while others would be obsolete when the function
was called from an ISR.</p>
</li>
<li>
<p>Each FreeRTOS port would need to provide a mechanism for determining
the execution context (task or ISR).</p>
</li>
<li>
<p>Architectures on which it is not easy to determine the execution
context (task or ISR) would require additional, wasteful, more
complex to use, and non-standard interrupt entry code that allowed
the execution context to be provided by software.</p>
</li>
</ul>
<h3 id="723-the-disadvantages-of-using-a-separate-interrupt-safe-api"><a class="header" href="#723-the-disadvantages-of-using-a-separate-interrupt-safe-api">7.2.3 The Disadvantages of Using a Separate, Interrupt Safe API</a></h3>
<p>Having two versions of some API functions allows both tasks and ISRs to
be more efficient, but introduces a new problem; sometimes it is
necessary to call a function that is not part of the FreeRTOS API, but
makes use of the FreeRTOS API, from both a task and an ISR.</p>
<p>This is normally only a problem when integrating third party code, as
that is the only time when the software's design is out of the control
of the application writer. If this does become an issue, then the problem
can be overcome using one of the following techniques:</p>
<ul>
<li>
<p>Defer interrupt processing to a task<sup class="footnote-reference"><a href="#12">1</a></sup>, so the API function is
only ever called from the context of a task.</p>
</li>
<li>
<p>If you are using a FreeRTOS port that supports interrupt nesting,
then use the version of the API function that ends in "FromISR", as
that version can be called from tasks and ISRs. (The reverse is not
true, API functions that do not end in "FromISR" must not be called
from an ISR.)</p>
</li>
<li>
<p>Third party code normally includes an RTOS abstraction layer that
can be implemented to test the context from which the function is
being called (task or interrupt), and then call the API function
that is appropriate for the context.</p>
</li>
</ul>
<div class="footnote-definition" id="12"><sup class="footnote-definition-label">1</sup>
<p>Deferred interrupt processing is covered in the next section of
this book.</p>
</div>
<h3 id="724-the-xhigherprioritytaskwoken-parameter"><a class="header" href="#724-the-xhigherprioritytaskwoken-parameter">7.2.4 The xHigherPriorityTaskWoken Parameter</a></h3>
<p>This section introduces the concept of the <code>xHigherPriorityTaskWoken</code>
parameter. Do not be concerned if you do not fully understand this
section yet, as practical examples are provided in following sections.</p>
<p>If a context switch is performed by an interrupt, then the task running
when the interrupt exits might be different than the task that was running
when the interrupt was entered—the interrupt will have interrupted one
task, but returned to a different task.</p>
<p>Some FreeRTOS API functions can move a task from the Blocked state to
the Ready state. This has already been seen with functions such as
<code>xQueueSendToBack()</code>, which will unblock a task if there was a task
waiting in the Blocked state for data to become available on the subject
queue.</p>
<p>If the priority of a task that is unblocked by a FreeRTOS API function
is higher than the priority of the task in the Running state, then, in
accordance with the FreeRTOS scheduling policy, a switch to the higher
priority task should occur. When the switch to the higher priority task
actually occurs is dependent on the context from which the API function
is called:</p>
<ul>
<li>
<p>If the API function was called from a task:</p>
<p>If <code>configUSE_PREEMPTION</code> is set to 1 in FreeRTOSConfig.h then the
switch to the higher priority task occurs automatically within the API
function, in other words, before the API function has exited. This has already been
seen in Figure 6.6, where a write to the timer command queue resulted
in a switch to the RTOS daemon task before the function that wrote to
the command queue had exited.</p>
</li>
<li>
<p>If the API function was called from an interrupt:</p>
<p>A switch to a higher priority task will not occur automatically inside
an interrupt. Instead, a variable is set to inform the application
writer that a context switch should be performed. Interrupt safe API
functions (those that end in "FromISR") have a pointer parameter
called <code>pxHigherPriorityTaskWoken</code> that is used for this purpose.</p>
<p>If a context switch should be performed, then the interrupt safe API
function will set <code>*pxHigherPriorityTaskWoken</code> to <code>pdTRUE</code>. To be able to
detect this has happened, the variable pointed to by
<code>pxHigherPriorityTaskWoken</code> must be initialized to <code>pdFALSE</code> before it is
used for the first time.</p>
<p>If the application writer opts not to request a context switch from
the ISR, then the higher priority task will remain in the Ready state
until the next time the scheduler runs, which in the worst case will be
during the next tick interrupt.</p>
<p>FreeRTOS API functions can only set <code>*pxHighPriorityTaskWoken</code> to
<code>pdTRUE</code>. If an ISR calls more than one FreeRTOS API function, then the
same variable can be passed as the <code>pxHigherPriorityTaskWoken</code> parameter
in each API function call, and the variable only needs to be
initialized to <code>pdFALSE</code> before it is used for the first time.</p>
</li>
</ul>
<p>There are several reasons why context switches do not occur
automatically inside the interrupt safe version of an API function:</p>
<ul>
<li>
<p>Avoiding unnecessary context switches</p>
<p>An interrupt may execute more than once before it is necessary for a
task to perform any processing. For example, consider a scenario
where a task processes a string that was received by an interrupt
driven UART; it would be wasteful for the UART ISR to switch to the
task each time a character was received because the task would only
have processing to perform after the complete string had been
received.</p>
</li>
<li>
<p>Control over the execution sequence</p>
<p>Interrupts can occur sporadically, and at unpredictable times.
Expert FreeRTOS users may want to temporarily avoid an unpredictable
switch to a different task at specific points in their
application, although this can also be achieved using the FreeRTOS
scheduler locking mechanism.</p>
</li>
<li>
<p>Portability</p>
<p>It is the simplest mechanism that can be used across all FreeRTOS ports.</p>
</li>
<li>
<p>Efficiency</p>
<p>Ports that target smaller processor architectures only allow a
context switch to be requested at the very end of an ISR, and
removing that restriction would require additional and more complex
code. It also allows more than one call to a FreeRTOS API function
within the same ISR without generating more than one request for a
context switch within the same ISR.</p>
</li>
<li>
<p>Execution in the RTOS tick interrupt</p>
<p>As will be seen later in this book, it is possible to add
application code into the RTOS tick interrupt. The result of
attempting a context switch inside the tick interrupt is dependent
on the FreeRTOS port in use. At best, it will result in an
unnecessary call to the scheduler.</p>
</li>
</ul>
<p>Use of the <code>pxHigherPriorityTaskWoken</code> parameter is optional. If it is not
required, then set <code>pxHigherPriorityTaskWoken</code> to NULL.</p>
<h3 id="725-the-portyield_from_isr-and-portend_switching_isr-macros"><a class="header" href="#725-the-portyield_from_isr-and-portend_switching_isr-macros">7.2.5 The portYIELD_FROM_ISR() and portEND_SWITCHING_ISR() Macros</a></h3>
<p>This section introduces the macros that are used to request a context
switch from an ISR. Do not be concerned if you do not fully understand
this section yet, as practical examples are provided in following
sections.</p>
<p><code>taskYIELD()</code> is a macro that can be called in a task to request a context
switch. <code>portYIELD_FROM_ISR()</code> and <code>portEND_SWITCHING_ISR()</code> are both
interrupt safe versions of <code>taskYIELD()</code>. <code>portYIELD_FROM_ISR()</code> and
<code>portEND_SWITCHING_ISR()</code> are both used in the same way, and do the same
thing<sup class="footnote-reference"><a href="#13">2</a></sup>. Some FreeRTOS ports only provide one of the two macros.
Newer FreeRTOS ports provide both macros. The examples in this book use
<code>portYIELD_FROM_ISR()</code>.</p>
<div class="footnote-definition" id="13"><sup class="footnote-definition-label">2</sup>
<p>Historically, <code>portEND_SWITCHING_ISR()</code> was the name used in
FreeRTOS ports that required interrupt handlers to use an assembly
code wrapper, and <code>portYIELD_FROM_ISR()</code> was the name used in FreeRTOS
ports that allowed the entire interrupt handler to be written in C.</p>
</div>
<p><a name="list7.1" title="Listing 7.1 The portEND\_SWITCHING\_ISR() macros"></a></p>
<pre><code class="language-c">portEND_SWITCHING_ISR( xHigherPriorityTaskWoken );
</code></pre>
<p><em><strong>Listing 7.1</strong></em> <em>The portEND_SWITCHING_ISR() macros</em></p>
<p><a name="list7.2" title="Listing 7.2 The portYIELD\_FROM\_ISR() macros"></a></p>
<pre><code class="language-c">portYIELD_FROM_ISR( xHigherPriorityTaskWoken );
</code></pre>
<p><em><strong>Listing 7.2</strong></em> <em>The portYIELD_FROM_ISR() macros</em></p>
<p>The <code>xHigherPriorityTaskWoken</code> parameter passed out of an interrupt safe
API function can be used directly as the parameter in a call to
<code>portYIELD_FROM_ISR()</code>.</p>
<p>If the <code>portYIELD_FROM_ISR()</code> <code>xHigherPriorityTaskWoken</code> parameter is
<code>pdFALSE</code> (zero), then a context switch is not requested, and the macro
has no effect. If the <code>portYIELD_FROM_ISR()</code> <code>xHigherPriorityTaskWoken</code>
parameter is not <code>pdFALSE</code>, then a context switch is requested, and the
task in the Running state might change. The interrupt will always return
to the task in the Running state, even if the task in the Running state
changed while the interrupt was executing.</p>
<p>Most FreeRTOS ports allow <code>portYIELD_FROM_ISR()</code> to be called anywhere
within an ISR. A few FreeRTOS ports (predominantly those for smaller
architectures), only allow <code>portYIELD_FROM_ISR()</code> to be called at the very
end of an ISR.</p>
<h2 id="73-deferred-interrupt-processing"><a class="header" href="#73-deferred-interrupt-processing">7.3 Deferred Interrupt Processing</a></h2>
<p>It is normally considered best practice to keep ISRs as short as
possible. Reasons for this include:</p>
<ul>
<li>
<p>Even if tasks have been assigned a very high priority, they will
only run if no interrupts are being serviced by the hardware.</p>
</li>
<li>
<p>ISRs can disrupt (add 'jitter' to) both the start time, and the
execution time, of a task.</p>
</li>
<li>
<p>Depending on the architecture on which FreeRTOS is running, it might
not be possible to accept any new interrupts, or at least a subset
of new interrupts, while an ISR is executing.</p>
</li>
<li>
<p>The application writer needs to consider the consequences of, and
guard against, resources such as variables, peripherals, and memory
buffers being accessed by a task and an ISR at the same time.</p>
</li>
<li>
<p>Some FreeRTOS ports allow interrupts to nest, but interrupt nesting
can increase complexity and reduce predictability. The shorter an
interrupt is, the less likely it is to nest.</p>
</li>
</ul>
<p>An interrupt service routine must record the cause of the interrupt, and
clear the interrupt. Any other processing necessitated by the interrupt
can often be performed in a task, allowing the interrupt service routine
to exit as quickly as is practical. This is called 'deferred interrupt
processing', because the processing necessitated by the interrupt is
'deferred' from the ISR to a task.</p>
<p>Deferring interrupt processing to a task also allows the application
writer to prioritize the processing relative to other tasks in the
application, and use all the FreeRTOS API functions.</p>
<p>If the priority of the task to which interrupt processing is deferred is
above the priority of any other task, then the processing will be
performed immediately, just as if the processing had been performed in
the ISR itself. This scenario is shown in Figure 7.1, in which Task 1 is
a normal application task, and Task 2 is the task to which interrupt
processing is deferred.</p>
<p><a name="fig7.1" title="Figure 7.1 Completing interrupt processing in a high priority task"></a></p>
<hr />
<p><img src="media/image48.png" alt="" /><br />
<em><strong>Figure 7.1</strong></em> <em>Completing interrupt processing in a high priority task</em></p>
<hr />
<p>In Figure 7.1, interrupt processing starts at time t2, and effectively
ends at time t4, but only the period between times t2 and t3 is spent in
the ISR. If deferred interrupt processing had not been used then the
entire period between times t2 and t4 would have been spent in the ISR.</p>
<p>There is no absolute rule as to when it is best to perform all
processing necessitated by an interrupt in the ISR, and when it is best
to defer part of the processing to a task. Deferring processing to a
task is most useful when:</p>
<ul>
<li>
<p>The processing necessitated by the interrupt is not trivial. For
example, if the interrupt is just storing the result of an analog to
digital conversion, then it is almost certain this is best performed
inside the ISR, but if result of the conversion must also be passed
through a software filter, then it may be best to execute the filter
in a task.</p>
</li>
<li>
<p>It is convenient for the interrupt processing to perform an action
that cannot be performed inside an ISR, such as write to a console,
or allocate memory.</p>
</li>
<li>
<p>The interrupt processing is not deterministic—meaning it is not
known in advance how long the processing will take.</p>
</li>
</ul>
<p>The following sections describe and demonstrate the concepts introduced
in this chapter so far, including FreeRTOS features that can be used to
implement deferred interrupt processing.</p>
<h2 id="74-binary-semaphores-used-for-synchronization"><a class="header" href="#74-binary-semaphores-used-for-synchronization">7.4 Binary Semaphores Used for Synchronization</a></h2>
<p>The interrupt safe version of the Binary Semaphore API can be used to
unblock a task each time a particular interrupt occurs, effectively
synchronizing the task with the interrupt. This allows the majority of
the interrupt event processing to be implemented within the synchronized
task, with only a very fast and short portion remaining directly in the
ISR. As described in the previous section, the binary semaphore is used
to 'defer' interrupt processing to a task<sup class="footnote-reference"><a href="#14">3</a></sup>.</p>
<div class="footnote-definition" id="14"><sup class="footnote-definition-label">3</sup>
<p>It is more efficient to unblock a task from an interrupt using a
direct to task notification than it is using a binary semaphore.
Direct to task notifications are not covered until Chapter 10, Task
Notifications.</p>
</div>
<p>As previously demonstrated in Figure 7.1, if the interrupt processing is
particularly time critical, then the priority of the deferred processing
task can be set to ensure the task always pre-empts the other tasks in
the system. The ISR can then be implemented to include a call to
<code>portYIELD_FROM_ISR()</code>, ensuring the ISR returns directly to the task to
which interrupt processing is being deferred. This has the effect of
ensuring the entire event processing executes contiguously (without a
break) in time, just as if it had all been implemented within the ISR
itself. Figure 7.2 repeats the scenario shown in Figure 7.1, but with the
text updated to describe how the execution of the deferred processing
task can be controlled using a semaphore.</p>
<p><a name="fig7.2" title="Figure 7.2 Using a binary semaphore to implement deferred interrupt processing"></a></p>
<hr />
<p><img src="media/image49.png" alt="" /><br />
<em><strong>Figure 7.2</strong></em> <em>Using a binary semaphore to implement deferred interrupt processing</em></p>
<hr />
<p>The deferred processing task uses a blocking 'take' call to a semaphore
as a means of entering the Blocked state to wait for the event to occur.
When the event occurs, the ISR uses a 'give' operation on the same
semaphore to unblock the task so that the required event processing can
proceed.</p>
<p>'Taking a semaphore' and 'giving a semaphore' are concepts that have
different meanings depending on their usage scenario. In this interrupt
synchronization scenario, the binary semaphore can be considered
conceptually as a queue with a length of one. The queue can contain a
maximum of one item at any time, so is always either empty or full
(hence, binary). By calling <code>xSemaphoreTake()</code>, the task to which
interrupt processing is deferred effectively attempts to read from the
queue with a block time, causing the task to enter the Blocked state if
the queue is empty. When the event occurs, the ISR uses the
<code>xSemaphoreGiveFromISR()</code> function to place a token (the semaphore) into
the queue, making the queue full. This causes the task to exit the
Blocked state and remove the token, leaving the queue empty once more.
When the task has completed its processing, it once more attempts to
read from the queue and, finding the queue empty, re-enters the Blocked
state to wait for the next event. This sequence is demonstrated in
Figure 7.3.</p>
<p>Figure 7.3 shows the interrupt 'giving' the semaphore, even though it has
not first 'taken' it, and the task 'taking' the semaphore, but never
giving it back. This is why the scenario is described as being
conceptually similar to writing to and reading from a queue. It often
causes confusion as it does not follow the same rules as other semaphore
usage scenarios, where a task that takes a semaphore must always give it
back—such as the scenarios described in Chapter 8, Resource Management.</p>
<p><a name="fig7.3" title="Figure 7.3 Using a binary semaphore to synchronize a task with an interrupt"></a></p>
<hr />
<p><img src="media/image50.png" alt="" /><br />
<em><strong>Figure 7.3</strong></em> <em>Using a binary semaphore to synchronize a task with an interrupt</em></p>
<hr />
<h3 id="741-the-xsemaphorecreatebinary-api-function"><a class="header" href="#741-the-xsemaphorecreatebinary-api-function">7.4.1 The xSemaphoreCreateBinary() API Function</a></h3>
<p>FreeRTOS also includes the <code>xSemaphoreCreateBinaryStatic()</code>
function, which allocates the memory required to create a binary
semaphore statically at compile time: Handles to all the various types
of FreeRTOS semaphore are stored in a variable of type
<code>SemaphoreHandle_t</code>.</p>
<p>Before a semaphore can be used, it must be created. To create a binary
semaphore, use the <code>xSemaphoreCreateBinary()</code> API function<sup class="footnote-reference"><a href="#15">4</a></sup>.</p>
<div class="footnote-definition" id="15"><sup class="footnote-definition-label">4</sup>
<p>Some Semaphore API functions are actually macros, not functions.
For simplicity, they are all referred to as functions throughout
this book.</p>
</div>
<p><a name="list7.3" title="Listing 7.3 The xSemaphoreCreateBinary() API function prototype"></a></p>
<pre><code class="language-c">SemaphoreHandle_t xSemaphoreCreateBinary( void );
</code></pre>
<p><em><strong>Listing 7.3</strong></em> <em>The xSemaphoreCreateBinary() API function prototype</em></p>
<p><strong>xSemaphoreCreateBinary() Return Value</strong></p>
<ul>
<li>
<p>Return value</p>
<p>If NULL is returned, then the semaphore cannot be created because
there is insufficient heap memory available for FreeRTOS to allocate the
semaphore data structures.</p>
<p>If a non-NULL value is returned, it indicates that the semaphore has been
created successfully. The returned value should be stored as the handle
to the created semaphore.</p>
</li>
</ul>
<h3 id="742-the-xsemaphoretake-api-function"><a class="header" href="#742-the-xsemaphoretake-api-function">7.4.2 The xSemaphoreTake() API Function</a></h3>
<p>'Taking' a semaphore means to 'obtain' or 'receive' the semaphore. The
semaphore can be taken only if it is available.</p>
<p>All the various types of FreeRTOS semaphore, except recursive mutexes,
can be 'taken' using the <code>xSemaphoreTake()</code> function.</p>
<p><code>xSemaphoreTake()</code> must not be used from an interrupt service routine.</p>
<p><a name="list7.4" title="Listing 7.4 The xSemaphoreTake() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xSemaphoreTake( SemaphoreHandle_t xSemaphore, TickType_t xTicksToWait );
</code></pre>
<p><em><strong>Listing 7.4</strong></em> <em>The xSemaphoreTake() API function prototype</em></p>
<p><strong>xSemaphoreTake() parameters and return value</strong></p>
<ul>
<li>
<p><code>xSemaphore</code></p>
<p>The semaphore being 'taken'.</p>
<p>A semaphore is referenced by a variable of type <code>SemaphoreHandle_t</code>. It
must be explicitly created before it can be used.</p>
</li>
<li>
<p><code>xTicksToWait</code></p>
<p>The maximum amount of time the task should remain in the Blocked
state to wait for the semaphore if it is not already available.</p>
<p>If <code>xTicksToWait</code> is zero, then <code>xSemaphoreTake()</code> will return
immediately if the semaphore is not available.</p>
<p>The block time is specified in tick periods, so the absolute time it
represents is dependent on the tick frequency. The macro <code>pdMS_TO_TICKS()</code>
can be used to convert a time specified in milliseconds to a time
specified in ticks.</p>
<p>Setting <code>xTicksToWait</code> to <code>portMAX_DELAY</code> will cause the task to wait
indefinitely (without a timeout) if <code>INCLUDE_vTaskSuspend</code> is set to 1 in
FreeRTOSConfig.h.</p>
</li>
<li>
<p>Return value</p>
<p>There are two possible return values:</p>
<ul>
<li>
<p><code>pdPASS</code></p>
<p><code>pdPASS</code> is returned only if the call to <code>xSemaphoreTake()</code> was
successful in obtaining the semaphore.</p>
<p>If a block time was specified (<code>xTicksToWait</code> was not zero), then it is
possible that the calling task was placed into the Blocked state to wait
for the semaphore if it was not immediately available, but the semaphore
became available before the block time expired.</p>
</li>
<li>
<p><code>pdFALSE</code></p>
<p>The semaphore is not available.</p>
<p>If a block time was specified (<code>xTicksToWait</code> was not zero), then the
calling task will have been placed into the Blocked state to wait for
the semaphore to become available, but the block time expired before
this happened.</p>
</li>
</ul>
</li>
</ul>
<h3 id="743-the-xsemaphoregivefromisr-api-function"><a class="header" href="#743-the-xsemaphoregivefromisr-api-function">7.4.3 The xSemaphoreGiveFromISR() API Function</a></h3>
<p>Binary and counting semaphores<sup class="footnote-reference"><a href="#16">5</a></sup> can be 'given' using the
<code>xSemaphoreGiveFromISR()</code> function.</p>
<div class="footnote-definition" id="16"><sup class="footnote-definition-label">5</sup>
<p>Counting semaphores are described in a later section of this book.</p>
</div>
<p><code>xSemaphoreGiveFromISR()</code> is the interrupt safe version of
<code>xSemaphoreGive()</code>, so has the <code>pxHigherPriorityTaskWoken</code> parameter that
was described at the start of this chapter.</p>
<p><a name="list" title="Listing 7.5 The xSemaphoreGiveFromISR() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xSemaphoreGiveFromISR( SemaphoreHandle_t xSemaphore,
                                  BaseType_t *pxHigherPriorityTaskWoken );
</code></pre>
<p><em><strong>Listing 7.5</strong></em> <em>The xSemaphoreGiveFromISR() API function prototype</em></p>
<p><strong>xSemaphoreGiveFromISR() parameters and return value</strong></p>
<ul>
<li>
<p><code>xSemaphore</code></p>
<p>The semaphore being 'given'.</p>
<p>A semaphore is referenced by a variable of type <code>SemaphoreHandle_t</code>,
and must be explicitly created before being used.</p>
</li>
<li>
<p><code>pxHigherPriorityTaskWoken</code></p>
<p>It is possible that a single semaphore will have one or more
tasks blocked on it waiting for the semaphore to become available.
Calling <code>xSemaphoreGiveFromISR()</code> can make the semaphore available, and so
cause a task that was waiting for the semaphore to leave the Blocked
state. If calling <code>xSemaphoreGiveFromISR()</code> causes a task to leave the
Blocked state, and the unblocked task has a priority higher than the
currently executing task (the task that was interrupted), then,
internally, <code>xSemaphoreGiveFromISR()</code> will set <code>*pxHigherPriorityTaskWoken</code>
to <code>pdTRUE</code>.</p>
<p>If <code>xSemaphoreGiveFromISR()</code> sets this value to <code>pdTRUE</code>, then normally a
context switch should be performed before the interrupt is exited. This
will ensure that the interrupt returns directly to the highest priority
Ready state task.</p>
</li>
<li>
<p>Return value</p>
<p>There are two possible return values:</p>
<ul>
<li>
<p><code>pdPASS</code></p>
<p><code>pdPASS</code> will be returned only if the call to <code>xSemaphoreGiveFromISR()</code>
is successful.</p>
</li>
<li>
<p><code>pdFAIL</code></p>
<p>If a semaphore is already available, it cannot be given, and
<code>xSemaphoreGiveFromISR()</code> will return <code>pdFAIL</code>.</p>
</li>
</ul>
</li>
</ul>
<h2 id="-15"><a class="header" href="#-15"><a name="example7.1" title="Example 7.1 Using a binary semaphore to synchronize a task with an interrupt"></a></a></h2>
<p><em><strong>Example 7.1</strong></em> <em>Using a binary semaphore to synchronize a task with an interrupt</em></p>
<hr />
<p>This example uses a binary semaphore to unblock a task from an interrupt
service routine, effectively synchronizing the task with the interrupt.</p>
<p>A simple periodic task is used to generate a software interrupt every
500 milliseconds. A software interrupt is used for convenience because
of the complexity of hooking into a real interrupt in some target
environments. Listing 7.6 shows the implementation of the periodic task.
Note that the task prints out a string both before and after the
interrupt is generated. This allows the sequence of execution to be
observed in the output produced when the example is executed.</p>
<p><a name="list7.6" title="Listing 7.6 Implementation of the task that periodically generates a software interrupt in Example 7.1"></a></p>
<pre><code class="language-c">/* The number of the software interrupt used in this example. The code
   shown is from the Windows project, where numbers 0 to 2 are used by the
   FreeRTOS Windows port itself, so 3 is the first number available to the
   application. */
#define mainINTERRUPT_NUMBER 3

static void vPeriodicTask( void *pvParameters )
{
    const TickType_t xDelay500ms = pdMS_TO_TICKS( 500UL );

    /* As per most tasks, this task is implemented within an infinite loop. */
    for( ;; )
    {
        /* Block until it is time to generate the software interrupt again. */
        vTaskDelay( xDelay500ms );

        /* Generate the interrupt, printing a message both before and after
           the interrupt has been generated, so the sequence of execution is
           evident from the output.

           The syntax used to generate a software interrupt is dependent on 
           the FreeRTOS port being used. The syntax used below can only be 
           used with the FreeRTOS Windows port, in which such interrupts are 
           only simulated. */
        vPrintString( "Periodic task - About to generate an interrupt.\r\n" );
        vPortGenerateSimulatedInterrupt( mainINTERRUPT_NUMBER );
        vPrintString( "Periodic task - Interrupt generated.\r\n\r\n\r\n" );
    }
}
</code></pre>
<p><em><strong>Listing 7.6</strong></em> <em>Implementation of the task that periodically generates a software interrupt in Example 7.1</em></p>
<p>Listing 7.7 shows the implementation of the task to which the interrupt
processing is deferred—the task that is synchronized with the software
interrupt through the use of a binary semaphore. Again, a string is
printed out on each iteration of the task, so the sequence in which the
task and the interrupt execute is evident from the output produced when
the example is executed.</p>
<p>It should be noted that, while the code shown in Listing 7.7 is adequate
for Example 7.1, where interrupts are generated by software, it is not
adequate for scenarios where interrupts are generated by hardware
peripherals. A following sub-section describes how the structure of the
code needs to be changed to make it suitable for use with hardware
generated interrupts.</p>
<p><a name="list7.7." title="Listing 7.7 The implementation of the task to which the interrupt processing is deferred (the task that..."></a></p>
<pre><code class="language-c">static void vHandlerTask( void *pvParameters )
{
    /* As per most tasks, this task is implemented within an infinite loop. */
    for( ;; )
    {
        /* Use the semaphore to wait for the event. The semaphore was created
           before the scheduler was started, so before this task ran for the 
           first time. The task blocks indefinitely, meaning this function 
           call will only return once the semaphore has been successfully 
           obtained - so there is no need to check the value returned by 
           xSemaphoreTake(). */
        xSemaphoreTake( xBinarySemaphore, portMAX_DELAY );

        /* To get here the event must have occurred. Process the event (in 
           this Case, just print out a message). */
        vPrintString( "Handler task - Processing event.\r\n" );
    }
}
</code></pre>
<p><em><strong>Listing 7.7</strong></em> <em>The implementation of the task to which the interrupt processing is deferred (the task that synchronizes with the interrupt) in Example 7.1</em></p>
<p>Listing 7.8 shows the ISR. This does very little other than 'give' the
semaphore to unblock the task to which interrupt processing is deferred.</p>
<p>Note how the <code>xHigherPriorityTaskWoken</code> variable is used. It is set to
<code>pdFALSE</code> before calling <code>xSemaphoreGiveFromISR()</code>, then used as the
parameter when <code>portYIELD_FROM_ISR()</code> is called. A context switch will be
requested inside the <code>portYIELD_FROM_ISR()</code> macro if
<code>xHigherPriorityTaskWoken</code> equals <code>pdTRUE</code>.</p>
<p>The prototype of the ISR, and the macro called to force a context
switch, are both correct for the FreeRTOS Windows port, and may be
different for other FreeRTOS ports. Refer to the port specific
documentation pages on the FreeRTOS.org website, and the examples
provided in the FreeRTOS download, to find the syntax required for the
port you are using.</p>
<p>Unlike most architectures on which FreeRTOS runs, the FreeRTOS Windows
port requires an ISR to return a value. The implementation of the
<code>portYIELD_FROM_ISR()</code> macro provided with the Windows port includes the
return statement, so Listing 7.8 does not show a value being returned
explicitly.</p>
<p><a name="list7.8" title="Listing 7.8 The ISR for the software interrupt used in Example 7.1"></a></p>
<pre><code class="language-c">static uint32_t ulExampleInterruptHandler( void )
{
    BaseType_t xHigherPriorityTaskWoken;

    /* The xHigherPriorityTaskWoken parameter must be initialized to
       pdFALSE as it will get set to pdTRUE inside the interrupt safe 
       API function if a context switch is required. */
    xHigherPriorityTaskWoken = pdFALSE;

    /* 'Give' the semaphore to unblock the task, passing in the address of
       xHigherPriorityTaskWoken as the interrupt safe API function's
       pxHigherPriorityTaskWoken parameter. */
    xSemaphoreGiveFromISR( xBinarySemaphore, &amp;xHigherPriorityTaskWoken );

    /* Pass the xHigherPriorityTaskWoken value into portYIELD_FROM_ISR().
       If xHigherPriorityTaskWoken was set to pdTRUE inside
       xSemaphoreGiveFromISR() then calling portYIELD_FROM_ISR() will request 
       a context switch. If xHigherPriorityTaskWoken is still pdFALSE then 
       calling portYIELD_FROM_ISR() will have no effect. Unlike most FreeRTOS 
       ports, the Windows port requires the ISR to return a value - the return 
       statement is inside the Windows version of portYIELD_FROM_ISR(). */
    portYIELD_FROM_ISR( xHigherPriorityTaskWoken );
}
</code></pre>
<p><em><strong>Listing 7.8</strong></em> <em>The ISR for the software interrupt used in Example 7.1</em></p>
<p>The <code>main()</code> function creates the binary semaphore, creates the tasks,
installs the interrupt handler, and starts the scheduler. The
implementation is shown in Listing 7.9.</p>
<p>The syntax of the function called to install an interrupt handler is
specific to the FreeRTOS Windows port, and may be different for other
FreeRTOS ports. Refer to the port specific documentation pages on the
FreeRTOS.org website, and the examples provided in the FreeRTOS
download, to find the syntax required for the port you are using.</p>
<p><a name="list7.9" title="Listing 7.9 The implementation of main() for Example 7.1"></a></p>
<pre><code class="language-c">int main( void )
{
    /* Before a semaphore is used it must be explicitly created. In this
       example a binary semaphore is created. */
    xBinarySemaphore = xSemaphoreCreateBinary();

    /* Check the semaphore was created successfully. */
    if( xBinarySemaphore != NULL )
    {
        /* Create the 'handler' task, which is the task to which interrupt
           processing is deferred. This is the task that will be synchronized 
           with the interrupt. The handler task is created with a high priority
           to ensure it runs immediately after the interrupt exits. In this 
           case a priority of 3 is chosen. */
        xTaskCreate( vHandlerTask, "Handler", 1000, NULL, 3, NULL );

        /* Create the task that will periodically generate a software
           interrupt. This is created with a priority below the handler task 
           to ensure it will get preempted each time the handler task exits 
           the Blocked state. */
        xTaskCreate( vPeriodicTask, "Periodic", 1000, NULL, 1, NULL );

        /* Install the handler for the software interrupt. The syntax necessary
           to do this is dependent on the FreeRTOS port being used. The syntax
           shown here can only be used with the FreeRTOS windows port, where 
           such interrupts are only simulated. */
        vPortSetInterruptHandler( mainINTERRUPT_NUMBER,
                                  ulExampleInterruptHandler );

        /* Start the scheduler so the created tasks start executing. */
        vTaskStartScheduler();
    }

    /* As normal, the following line should never be reached. */
    for( ;; );
}
</code></pre>
<p><em><strong>Listing 7.9</strong></em> <em>The implementation of main() for Example 7.1</em></p>
<p>Example 7.1 produces the output shown in Figure 7.4. As expected,
<code>vHandlerTask()</code> enters the Running state as soon as the interrupt is
generated, so the output from the task splits the output produced by the
periodic task. Further explanation is provided in Figure 7.5.</p>
<p><a name="fig7.4" title="Figure 7.4 The output produced when Example 7.1 is executed"></a>
<a name="fig7.5" title="Figure 7.5 The sequence of execution when Example 7.1 is executed"></a></p>
<hr />
<p><img src="media/image51.jpg" alt="" /><br />
<em><strong>Figure 7.4</strong></em> <em>The output produced when Example 7.1 is executed</em></p>
<p><img src="media/image52.png" alt="" /><br />
<em><strong>Figure 7.5</strong></em> <em>The sequence of execution when Example 7.1 is executed</em></p>
<hr />
<h3 id="744-improving-the-implementation-of-the-task-used-in-example-71"><a class="header" href="#744-improving-the-implementation-of-the-task-used-in-example-71">7.4.4 Improving the Implementation of the Task Used in Example 7.1</a></h3>
<p>Example 7.1 used a binary semaphore to synchronize a task with an
interrupt. The execution sequence was as follows:</p>
<ol>
<li>
<p>The interrupt occurred.</p>
</li>
<li>
<p>The ISR executed and 'gave' the semaphore to unblock the task.</p>
</li>
<li>
<p>The task executed immediately after the ISR, and 'took' the
semaphore.</p>
</li>
<li>
<p>The task processed the event, then attempted to 'take' the semaphore
again—entering the Blocked state because the semaphore was not yet
available (another interrupt had not yet occurred).</p>
</li>
</ol>
<p>The structure of the task used in Example 7.1 is adequate only if
interrupts occur at a relatively low frequency. To understand why,
consider what would happen if a second, and then a third, interrupt had
occurred before the task had completed its processing of the first
interrupt:</p>
<ul>
<li>
<p>When the second ISR executed, the semaphore would be empty, so the
ISR would give the semaphore, and the task would process the second
event immediately after it had completed processing the first event.
That scenario is shown in Figure 7.6.</p>
</li>
<li>
<p>When the third ISR executed, the semaphore would already be
available, preventing the ISR giving the semaphore again, so the
task would not know the third event had occurred. That scenario is
shown in Figure 7.7.</p>
</li>
</ul>
<p><a name="fig7.6" title="Figure 7.6 The scenario when one interrupt occurs before the task has finished processing the first event"></a>
<a name="fig7.7" title="Figure 7.7 The scenario when two interrupts occur before the task has finished processing the first event"></a></p>
<hr />
<p><img src="media/image53.png" alt="" /><br />
<em><strong>Figure 7.6</strong></em> <em>The scenario when one interrupt occurs before the task has finished processing the first event</em></p>
<p><img src="media/image54.png" alt="" /><br />
<em><strong>Figure 7.7</strong></em> <em>The scenario when two interrupts occur before the task has finished processing the first event</em></p>
<hr />
<p>The deferred interrupt handling task used in Example 7.1, and shown in
Listing 7.7, is structured so that it only processes one event between
each call to <code>xSemaphoreTake()</code>. That was adequate for Example 7.1, because
the interrupts that generated the events were triggered by software, and
occurred at a predictable time. In real applications, interrupts are
generated by hardware, and occur at unpredictable times. Therefore, to
minimize the chance of an interrupt being missed, the deferred interrupt
handling task must be structured so that it processes all the events
that are already available between each call to <code>xSemaphoreTake()</code><sup class="footnote-reference"><a href="#17">6</a></sup>.
This is demonstrated by Listing 7.10, which shows how a deferred interrupt
handler for a UART could be structured. In Listing 7.10, it is assumed the
UART generates a receive interrupt each time a character is received,
and that the UART places received characters into a hardware FIFO (a
hardware buffer).</p>
<div class="footnote-definition" id="17"><sup class="footnote-definition-label">6</sup>
<p>Alternatively, a counting semaphore, or a direct to task
notification, can be used to count events. Counting semaphores are
described in the next section. Direct to task notifications are
described in Chapter 9, Task Notifications. Direct to task
notifications are the preferred method as they are the most
efficient in both run time and RAM usage.</p>
</div>
<p>The deferred interrupt handling task used in Example 7.1 had one other
weakness; it did not use a timeout when it called <code>xSemaphoreTake()</code>.
Instead, the task passed <code>portMAX_DELAY</code> as the <code>xSemaphoreTake()</code>
<code>xTicksToWait</code> parameter, which results in the task waiting indefinitely
(without a timeout) for the semaphore to be available. Indefinite
timeouts are often used in example code because their use simplifies the
structure of the example, and therefore makes the example easier to
understand. However, indefinite timeouts are normally bad practice in
real applications, because they make it difficult to recover from an
error. As an example, consider the scenario where a task is waiting for
an interrupt to give a semaphore, but an error state in the hardware is
preventing the interrupt from being generated:</p>
<ul>
<li>
<p>If the task is waiting without a timeout, it will not know about
the error state, and will wait forever.</p>
</li>
<li>
<p>If the task is waiting with a timeout, then <code>xSemaphoreTake()</code> will
return <code>pdFAIL</code> when the timeout expires, and the task can then
detect and clear the error the next time it executes. This scenario
is also demonstrated in Listing 7.10.</p>
</li>
</ul>
<p><a name="list7.10" title="Listing 7.10 The recommended structure of a deferred interrupt processing task, using a UART receive..."></a></p>
<pre><code class="language-c">static void vUARTReceiveHandlerTask( void *pvParameters )
{
    /* xMaxExpectedBlockTime holds the maximum time expected between two
       interrupts. */
    const TickType_t xMaxExpectedBlockTime = pdMS_TO_TICKS( 500 );

    /* As per most tasks, this task is implemented within an infinite loop. */
    for( ;; )
    {
        /* The semaphore is 'given' by the UART's receive (Rx) interrupt. 
           Wait a maximum of xMaxExpectedBlockTime ticks for the next 
           interrupt. */
        if( xSemaphoreTake( xBinarySemaphore, xMaxExpectedBlockTime ) == pdPASS)
        {
            /* The semaphore was obtained. Process ALL pending Rx events before
               calling xSemaphoreTake() again. Each Rx event will have placed a
               character in the UART's receive FIFO, and UART_RxCount() is 
               assumed to return the number of characters in the FIFO. */
            while( UART_RxCount() &gt; 0 )
            {
                /* UART_ProcessNextRxEvent() is assumed to process one Rx 
                   character, reducing the number of characters in the FIFO 
                   by 1. */
                UART_ProcessNextRxEvent();
            }

            /* No more Rx events are pending (there are no more characters in 
               the FIFO), so loop back and call xSemaphoreTake() to wait for 
               the next interrupt. Any interrupts occurring between this point
               in the code and the call to xSemaphoreTake() will be latched in 
               the semaphore, so will not be lost. */
        }
        else
        {
            /* An event was not received within the expected time. Check for, 
               and if necessary clear, any error conditions in the UART that 
               might be preventing the UART from generating any more 
               interrupts. */
            UART_ClearErrors();
        }
    }
}
</code></pre>
<p><em><strong>Listing 7.10</strong></em> <em>The recommended structure of a deferred interrupt processing task, using a UART receive handler as an example</em></p>
<h2 id="75-counting-semaphores"><a class="header" href="#75-counting-semaphores">7.5 Counting Semaphores</a></h2>
<p>Just as binary semaphores can be thought of as queues that have a length
of one, counting semaphores can be thought of as queues that have a
length of more than one. Tasks are not interested in the data that is
stored in the queue—just the number of items in the queue.
<code>configUSE_COUNTING_SEMAPHORES</code> must be set to 1 in FreeRTOSConfig.h for
counting semaphores to be available.</p>
<p>Each time a counting semaphore is 'given', another space in its queue is
used. The number of items in the queue is the semaphore's 'count' value.</p>
<p>Counting semaphores are typically used for two things:</p>
<ol>
<li>
<p>Counting events<sup class="footnote-reference"><a href="#18">7</a></sup></p>
<p>In this scenario, an event handler will 'give' a semaphore each time
an event occurs, causing the semaphore's count value to be
incremented on each 'give'. A task will 'take' a semaphore each time
it processes an event, causing the semaphore's count value to be
decremented on each 'take'. The count value is the difference
between the number of events that have occurred and the number that
have been processed. This mechanism is shown in Figure 7.8.</p>
<p>Counting semaphores that are used to count events are created with
an initial count value of zero.</p>
<div class="footnote-definition" id="18"><sup class="footnote-definition-label">7</sup>
<p>It is more efficient to count events using a direct to task
notification than it is using a counting semaphore. Direct to task
notifications are not covered until Chapter 9.</p>
</div>
</li>
<li>
<p>Resource management.</p>
<p>In this scenario, the count value indicates the number of resources
available. To obtain control of a resource, a task must first obtain
a semaphore, which decrements the semaphore's count value. When the count
value reaches zero, there are no free resources. When a task
finishes with the resource, it 'gives' the semaphore
back, which increments the semaphore's count value.</p>
<p>Counting semaphores that are used to manage resources are created so
that their initial count value equals the number of resources that
are available. Chapter 7 covers using semaphores to manage
resources.</p>
</li>
</ol>
<p><a name="fig7.8" title="Figure 7.8 Using a counting semaphore to 'count' events"></a></p>
<hr />
<p><img src="media/image55.png" alt="" /><br />
<em><strong>Figure 7.8</strong></em> <em>Using a counting semaphore to 'count' events</em></p>
<hr />
<h3 id="751-the-xsemaphorecreatecounting-api-function"><a class="header" href="#751-the-xsemaphorecreatecounting-api-function">7.5.1 The xSemaphoreCreateCounting() API Function</a></h3>
<p>FreeRTOS also includes the <code>xSemaphoreCreateCountingStatic()</code>
function, which allocates the memory required to create a counting
semaphore statically at compile time: Handles to all the various types
of FreeRTOS semaphores are stored in a variable of type <code>SemaphoreHandle_t</code>.</p>
<p>Before a semaphore can be used, it must be created. To create a counting
semaphore, use the <code>xSemaphoreCreateCounting()</code> API function.</p>
<p><a name="list7.11" title="Listing 7.11 The xSemaphoreCreateCounting() API function prototype"></a></p>
<pre><code class="language-c">SemaphoreHandle_t xSemaphoreCreateCounting( UBaseType_t uxMaxCount,
                                            UBaseType_t uxInitialCount );
</code></pre>
<p><em><strong>Listing 7.11</strong></em> <em>The xSemaphoreCreateCounting() API function prototype</em></p>
<p><strong>xSemaphoreCreateCounting() parameters and return value</strong></p>
<ul>
<li>
<p><code>uxMaxCount</code></p>
<p>The maximum value to which the semaphore will count. To continue
the queue analogy, the <code>uxMaxCount</code> value is effectively the length of the
queue.</p>
<p>When the semaphore is to be used to count or latch events, <code>uxMaxCount</code>
is the maximum number of events that can be latched.</p>
<p>When the semaphore is to be used to manage access to a collection of
resources, <code>uxMaxCount</code> should be set to the total number of resources
that are available.</p>
</li>
<li>
<p><code>uxInitialCount</code></p>
<p>The initial count value of the semaphore after it has been created.</p>
<p>When the semaphore is to be used to count or latch events,
<code>uxInitialCount</code> should be set to zero (because when the semaphore
is created we assume no events have occurred yet).</p>
<p>When the semaphore is to be used to manage access to a collection of
resources, <code>uxInitialCount</code> should be set to equal <code>uxMaxCount</code> (because
when the semaphore is created we assume all the resources are available).</p>
</li>
<li>
<p>Return value</p>
<p>If NULL is returned, the semaphore cannot be created because
there is insufficient heap memory available for FreeRTOS to allocate the
semaphore data structures. Chapter 3 provides more information on heap
memory management.</p>
<p>If a non-NULL value is returned, it indicates that the semaphore has been
created successfully. The returned value should be stored as the handle
to the created semaphore.</p>
</li>
</ul>
<h2 id="-16"><a class="header" href="#-16"><a name="example7.2" title="Example 7.2 Using a counting semaphore to synchronize a task with an interrupt"></a></a></h2>
<p><em><strong>Example 7.2</strong></em> <em>Using a counting semaphore to synchronize a task with an interrupt</em></p>
<hr />
<p>Example 7.2 improves on the Example 7.1 implementation by using a counting
semaphore in place of the binary semaphore. <code>main()</code> is changed to include
a call to <code>xSemaphoreCreateCounting()</code> in place of the call to
<code>xSemaphoreCreateBinary()</code>. The new API call is shown in Listing 7.12.</p>
<p><a name="list7.12" title="Listing 7.12 The call to xSemaphoreCreateCounting() used to create the counting semaphore in Example 7.2"></a></p>
<pre><code class="language-c">/* Before a semaphore is used it must be explicitly created. In this example a
   counting semaphore is created. The semaphore is created to have a maximum 
   count value of 10, and an initial count value of 0. */
xCountingSemaphore = xSemaphoreCreateCounting( 10, 0 );
</code></pre>
<p><em><strong>Listing 7.12</strong></em> <em>The call to xSemaphoreCreateCounting() used to create the counting semaphore in Example 7.2</em></p>
<p>To simulate multiple events occurring at high frequency, the interrupt
service routine is changed to 'give' the semaphore more than once per
interrupt. Each event is latched in the semaphore's count value. The
modified interrupt service routine is shown in Listing 7.13.</p>
<p><a name="list7.13" title="Listing 7.13 The implementation of the interrupt service routine used by Example 7.2"></a></p>
<pre><code class="language-c">static uint32_t ulExampleInterruptHandler( void )
{
    BaseType_t xHigherPriorityTaskWoken;

    /* The xHigherPriorityTaskWoken parameter must be initialized to pdFALSE 
       as it will get set to pdTRUE inside the interrupt safe API function if 
       a context switch is required. */
    xHigherPriorityTaskWoken = pdFALSE;

    /* 'Give' the semaphore multiple times. The first will unblock the deferred
       interrupt handling task, the following 'gives' are to demonstrate that 
       the semaphore latches the events to allow the task to which interrupts 
       are deferred to process them in turn, without events getting lost. This 
       simulates multiple interrupts being received by the processor, even 
       though in this case the events are simulated within a single interrupt 
       occurrence. */
    xSemaphoreGiveFromISR( xCountingSemaphore, &amp;xHigherPriorityTaskWoken );
    xSemaphoreGiveFromISR( xCountingSemaphore, &amp;xHigherPriorityTaskWoken );
    xSemaphoreGiveFromISR( xCountingSemaphore, &amp;xHigherPriorityTaskWoken );

    /* Pass the xHigherPriorityTaskWoken value into portYIELD_FROM_ISR().
       If xHigherPriorityTaskWoken was set to pdTRUE inside
       xSemaphoreGiveFromISR() then calling portYIELD_FROM_ISR() will request 
       a context switch. If xHigherPriorityTaskWoken is still pdFALSE then 
       calling portYIELD_FROM_ISR() will have no effect. Unlike most FreeRTOS 
       ports, the Windows port requires the ISR to return a value - the return
       statement is inside the Windows version of portYIELD_FROM_ISR(). */
    portYIELD_FROM_ISR( xHigherPriorityTaskWoken );
}
</code></pre>
<p><em><strong>Listing 7.13</strong></em> <em>The implementation of the interrupt service routine used by Example 7.2</em></p>
<p>All the other functions remain unmodified from those used in Example 7.1.</p>
<p>The output produced when Example 7.2 is executed is shown in Figure 7.9.
As can be seen, the task to which interrupt handling is deferred
processes all three (simulated) events each time an interrupt is
generated. The events are latched into the count value of the semaphore,
allowing the task to process them in turn.</p>
<p><a name="fig7.9" title="Figure 7.9 The output produced when Example 7.2 is executed"></a></p>
<hr />
<p><img src="media/image56.jpg" alt="" /><br />
<em><strong>Figure 7.9</strong></em> <em>The output produced when Example 7.2 is executed</em></p>
<hr />
<h2 id="76-deferring-work-to-the-rtos-daemon-task"><a class="header" href="#76-deferring-work-to-the-rtos-daemon-task">7.6 Deferring Work to the RTOS Daemon Task</a></h2>
<p>The deferred interrupt handling examples presented so far have required
the application writer to create a task for each interrupt that uses the
deferred processing technique. It is also possible to use the
<code>xTimerPendFunctionCallFromISR()</code><sup class="footnote-reference"><a href="#19">8</a></sup> API function to defer interrupt
processing to the RTOS daemon task, which removes the need to create a
separate task for each interrupt. Deferring interrupt processing to the
daemon task is called 'centralized deferred interrupt processing'.</p>
<div class="footnote-definition" id="19"><sup class="footnote-definition-label">8</sup>
<p>The daemon task was originally
called the timer service task because it was originally only used to
execute software timer callback functions. Hence,
<code>xTimerPendFunctionCall()</code> is implemented in timers.c, and, in
accordance with the convention of prefixing a function's name with
the name of the file in which the function is implemented, the
function's name is prefixed with 'Timer'.</p>
</div>
<p>Chapter 6 described how software timer-related FreeRTOS API functions
send commands to the daemon task on the timer command queue. The
<code>xTimerPendFunctionCall()</code> and <code>xTimerPendFunctionCallFromISR()</code> API
functions use the same timer command queue to send an 'execute function'
command to the daemon task. The function sent to the daemon task is then
executed in the context of the daemon task.</p>
<p>Advantages of centralized deferred interrupt processing include:</p>
<ul>
<li>
<p>Lower resource usage</p>
<p>It removes the need to create a separate task for each deferred
interrupt.</p>
</li>
<li>
<p>Simplified user model</p>
<p>The deferred interrupt handling function is a standard C function.</p>
</li>
</ul>
<p>Disadvantages of centralized deferred interrupt processing include:</p>
<ul>
<li>
<p>Less flexibility</p>
<p>It is not possible to set the priority of each deferred interrupt
handling task separately. Each deferred interrupt handling function
executes at the priority of the daemon task. As described in Chapter
6, the priority of the daemon task is set by the
<code>configTIMER_TASK_PRIORITY</code> compile time configuration constant within
FreeRTOSConfig.h.</p>
</li>
<li>
<p>Less determinism</p>
<p><code>xTimerPendFunctionCallFromISR()</code> sends a command to the back of the
timer command queue. Commands that were already in the timer command
queue will be processed by the daemon task before the 'execute
function' command sent to the queue by
<code>xTimerPendFunctionCallFromISR()</code>.</p>
</li>
</ul>
<p>Different interrupts have different timing constraints, so it is common
to use both methods of deferring interrupt processing within the same
application.</p>
<h3 id="761-the-xtimerpendfunctioncallfromisr-api-function"><a class="header" href="#761-the-xtimerpendfunctioncallfromisr-api-function">7.6.1 The xTimerPendFunctionCallFromISR() API Function</a></h3>
<p><code>xTimerPendFunctionCallFromISR()</code> is the interrupt safe version of
<code>xTimerPendFunctionCall()</code>. Both API functions allow a function provided
by the application writer to be executed by, and therefore in the
context of, the RTOS daemon task. Both the function to be executed, and
the value of the function's input parameters, are sent to the daemon
task on the timer command queue. When the function actually executes is
therefore dependent on the priority of the daemon task relative to other
tasks in the application.</p>
<p><a name="list7.14" title="Listing 7.14 The xTimerPendFunctionCallFromISR() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xTimerPendFunctionCallFromISR( PendedFunction_t
                                          xFunctionToPend,
                                          void *pvParameter1,
                                          uint32_t ulParameter2,
                                          BaseType_t *pxHigherPriorityTaskWoken );
</code></pre>
<p><em><strong>Listing 7.14</strong></em> <em>The xTimerPendFunctionCallFromISR() API function prototype</em></p>
<p><a name="list7.15" title="Listing 7.15 The prototype to which a function passed in the xFunctionToPend parameter of xTimerPendFunctionCallFromISR()..."></a></p>
<pre><code class="language-c">void vPendableFunction( void *pvParameter1, uint32_t ulParameter2 );
</code></pre>
<p><em><strong>Listing 7.15</strong></em> <em>The prototype to which a function passed in the xFunctionToPend parameter of xTimerPendFunctionCallFromISR() must conform</em></p>
<p><strong>xTimerPendFunctionCallFromISR() parameters and return value</strong></p>
<ul>
<li>
<p><code>xFunctionToPend</code></p>
<p>A pointer to the function that will be executed in the daemon task
(in effect, just the function name). The prototype of the function must
be the same as that shown in Listing 7.15.</p>
</li>
<li>
<p><code>pvParameter1</code></p>
<p>The value that will be passed into the function that is executed by
the daemon task as that function's <code>pvParameter1</code> parameter. The parameter
has a <code>void *</code> type to allow it to be used to pass any data type. For
example, integer types can be directly cast to a <code>void *</code>, alternatively
the <code>void *</code> can be used to point to a structure.</p>
</li>
<li>
<p><code>ulParameter2</code></p>
<p>The value that will be passed into the function that is executed by
the daemon task as that function's <code>ulParameter2</code> parameter.</p>
</li>
<li>
<p><code>pxHigherPriorityTaskWoken</code></p>
<p><code>xTimerPendFunctionCallFromISR()</code> writes to the timer command
queue. If the RTOS daemon task was in the Blocked state to wait for data
to become available on the timer command queue, then writing to the
timer command queue will cause the daemon task to leave the Blocked
state. If the priority of the daemon task is higher than the priority of
the currently executing task (the task that was interrupted), then,
internally, <code>xTimerPendFunctionCallFromISR()</code> will set
<code>*pxHigherPriorityTaskWoken</code> to <code>pdTRUE</code>.</p>
<p>If <code>xTimerPendFunctionCallFromISR()</code> sets this value to <code>pdTRUE</code>, then a
context switch must be performed before the interrupt is exited. This
will ensure that the interrupt returns directly to the daemon task, as
the daemon task will be the highest priority Ready state task.</p>
</li>
<li>
<p>Return value</p>
<p>There are two possible return values:</p>
<ul>
<li>
<p><code>pdPASS</code></p>
<p><code>pdPASS</code> will be returned if the 'execute function' command was written
to the timer command queue.</p>
</li>
<li>
<p><code>pdFAIL</code></p>
<p><code>pdFAIL</code> will be returned if the 'execute function' command could not
be written to the timer command queue because the timer command queue
was already full. Chapter 6 describes how to set the length of the timer
command queue.</p>
</li>
</ul>
</li>
</ul>
<h2 id="-17"><a class="header" href="#-17"><a name="example7.3" title="Example 7.3 Centralized deferred interrupt processing"></a></a></h2>
<p><em><strong>Example 7.3</strong></em> <em>Centralized deferred interrupt processing</em></p>
<hr />
<p>Example 7.3 provides similar functionality to Example 7.1, but without
using a semaphore, and without creating a task specifically to perform
the processing necessitated by the interrupt. Instead, the processing is
performed by the RTOS daemon task.</p>
<p>The interrupt service routine used by Example 7.3 is shown in Listing 7.16.
It calls <code>xTimerPendFunctionCallFromISR()</code> to pass a pointer to a
function called <code>vDeferredHandlingFunction()</code> to the daemon task. The
deferred interrupt processing is performed by the
<code>vDeferredHandlingFunction()</code> function.</p>
<p>The interrupt service routine increments a variable called
<code>ulParameterValue</code> each time it executes. <code>ulParameterValue</code> is used as the
value of <code>ulParameter2</code> in the call to <code>xTimerPendFunctionCallFromISR()</code>, so it
will also be used as the value of <code>ulParameter2</code> in the call to
<code>vDeferredHandlingFunction()</code> when <code>vDeferredHandlingFunction()</code> is executed
by the daemon task. The function's other parameter, <code>pvParameter1</code>, is not
used in this example.</p>
<p><a name="list7.16" title="Listing 7.16 The software interrupt handler used in Example 7.3"></a></p>
<pre><code class="language-c">static uint32_t ulExampleInterruptHandler( void )
{
    static uint32_t ulParameterValue = 0;
    BaseType_t xHigherPriorityTaskWoken;

    /* The xHigherPriorityTaskWoken parameter must be initialized to pdFALSE 
       as it will get set to pdTRUE inside the interrupt safe API function if 
       a context switch is required. */
    xHigherPriorityTaskWoken = pdFALSE;

    /* Send a pointer to the interrupt's deferred handling function to the
       daemon task. The deferred handling function's pvParameter1 parameter 
       is not used so just set to NULL. The deferred handling function's 
       ulParameter2 parameter is used to pass a number that is incremented by 
       one each time this interrupt handler executes. */
    xTimerPendFunctionCallFromISR( vDeferredHandlingFunction, /* Function to execute */
                                   NULL, /* Not used */
                                   ulParameterValue, /* Incrementing value. */
                                   &amp;xHigherPriorityTaskWoken );
    ulParameterValue++;

    /* Pass the xHigherPriorityTaskWoken value into portYIELD_FROM_ISR(). If
       xHigherPriorityTaskWoken was set to pdTRUE inside
       xTimerPendFunctionCallFromISR() then calling portYIELD_FROM_ISR() will 
       request a context switch. If xHigherPriorityTaskWoken is still pdFALSE 
       then calling portYIELD_FROM_ISR() will have no effect. Unlike most 
       FreeRTOS ports, the Windows port requires the ISR to return a value - 
       the return statement is inside the Windows version 
       of portYIELD_FROM_ISR(). */
    portYIELD_FROM_ISR( xHigherPriorityTaskWoken );
}
</code></pre>
<p><em><strong>Listing 7.16</strong></em> <em>The software interrupt handler used in Example 7.3</em></p>
<p>The implementation of <code>vDeferredHandlingFunction()</code> is shown in Listing
7.17. It prints out a fixed string, and the value of its <code>ulParameter2</code>
parameter.</p>
<p><code>vDeferredHandlingFunction()</code> must have the prototype shown in Listing
7.15, even though, in this example, only one of its parameters is
actually used.</p>
<p><a name="list7.17" title="Listing 7.17 The function that performs the processing necessitated by the interrupt in Example 7.3"></a></p>
<pre><code class="language-c">static void vDeferredHandlingFunction( void *pvParameter1, uint32_t ulParameter2 )
{
    /* Process the event - in this case just print out a message and the value 
       of ulParameter2. pvParameter1 is not used in this example. */
    vPrintStringAndNumber( "Handler function - Processing event ", ulParameter2 );
}
</code></pre>
<p><em><strong>Listing 7.17</strong></em> <em>The function that performs the processing necessitated by the interrupt in Example 7.3</em></p>
<p>The <code>main()</code> function used by Example 7.3 is shown in Listing 7.18. It is
simpler than the <code>main()</code> function used by Example 7.1 because it does not
create either a semaphore or a task to perform the deferred interrupt
processing.</p>
<p><code>vPeriodicTask()</code> is the task that periodically generates software
interrupts. It is created with a priority below the priority of the
daemon task to ensure it is pre-empted by the daemon task as soon as the
daemon task leaves the Blocked state.</p>
<p><a name="list7.18" title="Listing 7.18 The implementation of main() for Example 7.3"></a></p>
<pre><code class="language-c">int main( void )
{
    /* The task that generates the software interrupt is created at a priority 
       below the priority of the daemon task. The priority of the daemon task 
       is set by the configTIMER_TASK_PRIORITY compile time configuration 
       constant in FreeRTOSConfig.h. */
    const UBaseType_t ulPeriodicTaskPriority = configTIMER_TASK_PRIORITY - 1;

    /* Create the task that will periodically generate a software interrupt. */
    xTaskCreate( vPeriodicTask, "Periodic", 1000, NULL, ulPeriodicTaskPriority, 
                 NULL );

    /* Install the handler for the software interrupt. The syntax necessary to 
       do this is dependent on the FreeRTOS port being used. The syntax shown 
       here can only be used with the FreeRTOS windows port, where such 
       interrupts are only simulated. */
    vPortSetInterruptHandler( mainINTERRUPT_NUMBER, ulExampleInterruptHandler );

    /* Start the scheduler so the created task starts executing. */
    vTaskStartScheduler();

    /* As normal, the following line should never be reached. */
    for( ;; );
}
</code></pre>
<p><em><strong>Listing 7.18</strong></em> <em>The implementation of main() for Example 7.3</em></p>
<p>Example 7.3 produces the output shown in Figure 7.10. The priority of the
daemon task is higher than the priority of the task that generates the
software interrupt, so <code>vDeferredHandlingFunction()</code> is executed by the
daemon task as soon as the interrupt is generated. That results in the
message output by <code>vDeferredHandlingFunction()</code> appear in between the
two messages output by the periodic task, just as it did when a
semaphore was used to unblock a dedicated deferred interrupt processing
task. Further explanation is provided in Figure 7.11.</p>
<p><a name="fig7.10" title="Figure 7.10 The output produced when Example 7.3 is executed"></a>
<a name="fig7.11" title="Figure 7.11 The sequence of execution when Example 7.3 is executed"></a></p>
<hr />
<p><img src="media/image57.jpg" alt="" /><br />
<em><strong>Figure 7.10</strong></em> <em>The output produced when Example 7.3 is executed</em></p>
<p><img src="media/image58.png" alt="" /><br />
<em><strong>Figure 7.11</strong></em> <em>The sequence of execution when Example 7.3 is executed</em></p>
<hr />
<h2 id="77-using-queues-within-an-interrupt-service-routine"><a class="header" href="#77-using-queues-within-an-interrupt-service-routine">7.7 Using Queues within an Interrupt Service Routine</a></h2>
<p>Binary and counting semaphores are used to communicate events. Queues
are used to communicate events and to transfer data.</p>
<p><code>xQueueSendToFrontFromISR()</code> is the version of <code>xQueueSendToFront()</code> that is
safe to use in an interrupt service routine, <code>xQueueSendToBackFromISR()</code>
is the version of <code>xQueueSendToBack()</code> that is safe to use in an interrupt
service routine, and <code>xQueueReceiveFromISR()</code> is the version of
<code>xQueueReceive()</code> that is safe to use in an interrupt service routine.</p>
<h3 id="771-the-xqueuesendtofrontfromisr-and-xqueuesendtobackfromisr-api-functions"><a class="header" href="#771-the-xqueuesendtofrontfromisr-and-xqueuesendtobackfromisr-api-functions">7.7.1 The xQueueSendToFrontFromISR() and xQueueSendToBackFromISR() API Functions</a></h3>
<p><a name="list7.19" title="Listing 7.19 The xQueueSendToFrontFromISR() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xQueueSendToFrontFromISR( QueueHandle_t xQueue, 
                                     const void *pvItemToQueue
                                     BaseType_t *pxHigherPriorityTaskWoken );
</code></pre>
<p><em><strong>Listing 7.19</strong></em> <em>The xQueueSendToFrontFromISR() API function prototype</em></p>
<p><a name="list7.20" title="Listing 7.20 The xQueueSendToBackFromISR() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xQueueSendToBackFromISR( QueueHandle_t xQueue,
                                    const void *pvItemToQueue
                                    BaseType_t *pxHigherPriorityTaskWoken );
</code></pre>
<p><em><strong>Listing 7.20</strong></em> <em>The xQueueSendToBackFromISR() API function prototype</em></p>
<p><code>xQueueSendFromISR()</code> and <code>xQueueSendToBackFromISR()</code> are functionally equivalent.</p>
<p><strong>xQueueSendToFrontFromISR() and xQueueSendToBackFromISR() parameters and return values</strong></p>
<ul>
<li>
<p><code>xQueue</code></p>
<p>The handle of the queue to which the data is being sent (written).
The queue handle will have been returned from the call to <code>xQueueCreate()</code>
used to create the queue.</p>
</li>
<li>
<p><code>pvItemToQueue</code></p>
<p>A pointer to the item that is to be placed on the queue.</p>
<p>The size of each item the queue will hold was defined when the queue was
created, so this many bytes will be copied from <code>pvItemToQueue</code> into the
queue storage area.</p>
</li>
<li>
<p><code>pxHigherPriorityTaskWoken</code></p>
<p>It is possible that a single queue will have one or more tasks
blocked on it, waiting for data to become available. Calling
<code>xQueueSendToFrontFromISR()</code> or <code>xQueueSendToBackFromISR()</code> can make data
available, and so cause such a task to leave the Blocked state. If
calling the API function causes a task to leave the Blocked state, and
the unblocked task has a priority higher than the currently executing
task (the task that was interrupted), then, internally, the API function
will set <code>*pxHigherPriorityTaskWoken</code> to <code>pdTRUE</code>.</p>
<p>If <code>xQueueSendToFrontFromISR()</code> or <code>xQueueSendToBackFromISR()</code> sets this
value to <code>pdTRUE</code>, then a context switch should be performed before the
interrupt is exited. This will ensure that the interrupt returns
directly to the highest priority Ready state task.</p>
</li>
<li>
<p>Return value</p>
<p>There are two possible return values:</p>
<ul>
<li>
<p><code>pdPASS</code></p>
<p><code>pdPASS</code> is returned only if data has been sent successfully to the queue.</p>
</li>
<li>
<p>`errQUEUE_FULL</p>
<p><code>errQUEUE_FULL</code> is returned if data cannot be sent to the queue because
the queue is already full.</p>
</li>
</ul>
</li>
</ul>
<h3 id="772-considerations-when-using-a-queue-from-an-isr"><a class="header" href="#772-considerations-when-using-a-queue-from-an-isr">7.7.2 Considerations When Using a Queue From an ISR</a></h3>
<p>Queues provide an easy and convenient way of passing data from an
interrupt to a task, but it is not efficient to use a queue if data is
arriving at a high frequency.</p>
<p>Many of the demo applications in the FreeRTOS download include a simple
UART driver that uses a queue to pass characters out of the UART's
receive ISR. In those demos a queue is used for two reasons: to
demonstrate queues being used from an ISR, and to deliberately load the
system in order to test the FreeRTOS port. The ISRs that use a queue in
this manner are definitely not intended to represent an efficient
design, and unless the data is arriving slowly, it is recommended that
production code does not copy this technique. More efficient techniques,
that are suitable for production code, include:</p>
<ul>
<li>
<p>Using Direct Memory Access (DMA) hardware to receive and buffer
characters. This method has practically no software overhead. A
direct to task notification<sup class="footnote-reference"><a href="#20">9</a></sup> can then be used to unblock the
task that will process the buffer only after a break in transmission
has been detected.</p>
<div class="footnote-definition" id="20"><sup class="footnote-definition-label">9</sup>
<p>Direct to task notifications provide the most efficient method of
unblocking a task from an ISR. Direct to task notifications are
covered in Chapter 9, Task Notifications.</p>
</div>
</li>
<li>
<p>Copying each received character into a thread safe RAM buffer<sup class="footnote-reference"><a href="#21">10</a></sup>.
Again, a direct to task notification can be used to unblock the task
that will process the buffer after a complete message has been
received, or after a break in transmission has been detected.</p>
<div class="footnote-definition" id="21"><sup class="footnote-definition-label">10</sup>
<p>The 'Stream Buffer', provided as part of FreeRTOS+TCP
(<a href="http://www.FreeRTOS.org/tcp">https://www.FreeRTOS.org/tcp</a>), can
be used for this purpose.</p>
</div>
</li>
<li>
<p>Processing the received characters directly within the ISR, then
using a queue to send just the result of processing the data (rather
than the raw data) to a task. This was previously demonstrated by
Figure 5.4.</p>
</li>
</ul>
<h2 id="-18"><a class="header" href="#-18"><a name="example7.4" title="Example 7.4 Sending and receiving on a queue from within an interrupt"></a></a></h2>
<p><em><strong>Example 7.4</strong></em> <em>Sending and receiving on a queue from within an interrupt</em></p>
<hr />
<p>This example demonstrates <code>xQueueSendToBackFromISR()</code> and
<code>xQueueReceiveFromISR()</code> being used within the same interrupt. As before,
for convenience the interrupt is generated by software.</p>
<p>A periodic task is created that sends five numbers to a queue every 200
milliseconds. It generates a software interrupt only after all five
values have been sent. The task implementation is shown in Listing 7.21.</p>
<p><a name="list7.21" title="Listing 7.21 The implementation of the task that writes to the queue in Example 7.4"></a></p>
<pre><code class="language-c">static void vIntegerGenerator( void *pvParameters )
{
    TickType_t xLastExecutionTime;
    uint32_t ulValueToSend = 0;
    int i;

    /* Initialize the variable used by the call to vTaskDelayUntil(). */
    xLastExecutionTime = xTaskGetTickCount();

    for( ;; )
    {
        /* This is a periodic task. Block until it is time to run again. The
           task will execute every 200ms. */
        vTaskDelayUntil( &amp;xLastExecutionTime, pdMS_TO_TICKS( 200 ) );

        /* Send five numbers to the queue, each value one higher than the
           previous value. The numbers are read from the queue by the interrupt
           service routine. The interrupt service routine always empties the 
           queue, so this task is guaranteed to be able to write all five 
           values without needing to specify a block time. */
        for( i = 0; i &lt; 5; i++ )
        {
            xQueueSendToBack( xIntegerQueue, &amp;ulValueToSend, 0 );
            ulValueToSend++;
        }

        /* Generate the interrupt so the interrupt service routine can read the
           values from the queue. The syntax used to generate a software 
           interrupt is dependent on the FreeRTOS port being used. The syntax 
           used below can only be used with the FreeRTOS Windows port, in which
           such interrupts are only simulated. */
        vPrintString( "Generator task - About to generate an interrupt.\r\n" );
        vPortGenerateSimulatedInterrupt( mainINTERRUPT_NUMBER );
        vPrintString( "Generator task - Interrupt generated.\r\n\r\n\r\n" );
    }
}
</code></pre>
<p><em><strong>Listing 7.21</strong></em> <em>The implementation of the task that writes to the queue in Example 7.4</em></p>
<p>The interrupt service routine calls <code>xQueueReceiveFromISR()</code> repeatedly
until all the values written to the queue by the periodic task have been
read out, and the queue is left empty. The last two bits of each
received value are used as an index into an array of strings. A pointer
to the string at the corresponding index position is then sent to a
different queue using a call to <code>xQueueSendFromISR()</code>. The implementation
of the interrupt service routine is shown in Listing 7.22.</p>
<p><a name="list7.22" title="Listing 7.22 The implementation of the interrupt service routine used by Example 7.4"></a></p>
<pre><code class="language-c">static uint32_t ulExampleInterruptHandler( void )
{
    BaseType_t xHigherPriorityTaskWoken;
    uint32_t ulReceivedNumber;

    /* The strings are declared static const to ensure they are not allocated
       on the interrupt service routine's stack, and so exist even when the 
       interrupt service routine is not executing. */

    static const char *pcStrings[] =
    {
        "String 0\r\n",
        "String 1\r\n",
        "String 2\r\n",
        "String 3\r\n"
    };

    /* As always, xHigherPriorityTaskWoken is initialized to pdFALSE to be 
       able to detect it getting set to pdTRUE inside an interrupt safe API 
       function.  Note that as an interrupt safe API function can only set 
       xHigherPriorityTaskWoken to pdTRUE, it is safe to use the same 
       xHigherPriorityTaskWoken variable in both the call to 
       xQueueReceiveFromISR() and the call to xQueueSendToBackFromISR(). */
    xHigherPriorityTaskWoken = pdFALSE;

    /* Read from the queue until the queue is empty. */
    while( xQueueReceiveFromISR( xIntegerQueue,
                                 &amp;ulReceivedNumber,
                                 &amp;xHigherPriorityTaskWoken ) != errQUEUE_EMPTY )
    {
        /* Truncate the received value to the last two bits (values 0 to 3
           inclusive), then use the truncated value as an index into the
           pcStrings[] array to select a string (char *) to send on the other 
           queue. */
        ulReceivedNumber &amp;= 0x03;
        xQueueSendToBackFromISR( xStringQueue,
                                 &amp;pcStrings[ ulReceivedNumber ],
                                 &amp;xHigherPriorityTaskWoken );
    }

    /* If receiving from xIntegerQueue caused a task to leave the Blocked 
       state, and if the priority of the task that left the Blocked state is 
       higher than the priority of the task in the Running state, then 
       xHigherPriorityTaskWoken will have been set to pdTRUE inside 
       xQueueReceiveFromISR().

       If sending to xStringQueue caused a task to leave the Blocked state, and
       if the priority of the task that left the Blocked state is higher than 
       the priority of the task in the Running state, then 
       xHigherPriorityTaskWoken will have been set to pdTRUE inside 
       xQueueSendToBackFromISR().

       xHigherPriorityTaskWoken is used as the parameter to portYIELD_FROM_ISR().
       If xHigherPriorityTaskWoken equals pdTRUE then calling portYIELD_FROM_ISR()
       will request a context switch. If xHigherPriorityTaskWoken is still 
       pdFALSE then calling portYIELD_FROM_ISR() will have no effect.

       The implementation of portYIELD_FROM_ISR() used by the Windows port 
       includes a return statement, which is why this function does not 
       explicitly return a value. */
    portYIELD_FROM_ISR( xHigherPriorityTaskWoken );
}
</code></pre>
<p><em><strong>Listing 7.22</strong></em> <em>The implementation of the interrupt service routine used by Example 7.4</em></p>
<p>The task that receives the character pointers from the interrupt service
routine blocks on the queue until a message arrives, printing out each
string as it is received. Its implementation is shown in Listing 7.23.</p>
<p><a name="list7.23" title="Listing 7.23 The task that prints out the strings received from the interrupt service routine in Example 7.4"></a></p>
<pre><code class="language-c">static void vStringPrinter( void *pvParameters )
{
    char *pcString;

    for( ;; )
    {
        /* Block on the queue to wait for data to arrive. */
        xQueueReceive( xStringQueue, &amp;pcString, portMAX_DELAY );

        /* Print out the string received. */
        vPrintString( pcString );
    }
}
</code></pre>
<p><em><strong>Listing 7.23</strong></em> <em>The task that prints out the strings received from the interrupt service routine in Example 7.4</em></p>
<p>As normal, <code>main()</code> creates the required queues and tasks before starting
the scheduler. Its implementation is shown in Listing 7.24.</p>
<p><a name="list7.24" title="Listing 7.24 The main() function for Example 7.4"></a></p>
<pre><code class="language-c">int main( void )
{
    /* Before a queue can be used it must first be created. Create both queues
       used by this example. One queue can hold variables of type uint32_t, the
       other queue can hold variables of type char*. Both queues can hold a 
       maximum of 10 items. A real application should check the return values 
       to ensure the queues have been successfully created. */
    xIntegerQueue = xQueueCreate( 10, sizeof( uint32_t ) );
    xStringQueue = xQueueCreate( 10, sizeof( char * ) );

    /* Create the task that uses a queue to pass integers to the interrupt 
       service routine. The task is created at priority 1. */
    xTaskCreate( vIntegerGenerator, "IntGen", 1000, NULL, 1, NULL );

    /* Create the task that prints out the strings sent to it from the
       interrupt service routine. This task is created at the higher 
       priority of 2. */
    xTaskCreate( vStringPrinter, "String", 1000, NULL, 2, NULL );

    /* Install the handler for the software interrupt. The syntax necessary to
       do this is dependent on the FreeRTOS port being used. The syntax shown 
       here can only be used with the FreeRTOS Windows port, where such 
       interrupts are only simulated. */
    vPortSetInterruptHandler( mainINTERRUPT_NUMBER, ulExampleInterruptHandler );

    /* Start the scheduler so the created tasks start executing. */
    vTaskStartScheduler();

    /* If all is well then main() will never reach here as the scheduler will 
       now be running the tasks. If main() does reach here then it is likely 
       that there was insufficient heap memory available for the idle task 
       to be created. Chapter 2 provides more information on heap memory 
       management. */
    for( ;; );
}
</code></pre>
<p><em><strong>Listing 7.24</strong></em> <em>The main() function for Example 7.4</em></p>
<p>The output produced when Example 7.4 is executed is shown in Figure 7.12.
As can be seen, the interrupt receives all five integers, and produces
five strings in response. More explanation is given in Figure 7.13.</p>
<p><a name="fig7.12" title="Figure 7.12 The output produced when Example 7.4 is executed"></a>
<a name="fig7.13" title="Figure 7.13 The sequence of execution produced by Example 7.4"></a></p>
<hr />
<p><img src="media/image59.jpg" alt="" /><br />
<em><strong>Figure 7.12</strong></em> <em>The output produced when Example 7.4 is executed</em></p>
<p><img src="media/image60.png" alt="" /><br />
<em><strong>Figure 7.13</strong></em> <em>The sequence of execution produced by Example 7.4</em></p>
<hr />
<h2 id="78-interrupt-nesting"><a class="header" href="#78-interrupt-nesting">7.8 Interrupt Nesting</a></h2>
<p>It is common for confusion to arise between task priorities and
interrupt priorities. This section discusses interrupt priorities, which
are the priorities at which interrupt service routines (ISRs) execute
relative to each other. The priority assigned to a task is in no way
related to the priority assigned to an interrupt. Hardware decides when
an ISR will execute, whereas software decides when a task will execute.
An ISR executed in response to a hardware interrupt will interrupt a
task, but a task cannot pre-empt an ISR.</p>
<p>Ports that support interrupt nesting require one or both of the
constants detailed below to be defined in FreeRTOSConfig.h.
<code>configMAX_SYSCALL_INTERRUPT_PRIORITY</code> and
<code>configMAX_API_CALL_INTERRUPT_PRIORITY</code> both define the same property.
Older FreeRTOS ports use <code>configMAX_SYSCALL_INTERRUPT_PRIORITY</code>, and newer
FreeRTOS ports use <code>configMAX_API_CALL_INTERRUPT_PRIORITY</code>.</p>
<p><strong>Constants that control interrupt nesting</strong></p>
<ul>
<li>
<p><code>configMAX_SYSCALL_INTERRUPT_PRIORITY</code> or <code>configMAX_API_CALL_INTERRUPT_PRIORITY</code></p>
<p>Sets the highest interrupt priority from which interrupt-safe
FreeRTOS API functions can be called.</p>
</li>
<li>
<p><code>configKERNEL_INTERRUPT_PRIORITY</code></p>
<p>Sets the interrupt priority used by the tick interrupt, and must
always be set to the lowest possible interrupt priority.</p>
<p>If the FreeRTOS port in use does not also use the
<code>configMAX_SYSCALL_INTERRUPT_PRIORITY</code> constant, then any interrupt that
uses interrupt-safe FreeRTOS API functions must also execute at the
priority defined by <code>configKERNEL_INTERRUPT_PRIORITY</code>.</p>
</li>
</ul>
<p>Each interrupt source has a numeric priority, and a logical priority:</p>
<ul>
<li>
<p>Numeric priority</p>
<p>The numeric priority is simply the number assigned to the interrupt
priority. For example, if an interrupt is assigned a priority of 7,
then its numeric priority is 7. Likewise, if an interrupt is assigned
a priority of 200, then its numeric priority is 200.</p>
</li>
<li>
<p>Logical priority</p>
<p>An interrupt's logical priority describes that interrupt's precedence
over other interrupts.</p>
<p>If two interrupts of differing priority occur at the same time, then
the processor will execute the ISR for whichever of the two interrupts
has the higher logical priority before it executes the ISR for
whichever of the two interrupts has the lower logical priority.</p>
<p>An interrupt can interrupt (nest with) any interrupt that has a lower
logical priority, but an interrupt cannot interrupt (nest with) any
interrupt that has an equal or higher logical priority.</p>
</li>
</ul>
<p>The relationship between an interrupt's numeric priority and logical
priority is dependent on the processor architecture; on some processors,
the higher the numeric priority assigned to an interrupt the <em>higher</em>
that interrupt's logical priority will be, while on other processor
architectures the higher the numeric priority assigned to an interrupt
the <em>lower</em> that interrupt's logical priority will be.</p>
<p>A full interrupt nesting model is created by setting
<code>configMAX_SYSCALL_INTERRUPT_PRIORITY</code> to a higher logical interrupt
priority than <code>configKERNEL_INTERRUPT_PRIORITY</code>. This is demonstrated in
Figure 7.14, which shows a scenario where:</p>
<ul>
<li>The processor has seven unique interrupt priorities.</li>
<li>Interrupts assigned a numeric priority of 7 have a higher logical
priority than interrupts assigned a numeric priority of 1.</li>
<li><code>configKERNEL_INTERRUPT_PRIORITY</code> is set to one.</li>
<li><code>configMAX_SYSCALL_INTERRUPT_PRIORITY</code> is set to three.</li>
</ul>
<p><a name="fig7.14" title="Figure 7.14 Constants affecting interrupt nesting behavior"></a></p>
<hr />
<p><img src="media/image61.png" alt="" /><br />
<em><strong>Figure 7.14</strong></em> <em>Constants affecting interrupt nesting behavior</em></p>
<hr />
<p>Referring to Figure 7.14:</p>
<ul>
<li>
<p>Interrupts that use priorities 1 to 3, inclusive, are prevented from
executing while the kernel or the application is inside a critical
section. ISRs running at these priorities can use interrupt-safe
FreeRTOS API functions. Critical sections are described in Chapter 7.</p>
</li>
<li>
<p>Interrupts that use priority 4, or above, are not affected by
critical sections, so nothing the scheduler does will prevent these
interrupts from executing immediately—within the limitations of the
hardware itself. ISRs executing at these priorities cannot use any
FreeRTOS API functions.</p>
</li>
<li>
<p>Typically, functionality that requires very strict timing accuracy
(motor control, for example) would use a priority above
<code>configMAX_SYSCALL_INTERRUPT_PRIORITY</code> to ensure the scheduler does
not introduce jitter into the interrupt response time.</p>
</li>
</ul>
<h3 id="781-a-note-to-arm-cortex-m11-and-arm-gic-users"><a class="header" href="#781-a-note-to-arm-cortex-m11-and-arm-gic-users">7.8.1 A Note to ARM Cortex-M<sup class="footnote-reference"><a href="#22">11</a></sup> and ARM GIC Users</a></h3>
<div class="footnote-definition" id="22"><sup class="footnote-definition-label">11</sup>
<p>This section only partially applies to Cortex-M0 and Cortex-M0+ cores.</p>
</div>
<p>Interrupt configuration on Cortex-M processors is confusing, and prone
to error. To assist your development, the FreeRTOS Cortex-M ports
automatically check the interrupt configuration, but only if
<code>configASSERT()</code> is defined. <code>configASSERT()</code> is described in section 11.2.</p>
<p>The ARM Cortex cores, and ARM Generic Interrupt Controllers (GICs), use
numerically <em>low</em> priority numbers to represent logically <em>high</em>
priority interrupts. This can seem counter-intuitive, and is easy to
forget. If you wish to assign an interrupt a logically low priority,
then it must be assigned a numerically high value. If you wish to assign
an interrupt a logically high priority, then it must be assigned a
numerically low value.</p>
<p>The Cortex-M interrupt controller allows a maximum of eight bits to be
used to specify each interrupt priority, making 255 the lowest possible
priority. Zero is the highest priority. However, Cortex-M
microcontrollers normally only implement a subset of the eight possible
bits. The number of bits actually implemented is dependent on the
microcontroller family.</p>
<p>When only a subset of the eight possible bits has been implemented, it
is only the most significant bits of the byte that can be used—leaving
the least significant bits unimplemented. Unimplemented bits can take
any value, but it is normal to set them to 1. This is demonstrated by
Figure 7.15, which shows how a priority of binary 101 is stored in a
Cortex-M microcontroller that implements four priority bits.</p>
<p><a name="fig7.15" title="Figure 7.15 How a priority of binary 101 is stored by a Cortex-M microcontroller that implements four priority bits"></a></p>
<hr />
<p><img src="media/image62.png" alt="" /><br />
<em><strong>Figure 7.15</strong></em> <em>How a priority of binary 101 is stored by a Cortex-M microcontroller that implements four priority bits</em></p>
<hr />
<p>In Figure 7.15 the binary value 101 has been shifted into the most
significant four bits because the least significant four bits are not
implemented. The unimplemented bits have been set to 1.</p>
<p>Some library functions expect priority values to be specified after they
have been shifted up into the implemented (most significant) bits. When
using such a function, the priority shown in Figure 7.15 can be specified
as decimal 95. Decimal 95 is binary 101 shifted up by four to make
binary 101nnnn (where 'n' is an unimplemented bit), and with the
unimplemented bits set to 1 to make binary 1011111.</p>
<p>Some library functions expect priority values to be specified before
they have been shifted up into the implemented (most significant) bits.
When using such a function the priority shown in Figure 7.15 must be
specified as decimal 5. Decimal 5 is binary 101 without any shift.</p>
<p><code>configMAX_SYSCALL_INTERRUPT_PRIORITY</code> and <code>configKERNEL_INTERRUPT_PRIORITY</code>
must be specified in a way that allows them to be written directly to
the Cortex-M registers, so after the priority values have been shifted
up into the implemented bits.</p>
<p><code>configKERNEL_INTERRUPT_PRIORITY</code> must always be set to the lowest
possible interrupt priority. Unimplemented priority bits can be set to
1, so the constant can always be set to 255, no matter how many priority
bits are actually implemented.</p>
<p>Cortex-M interrupts will default to a priority of zero—the highest
possible priority. The implementation of the Cortex-M hardware does not
permit <code>configMAX_SYSCALL_INTERRUPT_PRIORITY</code> to be set to 0, so the
priority of an interrupt that uses the FreeRTOS API must never be left
at its default value.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="8-resource-management-1"><a class="header" href="#8-resource-management-1">8 Resource Management</a></h1>
<h2 id="81-chapter-introduction-and-scope"><a class="header" href="#81-chapter-introduction-and-scope">8.1 Chapter Introduction and Scope</a></h2>
<p>In a multitasking system there is potential for error if one task starts
to access a resource, but does not complete its access before being
transitioned out of the Running state. If the task leaves the resource
in an inconsistent state, then access to the same resource by any other
task or interrupt could result in data corruption, or other similar
issue.</p>
<p>Following are some examples:</p>
<ul>
<li>
<p>Accessing Peripherals</p>
<p>Consider the following scenario where two tasks attempt to write to an
Liquid Crystal Display (LCD).</p>
<ol>
<li>
<p>Task A executes and starts to write the string "Hello world" to the
LCD.</p>
</li>
<li>
<p>Task A is pre-empted by Task B after outputting just the beginning
of the string—"Hello w".</p>
</li>
<li>
<p>Task B writes "Abort, Retry, Fail?" to the LCD before entering the
Blocked state.</p>
</li>
<li>
<p>Task A continues from the point at which it was pre-empted, and
completes outputting the remaining characters of its string—"orld".</p>
</li>
</ol>
<p>The LCD now displays the corrupted string "Hello wAbort, Retry, Fail?orld".</p>
</li>
<li>
<p>Read, Modify, Write Operations</p>
<p>Listing 8.1 shows a line of C code, and an example of how the C code
would typically be translated into assembly code. It can be seen that
the value of PORTA is first read from memory into a register, modified
within the register, and then written back to memory. This is called a
read, modify, write operation.</p>
<p><a name="list8.1" title="Listing 8.1 An example read, modify, write sequence"></a></p>
<pre><code class="language-c">/* The C code being compiled. */
PORTA |= 0x01;

/* The assembly code produced when the C code is compiled. */
LOAD  R1,[#PORTA] ; Read a value from PORTA into R1
MOVE  R2,#0x01    ; Move the absolute constant 1 into R2
OR    R1,R2       ; Bitwise OR R1 (PORTA) with R2 (constant 1)
STORE R1,[#PORTA] ; Store the new value back to PORTA
</code></pre>
<p><em><strong>Listing 8.1</strong></em> <em>An example read, modify, write sequence</em></p>
<p>This is a 'non-atomic' operation because it takes more than one
instruction to complete, and can be interrupted. Consider the following
scenario where two tasks attempt to update a memory mapped register
called PORTA.</p>
<ol>
<li>
<p>Task A loads the value of PORTA into a register—the read portion of
the operation.</p>
</li>
<li>
<p>Task A is pre-empted by Task B before it completes the modify and
write portions of the same operation.</p>
</li>
<li>
<p>Task B updates the value of PORTA, then enters the Blocked state.</p>
</li>
<li>
<p>Task A continues from the point at which it was pre-empted. It
modifies the copy of the PORTA value that it already holds in a
register, before writing the updated value back to PORTA.</p>
</li>
</ol>
<p>In this scenario, Task A updates and writes back an out of date value
for PORTA. Task B modifies PORTA after Task A takes a copy of the PORTA
value, and before Task A writes its modified value back to the PORTA
register. When Task A writes to PORTA, it overwrites the modification
that has already been performed by Task B, effectively corrupting the
PORTA register value.</p>
<p>This example uses a peripheral register, but the same principle applies
when performing read, modify, write operations on variables.</p>
</li>
</ul>
<ul>
<li>
<p>Non-atomic Access to Variables</p>
<p>Updating multiple members of a structure, or updating a variable that is
larger than the natural word size of the architecture (for example,
updating a 32-bit variable on a 16-bit machine), are examples of
non-atomic operations. If they are interrupted, they can result in data
loss or corruption.</p>
</li>
<li>
<p>Function Reentrancy</p>
<p>A function is 'reentrant' if it is safe to call the function from more
than one task, or from both tasks and interrupts. Reentrant functions
are said to be 'thread safe' because they can be accessed from more than
one thread of execution without the risk of data or logical operations
becoming corrupted.</p>
<p>Each task maintains its own stack and its own set of processor
(hardware) register values. If a function does not access any data other
than data stored on the stack or held in a register, then the function
is reentrant, and thread safe. Listing 8.2 is an example of a reentrant
function. Listing 8.3 is an example of a function that is not reentrant.</p>
<p>If an application uses the newlib C Library, it must set <code>configUSE_NEWLIB_REENTRANT</code> to 1
in FreeRTOSConfig.h to ensure that the Thread Local Storage required by newlib is
allocated correctly.</p>
<p>If an application uses the picolibc C Library, it must set <code>configUSE_PICOLIBC_TLS</code> to 1 in
FreeRTOSConfig.h to ensure that the Thread Local Storage required by picolibc is
allocated correctly.</p>
<p>If an application uses any other C library and it requires Thread Local Storage (TLS), it
must set <code>configUSE_C_RUNTIME_TLS_SUPPORT</code> to 1 in FreeRTOSConfig.h and must implement
the following macros-</p>
<ul>
<li><code>configTLS_BLOCK_TYPE</code> - Type of the per task TLS block.</li>
<li><code>configINIT_TLS_BLOCK</code> - Initialize per task TLS block.</li>
<li><code>configSET_TLS_BLOCK</code> - Update current TLS block. Called during context switch to ensure
that the correct TLS block is used.</li>
<li><code>configDEINIT_TLS_BLOCK</code> - Free the TLS block.</li>
</ul>
<p><a name="list8.2" title="Listing 8.2 An example of a reentrant function"></a></p>
<pre><code class="language-c">/* A parameter is passed into the function. This will either be passed on the 
   stack, or in a processor register. Either way is safe as each task or 
   interrupt that calls the function maintains its own stack and its own set 
   of register values, so each task or interrupt that calls the function will 
   have its own copy of lVar1. */
long lAddOneHundred( long lVar1 )
{
    /* This function scope variable will also be allocated to the stack or a 
       register, depending on the compiler and optimization level. Each task
       or interrupt that calls this function will have its own copy of lVar2. */
    long lVar2;

    lVar2 = lVar1 + 100;
    return lVar2;
}
</code></pre>
<p><em><strong>Listing 8.2</strong></em> <em>An example of a reentrant function</em></p>
<p><a name="list8.3" title="Listing 8.3 An example of a function that is not reentrant"></a></p>
<pre><code class="language-c">/* In this case lVar1 is a global variable, so every task that calls
   lNonsenseFunction will access the same single copy of the variable. */
long lVar1;

long lNonsenseFunction( void )
{
    /* lState is static, so is not allocated on the stack. Each task that
       calls this function will access the same single copy of the variable. */
    static long lState = 0;
    long lReturn;

    switch( lState )
    {
        case 0 : lReturn = lVar1 + 10;
                 lState = 1;
                 break;

        case 1 : lReturn = lVar1 + 20;
                 lState = 0;
                 break;
    }
}
</code></pre>
<p><em><strong>Listing 8.3</strong></em> <em>An example of a function that is not reentrant</em></p>
</li>
</ul>
<h3 id="811-mutual-exclusion"><a class="header" href="#811-mutual-exclusion">8.1.1 Mutual Exclusion</a></h3>
<p>To ensure data consistency is maintained at all times, access to a
resource that is shared between tasks, or is shared between tasks and interrupts,
must be managed using a 'mutual exclusion' technique. The goal is to
ensure that, once a task starts to access a shared resource that is not
re-entrant and not thread-safe, the same task has exclusive access to
the resource until the resource has been returned to a consistent state.</p>
<p>FreeRTOS provides several features that can be used to implement mutual
exclusion, but the best mutual exclusion method is to (whenever
possible, as it is often not practical) design the application in such a
way that resources are not shared, and each resource is accessed only
from a single task.</p>
<h3 id="812-scope"><a class="header" href="#812-scope">8.1.2 Scope</a></h3>
<p>This chapter covers:</p>
<ul>
<li>When and why resource management and control is necessary.</li>
<li>What a critical section is.</li>
<li>What mutual exclusion means.</li>
<li>What it means to suspend the scheduler.</li>
<li>How to use a mutex.</li>
<li>How to create and use a gatekeeper task.</li>
<li>What priority inversion is, and how priority inheritance can reduce
(but not remove) its impact.</li>
</ul>
<h2 id="82-critical-sections-and-suspending-the-scheduler"><a class="header" href="#82-critical-sections-and-suspending-the-scheduler">8.2 Critical Sections and Suspending the Scheduler</a></h2>
<h3 id="821-basic-critical-sections"><a class="header" href="#821-basic-critical-sections">8.2.1 Basic Critical Sections</a></h3>
<p>Basic critical sections are regions of code that are surrounded by calls
to the macros <code>taskENTER_CRITICAL()</code> and <code>taskEXIT_CRITICAL()</code>,
respectively. Critical sections are also known as critical regions.</p>
<p><code>taskENTER_CRITICAL()</code> and <code>taskEXIT_CRITICAL()</code> do not take any parameters,
or return a value<sup class="footnote-reference"><a href="#23">1</a></sup>. Their use is demonstrated in Listing 8.4.</p>
<div class="footnote-definition" id="23"><sup class="footnote-definition-label">1</sup>
<p>A function-like macro does not really 'return a value' in the
same way that a real function does. This book applies the term
'return a value' to macros when it is simplest to think of the macro
as if it were a function.</p>
</div>
<p><a name="list8.4" title="Listing 8.4 Using a critical section to guard access to a register"></a></p>
<pre><code class="language-c">/* Ensure access to the PORTA register cannot be interrupted by placing
   it within a critical section. Enter the critical section. */
taskENTER_CRITICAL();

/* A switch to another task cannot occur between the call to
   taskENTER_CRITICAL() and the call to taskEXIT_CRITICAL(). Interrupts may
   still execute on FreeRTOS ports that allow interrupt nesting, but only
   interrupts whose logical priority is above the value assigned to the
   configMAX_SYSCALL_INTERRUPT_PRIORITY constant – and those interrupts are
   not permitted to call FreeRTOS API functions. */
PORTA |= 0x01;

/* Access to PORTA has finished, so it is safe to exit the critical section. */
taskEXIT_CRITICAL();
</code></pre>
<p><em><strong>Listing 8.4</strong></em> <em>Using a critical section to guard access to a register</em></p>
<p>The example projects that accompany this book use a function called
<code>vPrintString()</code> to write strings to standard out, which is the terminal
window when the FreeRTOS Windows port is used. <code>vPrintString()</code> is called
from many different tasks; so, in theory, its implementation could
protect access to standard out using a critical section, as shown in
Listing 8.5.</p>
<p><a name="list8.5" title="Listing 8.5 A possible implementation of vPrintString()"></a></p>
<pre><code class="language-c">void vPrintString( const char *pcString )
{
    /* Write the string to stdout, using a critical section as a crude method of
       mutual exclusion. */
    taskENTER_CRITICAL();
    {
        printf( "%s", pcString );
        fflush( stdout );
    }
    taskEXIT_CRITICAL();
}
</code></pre>
<p><em><strong>Listing 8.5</strong></em> <em>A possible implementation of vPrintString()</em></p>
<p>Critical sections implemented in this way are a very crude method of
providing mutual exclusion. They work by disabling interrupts, either
completely, or up to the interrupt priority set by
<code>configMAX_SYSCALL_INTERRUPT_PRIORITY</code>, depending on the FreeRTOS port
being used. Pre-emptive context switches can occur only from within an
interrupt, so, as long as interrupts remain disabled, the task that
called <code>taskENTER_CRITICAL()</code> is guaranteed to remain in the Running state
until the critical section is exited.</p>
<p>Basic critical sections must be kept very short, otherwise they will
adversely affect interrupt response times. Every call to
<code>taskENTER_CRITICAL()</code> must be closely paired with a call to
<code>taskEXIT_CRITICAL()</code>. For this reason, standard out (stdout, or the
stream where a computer writes its output data) should not be protected
using a critical section (as shown in Listing 8.5), because writing to
the terminal can be a relatively long operation. The examples in this
chapter explore alternative solutions.</p>
<p>It is safe for critical sections to become nested, because the kernel
keeps a count of the nesting depth. The critical section will be exited
only when the nesting depth returns to zero, which is when one call to
<code>taskEXIT_CRITICAL()</code> has been executed for every preceding call to
<code>taskENTER_CRITICAL()</code>.</p>
<p>Calling <code>taskENTER_CRITICAL()</code> and <code>taskEXIT_CRITICAL()</code> is the only
legitimate way for a task to alter the interrupt enable state of the
processor on which FreeRTOS is running. Altering the interrupt enable
state by any other means will invalidate the macro's nesting count.</p>
<p><code>taskENTER_CRITICAL()</code> and <code>taskEXIT_CRITICAL()</code> do not end in 'FromISR', so
must not be called from an interrupt service routine.
<code>taskENTER_CRITICAL_FROM_ISR()</code> is an interrupt safe version of
<code>taskENTER_CRITICAL()</code>, and <code>taskEXIT_CRITICAL_FROM_ISR()</code> is an interrupt
safe version of <code>taskEXIT_CRITICAL()</code>. The interrupt safe versions are
only provided for FreeRTOS ports that allow interrupts to nest—they
would be obsolete in ports that do not allow interrupts to nest.</p>
<p><code>taskENTER_CRITICAL_FROM_ISR()</code> returns a value that must be passed into
the matching call to <code>taskEXIT_CRITICAL_FROM_ISR()</code>. This is demonstrated
in Listing 8.6.</p>
<p><a name="list8.6" title="Listing 8.6 Using a critical section in an interrupt service routine"></a></p>
<pre><code class="language-c">void vAnInterruptServiceRoutine( void )
{
    /* Declare a variable in which the return value from 
       taskENTER_CRITICAL_FROM_ISR() will be saved. */
    UBaseType_t uxSavedInterruptStatus;

    /* This part of the ISR can be interrupted by any higher priority 
       interrupt. */

    /* Use taskENTER_CRITICAL_FROM_ISR() to protect a region of this ISR.
       Save the value returned from taskENTER_CRITICAL_FROM_ISR() so it can 
       be passed into the matching call to taskEXIT_CRITICAL_FROM_ISR(). */
    uxSavedInterruptStatus = taskENTER_CRITICAL_FROM_ISR();

    /* This part of the ISR is between the call to 
       taskENTER_CRITICAL_FROM_ISR() and taskEXIT_CRITICAL_FROM_ISR(), so can 
       only be interrupted by interrupts that have a priority above that set 
       by the configMAX_SYSCALL_INTERRUPT_PRIORITY constant. */

    /* Exit the critical section again by calling taskEXIT_CRITICAL_FROM_ISR(),
       passing in the value returned by the matching call to 
       taskENTER_CRITICAL_FROM_ISR(). */
    taskEXIT_CRITICAL_FROM_ISR( uxSavedInterruptStatus );

    /* This part of the ISR can be interrupted by any higher priority 
       interrupt. */
}
</code></pre>
<p><em><strong>Listing 8.6</strong></em> <em>Using a critical section in an interrupt service routine</em></p>
<p>It is wasteful to use more processing time executing the code that
enters, and then subsequently exits, a critical section, than executing
the code actually being protected by the critical section. Basic
critical sections are very fast to enter, very fast to exit, and always
deterministic, making their use ideal when the region of code being
protected is very short.</p>
<h3 id="822-suspending-or-locking-the-scheduler"><a class="header" href="#822-suspending-or-locking-the-scheduler">8.2.2 Suspending (or Locking) the Scheduler</a></h3>
<p>Critical sections can also be created by suspending the scheduler.
Suspending the scheduler is sometimes also known as 'locking' the
scheduler.</p>
<p>Basic critical sections protect a region of code from access by other
tasks and by interrupts, but a critical section implemented by suspending
the scheduler only protects a region of code from access by other tasks,
because interrupts remain enabled.</p>
<p>A critical section that is too long to be implemented by simply
disabling interrupts can, instead, be implemented by suspending the
scheduler. However, interrupt activity while the scheduler is suspended
can make resuming (or 'un-suspending') the scheduler a relatively long
operation, so consideration must be given to which is the best method to
use in each case.</p>
<h3 id="823-the-vtasksuspendall-api-function"><a class="header" href="#823-the-vtasksuspendall-api-function">8.2.3 The vTaskSuspendAll() API Function</a></h3>
<p><a name="list8.7" title="Listing 8.7 The vTaskSuspendAll() API function prototype"></a></p>
<pre><code class="language-c">void vTaskSuspendAll( void );
</code></pre>
<p><em><strong>Listing 8.7</strong></em> <em>The vTaskSuspendAll() API function prototype</em></p>
<p>The scheduler is suspended by calling <code>vTaskSuspendAll()</code>. Suspending the
scheduler prevents a context switch from occurring, but leaves
interrupts enabled. If an interrupt requests a context switch while the
scheduler is suspended, then the request is held pending, and is
performed only when the scheduler is resumed (un-suspended).</p>
<p>FreeRTOS API functions must not be called while the scheduler is suspended.</p>
<h3 id="824-the-xtaskresumeall-api-function"><a class="header" href="#824-the-xtaskresumeall-api-function">8.2.4 The xTaskResumeAll() API Function</a></h3>
<p><a name="list8.8" title="Listing 8.8 The xTaskResumeAll() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xTaskResumeAll( void );
</code></pre>
<p><em><strong>Listing 8.8</strong></em> <em>The xTaskResumeAll() API function prototype</em></p>
<p>The scheduler is resumed (un-suspended) by calling <code>xTaskResumeAll()</code>.</p>
<p><strong>xTaskResumeAll() return value</strong></p>
<ul>
<li>
<p>Return value</p>
<p>Context switches that are requested while the scheduler is suspended are held pending and performed
only as the scheduler is being resumed. If a pending context switch is performed before <code>xTaskResumeAll()</code>
returns, then <code>pdTRUE</code> is returned. Otherwise <code>pdFALSE</code> is returned.</p>
</li>
</ul>
<p>It is safe for calls to <code>vTaskSuspendAll()</code> and <code>xTaskResumeAll()</code> to become
nested, because the kernel keeps a count of the nesting depth. The
scheduler will be resumed only when the nesting depth returns to
zero—which is when one call to <code>xTaskResumeAll()</code> has been executed for
every preceding call to <code>vTaskSuspendAll()</code>.</p>
<p>Listing 8.9 shows the actual implementation of <code>vPrintString()</code>, which
suspends the scheduler to protect access to the terminal output.</p>
<p><a name="list8.9" title="Listing 8.9 The implementation of vPrintString()"></a></p>
<pre><code class="language-c">void vPrintString( const char *pcString )
{
    /* Write the string to stdout, suspending the scheduler as a method of 
       mutual exclusion. */
    vTaskSuspendScheduler();
    {
        printf( "%s", pcString );
        fflush( stdout );
    }
    xTaskResumeScheduler();
}
</code></pre>
<p><em><strong>Listing 8.9</strong></em> <em>The implementation of vPrintString()</em></p>
<h2 id="83-mutexes-and-binary-semaphores"><a class="header" href="#83-mutexes-and-binary-semaphores">8.3 Mutexes (and Binary Semaphores)</a></h2>
<p>A Mutex is a special type of binary semaphore that is used to control
access to a resource that is shared between two or more tasks. The word
MUTEX originates from 'MUTual EXclusion'. <code>configUSE_MUTEXES</code> must be set
to 1 in FreeRTOSConfig.h for mutexes to be available.</p>
<p>When used in a mutual exclusion scenario, the mutex can be thought of as
a token that is associated with the resource being shared. For a task to
access the resource legitimately, it must first successfully 'take' the
token (be the token holder). When the token holder has finished with the
resource, it must 'give' the token back. Only when the token has been
returned can another task successfully take the token, and then safely
access the same shared resource. A task is not permitted to access the
shared resource unless it holds the token. This mechanism is shown in
Figure 8.1.</p>
<p>Even though mutexes and binary semaphores share many characteristics,
the scenario shown in Figure 8.1 (where a mutex is used for mutual
exclusion) is completely different to that shown in Figure 7.6 (where a
binary semaphore is used for synchronization). The primary difference is
what happens to the semaphore after it has been obtained:</p>
<ul>
<li>A semaphore that is used for mutual exclusion must always be
returned.</li>
<li>A semaphore that is used for synchronization is normally discarded
and not returned.</li>
</ul>
<p><a name="fig8.1" title="Figure 8.1 Mutual exclusion implemented using a mutex"></a></p>
<hr />
<p><img src="media/image63.png" alt="" /><br />
<em><strong>Figure 8.1</strong></em> <em>Mutual exclusion implemented using a mutex</em></p>
<hr />
<p>The mechanism works purely through the discipline of the application
writer. There is no reason why a task cannot access the resource at any
time, but each task 'agrees' not to do so, unless it is able to become
the mutex holder.</p>
<h3 id="831-the-xsemaphorecreatemutex-api-function"><a class="header" href="#831-the-xsemaphorecreatemutex-api-function">8.3.1 The xSemaphoreCreateMutex() API Function</a></h3>
<p>FreeRTOS also includes the <code>xSemaphoreCreateMutexStatic()</code>
function, which allocates the memory required to create a mutex
statically at compile time: A mutex is a type of semaphore. Handles to
all the various types of FreeRTOS semaphore are stored in a variable of
type <code>SemaphoreHandle_t</code>.</p>
<p>Before a mutex can be used, it must be created. To create a mutex type
semaphore, use the <code>xSemaphoreCreateMutex()</code> API function.</p>
<p><a name="list8.10" title="Listing 8.10 The xSemaphoreCreateMutex() API function prototype"></a></p>
<pre><code class="language-c">SemaphoreHandle_t xSemaphoreCreateMutex( void );
</code></pre>
<p><em><strong>Listing 8.10</strong></em> <em>The xSemaphoreCreateMutex() API function prototype</em></p>
<p><strong>xSemaphoreCreateMutex() return value</strong></p>
<ul>
<li>
<p>Return value</p>
<p>If NULL is returned, then the mutex could not be created because
there is insufficient heap memory available for FreeRTOS to allocate the
mutex data structures. Chapter 3 provides more information on heap
memory management.</p>
<p>A non-NULL return value indicates that the mutex has been created
successfully. The returned value should be stored as the handle to the
created mutex.</p>
</li>
</ul>
<h2 id="-19"><a class="header" href="#-19"><a name="example8.1" title="Example 8.1 Rewriting vPrintString() to use a semaphore"></a></a></h2>
<p><em><strong>Example 8.1</strong></em> <em>Rewriting vPrintString() to use a semaphore</em></p>
<hr />
<p>This example creates a new version of <code>vPrintString()</code> called
<code>prvNewPrintString()</code>, then calls the new function from multiple tasks.
<code>prvNewPrintString()</code> is functionally identical to <code>vPrintString()</code>, but
controls access to standard out using a mutex, rather than by locking
the scheduler. The implementation of <code>prvNewPrintString()</code> is shown in
Listing 8.11.</p>
<p><a name="list8.11" title="Listing 8.11 The implementation of prvNewPrintString()"></a></p>
<pre><code class="language-c">static void prvNewPrintString( const char *pcString )
{
    /* The mutex is created before the scheduler is started, so already exists
       by the time this task executes.

       Attempt to take the mutex, blocking indefinitely to wait for the mutex
       if it is not available straight away. The call to xSemaphoreTake() will
       only return when the mutex has been successfully obtained, so there is 
       no need to check the function return value. If any other delay period 
       was used then the code must check that xSemaphoreTake() returns pdTRUE 
       before accessing the shared resource (which in this case is standard 
       out). As noted earlier in this book, indefinite time outs are not 
       recommended for production code. */
    xSemaphoreTake( xMutex, portMAX_DELAY );
    {
        /* The following line will only execute once the mutex has been 
           successfully obtained. Standard out can be accessed freely now as 
           only one task can have the mutex at any one time. */
        printf( "%s", pcString );
        fflush( stdout );

        /* The mutex MUST be given back! */
    }
    xSemaphoreGive( xMutex );
}
</code></pre>
<p><em><strong>Listing 8.11</strong></em> <em>The implementation of prvNewPrintString()</em></p>
<p><code>prvNewPrintString()</code> is called repeatedly by two instances of a task
implemented by <code>prvPrintTask()</code>. A random delay time is used between each
call. The task parameter is used to pass a unique string into each
instance of the task. The implementation of <code>prvPrintTask()</code> is shown in
Listing 8.12.</p>
<p><a name="list8.12" title="Listing 8.12 The implementation of prvPrintTask() for Example 8.1"></a></p>
<pre><code class="language-c">static void prvPrintTask( void *pvParameters )
{
    char *pcStringToPrint;
    const TickType_t xMaxBlockTimeTicks = 0x20;

    /* Two instances of this task are created. The string printed by the task 
       is passed into the task using the task's parameter. The parameter is 
       cast to the required type. */
    pcStringToPrint = ( char * ) pvParameters;

    for( ;; )
    {
        /* Print out the string using the newly defined function. */
        prvNewPrintString( pcStringToPrint );

        /* Wait a pseudo random time. Note that rand() is not necessarily
           reentrant, but in this case it does not really matter as the code 
           does not care what value is returned. In a more secure application 
           a version of rand() that is known to be reentrant should be used - 
           or calls to rand() should be protected using a critical section. */
        vTaskDelay( ( rand() % xMaxBlockTimeTicks ) );
    }
}
</code></pre>
<p><em><strong>Listing 8.12</strong></em> <em>The implementation of prvPrintTask() for Example 8.1</em></p>
<p>As normal, <code>main()</code> simply creates the mutex, creates the tasks, then
starts the scheduler. The implementation is shown in Listing 8.13.</p>
<p>The two instances of <code>prvPrintTask()</code> are created at different priorities,
so the lower priority task will sometimes be pre-empted by the higher
priority task. As a mutex is used to ensure each task gets mutually
exclusive access to the terminal, even when pre-emption occurs, the
strings that are displayed will be correct and in no way corrupted. The
frequency of pre-emption can be increased by reducing the maximum time
the tasks spend in the Blocked state, which is set by the
<code>xMaxBlockTimeTicks</code> constant.</p>
<p>Notes specific to using Example 8.1 with the FreeRTOS Windows port:</p>
<ul>
<li>
<p>Calling <code>printf()</code> generates a Windows system call. Windows system
calls are outside the control of FreeRTOS, and can introduce
instability.</p>
</li>
<li>
<p>The way in which Windows system calls execute mean it is rare to see
a corrupted string, even when the mutex is not used.</p>
</li>
</ul>
<p><a name="list8.13" title="Listing 8.13 The implementation of main() for Example 8.1"></a></p>
<pre><code class="language-c">int main( void )
{
    /* Before a semaphore is used it must be explicitly created. In this
       example a mutex type semaphore is created. */
    xMutex = xSemaphoreCreateMutex();

    /* Check the semaphore was created successfully before creating the
       tasks. */
    if( xMutex != NULL )
    {
        /* Create two instances of the tasks that write to stdout. The string
           they write is passed in to the task as the task's parameter. The 
           tasks are created at different priorities so some pre-emption will 
           occur. */
        xTaskCreate( prvPrintTask, "Print1", 1000,
                     "Task 1 ***************************************\r\n",
                     1, NULL );

        xTaskCreate( prvPrintTask, "Print2", 1000,
                     "Task 2 ---------------------------------------\r\n", 
                     2, NULL );

        /* Start the scheduler so the created tasks start executing. */
        vTaskStartScheduler();
    }

    /* If all is well then main() will never reach here as the scheduler will
       now be running the tasks. If main() does reach here then it is likely 
       that there was insufficient heap memory available for the idle task to 
       be created.  Chapter 3 provides more information on heap memory 
       management. */
    for( ;; );
}
</code></pre>
<p><em><strong>Listing 8.13</strong></em> <em>The implementation of main() for Example 8.1</em></p>
<p>The output produced when Example 8.1 is executed is shown in Figure 8.2. A
possible execution sequence is described in Figure 8.3.</p>
<p><a name="fig8.2" title="Figure 8.2 The output produced when Example 8.1 is executed"></a></p>
<hr />
<p><img src="media/image64.jpg" alt="" /><br />
<em><strong>Figure 8.2</strong></em> <em>The output produced when Example 8.1 is executed</em></p>
<hr />
<p>Figure 8.2 shows that, as expected, there is no corruption in the strings
that are displayed on the terminal. The random ordering is a result of
the random delay periods used by the tasks.</p>
<p><a name="fig8.3" title="Figure 8.3 A possible sequence of execution for Example 8.1"></a></p>
<hr />
<p><img src="media/image65.png" alt="" /><br />
<em><strong>Figure 8.3</strong></em> <em>A possible sequence of execution for Example 8.1</em></p>
<hr />
<h3 id="832-priority-inversion"><a class="header" href="#832-priority-inversion">8.3.2 Priority Inversion</a></h3>
<p>Figure 8.3 demonstrates one of the potential pitfalls of using a mutex to
provide mutual exclusion. The sequence of execution depicted shows the
higher priority Task 2 having to wait for the lower priority Task 1 to
give up control of the mutex. A higher priority task being delayed by a
lower priority task in this manner is called 'priority inversion'. This
undesirable behavior would be exaggerated further if a medium priority
task started to execute while the high priority task was waiting for the
semaphore—the result would be a high priority task waiting for a low
priority task—without the low priority task even being able to execute.
This is most often referred to as <em>unbounded priority inversion</em> because
the medium priority task could block the low and high priority tasks
indefinitely.
This worst case scenario is shown in Figure 8.4.</p>
<p><a name="fig8.4" title="Figure 8.4 A worst case priority inversion scenario"></a></p>
<hr />
<p><img src="media/image66.png" alt="" /><br />
<em><strong>Figure 8.4</strong></em> <em>A worst case priority inversion scenario</em></p>
<hr />
<p>Priority inversion can be a significant problem, but in small embedded
systems it can often be avoided at system design time by considering
how resources are accessed.</p>
<h3 id="833-priority-inheritance"><a class="header" href="#833-priority-inheritance">8.3.3 Priority Inheritance</a></h3>
<p>FreeRTOS mutexes and binary semaphores are very similar—the difference
being that mutexes include a basic 'priority inheritance' mechanism,
whereas binary semaphores do not. Priority inheritance is a scheme that
minimizes the negative effects of priority inversion. It does not 'fix'
priority inversion, but merely lessens its impact by ensuring that the
inversion is always time bounded. However, priority inheritance
complicates system timing analysis, and it is not good practice to rely
on it for correct system operation.</p>
<p>Priority inheritance works by temporarily raising the priority of the
mutex holder to the priority of the highest priority task that is
attempting to obtain the same mutex. The low priority task that holds
the mutex 'inherits' the priority of the task waiting for the mutex.
This is demonstrated by Figure 8.5. The priority of the mutex holder is
reset automatically to its original value when it gives the mutex back.</p>
<p><a name="fig8.5" title="Figure 8.5 Priority inheritance minimizing the effect of priority inversion"></a></p>
<hr />
<p><img src="media/image67.png" alt="" /><br />
<em><strong>Figure 8.5</strong></em> <em>Priority inheritance minimizing the effect of priority inversion</em></p>
<hr />
<p>As just seen, priority inheritance functionality effects the priority of
tasks that are using the mutex. For that reason, mutexes must not be
used from interrupt service routines.</p>
<p>FreeRTOS implements a basic priority inheritance mechanism which was
designed with optimizing both space and execution cycles in mind. A full
priority inheritance mechanism requires significantly more data and
processor cycles to determine inherited priority at any moment,
especially when a task holds more than one mutex at a time.</p>
<p>Specific behaviors of the priority inheritance mechanism to keep in mind:</p>
<ul>
<li>A task can have its inherited priority raised further if it
takes a mutex without first releasing mutexes it already holds.</li>
<li>A task remains at its highest inherited priority until
it has released all the mutexes it holds. This is regardless of
the order the mutexes are released.</li>
<li>A task will remain at the highest inherited priority if multiple
mutexes are held regardless of tasks waiting on any of the held
mutexes completing their wait (timing out).</li>
</ul>
<h3 id="834-deadlock-or-deadly-embrace"><a class="header" href="#834-deadlock-or-deadly-embrace">8.3.4 Deadlock (or Deadly Embrace)</a></h3>
<p>'Deadlock' is another potential pitfall of using mutexes for mutual
exclusion. Deadlock is sometimes also known by the more dramatic name
'deadly embrace'.</p>
<p>Deadlock occurs when two tasks cannot proceed because they are both
waiting for a resource that is held by the other. Consider the following
scenario where Task A and Task B both need to acquire mutex X <em>and</em>
mutex Y in order to perform an action:</p>
<ol>
<li>
<p>Task A executes and successfully takes mutex X.</p>
</li>
<li>
<p>Task A is pre-empted by Task B.</p>
</li>
<li>
<p>Task B successfully takes mutex Y before attempting to also take
mutex X—but mutex X is held by Task A so is not available to Task B.
Task B opts to enter the Blocked state to wait for mutex X to be
released.</p>
</li>
<li>
<p>Task A continues executing. It attempts to take mutex Y—but mutex Y
is held by Task B, so is not available to Task A. Task A opts to
enter the Blocked state to wait for mutex Y to be released.</p>
</li>
</ol>
<p>At the end of this scenario, Task A is waiting for a mutex held by Task
B, and Task B is waiting for a mutex held by Task A. Deadlock has
occurred because neither task can proceed.</p>
<p>As with priority inversion, the best method of avoiding deadlock is to
consider its potential at design time, and design the system to ensure
that deadlock cannot occur. In particular, and as previously stated in
this book, it is normally bad practice for a task to wait indefinitely
(without a time out) to obtain a mutex. Instead, use a time out that is
a little longer than the maximum time it is expected to have to wait for
the mutex—then failure to obtain the mutex within that time will be a
symptom of a design error, which might be a deadlock.</p>
<p>In practice, deadlock is not a big problem in small embedded systems,
because the system designers can have a good understanding of the entire
application, and so can identify and remove the areas where it could
occur.</p>
<h3 id="835-recursive-mutexes"><a class="header" href="#835-recursive-mutexes">8.3.5 Recursive Mutexes</a></h3>
<p>It is also possible for a task to deadlock with itself. This will happen
if a task attempts to take the same mutex more than once, without first
returning the mutex. Consider the following scenario:</p>
<ol>
<li>
<p>A task successfully obtains a mutex.</p>
</li>
<li>
<p>While holding the mutex, the task calls a library function.</p>
</li>
<li>
<p>The implementation of the library function attempts to take the same
mutex, and enters the Blocked state to wait for the mutex to become
available.</p>
</li>
</ol>
<p>At the end of this scenario the task is in the Blocked state to wait for
the mutex to be returned, but the task is already the mutex holder. A
deadlock has occurred because the task is in the Blocked state to wait
for itself.</p>
<p>This type of deadlock can be avoided by using a recursive mutex in place
of a standard mutex. A recursive mutex can be 'taken' more than once by
the same task, and will be returned only after one call to 'give' the
recursive mutex has been executed for every preceding call to 'take' the
recursive mutex.</p>
<p>Standard mutexes and recursive mutexes are created and used in a similar
way:</p>
<ul>
<li>
<p>Standard mutexes are created using <code>xSemaphoreCreateMutex()</code>.
Recursive mutexes are created using
<code>xSemaphoreCreateRecursiveMutex()</code>. The two API functions have the
same prototype.</p>
</li>
<li>
<p>Standard mutexes are 'taken' using <code>xSemaphoreTake()</code>. Recursive
mutexes are 'taken' using <code>xSemaphoreTakeRecursive()</code>. The two API
functions have the same prototype.</p>
</li>
<li>
<p>Standard mutexes are 'given' using <code>xSemaphoreGive()</code>. Recursive
mutexes are 'given' using <code>xSemaphoreGiveRecursive()</code>. The two API
functions have the same prototype.</p>
</li>
</ul>
<p>Listing 8.14 demonstrates how to create and use a recursive mutex.</p>
<p><a name="list8.14" title="Listing 8.14 Creating and using a recursive mutex"></a></p>
<pre><code class="language-c">/* Recursive mutexes are variables of type SemaphoreHandle_t. */
SemaphoreHandle_t xRecursiveMutex;

/* The implementation of a task that creates and uses a recursive mutex. */
void vTaskFunction( void *pvParameters )
{
    const TickType_t xMaxBlock20ms = pdMS_TO_TICKS( 20 );

    /* Before a recursive mutex is used it must be explicitly created. */
    xRecursiveMutex = xSemaphoreCreateRecursiveMutex();

    /* Check the semaphore was created successfully. configASSERT() is 
       described in section 11.2. */
    configASSERT( xRecursiveMutex );

    /* As per most tasks, this task is implemented as an infinite loop. */
    for( ;; )
    {
        /* ... */

        /* Take the recursive mutex. */
        if( xSemaphoreTakeRecursive( xRecursiveMutex, xMaxBlock20ms ) == pdPASS )
        {
            /* The recursive mutex was successfully obtained. The task can now
               access the resource the mutex is protecting. At this point the 
               recursive call count (which is the number of nested calls to 
               xSemaphoreTakeRecursive()) is 1, as the recursive mutex has 
               only been taken once. */

            /* While it already holds the recursive mutex, the task takes the 
               mutex again. In a real application, this is only likely to occur
               inside a sub-function called by this task, as there is no 
               practical reason to knowingly take the same mutex more than 
               once. The calling task is already the mutex holder, so the 
               second call to xSemaphoreTakeRecursive() does nothing more than
               increment the recursive call count to 2. */
            xSemaphoreTakeRecursive( xRecursiveMutex, xMaxBlock20ms );

            /* ... */

            /* The task returns the mutex after it has finished accessing the
               resource the mutex is protecting. At this point the recursive 
               call count is 2, so the first call to xSemaphoreGiveRecursive()
               does not return the mutex. Instead, it simply decrements the 
               recursive call count back to 1. */
            xSemaphoreGiveRecursive( xRecursiveMutex );

            /* The next call to xSemaphoreGiveRecursive() decrements the 
               recursive call count to 0, so this time the recursive mutex is 
               returned. */
            xSemaphoreGiveRecursive( xRecursiveMutex );

            /* Now one call to xSemaphoreGiveRecursive() has been executed for
               every proceeding call to xSemaphoreTakeRecursive(), so the task
               is no longer the mutex holder. */
        }
    }
}
</code></pre>
<p><em><strong>Listing 8.14</strong></em> <em>Creating and using a recursive mutex</em></p>
<h3 id="836-mutexes-and-task-scheduling"><a class="header" href="#836-mutexes-and-task-scheduling">8.3.6 Mutexes and Task Scheduling</a></h3>
<p>If two tasks of different priority use the same mutex, then the FreeRTOS
scheduling policy makes the order in which the tasks will execute clear;
the highest priority task that is able to run will be selected as the
task that enters the Running state. For example, if a high priority task
is in the Blocked state to wait for a mutex that is held by a low
priority task, then the high priority task will pre-empt the low
priority task as soon as the low priority task returns the mutex. The
high priority task will then become the mutex holder. This scenario has
already been seen in Figure 8.5.</p>
<p>It is, however, common to make an incorrect assumption as to the order in
which the tasks will execute when the tasks have the same priority. If
Task 1 and Task 2 have the same priority, and Task 1 is in the Blocked
state to wait for a mutex that is held by Task 2, then Task 1 will not
pre-empt Task 2 when Task 2 'gives' the mutex. Instead, Task 2 will
remain in the Running state, and Task 1 will simply move from the
Blocked state to the Ready state. This scenario is shown in Figure 8.6,
in which the vertical lines mark the times at which a tick interrupt
occurs.</p>
<p><a name="fig8.6" title="Figure 8.6 A possible sequence of execution when tasks that have the same priority use the same mutex"></a></p>
<hr />
<p><img src="media/image68.png" alt="" /><br />
<em><strong>Figure 8.6</strong></em> <em>A possible sequence of execution when tasks that have the same priority use the same mutex</em></p>
<hr />
<p>In the scenario shown in Figure 8.6, the FreeRTOS scheduler does <em>not</em>
make Task 1 the Running state task as soon as the mutex is available
because:</p>
<ul>
<li>
<p>Task 1 and Task 2 have the same priority, so unless Task 2 enters
the Blocked state, a switch to Task 1 should not occur until the
next tick interrupt (assuming <code>configUSE_TIME_SLICING</code> is set to 1 in
FreeRTOSConfig.h).</p>
</li>
<li>
<p>If a task uses a mutex in a tight loop, and a context switch
occurred each time the task 'gave' the mutex, then the task would
only ever remain in the Running state for a short time. If two or
more tasks used the same mutex in a tight loop, then processing time
would be wasted by rapidly switching between the tasks.</p>
</li>
</ul>
<p>If a mutex is used in a tight loop by more than one task, and the tasks
that use the mutex have the same priority, then care must be taken to
ensure the tasks receive an approximately equal amount of processing
time. The reason the tasks might not receive an equal amount of
processing time is demonstrated by Figure 8.7, which shows a sequence of
execution that could occur if two instances of the task shown by Listing
8.15 are created at the same priority.</p>
<p><a name="list8.15" title="Listing 8.15 A task that uses a mutex in a tight loop"></a></p>
<pre><code class="language-c">/* The implementation of a task that uses a mutex in a tight loop. The task 
   creates a text string in a local buffer, then writes the string to a display.
   Access to the display is protected by a mutex. */

void vATask( void *pvParameter )
{
    extern SemaphoreHandle_t xMutex;
    char cTextBuffer[ 128 ];

    for( ;; )
    {
        /* Generate the text string – this is a fast operation. */
        vGenerateTextInALocalBuffer( cTextBuffer );

        /* Obtain the mutex that is protecting access to the display. */
        xSemaphoreTake( xMutex, portMAX_DELAY );

        /* Write the generated text to the display–this is a slow operation. */
        vCopyTextToFrameBuffer( cTextBuffer );

        /* The text has been written to the display, so return the mutex. */
        xSemaphoreGive( xMutex );
    }
}
</code></pre>
<p><em><strong>Listing 8.15</strong></em> <em>A task that uses a mutex in a tight loop</em></p>
<p>The comments in Listing 8.15 note that creating the string is a fast
operation, and updating the display is a slow operation. Therefore, as
the mutex is held while the display is being updated, the task will hold
the mutex for the majority of its run time.</p>
<p>In Figure 8.7, the vertical lines mark the times at which a tick
interrupt occurs.</p>
<p><a name="fig8.7" title="Figure 8.7 A sequence of execution that could occur if two instances of the task shown by Listing 8.15 are created at the same priority"></a></p>
<hr />
<p><img src="media/image69.png" alt="" /><br />
<em><strong>Figure 8.7</strong></em> <em>A sequence of execution that could occur if two instances of the task shown by Listing 8.15 are created at the same priority</em></p>
<hr />
<p>Step 7 in Figure 8.7 shows Task 1 re-entering the Blocked state—that
happens inside the <code>xSemaphoreTake()</code> API function.</p>
<p>Figure 8.7 demonstrates that Task 1 will be prevented from obtaining the
mutex until the start of a time slice coincides with one of the short
periods during which Task 2 is not the mutex holder.</p>
<p>The scenario shown in Figure 8.7 can be avoided by adding a call to
<code>taskYIELD()</code> after the call to <code>xSemaphoreGive()</code>. This is demonstrated in
Listing 8.16, where <code>taskYIELD()</code> is called if the tick count changed while
the task held the mutex.</p>
<p><a name="list8.16" title="Listing 8.16 Ensuring tasks that use a mutex in a loop receive a more equal amount of processing time..."></a></p>
<pre><code class="language-c">void vFunction( void *pvParameter )
{
    extern SemaphoreHandle_t xMutex;
    char cTextBuffer[ 128 ];
    TickType_t xTimeAtWhichMutexWasTaken;

    for( ;; )
    {
        /* Generate the text string – this is a fast operation. */
        vGenerateTextInALocalBuffer( cTextBuffer );

        /* Obtain the mutex that is protecting access to the display. */
        xSemaphoreTake( xMutex, portMAX_DELAY );

        /* Record the time at which the mutex was taken. */
        xTimeAtWhichMutexWasTaken = xTaskGetTickCount();

        /* Write the generated text to the display–this is a slow operation. */
        vCopyTextToFrameBuffer( cTextBuffer );

        /* The text has been written to the display, so return the mutex. */
        xSemaphoreGive( xMutex );

        /* If taskYIELD() was called on each iteration then this task would
           only ever remain in the Running state for a short period of time, 
           and processing time would be wasted by rapidly switching between 
           tasks. Therefore, only call taskYIELD() if the tick count changed 
           while the mutex was held. */
        if( xTaskGetTickCount() != xTimeAtWhichMutexWasTaken )
        {
            taskYIELD();
        }
    }
}
</code></pre>
<p><em><strong>Listing 8.16</strong></em> <em>Ensuring tasks that use a mutex in a loop receive a more equal amount of processing time, while also ensuring processing time is not wasted by switching between tasks too rapidly</em></p>
<h2 id="84-gatekeeper-tasks"><a class="header" href="#84-gatekeeper-tasks">8.4 Gatekeeper Tasks</a></h2>
<p>Gatekeeper tasks provide a clean method of implementing mutual exclusion
without the risk of priority inversion or deadlock.</p>
<p>A gatekeeper task is a task that has sole ownership of a resource. Only
the gatekeeper task is allowed to access the resource directly—any other
task needing to access the resource can do so only indirectly by using
the services of the gatekeeper.</p>
<h3 id="841-re-writing-vprintstring-to-use-a-gatekeeper-task"><a class="header" href="#841-re-writing-vprintstring-to-use-a-gatekeeper-task">8.4.1 Re-writing vPrintString() to use a gatekeeper task</a></h3>
<p>Example 8.2 provides another alternative implementation for
<code>vPrintString()</code>. This time, a gatekeeper task is used to manage access to
standard out. When a task wants to write a message to standard out, it
does not call a print function directly but, instead, sends the message
to the gatekeeper.</p>
<p>The gatekeeper task uses a FreeRTOS queue to serialize access to
standard out. The internal implementation of the task does not have to
consider mutual exclusion because it is the only task permitted to
access standard out directly.</p>
<p>The gatekeeper task spends most of its time in the Blocked state,
waiting for messages to arrive on the queue. When a message arrives, the
gatekeeper simply writes the message to standard out, before returning
to the Blocked state to wait for the next message. The implementation of
the gatekeeper task is shown by Listing 8.18.</p>
<p>Interrupts can send to queues, so interrupt service routines can also
safely use the services of the gatekeeper to write messages to the
terminal. In this example, a tick hook function is used to write out a
message every 200 ticks.</p>
<p>A tick hook (or tick callback) is a function that is called by the
kernel during each tick interrupt. To use a tick hook function:</p>
<ol>
<li>
<p>Set <code>configUSE_TICK_HOOK</code> to 1 in FreeRTOSConfig.h.</p>
</li>
<li>
<p>Provide the implementation of the hook function, using the exact
function name and prototype shown in Listing 8.17.</p>
</li>
</ol>
<p><a name="list8.17" title="Listing 8.17 The name and prototype for a tick hook function"></a></p>
<pre><code class="language-c">void vApplicationTickHook( void );
</code></pre>
<p><em><strong>Listing 8.17</strong></em> <em>The name and prototype for a tick hook function</em></p>
<p>Tick hook functions execute within the context of the tick interrupt,
and so must be kept very short, must use only a moderate amount of stack
space, and must not call any FreeRTOS API functions that do not end with
'FromISR()'.</p>
<p>The scheduler will always execute immediately after the tick hook
function, so interrupt safe FreeRTOS API functions called from the tick
hook do not need to use their <code>pxHigherPriorityTaskWoken</code> parameter, and
that parameter can be set to NULL.</p>
<p><a name="list8.18" title="Listing 8.18 The gatekeeper task"></a></p>
<pre><code class="language-c">static void prvStdioGatekeeperTask( void *pvParameters )
{
    char *pcMessageToPrint;

    /* This is the only task that is allowed to write to standard out. Any
       other task wanting to write a string to the output does not access 
       standard out directly, but instead sends the string to this task. As 
       only this task accesses standard out there are no mutual exclusion or 
       serialization issues to consider within the implementation of the task 
       itself. */
    for( ;; )
    {
        /* Wait for a message to arrive. An indefinite block time is specified
           so there is no need to check the return value – the function will 
           only return when a message has been successfully received. */
        xQueueReceive( xPrintQueue, &amp;pcMessageToPrint, portMAX_DELAY );

        /* Output the received string. */
        printf( "%s", pcMessageToPrint );
        fflush( stdout );

        /* Loop back to wait for the next message. */
    }
}
</code></pre>
<p><em><strong>Listing 8.18</strong></em> <em>The gatekeeper task</em></p>
<h2 id="-20"><a class="header" href="#-20"><a name="example8.2" title="Example 8.2 The alternative implementation for print task"></a></a></h2>
<p><em><strong>Example 8.2</strong></em> <em>The alternative implementation for print task</em></p>
<hr />
<p>The task that writes to the queue is shown in Listing 8.19. As before,
two separate instances of the task are created, and the string the task
writes to the queue is passed into the task using the task parameter.</p>
<p><a name="list8.19" title="The print task implementation for Example 8.2"></a></p>
<pre><code class="language-c">static void prvPrintTask( void *pvParameters )
{
    int iIndexToString;
    const TickType_t xMaxBlockTimeTicks = 0x20;

    /* Two instances of this task are created. The task parameter is used to 
       pass an index into an array of strings into the task. Cast this to the
       required type. */
    iIndexToString = ( int ) pvParameters;

    for( ;; )
    {
        /* Print out the string, not directly, but instead by passing a pointer
           to the string to the gatekeeper task via a queue. The queue is 
           created before the scheduler is started so will already exist by the
           time this task executes for the first time. A block time is not 
           specified because there should always be space in the queue. */
        xQueueSendToBack( xPrintQueue, &amp;( pcStringsToPrint[ iIndexToString ]), 0 );

        /* Wait a pseudo random time. Note that rand() is not necessarily
           reentrant, but in this case it does not really matter as the code 
           does not care what value is returned. In a more secure application 
           a version of rand() that is known to be reentrant should be used - 
           or calls to rand() should be protected using a critical section. */
        vTaskDelay( ( rand() % xMaxBlockTimeTicks ) );
    }
}
</code></pre>
<p><em><strong>Listing 8.19</strong></em> <em>The print task implementation for Example 8.2</em></p>
<p>The tick hook function counts the number of times it is called, sending
its message to the gatekeeper task each time the count reaches 200. For
demonstration purposes only, the tick hook writes to the front of the
queue, and the tasks write to the back of the queue. The tick hook
implementation is shown in Listing 8.20.</p>
<p><a name="list8.20" title="Listing 8.20 The tick hook implementation"></a></p>
<pre><code class="language-c">void vApplicationTickHook( void )
{
    static int iCount = 0;

    /* Print out a message every 200 ticks. The message is not written out
       directly, but sent to the gatekeeper task. */
    iCount++;

    if( iCount &gt;= 200 )
    {
        /* As xQueueSendToFrontFromISR() is being called from the tick hook, it
           is not necessary to use the xHigherPriorityTaskWoken parameter (the 
           third parameter), and the parameter is set to NULL. */
        xQueueSendToFrontFromISR( xPrintQueue, 
                                  &amp;( pcStringsToPrint[ 2 ] ), 
                                  NULL );

        /* Reset the count ready to print out the string again in 200 ticks
           time. */
        iCount = 0;
    }
}
</code></pre>
<p><em><strong>Listing 8.20</strong></em> <em>The tick hook implementation</em></p>
<p>As normal, <code>main()</code> creates the queues and tasks necessary to run the
example, then starts the scheduler. The implementation of <code>main()</code> is
shown in Listing 8.21.</p>
<pre><code class="language-c">/* Define the strings that the tasks and interrupt will print out via the
   gatekeeper. */
static char *pcStringsToPrint[] =
{
    "Task 1 ****************************************************\r\n",
    "Task 2 ----------------------------------------------------\r\n",
    "Message printed from the tick hook interrupt ##############\r\n"
};

/*-----------------------------------------------------------*/

/* Declare a variable of type QueueHandle_t. The queue is used to send messages
   from the print tasks and the tick interrupt to the gatekeeper task. */
QueueHandle_t xPrintQueue;

/*-----------------------------------------------------------*/

int main( void )
{
    /* Before a queue is used it must be explicitly created. The queue is 
       created to hold a maximum of 5 character pointers. */
    xPrintQueue = xQueueCreate( 5, sizeof( char * ) );

    /* Check the queue was created successfully. */
    if( xPrintQueue != NULL )
    {
        /* Create two instances of the tasks that send messages to the 
           gatekeeper. The index to the string the task uses is passed to the 
           task via the task parameter (the 4th parameter to xTaskCreate()). 
           The tasks are created at different priorities so the higher priority
           task will occasionally preempt the lower priority task. */
        xTaskCreate( prvPrintTask, "Print1", 1000, ( void * ) 0, 1, NULL );
        xTaskCreate( prvPrintTask, "Print2", 1000, ( void * ) 1, 2, NULL );

        /* Create the gatekeeper task. This is the only task that is permitted
           to directly access standard out. */
        xTaskCreate( prvStdioGatekeeperTask, "Gatekeeper", 1000, NULL, 0, NULL );

        /* Start the scheduler so the created tasks start executing. */
        vTaskStartScheduler();
    }

    /* If all is well then main() will never reach here as the scheduler will 
       now be running the tasks. If main() does reach here then it is likely 
       that there was insufficient heap memory available for the idle task to 
       be created. Chapter 3 provides more information on heap memory 
       management. */
    for( ;; );
}
</code></pre>
<p><a name="list8.21" title="Listing 8.21 The implementation of main() for Example 8.2"></a></p>
<p><em><strong>Listing 8.21</strong></em> <em>The implementation of main() for Example 8.2</em></p>
<p>The output produced when Example 8.2 is executed is shown in Figure 8.8.
As can be seen, the strings originating from the tasks, and the strings
originating from the interrupt, all print out correctly with no
corruption.</p>
<p><a name="fig8.8" title="Figure 8.8 The output produced when Example 8.2 is executed"></a></p>
<hr />
<p><img src="media/image70.jpg" alt="" /><br />
<em><strong>Figure 8.8</strong></em> <em>The output produced when Example 8.2 is executed</em></p>
<hr />
<p>The gatekeeper task is assigned a lower priority than the print tasks—so
messages sent to the gatekeeper remain in the queue until both print
tasks are in the Blocked state. In some situations, it would be
appropriate to assign the gatekeeper a higher priority, so messages get
processed immediately—but doing so would be at the cost of the
gatekeeper delaying lower priority tasks until it has completed
accessing the protected resource.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="9-event-groups-1"><a class="header" href="#9-event-groups-1">9 Event Groups</a></h1>
<h2 id="91-chapter-introduction-and-scope"><a class="header" href="#91-chapter-introduction-and-scope">9.1 Chapter Introduction and Scope</a></h2>
<p>It has already been noted that real-time embedded systems have to take
actions in response to events. Previous chapters have described features
of FreeRTOS that allow events to be communicated to tasks. Examples of
such features include semaphores and queues, both of which have the
following properties:</p>
<ul>
<li>
<p>They allow a task to wait in the Blocked state for a single event to
occur.</p>
</li>
<li>
<p>They unblock a single task when the event occurs. The task that is
unblocked is the highest priority task that was waiting for the
event.</p>
</li>
</ul>
<p>Event groups are another feature of FreeRTOS that allow events to be
communicated to tasks. Unlike queues and semaphores:</p>
<ul>
<li>
<p>Event groups allow a task to wait in the Blocked state for a
combination of one of more events to occur.</p>
</li>
<li>
<p>Event groups unblock all the tasks that were waiting for the same
event, or combination of events, when the event occurs.</p>
</li>
</ul>
<p>These unique properties of event groups make them useful for
synchronizing multiple tasks, broadcasting events to more than one task,
allowing a task to wait in the Blocked state for any one of a set of
events to occur, and allowing a task to wait in the Blocked state for
multiple actions to complete.</p>
<p>Event groups also provide the opportunity to reduce the RAM used by an
application as, often, it is possible to replace many binary semaphores
with a single event group.</p>
<p>Event group functionality is optional. To include event group
functionality, build the FreeRTOS source file event_groups.c as part of
your project.</p>
<h3 id="911-scope"><a class="header" href="#911-scope">9.1.1 Scope</a></h3>
<p>This chapter aims to give readers a good understanding of:</p>
<ul>
<li>Practical uses for event groups.</li>
<li>The advantages and disadvantages of event groups relative to other
FreeRTOS features.</li>
<li>How to set bits in an event group.</li>
<li>How to wait in the Blocked state for bits to become set in an event
group.</li>
<li>How to use an event group to synchronize a set of tasks.</li>
</ul>
<h2 id="92-characteristics-of-an-event-group"><a class="header" href="#92-characteristics-of-an-event-group">9.2 Characteristics of an Event Group</a></h2>
<h3 id="921-event-groups-event-flags-and-event-bits"><a class="header" href="#921-event-groups-event-flags-and-event-bits">9.2.1 Event Groups, Event Flags and Event Bits</a></h3>
<p>An event 'flag' is a Boolean (1 or 0) value used to indicate if an event
has occurred or not. An event 'group' is a set of event flags.</p>
<p>An event flag can only be 1 or 0, allowing the state of an event flag to
be stored in a single bit, and the state of all the event flags in an
event group to be stored in a single variable; the state of each event
flag in an event group is represented by a single bit in a variable of
type <code>EventBits_t</code>. For that reason, event flags are also known as event
'bits'. If a bit is set to 1 in the <code>EventBits_t</code> variable, then the event
represented by that bit has occurred. If a bit is set to 0 in the
<code>EventBits_t</code> variable, then the event represented by that bit has not
occurred.</p>
<p>Figure 9.1 shows how individual event flags are mapped to individual bits
in a variable of type <code>EventBits_t</code>.</p>
<p><a name="fig9.1" title="Figure 9.1 Event flag to bit number mapping in a variable of type EventBits\_t"></a></p>
<hr />
<p><img src="media/image71.png" alt="" /><br />
<em><strong>Figure 9.1</strong></em> <em>Event flag to bit number mapping in a variable of type EventBits_t</em></p>
<hr />
<p>As an example, if the value of an event group is 0x92 (binary 1001 0010)
then only event bits 1, 4 and 7 are set, so only the events represented
by bits 1, 4 and 7 have occurred. Figure 9.2 shows a variable of type
<code>EventBits_t</code> that has event bits 1, 4 and 7 set, and all the other event
bits clear, giving the event group a value of 0x92.</p>
<p><a name="fig9.2" title="Figure 9.2 An event group in which only bits 1, 4 and 7 are set, and all the other event flags are clear, making the event group's value 0x92"></a></p>
<hr />
<p><img src="media/image72.png" alt="" /><br />
<em><strong>Figure 9.2</strong></em> <em>An event group in which only bits 1, 4 and 7 are set, and all the other event flags are clear, making the event group's value 0x92</em></p>
<hr />
<p>It is up to the application writer to assign a meaning to individual
bits within an event group. For example, the application writer might
create an event group, then:</p>
<ul>
<li>
<p>Define bit 0 within the event group to mean "a message has been
received from the network".</p>
</li>
<li>
<p>Define bit 1 within the event group to mean "a message is ready to
be sent onto the network".</p>
</li>
<li>
<p>Define bit 2 within the event group to mean "abort the current
network connection".</p>
</li>
</ul>
<h3 id="922-more-about-the-eventbits_t-data-type"><a class="header" href="#922-more-about-the-eventbits_t-data-type">9.2.2 More About the EventBits_t Data Type</a></h3>
<p>The number of event bits in an event group is dependent on the
<code>configTICK_TYPE_WIDTH_IN_BITS</code> compile time configuration constant in
FreeRTOSConfig.h<sup class="footnote-reference"><a href="#24">1</a></sup>:</p>
<div class="footnote-definition" id="24"><sup class="footnote-definition-label">1</sup>
<p><code>configTICK_TYPE_WIDTH_IN_BITS</code> configures the type used to hold the RTOS
tick count, so would seem unrelated to the event groups feature. Its
effect on the <code>EventBits_t</code> type is a consequence of FreeRTOS's
internal implementation, and desirable as it is to set <code>configTICK_TYPE_WIDTH_IN_BITS</code>
to <code>TICK_TYPE_WIDTH_16_BITS</code>, this should be done only when FreeRTOS is executing on an
architecture that can handle 16-bit types more efficiently than
32-bit types.</p>
</div>
<ul>
<li>
<p>If <code>configTICK_TYPE_WIDTH_IN_BITS</code> is <code>TICK_TYPE_WIDTH_16_BITS</code>, then each
event group contains 8 usable event bits.</p>
</li>
<li>
<p>If <code>configTICK_TYPE_WIDTH_IN_BITS</code> is <code>TICK_TYPE_WIDTH_32_BITS</code>, then each event group contains 24
usable event bits.</p>
</li>
<li>
<p>If <code>configTICK_TYPE_WIDTH_IN_BITS</code> is <code>TICK_TYPE_WIDTH_64_BITS</code>, then each
event group contains 56 usable event bits.</p>
</li>
</ul>
<h3 id="923-access-by-multiple-tasks"><a class="header" href="#923-access-by-multiple-tasks">9.2.3 Access by Multiple Tasks</a></h3>
<p>Event groups are objects in their own right that can be accessed by any
task or ISR that knows of their existence. Any number of tasks can set
bits in the same event group, and any number of tasks can read bits from
the same event group.</p>
<h3 id="924-a-practical-example-of-using-an-event-group"><a class="header" href="#924-a-practical-example-of-using-an-event-group">9.2.4 A Practical Example of Using an Event Group</a></h3>
<p>The implementation of the FreeRTOS+TCP TCP/IP stack provides a practical
example of how an event group can be used to simultaneously simplify a
design, and minimize resource usage.</p>
<p>A TCP socket must respond to many different events. Examples of events
include accept events, bind events, read events and close events. The
events a socket can expect at any given time are dependent on the state
of the socket. For example, if a socket has been created, but not yet
bound to an address, then it can expect to receive a bind event, but
would not expect to receive a read event (it cannot read data if it does
not have an address).</p>
<p>The state of a FreeRTOS+TCP socket is held in a structure called
<code>FreeRTOS_Socket_t</code>. The structure contains an event group that has an
event bit defined for each event the socket must process. FreeRTOS+TCP
API calls that block to wait for an event, or group of events, simply
block on the event group.</p>
<p>The event group also contains an 'abort' bit, allowing a TCP connection
to be aborted, no matter which event the socket is waiting for at the
time.</p>
<h2 id="93-event-management-using-event-groups"><a class="header" href="#93-event-management-using-event-groups">9.3 Event Management Using Event Groups</a></h2>
<h3 id="931-the-xeventgroupcreate-api-function"><a class="header" href="#931-the-xeventgroupcreate-api-function">9.3.1 The xEventGroupCreate() API Function</a></h3>
<p>FreeRTOS also includes the <code>xEventGroupCreateStatic()</code> function,
which allocates the memory required to create an event group statically
at compile time: An event group must be explicitly created before it can
be used.</p>
<p>Event groups are referenced using variables of type <code>EventGroupHandle_t</code>.
The <code>xEventGroupCreate()</code> API function is used to create an event group,
and returns an <code>EventGroupHandle_t</code> to reference the event group it
creates.</p>
<p><a name="list9.1" title="Listing 9.1 The xEventGroupCreate() API function prototype"></a></p>
<pre><code class="language-c">EventGroupHandle_t xEventGroupCreate( void );
</code></pre>
<p><em><strong>Listing 9.1</strong></em> <em>The xEventGroupCreate() API function prototype</em></p>
<p><strong>xEventGroupCreate() return value</strong></p>
<ul>
<li>
<p>Return Value</p>
<p>If NULL is returned, then the event group cannot be created
because there is insufficient heap memory available for FreeRTOS to
allocate the event group data structures. Chapter 3 provides more
information on heap memory management.</p>
<p>A non-NULL value being returned indicates that the event group has
been created successfully. The returned value should be stored as the
handle to the created event group.</p>
</li>
</ul>
<h3 id="932-the-xeventgroupsetbits-api-function"><a class="header" href="#932-the-xeventgroupsetbits-api-function">9.3.2 The xEventGroupSetBits() API Function</a></h3>
<p>The <code>xEventGroupSetBits()</code> API function sets one or more bits in an event
group, and is typically used to notify a task that the events
represented by the bit, or bits, being set has occurred.</p>
<blockquote>
<p><em>Note: Never call <code>xEventGroupSetBits()</code> from an interrupt service
routine. The interrupt-safe version <code>xEventGroupSetBitsFromISR()</code> should
be used in its place.</em></p>
</blockquote>
<p><a name="list9.2" title="Listing 9.2. The xEventGroupSetBits() API function prototype"></a></p>
<pre><code class="language-c">EventBits_t xEventGroupSetBits( EventGroupHandle_t xEventGroup,

const EventBits_t uxBitsToSet );
</code></pre>
<p><em><strong>Listing 9.2</strong></em> <em>The xEventGroupSetBits() API function prototype</em></p>
<p><strong>xEventGroupSetBits() parameters and return value</strong></p>
<ul>
<li>
<p><code>xEventGroup</code></p>
<p>The handle of the event group in which bits are being set. The event
group handle will have been returned from the call to
<code>xEventGroupCreate()</code> used to create the event group.</p>
</li>
<li>
<p><code>uxBitsToSet</code></p>
<p>A bit mask that specifies the event bit, or event bits, to set to
1 in the event group. The value of the event group is updated by bitwise
ORing the event group's existing value with the value passed in
<code>uxBitsToSet</code>.</p>
<p>As an example, setting <code>uxBitsToSet</code> to 0x04 (binary 0100) will result
in event bit 3 in the event group becoming set (if it was not already
set), while leaving all the other event bits in the event group
unchanged.</p>
</li>
<li>
<p>Return Value</p>
<p>The value of the event group at the time the call to
<code>xEventGroupSetBits()</code> returned. Note that the value returned will not
necessarily have the bits specified by <code>uxBitsToSet</code> set, because the bits
may have been cleared again by a different task.</p>
</li>
</ul>
<h3 id="933-the-xeventgroupsetbitsfromisr-api-function"><a class="header" href="#933-the-xeventgroupsetbitsfromisr-api-function">9.3.3 The xEventGroupSetBitsFromISR() API Function</a></h3>
<p><code>xEventGroupSetBitsFromISR()</code> is the interrupt safe version of
<code>xEventGroupSetBits()</code>.</p>
<p>Giving a semaphore is a deterministic operation because it is known in
advance that giving a semaphore can result in at most one task leaving
the Blocked state. When bits are set in an event group it is not known
in advance how many tasks will leave the Blocked state, so setting bits
in an event group is not a deterministic operation.</p>
<p>The FreeRTOS design and implementation standard does not permit
non-deterministic operations to be performed inside an interrupt service
routine, or when interrupts are disabled. For that reason,
<code>xEventGroupSetBitsFromISR()</code> does not set event bits directly inside the
interrupt service routine, but instead defers the action to the RTOS
daemon task.</p>
<p><a name="list9.3" title="Listing 9.3 The xEventGroupSetBitsFromISR() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xEventGroupSetBitsFromISR( EventGroupHandle_t xEventGroup,
                                      const EventBits_t uxBitsToSet,
                                      BaseType_t *pxHigherPriorityTaskWoken );
</code></pre>
<p><em><strong>Listing 9.3</strong></em> <em>The xEventGroupSetBitsFromISR() API function prototype</em></p>
<p><strong>xEventGroupSetBitsFromISR() parameters and return value</strong></p>
<ul>
<li>
<p><code>xEventGroup</code></p>
<p>The handle of the event group in which bits are being set. The event
group handle will have been returned from the call to
<code>xEventGroupCreate()</code> used to create the event group.</p>
</li>
<li>
<p><code>uxBitsToSet</code></p>
<p>A bit mask that specifies the event bit, or event bits, to set to
1 in the event group. The value of the event group is updated by bitwise
ORing the event group's existing value with the value passed in
<code>uxBitsToSet</code>.</p>
<p>As an example, setting <code>uxBitsToSet</code> to 0x05 (binary 0101) will result
in event bit 2 and event bit 0 in the event group becoming set (if they
were not already set), while leaving all the other event bits in the
event group unchanged.</p>
</li>
<li>
<p><code>pxHigherPriorityTaskWoken</code></p>
<p><code>xEventGroupSetBitsFromISR()</code> does not set the event bits directly
inside the interrupt service routine, but instead defers the action to
the RTOS daemon task by sending a command on the timer command queue. If
the daemon task was in the Blocked state to wait for data to become
available on the timer command queue, then writing to the timer command
queue will cause the daemon task to leave the Blocked state. If the
priority of the daemon task is higher than the priority of the currently
executing task (the task that was interrupted), then, internally,
<code>xEventGroupSetBitsFromISR()</code> will set <code>*pxHigherPriorityTaskWoken</code> to
<code>pdTRUE</code>.</p>
<p>If <code>xEventGroupSetBitsFromISR()</code> sets this value to <code>pdTRUE</code>, then a
context switch should be performed before the interrupt is exited. This
will ensure that the interrupt returns directly to the daemon task, as
the daemon task will be the highest priority Ready state task.</p>
</li>
<li>
<p>Return Value</p>
<p>There are two possible return values:</p>
<ul>
<li>
<p><code>pdPASS</code> will be returned only if data was successfully sent to the
timer command queue.</p>
</li>
<li>
<p><code>pdFALSE</code> will be returned if the 'set bits' command could not be
written to the timer command queue because the queue was already
full.</p>
</li>
</ul>
</li>
</ul>
<h3 id="934-the-xeventgroupwaitbits-api-function"><a class="header" href="#934-the-xeventgroupwaitbits-api-function">9.3.4 The xEventGroupWaitBits() API Function</a></h3>
<p>The <code>xEventGroupWaitBits()</code> API function allows a task to read the value
of an event group, and optionally wait in the Blocked state for one or
more event bits in the event group to become set, if the event bits are
not already set.</p>
<p><a name="list9.4" title="Listing 9.4 The xEventGroupWaitBits() API function prototype"></a></p>
<pre><code class="language-c">EventBits_t xEventGroupWaitBits( EventGroupHandle_t xEventGroup,
                                 const EventBits_t uxBitsToWaitFor,
                                 const BaseType_t xClearOnExit,
                                 const BaseType_t xWaitForAllBits,
                                 TickType_t xTicksToWait );
</code></pre>
<p><em><strong>Listing 9.4</strong></em> <em>The xEventGroupWaitBits() API function prototype</em></p>
<p>The condition used by the scheduler to determine if a task will enter
the Blocked state, and when a task will leave the Blocked state, is
called the 'unblock condition'. The unblock condition is specified by a
combination of the <code>uxBitsToWaitFor</code> and the <code>xWaitForAllBits</code> parameter
values:</p>
<ul>
<li>
<p><code>uxBitsToWaitFor</code> specifies which event bits in the event group to
test</p>
</li>
<li>
<p><code>xWaitForAllBits</code> specifies whether to use a bitwise OR test, or a
bitwise AND test</p>
</li>
</ul>
<p>A task will not enter the Blocked state if its unblock condition is met
at the time <code>xEventGroupWaitBits()</code> is called.</p>
<p>Examples of conditions that will result in a task either entering the
Blocked state, or exiting the Blocked state, are provided in Table 6.
Table 6 only shows the least significant four binary bits of the event
group and uxBitsToWaitFor values—the other bits of those two values are
assumed to be zero.</p>
<p><a name="tbl6" title="Table 6 The Effect of the uxBitsToWaitFor and xWaitForAllBits Parameters"></a></p>
<hr />
<div class="table-wrapper"><table><thead><tr><th>Existing Event Group Value</th><th>uxBitsToWaitFor value</th><th>xWaitForAllBits value</th><th>Resultant Behavior</th></tr></thead><tbody>
<tr><td>0000</td><td>0101</td><td>pdFALSE</td><td>The calling task will enter the Blocked state because neither of bit 0 or bit 2 are set in the event group, and will leave the Blocked state when either bit 0 OR bit 2 are set in the event group.</td></tr>
<tr><td>0100</td><td>0101</td><td>pdTRUE</td><td>The calling task will enter the Blocked state because bit 0 and bit 2 are not both set in the event group, and will leave the Blocked state when both bit 0 AND bit 2 are set in the event group.</td></tr>
<tr><td>0100</td><td>0110</td><td>pdFALSE</td><td>The calling task will not enter the Blocked state because xWaitForAllBits is pdFALSE, and one of the two bits specified by uxBitsToWaitFor is already set in the event group.</td></tr>
<tr><td>0100</td><td>0110</td><td>pdTRUE</td><td>The calling task will enter the Blocked state because xWaitForAllBits is pdTRUE, and only one of the two bits specified by uxBitsToWaitFor is already set in the event group. The task will leave the Blocked state when both bit 1 and bit 2 are set in the event group.</td></tr>
</tbody></table>
</div>
<p><em><strong>Table 6</strong></em> <em>The Effect of the uxBitsToWaitFor and xWaitForAllBits Parameters</em></p>
<hr />
<p>The calling task specifies bits to test using the <code>uxBitsToWaitFor</code>
parameter, and it is likely the calling task will need to clear these
bits back to zero after its unblock condition has been met. Event bits
can be cleared using the <code>xEventGroupClearBits()</code> API function, but using
that function to manually clear event bits will lead to race conditions
in the application code if:</p>
<ul>
<li>There is more than one task using the same event group.</li>
<li>Bits are set in the event group by a different task, or by an
interrupt service routine.</li>
</ul>
<p>The <code>xClearOnExit</code> parameter is provided to avoid these potential race
conditions. If <code>xClearOnExit</code> is set to <code>pdTRUE</code>, then the testing and
clearing of event bits appears to the calling task to be an atomic
operation (uninterruptable by other tasks or interrupts).</p>
<p><strong>xEventGroupWaitBits() parameters and return value</strong></p>
<ul>
<li>
<p><code>xEventGroup</code></p>
<p>The handle of the event group that contains the event bits being
read. The event group handle will have been returned from the call to
<code>xEventGroupCreate()</code> used to create the event group.</p>
</li>
<li>
<p><code>uxBitsToWaitFor</code></p>
<p>A bit mask that specifies the event bit, or event bits, to test
in the event group.</p>
<p>For example, if the calling task wants to wait for event bit 0 and/or
event bit 2 to become set in the event group, then set <code>uxBitsToWaitFor</code>
to 0x05 (binary 0101). Refer to Table 6 for further examples.</p>
</li>
<li>
<p><code>xClearOnExit</code></p>
<p>If the calling task's unblock condition has been met, and
<code>xClearOnExit</code> is set to <code>pdTRUE</code>, then the event bits specified by
<code>uxBitsToWaitFor</code> will be cleared back to 0 in the event group before the
calling task exits the <code>xEventGroupWaitBits()</code> API function.</p>
<p>If <code>xClearOnExit</code> is set to <code>pdFALSE</code>, then the state of the event bits
in the event group are not modified by the <code>xEventGroupWaitBits()</code> API
function.</p>
</li>
<li>
<p><code>xWaitForAllBits</code></p>
<p>The <code>uxBitsToWaitFor</code> parameter specifies the event bits to test in
the event group. <code>xWaitForAllBits</code> specifies if the calling task should be
removed from the Blocked state when one or more of the events bits
specified by the <code>uxBitsToWaitFor</code> parameter are set, or only when all of
the event bits specified by the <code>uxBitsToWaitFor</code> parameter are set.</p>
<p>If <code>xWaitForAllBits</code> is set to <code>pdFALSE</code>, then a task that entered the
Blocked state to wait for its unblock condition to be met will leave the
Blocked state when any of the bits specified by <code>uxBitsToWaitFor</code> become
set (or the timeout specified by the <code>xTicksToWait</code> parameter expires).</p>
<p>If <code>xWaitForAllBits</code> is set to <code>pdTRUE</code>, then a task that entered the
Blocked state to wait for its unblock condition to be met will only
leave the Blocked state when all of the bits specified by
<code>uxBitsToWaitFor</code> are set (or the timeout specified by the <code>xTicksToWait</code>
parameter expires).</p>
<p>Refer to Table 6 for examples.</p>
</li>
<li>
<p><code>xTicksToWait</code></p>
<p>The maximum amount of time the task should remain in the Blocked
state to wait for its unblock condition to be met.</p>
<p><code>xEventGroupWaitBits()</code> will return immediately if <code>xTicksToWait</code> is
zero, or the unblock condition is met at the time <code>xEventGroupWaitBits()</code>
is called.</p>
<p>The block time is specified in tick periods, so the absolute time it
represents is dependent on the tick frequency. The macro <code>pdMS_TO_TICKS()</code>
can be used to convert a time specified in milliseconds into a time
specified in ticks.</p>
<p>Setting <code>xTicksToWait</code> to <code>portMAX_DELAY</code> will cause the task to wait
indefinitely (without timing out), provided <code>INCLUDE_vTaskSuspend</code> is set
to 1 in FreeRTOSConfig.h.</p>
</li>
<li>
<p>Returned Value</p>
<p>If <code>xEventGroupWaitBits()</code> returned because the calling task's
unblock condition was met, then the returned value is the value of the
event group at the time the calling task's unblock condition was met
(before any bits were automatically cleared if <code>xClearOnExit</code> was <code>pdTRUE</code>).
In this case the returned value will also meet the unblock condition.</p>
<p>If <code>xEventGroupWaitBits()</code> returned because the block time specified by
the <code>xTicksToWait</code> parameter expired, then the returned value is the value
of the event group at the time the block time expired. In this case the
returned value will not meet the unblock condition.</p>
</li>
</ul>
<h3 id="935-the-xeventgroupgetstaticbuffer-api-function"><a class="header" href="#935-the-xeventgroupgetstaticbuffer-api-function">9.3.5 The xEventGroupGetStaticBuffer() API Function</a></h3>
<p>The <code>xEventGroupGetStaticBuffer()</code> API function provides a method to retrieve a pointer
to a buffer of a statically created event group. It is the same buffer that is supplied
at the time of creation of the event group.</p>
<p>*Note: Never call <code>xEventGroupGetStaticBuffer()</code> from an interrupt service
routine.</p>
<p><a name="list9.5" title="Listing 9.5 The xEventGroupGetStaticBuffer() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xEventGroupGetStaticBuffer( EventGroupHandle_t xEventGroup,

StaticEventGroup_t ** ppxEventGroupBuffer );
</code></pre>
<p><em><strong>Listing 9.5</strong></em> <em>The xEventGroupGetStaticBuffer() API function prototype</em></p>
<p><strong>xEventGroupGetStaticBuffer() parameters and return value</strong></p>
<ul>
<li>
<p><code>xEventGroup</code></p>
<p>The event group for which to retrieve the buffer. This event group must
be created by <code>xEventGroupCreateStatic()</code>.</p>
</li>
<li>
<p><code>ppxEventGroupBuffer</code></p>
<p>Used to return a pointer to the event groups's data structure buffer.
It is the same buffer that is supplied at the time of creation.</p>
</li>
<li>
<p>Return Value</p>
<p>There are two possible return values:</p>
<ul>
<li>
<p><code>pdTRUE</code> will be returned if the buffer was successfully retrieved.</p>
</li>
<li>
<p><code>pdFALSE</code> will be returned if the buffer was not successfully retrieved.</p>
</li>
</ul>
</li>
</ul>
<h2 id="-21"><a class="header" href="#-21"><a name="example9.1" title="Example 9.1 Experimenting with event groups"></a></a></h2>
<p><em><strong>Example 9.1</strong></em> <em>Experimenting with event groups</em></p>
<hr />
<p>This example demonstrates how to:</p>
<ul>
<li>Create an event group.</li>
<li>Set bits in an event group from an interrupt service routine.</li>
<li>Set bits in an event group from a task.</li>
<li>Block on an event group.</li>
</ul>
<p>The effect of the <code>xEventGroupWaitBits()</code> <code>xWaitForAllBits</code> parameter is
demonstrated by first executing the example with <code>xWaitForAllBits</code> set to
<code>pdFALSE</code>, and then executing the example with <code>xWaitForAllBits</code> set to
<code>pdTRUE</code>.</p>
<p>Event bit 0 and event bit 1 are set from a task. Event bit 2 is set from
an interrupt service routine. These three bits are given descriptive
names using the #define statements shown in Listing 9.6.</p>
<p><a name="list9.6" title="Listing 9.6 Event bit definitions used in Example 9.1"></a></p>
<pre><code class="language-c">/* Definitions for the event bits in the event group. */
#define mainFIRST_TASK_BIT ( 1UL &lt;&lt; 0UL )  /* Event bit 0, set by a task */
#define mainSECOND_TASK_BIT ( 1UL &lt;&lt; 1UL ) /* Event bit 1, set by a task */
#define mainISR_BIT ( 1UL &lt;&lt; 2UL )         /* Event bit 2, set by an ISR */
</code></pre>
<p><em><strong>Listing 9.6</strong></em> <em>Event bit definitions used in Example 9.1</em></p>
<p>Listing 9.7 shows the implementation of the task that sets event bit 0
and event bit 1. It sits in a loop, repeatedly setting one bit, then the
other, with a delay of 200 milliseconds between each call to
<code>xEventGroupSetBits()</code>. A string is printed out before each bit is set to
allow the sequence of execution to be seen in the console.</p>
<p><a name="list9.7" title="Listing 9.7 The task that sets two bits in the event group in Example 9.1"></a></p>
<pre><code class="language-c">static void vEventBitSettingTask( void *pvParameters )
{
    const TickType_t xDelay200ms = pdMS_TO_TICKS( 200UL ), xDontBlock = 0;

    for( ;; )
    {
        /* Delay for a short while before starting the next loop. */
        vTaskDelay( xDelay200ms );

        /* Print out a message to say event bit 0 is about to be set by the
           task, then set event bit 0. */
        vPrintString( "Bit setting task -\t about to set bit 0.\r\n" );
        xEventGroupSetBits( xEventGroup, mainFIRST_TASK_BIT );

        /* Delay for a short while before setting the other bit. */
        vTaskDelay( xDelay200ms );

        /* Print out a message to say event bit 1 is about to be set by the
           task, then set event bit 1. */
        vPrintString( "Bit setting task -\t about to set bit 1.\r\n" );
        xEventGroupSetBits( xEventGroup, mainSECOND_TASK_BIT );
    }
}
</code></pre>
<p><em><strong>Listing 9.7</strong></em> <em>The task that sets two bits in the event group in Example 9.1</em></p>
<p>Listing 9.8 shows the implementation of the interrupt service routine
that sets bit 2 in the event group. Again, a string is printed out
before the bit is set to allow the sequence of execution to be seen in
the console. In this case however, because console output should not be
performed directly in an interrupt service routine,
<code>xTimerPendFunctionCallFromISR()</code> is used to perform the output in the
context of the RTOS daemon task.</p>
<p>As in previous examples, the interrupt service routine is triggered by a
simple periodic task that forces a software interrupt. In this example,
the interrupt is generated every 500 milliseconds.</p>
<p><a name="list9.8" title="Listing 9.8 The ISR that sets bit 2 in the event group in Example 9.1"></a></p>
<pre><code class="language-c">static uint32_t ulEventBitSettingISR( void )
{
    /* The string is not printed within the interrupt service routine, but is 
       instead sent to the RTOS daemon task for printing. It is therefore
       declared static to ensure the compiler does not allocate the string on
       the stack of the ISR, as the ISR's stack frame will not exist when the
       string is printed from the daemon task. */
    static const char *pcString = "Bit setting ISR -\t about to set bit 2.\r\n";
    BaseType_t xHigherPriorityTaskWoken = pdFALSE;
    
    /* Print out a message to say bit 2 is about to be set. Messages cannot 
       be printed from an ISR, so defer the actual output to the RTOS daemon 
       task by pending a function call to run in the context of the RTOS 
       daemon task. */
    xTimerPendFunctionCallFromISR( vPrintStringFromDaemonTask,
                                   ( void * ) pcString,
                                   0,
                                   &amp;xHigherPriorityTaskWoken );

    /* Set bit 2 in the event group. */
    xEventGroupSetBitsFromISR( xEventGroup, 
                               mainISR_BIT, 
                               &amp;xHigherPriorityTaskWoken );

    /* xTimerPendFunctionCallFromISR() and xEventGroupSetBitsFromISR() both
       write to the timer command queue, and both used the same 
       xHigherPriorityTaskWoken variable. If writing to the timer command 
       queue resulted in the RTOS daemon task leaving the Blocked state, and 
       if the priority of the RTOS daemon task is higher than the priority of 
       the currently executing task (the task this interrupt interrupted) then 
       xHigherPriorityTaskWoken will have been set to pdTRUE.

       xHigherPriorityTaskWoken is used as the parameter to 
       portYIELD_FROM_ISR(). If xHigherPriorityTaskWoken equals pdTRUE, then 
       calling portYIELD_FROM_ISR() will request a context switch. If 
       xHigherPriorityTaskWoken is still pdFALSE, then calling 
       portYIELD_FROM_ISR() will have no effect.

       The implementation of portYIELD_FROM_ISR() used by the Windows port 
       includes a return statement, which is why this function does not 
       explicitly return a value. */

    portYIELD_FROM_ISR( xHigherPriorityTaskWoken );
}
</code></pre>
<p><em><strong>Listing 9.8</strong></em> <em>The ISR that sets bit 2 in the event group in Example 9.1</em></p>
<p>Listing 9.9 shows the implementation of the task that calls
<code>xEventGroupWaitBits()</code> to block on the event group. The task prints out a
string for each bit that is set in the event group.</p>
<p>The <code>xEventGroupWaitBits()</code> <code>xClearOnExit</code> parameter is set to <code>pdTRUE</code>, so
the event bit, or bits, that caused the call to <code>xEventGroupWaitBits()</code> to
return will be cleared automatically before <code>xEventGroupWaitBits()</code>
returns.</p>
<p><a name="list9.9" title="Listing 9.9 The task that blocks to wait for event bits to become set in Example 9.1"></a></p>
<pre><code class="language-c">static void vEventBitReadingTask( void *pvParameters )
{
    EventBits_t xEventGroupValue;
    const EventBits_t xBitsToWaitFor = ( mainFIRST_TASK_BIT  |
                                         mainSECOND_TASK_BIT |
                                         mainISR_BIT );

    for( ;; )
    {
        /* Block to wait for event bits to become set within the event 
           group. */
        xEventGroupValue = xEventGroupWaitBits( /* The event group to read */
                                                xEventGroup,

                                                /* Bits to test */
                                                xBitsToWaitFor,

                                                /* Clear bits on exit if the
                                                   unblock condition is met */
                                                pdTRUE,

                                                /* Don't wait for all bits. This
                                                   parameter is set to pdTRUE for the
                                                   second execution. */
                                                pdFALSE,

                                                /* Don't time out. */
                                                portMAX_DELAY );

        /* Print a message for each bit that was set. */
        if( ( xEventGroupValue &amp; mainFIRST_TASK_BIT ) != 0 )
        {
            vPrintString( "Bit reading task -\t Event bit 0 was set\r\n" );
        }

        if( ( xEventGroupValue &amp; mainSECOND_TASK_BIT ) != 0 )
        {
            vPrintString( "Bit reading task -\t Event bit 1 was set\r\n" );
        }

        if( ( xEventGroupValue &amp; mainISR_BIT ) != 0 )
        {
            vPrintString( "Bit reading task -\t Event bit 2 was set\r\n" );
        }
    }
}
</code></pre>
<p><em><strong>Listing 9.9</strong></em> <em>The task that blocks to wait for event bits to become set in Example 9.1</em></p>
<p>The <code>main()</code> function creates the event group, and the tasks, before
starting the scheduler. See Listing 9.10 for its implementation. The
priority of the task that reads from the event group is higher than the
priority of the task that writes to the event group, ensuring the
reading task will pre-empt the writing task each time the reading task's
unblock condition is met.</p>
<p><a name="list9.10" title="Listing 9.10 Creating the event group and tasks in Example 9.1"></a></p>
<pre><code class="language-c">int main( void )
{
    /* Before an event group can be used it must first be created. */
    xEventGroup = xEventGroupCreate();

    /* Create the task that sets event bits in the event group. */
    xTaskCreate( vEventBitSettingTask, "Bit Setter", 1000, NULL, 1, NULL );

    /* Create the task that waits for event bits to get set in the event 
       group. */
    xTaskCreate( vEventBitReadingTask, "Bit Reader", 1000, NULL, 2, NULL );

    /* Create the task that is used to periodically generate a software
       interrupt. */
    xTaskCreate( vInterruptGenerator, "Int Gen", 1000, NULL, 3, NULL );

    /* Install the handler for the software interrupt. The syntax necessary
       to do this is dependent on the FreeRTOS port being used. The syntax 
       shown here can only be used with the FreeRTOS Windows port, where such 
       interrupts are only simulated. */
    vPortSetInterruptHandler( mainINTERRUPT_NUMBER, ulEventBitSettingISR );

    /* Start the scheduler so the created tasks start executing. */
    vTaskStartScheduler();

    /* The following line should never be reached. */
    for( ;; );
    return 0;
}
</code></pre>
<p><em><strong>Listing 9.10</strong></em> <em>Creating the event group and tasks in Example 9.1</em></p>
<p>The output produced when Example 9.1 is executed with the
<code>xEventGroupWaitBits()</code> <code>xWaitForAllBits</code> parameter set to <code>pdFALSE</code> is shown
in Figure 9.3. In Figure 9.3, it can be seen that, because the
<code>xWaitForAllBits</code> parameter in the call to <code>xEventGroupWaitBits()</code> was set
to <code>pdFALSE</code>, the task that reads from the event group leaves the Blocked
state and executes immediately every time any of the event bits are set.</p>
<p><a name="fig9.3" title="Figure 9.3 The output produced when Example 9.1 is executed with xWaitForAllBits set to pdFALSE"></a></p>
<hr />
<p><img src="media/image73.jpg" alt="" /><br />
<em><strong>Figure 9.3</strong></em> <em>The output produced when Example 9.1 is executed with xWaitForAllBits set to pdFALSE</em></p>
<hr />
<p>The output produced when Example 9.1 is executed with the
<code>xEventGroupWaitBits()</code> <code>xWaitForAllBits</code> parameter set to <code>pdTRUE</code> is shown
in Figure 9.4. In Figure 9.4 it can be seen that, because the
<code>xWaitForAllBits</code> parameter was set to <code>pdTRUE</code>, the task that reads from
the event group only leaves the Blocked state after all three of the
event bits are set.</p>
<p><a name="fig9.4" title="Figure 9.4 The output produced when Example 9.1 is executed with xWaitForAllBits set to pdTRUE"></a></p>
<hr />
<p><img src="media/image74.jpg" alt="" /><br />
<em><strong>Figure 9.4</strong></em> <em>The output produced when Example 9.1 is executed with xWaitForAllBits set to pdTRUE</em></p>
<hr />
<h2 id="94-task-synchronization-using-an-event-group"><a class="header" href="#94-task-synchronization-using-an-event-group">9.4 Task Synchronization Using an Event Group</a></h2>
<p>Sometimes the design of an application requires two or more tasks to
synchronize with each other. For example, consider a design where Task A
receives an event, then delegates some of the processing necessitated by
the event to three other tasks: Task B, Task C and Task D. If Task A
cannot receive another event until tasks B, C and D have all completed
processing the previous event, then all four tasks will need to
synchronize with each other. Each task's synchronization point will be
after that task has completed its processing, and cannot proceed further
until each of the other tasks have done the same. Task A can only
receive another event after all four tasks have reached their
synchronization point.</p>
<p>A less abstract example of the need for this type of task
synchronization is found in one of the FreeRTOS+TCP demonstration
projects. The demonstration shares a TCP socket between two tasks; one
task sends data to the socket, and a different task receives data from
the same socket<sup class="footnote-reference"><a href="#25">2</a></sup>. It is not safe for either task to close the TCP
socket until it is sure the other task will not attempt to access the
socket again. If either of the two tasks wishes to close the socket,
then it must inform the other task of its intent, and then wait for the
other task to stop using the socket before proceeding. The scenario
where it is the task that sends data to the socket that wishes to close
the socket is demonstrated by the pseudo code shown in Listing 9.10.</p>
<div class="footnote-definition" id="25"><sup class="footnote-definition-label">2</sup>
<p>At the time of writing, this is the only way a single
FreeRTOS+TCP socket can be shared between tasks.</p>
</div>
<p>The scenario demonstrated by Listing 9.10 is trivial, as there are only
two tasks that need to synchronize with each other, but it is easy to
see how the scenario would become more complex, and require more tasks
to join the synchronization, if other tasks were performing processing
that was dependent on the socket being open.</p>
<p><a name="list9.11" title="Listing 9.11 Pseudo code for two tasks that synchronize with each other to ensure a shared TCP socket..."></a></p>
<pre><code class="language-c">void SocketTxTask( void *pvParameters )
{
    xSocket_t xSocket;
    uint32_t ulTxCount = 0UL;

    for( ;; )
    {
        /* Create a new socket. This task will send to this socket, and another
           task will receive from this socket. */
        xSocket = FreeRTOS_socket( ... );

        /* Connect the socket. */
        FreeRTOS_connect( xSocket, ... );

        /* Use a queue to send the socket to the task that receives data. */
        xQueueSend( xSocketPassingQueue, &amp;xSocket, portMAX_DELAY );

        /* Send 1000 messages to the socket before closing the socket. */
        for( ulTxCount = 0; ulTxCount &lt; 1000; ulTxCount++ )
        {
            if( FreeRTOS_send( xSocket, ... ) &lt; 0 )
            {
                /* Unexpected error - exit the loop, after which the socket 
                   will be closed. */
                break;
            }
        }

        /* Let the Rx task know the Tx task wants to close the socket. */
        TxTaskWantsToCloseSocket();

        /* This is the Tx task's synchronization point. The Tx task waits here
           for the Rx task to reach its synchronization point. The Rx task will
           only reach its synchronization point when it is no longer using the 
           socket, and the socket can be closed safely. */
        xEventGroupSync( ... );

        /* Neither task is using the socket. Shut down the connection, then
           close the socket. */
        FreeRTOS_shutdown( xSocket, ... );
        WaitForSocketToDisconnect();
        FreeRTOS_closesocket( xSocket );
    }
}
/*-----------------------------------------------------------*/

void SocketRxTask( void *pvParameters )
{
    xSocket_t xSocket;

    for( ;; )
    {
        /* Wait to receive a socket that was created and connected by the Tx
           task. */
        xQueueReceive( xSocketPassingQueue, &amp;xSocket, portMAX_DELAY );

        /* Keep receiving from the socket until the Tx task wants to close the
           socket. */
        while( TxTaskWantsToCloseSocket() == pdFALSE )
        {
           /* Receive then process data. */
           FreeRTOS_recv( xSocket, ... );
           ProcessReceivedData();
        }

        /* This is the Rx task's synchronization point - it only reaches here
           when it is no longer using the socket, and it is therefore safe for 
           the Tx task to close the socket. */
        xEventGroupSync( ... );
    }
}
</code></pre>
<p><em><strong>Listing 9.11</strong></em> <em>Pseudo code for two tasks that synchronize with each other to ensure a shared TCP socket is no longer in use by either task before the socket is closed</em></p>
<p>An event group can be used to create a synchronization point:</p>
<ul>
<li>
<p>Each task that must participate in the synchronization is assigned a
unique event bit within the event group.</p>
</li>
<li>
<p>Each task sets its own event bit when it reaches the synchronization
point.</p>
</li>
<li>
<p>Having set its own event bit, each task blocks on the event group to
wait for the event bits that represent all the other synchronizing
tasks to also become set.</p>
</li>
</ul>
<p>However, the <code>xEventGroupSetBits()</code> and <code>xEventGroupWaitBits()</code> API
functions cannot be used in this scenario. If they were used, then the
setting of a bit (to indicate a task had reached its synchronization
point) and the testing of bits (to determine if the other synchronizing
tasks had reached their synchronization point) would be performed as two
separate operations. To see why that would be a problem, consider a
scenario where Task A, Task B and Task C attempt to synchronize using an
event group:</p>
<ol>
<li>
<p>Task A and Task B have already reached the synchronization point, so
their event bits are set in the event group, and they are in the
Blocked state to wait for task C's event bit to also become set.</p>
</li>
<li>
<p>Task C reaches the synchronization point, and uses
<code>xEventGroupSetBits()</code> to set its bit in the event group. As soon as
Task C's bit is set, Task A and Task B leave the Blocked state, and
clear all three event bits.</p>
</li>
<li>
<p>Task C then calls <code>xEventGroupWaitBits()</code> to wait for all three event
bits to become set, but by that time, all three event bits have
already been cleared, Task A and Task B have left their respective
synchronization points, and so the synchronization has failed.</p>
</li>
</ol>
<p>To successfully use an event group to create a synchronization point,
the setting of an event bit, and the subsequent testing of event bits,
must be performed as a single uninterruptable operation. The
<code>xEventGroupSync()</code> API function is provided for that purpose.</p>
<h3 id="941-the-xeventgroupsync-api-function"><a class="header" href="#941-the-xeventgroupsync-api-function">9.4.1 The xEventGroupSync() API Function</a></h3>
<p><code>xEventGroupSync()</code> is provided to allow two or more tasks to use an event
group to synchronize with each other. The function allows a task to set
one or more event bits in an event group, then wait for a combination of
event bits to become set in the same event group, as a single
uninterruptable operation.</p>
<p>The <code>xEventGroupSync()</code> <code>uxBitsToWaitFor</code> parameter specifies the calling
task's unblock condition. The event bits specified by <code>uxBitsToWaitFor</code>
will be cleared back to zero before <code>xEventGroupSync()</code> returns, if
<code>xEventGroupSync()</code> returned because the unblock condition had been met.</p>
<p><a name="list9.12" title="Listing 9.12 The xEventGroupSync() API function prototype"></a></p>
<pre><code class="language-c">EventBits_t xEventGroupSync( EventGroupHandle_t xEventGroup,
                             const EventBits_t uxBitsToSet,
                             const EventBits_t uxBitsToWaitFor,
                             TickType_t xTicksToWait );
</code></pre>
<p><em><strong>Listing 9.12</strong></em> <em>The xEventGroupSync() API function prototype</em></p>
<p><strong>xEventGroupSync() parameters and return value</strong></p>
<ul>
<li>
<p><code>xEventGroup</code></p>
<p>The handle of the event group in which event bits are to be set, and
then tested. The event group handle will have been returned from the
call to <code>xEventGroupCreate()</code> used to create the event group.</p>
</li>
<li>
<p><code>uxBitsToSet</code></p>
<p>A bit mask that specifies the event bit, or event bits, to set to
1 in the event group. The value of the event group is updated by bitwise
ORing the event group's existing value with the value passed in
<code>uxBitsToSet</code>.</p>
<p>As an example, setting <code>uxBitsToSet</code> to 0x04 (binary 0100) will result
in event bit 2 becoming set (if it was not already set), while leaving
all the other event bits in the event group unchanged.</p>
</li>
<li>
<p><code>uxBitsToWaitFor</code></p>
<p>A bit mask that specifies the event bit, or event bits, to test
in the event group.</p>
<p>For example, if the calling task wants to wait for event bits 0, 1
and 2 to become set in the event group, then set <code>uxBitsToWaitFor</code> to 0x07
(binary 111).</p>
</li>
<li>
<p><code>xTicksToWait</code></p>
<p>The maximum amount of time the task should remain in the Blocked
state to wait for its unblock condition to be met.</p>
<p><code>xEventGroupSync()</code> will return immediately if <code>xTicksToWait</code> is zero, or
the unblock condition is met at the time <code>xEventGroupSync()</code> is
called.</p>
<p>The block time is specified in tick periods, so the absolute time it
represents is dependent on the tick frequency. The macro <code>pdMS_TO_TICKS()</code>
can be used to convert a time specified in milliseconds into a time
specified in ticks.</p>
<p>Setting <code>xTicksToWait</code> to <code>portMAX_DELAY</code> will cause the task to wait
indefinitely (without timing out), provided <code>INCLUDE_vTaskSuspend</code> is set
to 1 in FreeRTOSConfig.h.</p>
</li>
<li>
<p>Returned Value</p>
<p>If <code>xEventGroupSync()</code> returned because the calling task's unblock
condition was met, then the returned value is the value of the event
group at the time the calling task's unblock condition was met (before
any bits were automatically cleared back to zero). In this case the
returned value will also meet the calling task's unblock condition.</p>
<p>If <code>xEventGroupSync()</code> returned because the block time specified by the
<code>xTicksToWait</code> parameter expired, then the returned value is the value of
the event group at the time the block time expired. In this case the
returned value will not meet the calling task's unblock
condition.</p>
</li>
</ul>
<h2 id="-22"><a class="header" href="#-22"><a name="example9.2" title="Example 9.2 Synchronizing tasks"></a></a></h2>
<p><em><strong>Example 9.2</strong></em> <em>Synchronizing tasks</em></p>
<hr />
<p>Example 9.2 uses <code>xEventGroupSync()</code> to synchronize three instances of a
single task implementation. The task parameter is used to pass into each
instance the event bit the task will set when it calls
<code>xEventGroupSync()</code>.</p>
<p>The task prints a message before calling <code>xEventGroupSync()</code>, and again
after the call to <code>xEventGroupSync()</code> has returned. Each message includes
a time stamp. This allows the sequence of execution to be observed in
the output produced. A pseudo random delay is used to prevent all the
tasks reaching the synchronization point at the same time.</p>
<p>See Listing 9.12 for the task's implementation.</p>
<p><a name="list9.13" title="Listing 9.13 The implementation of the task used in Example 9.2"></a></p>
<pre><code class="language-c">static void vSyncingTask( void *pvParameters )
{
    const TickType_t xMaxDelay = pdMS_TO_TICKS( 4000UL );
    const TickType_t xMinDelay = pdMS_TO_TICKS( 200UL );
    TickType_t xDelayTime;
    EventBits_t uxThisTasksSyncBit;
    const EventBits_t uxAllSyncBits = ( mainFIRST_TASK_BIT  |
                                        mainSECOND_TASK_BIT |
                                        mainTHIRD_TASK_BIT );

    /* Three instances of this task are created - each task uses a different 
       event bit in the synchronization. The event bit to use is passed into 
       each task instance using the task parameter. Store it in the 
       uxThisTasksSyncBit variable. */
    uxThisTasksSyncBit = ( EventBits_t ) pvParameters;

    for( ;; )
    {
        /* Simulate this task taking some time to perform an action by delaying
           for a pseudo random time. This prevents all three instances of this 
           task reaching the synchronization point at the same time, and so 
           allows the example's behavior to be observed more easily. */
        xDelayTime = ( rand() % xMaxDelay ) + xMinDelay;
        vTaskDelay( xDelayTime );

        /* Print out a message to show this task has reached its synchronization
           point. pcTaskGetTaskName() is an API function that returns the name
           assigned to the task when the task was created. */
        vPrintTwoStrings( pcTaskGetTaskName( NULL ), "reached sync point" );

        /* Wait for all the tasks to have reached their respective
           synchronization points. */
        xEventGroupSync( /* The event group used to synchronize. */
                         xEventGroup,

                         /* The bit set by this task to indicate it has reached
                            the synchronization point. */
                         uxThisTasksSyncBit,

                         /* The bits to wait for, one bit for each task taking 
                            part in the synchronization. */
                         uxAllSyncBits,

                         /* Wait indefinitely for all three tasks to reach the
                            synchronization point. */
                         portMAX_DELAY );

        /* Print out a message to show this task has passed its synchronization
           point. As an indefinite delay was used the following line will only 
           be executed after all the tasks reached their respective 
           synchronization points. */
        vPrintTwoStrings( pcTaskGetTaskName( NULL ), "exited sync point" );
    }
}
</code></pre>
<p><em><strong>Listing 9.13</strong></em> <em>The implementation of the task used in Example 9.2</em></p>
<p>The <code>main()</code> function creates the event group, creates all three tasks,
and then starts the scheduler. See Listing 9.14 for its implementation.</p>
<p><a name="list9.14" title="Listing 9.14 The main() function used in Example 9.2"></a></p>
<pre><code class="language-c">/* Definitions for the event bits in the event group. */

#define mainFIRST_TASK_BIT ( 1UL &lt;&lt; 0UL ) /* Event bit 0, set by the 1st task */
#define mainSECOND_TASK_BIT( 1UL &lt;&lt; 1UL ) /* Event bit 1, set by the 2nd task */
#define mainTHIRD_TASK_BIT ( 1UL &lt;&lt; 2UL ) /* Event bit 2, set by the 3rd task */

/* Declare the event group used to synchronize the three tasks. */
EventGroupHandle_t xEventGroup;

int main( void )
{
    /* Before an event group can be used it must first be created. */
    xEventGroup = xEventGroupCreate();

    /* Create three instances of the task. Each task is given a different
       name, which is later printed out to give a visual indication of which 
       task is executing. The event bit to use when the task reaches its
       synchronization point is passed into the task using the task parameter. */
    xTaskCreate( vSyncingTask, "Task 1", 1000, mainFIRST_TASK_BIT, 1, NULL );
    xTaskCreate( vSyncingTask, "Task 2", 1000, mainSECOND_TASK_BIT, 1, NULL );
    xTaskCreate( vSyncingTask, "Task 3", 1000, mainTHIRD_TASK_BIT, 1, NULL );

    /* Start the scheduler so the created tasks start executing. */
    vTaskStartScheduler();

    /* As always, the following line should never be reached. */
    for( ;; );
    return 0;
}
</code></pre>
<p><em><strong>Listing 9.14</strong></em> <em>The main() function used in Example 9.2</em></p>
<p>The output produced when Example 9.2 is executed is shown in Figure 9.5.
It can be seen that, even though each task reaches the synchronization
point at a different (pseudo random) time, each task exits the
synchronization point at the same time<sup class="footnote-reference"><a href="#26">3</a></sup> (which is the time at which
the last task reached the synchronization point).</p>
<div class="footnote-definition" id="26"><sup class="footnote-definition-label">3</sup>
<p>Figure 9.5 shows the example running in the FreeRTOS Windows port,
which does not provide true real time behavior (especially when
using Windows system calls to print to the console), and will
therefore show some timing variation.</p>
</div>
<p><a name="fig9.5" title="Figure 9.5 The output produced when Example 9.2 is executed"></a></p>
<hr />
<p><img src="media/image75.jpg" alt="" /><br />
<em><strong>Figure 9.5</strong></em> <em>The output produced when Example 9.2 is executed</em></p>
<hr />
<div style="break-before: page; page-break-before: always;"></div><h1 id="10-task-notifications-1"><a class="header" href="#10-task-notifications-1">10 Task Notifications</a></h1>
<h2 id="101-introduction"><a class="header" href="#101-introduction">10.1 Introduction</a></h2>
<p>FreeRTOS applications are typically structured as a series of independent tasks that communicate with each other to collectively provide the system functionality.  Task notifications are an efficient mechanism allowing one task to directly notify another task.</p>
<h3 id="1011-communicating-through-intermediary-objects"><a class="header" href="#1011-communicating-through-intermediary-objects">10.1.1 Communicating Through Intermediary Objects</a></h3>
<p>This book has already described various ways in which tasks can
communicate with each other. The methods described so far have required
the creation of a communication object. Examples of communication
objects include queues, event groups, and various different types of
semaphore.</p>
<p>When a communication object is used, events and data are not sent
directly to a receiving task, or a receiving ISR, but are instead sent
to the communication object. Likewise, tasks and ISRs receive events and
data from the communication object, rather than directly from the task
or ISR that sent the event or data. This is depicted in Figure 10.1.</p>
<p><a name="fig10.1" title="Figure 10.1 A communication object being used to send an event from one task to another"></a></p>
<hr />
<p><img src="media/image76.png" alt="" /><br />
<em><strong>Figure 10.1</strong></em> <em>A communication object being used to send an event from one task to another</em></p>
<hr />
<h3 id="1012-task-notificationsdirect-to-task-communication"><a class="header" href="#1012-task-notificationsdirect-to-task-communication">10.1.2 Task Notifications—Direct to Task Communication</a></h3>
<p>'Task Notifications' allow tasks to interact with other tasks, and to
synchronize with ISRs, without the need for a separate communication
object. By using a task notification, a task or ISR can send an event
directly to the receiving task. This is depicted in Figure 10.2.</p>
<p><a name="fig10.2" title="Figure 10.2 A task notification used to send an event directly from one task to another"></a></p>
<hr />
<p><img src="media/image77.png" alt="" /><br />
<em><strong>Figure 10.2</strong></em> <em>A task notification used to send an event directly from one task to another</em></p>
<hr />
<p>Task notification functionality is optional. To include task
notification functionality set <code>configUSE_TASK_NOTIFICATIONS</code> to 1 in FreeRTOSConfig.h.</p>
<p>When <code>configUSE_TASK_NOTIFICATIONS</code> is set to 1, each task has at least one
'Notification State', which can be either 'Pending' or 'Not-Pending',
and a 'Notification Value', which is a 32-bit unsigned integer. When a
task receives a notification, its notification state is set to pending.
When a task reads its notification value, its notification state is set
to not-pending.  If the <code>configTASK_NOTIFICATION_ARRAY_ENTRIES</code> is set to a value
&gt; 1 then there are multiple Notification states and values identified by index.</p>
<p>A task can wait in the Blocked state, with an optional time out, for its
notification state to become pending.</p>
<h3 id="1013-scope"><a class="header" href="#1013-scope">10.1.3 Scope</a></h3>
<p>This chapter discusses:</p>
<ul>
<li>A task's notification state and notification value.</li>
<li>How and when a task notification can be used in place of a
communication object, such as a semaphore.</li>
<li>The advantages of using a task notification in place of a
communication object.</li>
</ul>
<h2 id="102-task-notifications-benefits-and-limitations"><a class="header" href="#102-task-notifications-benefits-and-limitations">10.2 Task Notifications; Benefits and Limitations</a></h2>
<h3 id="1021-performance-benefits-of-task-notifications"><a class="header" href="#1021-performance-benefits-of-task-notifications">10.2.1 Performance Benefits of Task Notifications</a></h3>
<p>Using a task notification to send an event or data to a task is
significantly faster than using a queue, semaphore or event group to
perform an equivalent operation.</p>
<h3 id="1022-ram-footprint-benefits-of-task-notifications"><a class="header" href="#1022-ram-footprint-benefits-of-task-notifications">10.2.2 RAM Footprint Benefits of Task Notifications</a></h3>
<p>Likewise, using a task notification to send an event or data to a task
requires significantly less RAM than using a queue, semaphore or event
group to perform an equivalent operation. This is because each
communication object (queue, semaphore or event group) must be created
before it can be used, whereas enabling task notification functionality
has a fixed overhead.  The RAM cost for task notifications is
<code>configTASK_NOTIFICATION_ARRAY_ENTRIES</code> * 5 bytes per task.  The
default value for <code>configTASK_NOTIFICATION_ARRAY_ENTRIES</code> is 1 making
the default size for task notifications is 5 bytes per task.</p>
<h3 id="1023-limitations-of-task-notifications"><a class="header" href="#1023-limitations-of-task-notifications">10.2.3 Limitations of Task Notifications</a></h3>
<p>Task notifications are faster and use less RAM than communication
objects, but task notifications cannot be used in all scenarios. This
section documents the scenarios in which a task notification cannot be
used:</p>
<ul>
<li>
<p>Sending an event or data to an ISR</p>
<p>Communication objects can be used to send events and data from an ISR
to a task, and from a task to an ISR.</p>
<p>Task notifications can be used to send events and data from an ISR to
a task, but they cannot be used to send events or data from a task to
an ISR.</p>
</li>
<li>
<p>Enabling more than one receiving task</p>
<p>A communication object can be accessed by any task or ISR that knows
its handle (which might be a queue handle, semaphore handle, or event
group handle). Any number of tasks and ISRs can process events or data
sent to any given communication object.</p>
<p>Task notifications are sent directly to the receiving task, so they can
only be processed by the task to which the notification is sent.
However, this is rarely a limitation in practical cases because, while
it is common to have multiple tasks and ISRs sending to the same
communication object, it is rare to have multiple tasks and ISRs
receiving from the same communication object.</p>
</li>
<li>
<p>Buffering multiple data items</p>
<p>A queue is a communication object that can hold more than one data
item at a time. Data that has been sent to the queue, but not yet
received from the queue, is buffered inside the queue object.</p>
<p>Task notifications send data to a task by updating the receiving
task's notification value. A task's notification value can only hold
one value at a time.</p>
</li>
<li>
<p>Broadcasting to more than one task</p>
<p>An event group is a communication object that can be used to send an
event to more than one task at a time.</p>
<p>Task notifications are sent directly to the receiving task, so can
only be processed by the receiving task.</p>
</li>
<li>
<p>Waiting in the blocked state for a send to complete</p>
<p>If a communication object is temporarily in a state that means no more
data or events can be written to it (for example, when a queue is full
no more data can be sent to the queue), then tasks attempting to write
to the object can optionally enter the Blocked state to wait for their
write operation to complete.</p>
<p>If a task attempts to send a task notification to a task that already
has a notification pending, then it is not possible for the sending
task to wait in the Blocked state for the receiving task to reset its
notification state. As will be seen, this is rarely a limitation in
practical cases in which a task notification is used.</p>
</li>
</ul>
<h2 id="103-using-task-notifications"><a class="header" href="#103-using-task-notifications">10.3 Using Task Notifications</a></h2>
<h3 id="1031-task-notification-api-options"><a class="header" href="#1031-task-notification-api-options">10.3.1 Task Notification API Options</a></h3>
<p>Task notifications are a very powerful feature that can often be used in
place of a binary semaphore, a counting semaphore, an event group, and
sometimes even a queue. This wide range of usage scenarios can be
achieved by using the <code>xTaskNotify()</code> API function to send a task
notification, and the <code>xTaskNotifyWait()</code> API function to receive a task
notification.</p>
<p>However, in the majority of cases, the full flexibility provided by the
<code>xTaskNotify()</code> and <code>xTaskNotifyWait()</code> API functions is not required, and
simpler functions would suffice. Therefore, the <code>xTaskNotifyGive()</code> API
function is provided as a simpler but less flexible alternative to
<code>xTaskNotify()</code>, and the <code>ulTaskNotifyTake()</code> API function is provided as a
simpler but less flexible alternative to <code>xTaskNotifyWait()</code>.</p>
<p>The task notification system is not limited to a single notification event.  The
configuration parameter <code>configTASK_NOTIFICATION_ARRAY_ENTRIES</code> is set to 1 by default.
If it is set to a value greater than 1, an array of notifications are created inside
each task.  This allows notifications to be managed by index.  Every task
notification api function has an indexed version.  Using the non-indexed version
will result in accessing notification[0] (the first one in the array).  The <code>indexed</code>
version of each API function is identified by the suffix <code>Indexed</code> so the function
<code>xTaskNotify</code> becomes <code>xTaskNotifyIndexed</code>.  For simplicity only the non-indexed
versions of each function will be used throughout this book.</p>
<p>The task notification API's are implemented as macro that make calls to the
underlying <code>Generic</code> versions of each API function type.  For simplicy the API
macros will be called functions throughout this book.</p>
<h4 id="10311-the-complete-list-of-api-functions-27"><a class="header" href="#10311-the-complete-list-of-api-functions-27">10.3.1.1 The complete list of API functions <sup>27</sup></a></h4>
<ul>
<li><code>xTaskNotifyGive</code></li>
<li><code>xTaskNotifyGiveIndexed</code></li>
<li><code>vTaskNotifyGiveFromISR</code></li>
<li><code>vTaskNotifyGiveIndexedFromISR</code></li>
<li><code>vTaskNotifyTake</code></li>
<li><code>vTaskNotifyTakeIndexed</code></li>
<li><code>xTaskNotify</code></li>
<li><code>xTaskNotifyIndexed</code></li>
<li><code>xTaskNotifyWait</code></li>
<li><code>xTaskNotifyWaitIndexed</code></li>
<li><code>xTaskNotifyStateClear</code></li>
<li><code>xTaskNotifyStateClearIndexed</code></li>
<li><code>ulTaskNotifyValueClear</code></li>
<li><code>ulTaskNotifyValueClearIndexed</code></li>
<li><code>xTaskNotifyAndQueryIndexedFromISR</code></li>
<li><code>xTaskNotifyAndQueryFromISR</code></li>
<li><code>xTaskNotifyFromISR</code></li>
<li><code>xTaskNotifyIndexedFromISR</code></li>
<li><code>xTaskNotifyAndQuery</code></li>
<li><code>xTaskNotifyAndQueryIndexed</code></li>
</ul>
<p><em>(27): These functions are actually implemented as macros.</em></p>
<blockquote>
<p>Note: The <code>FromISR</code> functions do not exist for receiving notifications because a notification is always sent to a task and interrupts are not associated with any task.</p>
</blockquote>
<h3 id="1032-the-xtasknotifygive-api-functions"><a class="header" href="#1032-the-xtasknotifygive-api-functions">10.3.2 The xTaskNotifyGive() API Functions</a></h3>
<p><code>xTaskNotifyGive()</code> sends a notification directly to a task, and
increments (adds one to) the receiving task's notification value.
Calling <code>xTaskNotifyGive()</code> will set the receiving task's notification
state to pending, if it was not already pending.</p>
<p>The <code>xTaskNotifyGive()</code> API function is provided to allow a task
notification to be used as a lighter weight and faster alternative to a
binary or counting semaphore.</p>
<p><a name="list10.1" title="Listing 10.1 The xTaskNotifyGive() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xTaskNotifyGive( TaskHandle_t xTaskToNotify );
BaseType_t xTaskNotifyGiveIndexed( TaskHandle_t xTaskToNotify, UBaseType_t uxIndexToNotify );
</code></pre>
<p><em><strong>Listing 10.1</strong></em> <em>The xTaskNotifyGive() API function prototype</em></p>
<p><strong>xTaskNotifyGive()/xTaskNotifyGiveIndexed() parameters and return value</strong></p>
<ul>
<li>
<p><code>xTaskToNotify</code></p>
<p>The handle of the task to which the notification is being sent—see
the <code>pxCreatedTask</code> parameter of the <code>xTaskCreate()</code> API function for
information on obtaining handles to tasks.</p>
</li>
<li>
<p><code>uxIndexToNotify</code></p>
<p>The index into the array</p>
</li>
<li>
<p>Return value</p>
<p><code>xTaskNotifyGive()</code> is a macro that calls <code>xTaskNotify()</code>. The
parameters passed into <code>xTaskNotify()</code> by the macro are set such that
<code>pdPASS</code> is the only possible return value. <code>xTaskNotify()</code> is described
later in this book.</p>
</li>
</ul>
<h3 id="1033-the-vtasknotifygivefromisr-api-function"><a class="header" href="#1033-the-vtasknotifygivefromisr-api-function">10.3.3 The vTaskNotifyGiveFromISR() API Function</a></h3>
<p><code>vTaskNotifyGiveFromISR()</code> is a version of <code>xTaskNotifyGive()</code> that can be
used in an interrupt service routine.</p>
<p><a name="list10.2" title="Listing 10.2 The vTaskNotifyGiveFromISR() API function prototype"></a></p>
<pre><code class="language-c">void vTaskNotifyGiveFromISR( TaskHandle_t xTaskToNotify,
                             BaseType_t *pxHigherPriorityTaskWoken );
</code></pre>
<p><em><strong>Listing 10.2</strong></em> <em>The vTaskNotifyGiveFromISR() API function prototype</em></p>
<p><strong>vTaskNotifyGiveFromISR() parameters and return value</strong></p>
<ul>
<li>
<p><code>xTaskToNotify</code></p>
<p>The handle of the task to which the notification is being sent—see
the <code>pxCreatedTask</code> parameter of the <code>xTaskCreate()</code> API function for
information on obtaining handles to tasks.</p>
</li>
<li>
<p><code>pxHigherPriorityTaskWoken</code></p>
<p>If the task to which the notification is being sent is waiting in
the Blocked state to receive a notification, then sending the
notification will cause the task to leave the Blocked state.</p>
<p>If calling <code>vTaskNotifyGiveFromISR()</code> causes a task to leave the
Blocked state, and the unblocked task has a priority higher than the
priority of the currently executing task (the task that was
interrupted), then, internally, <code>vTaskNotifyGiveFromISR()</code> will set
<code>*pxHigherPriorityTaskWoken</code> to <code>pdTRUE</code>.</p>
<p>If <code>vTaskNotifyGiveFromISR()</code> sets this value to <code>pdTRUE</code>, then a context
switch should be performed before the interrupt is exited. This will
ensure that the interrupt returns directly to the highest priority Ready
state task.</p>
<p>As with all interrupt safe API functions, the
<code>pxHigherPriorityTaskWoken</code> parameter must be set to <code>pdFALSE</code> before it is used.</p>
</li>
</ul>
<h3 id="1034-the-ultasknotifytake-api-function"><a class="header" href="#1034-the-ultasknotifytake-api-function">10.3.4 The ulTaskNotifyTake() API Function</a></h3>
<p><code>ulTaskNotifyTake()</code> allows a task to wait in the Blocked state for its
notification value to be greater than zero, and either decrements
(subtracts one from) or clears the task's notification value before it
returns.</p>
<p>The <code>ulTaskNotifyTake()</code> API function is provided to allow a task
notification to be used as a lighter weight and faster alternative to a
binary or counting semaphore.</p>
<p><a name="list10.3" title="Listing 10.3 The ulTaskNotifyTake() API function prototype"></a></p>
<pre><code class="language-c">uint32_t ulTaskNotifyTake( BaseType_t xClearCountOnExit, TickType_t
xTicksToWait );
</code></pre>
<p><em><strong>Listing 10.3</strong></em> <em>The ulTaskNotifyTake() API function prototype</em></p>
<p><strong>ulTaskNotifyTake() parameters and return value</strong></p>
<ul>
<li>
<p><code>xClearCountOnExit</code></p>
<p>If <code>xClearCountOnExit</code> is set to <code>pdTRUE</code>, then the calling task's
notification value will be cleared to zero before the call to
<code>ulTaskNotifyTake()</code> returns.</p>
<p>If <code>xClearCountOnExit</code> is set to <code>pdFALSE</code>, and the calling task's
notification value is greater than zero, then the calling task's
notification value will be decremented before the call to
<code>ulTaskNotifyTake()</code> returns.</p>
</li>
<li>
<p><code>xTicksToWait</code></p>
<p>The maximum amount of time the calling task should remain in the
Blocked state to wait for its notification value to be greater than
zero.</p>
<p>The block time is specified in tick periods, so the absolute time it
represents is dependent on the tick frequency. The macro <code>pdMS_TO_TICKS()</code>
can be used to convert a time specified in milliseconds to a time
specified in ticks.</p>
<p>Setting <code>xTicksToWait</code> to <code>portMAX_DELAY</code> will cause the task to wait
indefinitely (without timing out), provided <code>INCLUDE_vTaskSuspend</code> is set
to 1 in <code>FreeRTOSConfig.h</code>.</p>
</li>
<li>
<p>Return value</p>
<p>The returned value is the calling task's notification value
<em>before</em> it was either cleared to zero or decremented, as
specified by the value of the <code>xClearCountOnExit</code> parameter.</p>
<p>If a block time was specified (<code>xTicksToWait</code> was not zero), and the
return value is not zero, then it is possible the calling task was
placed into the Blocked state to wait for its notification value to be
greater than zero, and its notification value was updated before the
block time expired.</p>
<p>If a block time was specified (<code>xTicksToWait</code> was not zero), and the
return value is zero, then the calling task was placed into the Blocked
state to wait for its notification value to be greater than zero, but
the specified block time expired before that happened.</p>
</li>
</ul>
<h2 id="-23"><a class="header" href="#-23"><a name="example10.1" title="Example 10.1 Using a task notification in place of a semaphore, method 1"></a></a></h2>
<p><em><strong>Example 10.1</strong></em> <em>Using a task notification in place of a semaphore, method 1</em></p>
<hr />
<p>Example 7.1 used a binary semaphore to unblock a task from within an
interrupt service routine—effectively synchronizing the task with the
interrupt. This example replicates the functionality of Example 7.1, but
uses a direct to task notification in place of the binary semaphore.</p>
<p>Listing 10.4 shows the implementation of the task that is synchronized
with the interrupt. The call to <code>xSemaphoreTake()</code> that was used in
Example 7.1 has been replaced by a call to <code>ulTaskNotifyTake()</code>.</p>
<p>The <code>ulTaskNotifyTake()</code> <code>xClearCountOnExit</code> parameter is set to <code>pdTRUE</code>,
which results in the receiving task's notification value being cleared
to zero before <code>ulTaskNotifyTake()</code> returns. It is therefore necessary to
process all the events that are already available between each call to
<code>ulTaskNotifyTake()</code>. In Example 7.1, because a binary semaphore was used,
the number of pending events had to be determined from the hardware,
which is not always practical. In Example 10.1, the number of pending
events is returned from <code>ulTaskNotifyTake()</code>.</p>
<p>Interrupt events that occur between calls to <code>ulTaskNotifyTake</code> are
latched in the task's notification value, and calls to
<code>ulTaskNotifyTake()</code> will return immediately if the calling task already
has notifications pending.</p>
<p><a name="list10.4" title="Listing 10.4 The implementation of the task to which the interrupt processing is deferred (the task that..."></a></p>
<pre><code class="language-c">/* The rate at which the periodic task generates software interrupts. */
const TickType_t xInterruptFrequency = pdMS_TO_TICKS( 500UL );

static void vHandlerTask( void *pvParameters )
{
    /* xMaxExpectedBlockTime is set to be a little longer than the maximum
       expected time between events. */
    const TickType_t xMaxExpectedBlockTime = xInterruptFrequency +
                                             pdMS_TO_TICKS( 10 );
    uint32_t ulEventsToProcess;

    /* As per most tasks, this task is implemented within an infinite loop. */
    for( ;; )
    {
        /* Wait to receive a notification sent directly to this task from the
           interrupt service routine. */
        ulEventsToProcess = ulTaskNotifyTake( pdTRUE, xMaxExpectedBlockTime );
        if( ulEventsToProcess != 0 )
        {
            /* To get here at least one event must have occurred. Loop here 
               until all the pending events have been processed (in this case,
               just print out a message for each event). */
            while( ulEventsToProcess &gt; 0 )
            {
                vPrintString( "Handler task - Processing event.\r\n" );
                ulEventsToProcess--;
            }
        }
        else
        {
            /* If this part of the function is reached then an interrupt did 
               not arrive within the expected time, and (in a real application)
               it may be necessary to perform some error recovery operations. */
        }
    }
}
</code></pre>
<p><em><strong>Listing 10.4</strong></em> <em>The implementation of the task to which the interrupt processing is deferred (the task that synchronizes with the interrupt) in Example 10.1</em></p>
<p>The periodic task used to generate software interrupts prints a message
before the interrupt is generated, and again after the interrupt has
been generated. This allows the sequence of execution to be observed in
the output produced.</p>
<p>Listing 10.5 shows the interrupt handler. This does very little other
than send a notification directly to the task to which interrupt
handling is deferred.</p>
<p><a name="list10.5" title="Listing 10.5 The implementation of the interrupt service routine used in Example 10.1"></a></p>
<pre><code class="language-c">static uint32_t ulExampleInterruptHandler( void )
{
    BaseType_t xHigherPriorityTaskWoken;

    /* The xHigherPriorityTaskWoken parameter must be initialized to pdFALSE as
       it will get set to pdTRUE inside the interrupt safe API function if a
       context switch is required. */
    xHigherPriorityTaskWoken = pdFALSE;

    /* Send a notification directly to the task to which interrupt processing 
       is being deferred. */
    vTaskNotifyGiveFromISR( /* The handle of the task to which the notification
                               is being sent. The handle was saved when the task
                               was created. */
                            xHandlerTask,

                            /* xHigherPriorityTaskWoken is used in the usual 
                               way. */
                            &amp;xHigherPriorityTaskWoken );

    /* Pass the xHigherPriorityTaskWoken value into portYIELD_FROM_ISR(). If 
       xHigherPriorityTaskWoken was set to pdTRUE inside vTaskNotifyGiveFromISR()
       then calling portYIELD_FROM_ISR() will request a context switch. If
       xHigherPriorityTaskWoken is still pdFALSE then calling 
       portYIELD_FROM_ISR() will have no effect. The implementation of
       portYIELD_FROM_ISR() used by the Windows port includes a return statement,
       which is why this function does not explicitly return a value. */
    portYIELD_FROM_ISR( xHigherPriorityTaskWoken );
}
</code></pre>
<p><em><strong>Listing 10.5</strong></em> <em>The implementation of the interrupt service routine used in Example 10.1</em></p>
<p>The output produced when Example 10.1 is executed is shown in Figure 10.3.
As expected, it is identical to that produced when Example 7.1 is
executed. <code>vHandlerTask()</code> enters the Running state as soon as the
interrupt is generated, so the output from the task splits the output
produced by the periodic task. Further explanation is provided in Figure 10.4.</p>
<p><a name="fig10.3" title="Figure 10.3 The output produced when Example 7.1 is executed"></a>
<a name="fig10.4" title="Figure 10.4 The sequence of execution when Example 10.1 is executed"></a></p>
<hr />
<p><img src="media/image78.png" alt="" /><br />
<em><strong>Figure 10.3</strong></em> <em>The output produced when Example 7.1 is executed</em></p>
<p><img src="media/image79.png" alt="" /><br />
<em><strong>Figure 10.4</strong></em> <em>The sequence of execution when Example 10.1 is executed</em></p>
<hr />
<h2 id="-24"><a class="header" href="#-24"><a name="example10.2" title="Example 10.2 Using a task notification in place of a semaphore, method 2"></a></a></h2>
<p><em><strong>Example 10.2</strong></em> <em>Using a task notification in place of a semaphore, method 2</em></p>
<hr />
<p>In Example 10.1, the <code>ulTaskNotifyTake()</code> <code>xClearOnExit</code> parameter was set to
<code>pdTRUE</code>. Example 10.1 modifies Example 10.1 slightly to demonstrate the
behavior when the <code>ulTaskNotifyTake()</code> <code>xClearOnExit</code> parameter is instead
set to <code>pdFALSE</code>.</p>
<p>When <code>xClearOnExit</code> is <code>pdFALSE</code>, calling <code>ulTaskNotifyTake()</code> will only
decrement (reduce by one) the calling task's notification value, instead
of clearing it to zero. The notification count is therefore the
difference between the number of events that have occurred, and the
number of events that have been processed. That allows the structure of
<code>vHandlerTask()</code> to be simplified in two ways:</p>
<ol>
<li>
<p>The number of events waiting to be processed is held in the
notification value, so it does not need to be held in a local
variable.</p>
</li>
<li>
<p>It is only necessary to process one event between each call to
<code>ulTaskNotifyTake()</code>.</p>
</li>
</ol>
<p>The implementation of <code>vHandlerTask()</code> used in Example 10.2 is shown in
Listing 10.6.</p>
<p><a name="list10.6" title="Listing 10.6 The implementation of the task to which the interrupt processing is deferred (the task..."></a></p>
<pre><code class="language-c">static void vHandlerTask( void *pvParameters )
{
    /* xMaxExpectedBlockTime is set to be a little longer than the maximum 
       expected time between events. */
    const TickType_t xMaxExpectedBlockTime = xInterruptFrequency + 
                                             pdMS_TO_TICKS( 10 );

    /* As per most tasks, this task is implemented within an infinite loop. */
    for( ;; )
    {
        /* Wait to receive a notification sent directly to this task from the
           interrupt service routine. The xClearCountOnExit parameter is now
           pdFALSE, so the task's notification value will be decremented by
           ulTaskNotifyTake(), and not cleared to zero. */
        if( ulTaskNotifyTake( pdFALSE, xMaxExpectedBlockTime ) != 0 )
        {
            /* To get here an event must have occurred. Process the event (in 
               this case just print out a message). */
            vPrintString( "Handler task - Processing event.\r\n" );
        }
        else
        {
            /* If this part of the function is reached then an interrupt did 
               not arrive within the expected time, and (in a real application)
               it may be necessary to perform some error recovery operations. */
        }
    }
}
</code></pre>
<p><em><strong>Listing 10.6</strong></em> <em>The implementation of the task to which the interrupt processing is deferred (the task that synchronizes with the interrupt) in Example 102</em></p>
<p>For demonstration purposes, the interrupt service routine has also been
modified to send more than one task notification per interrupt, and in
so doing, simulate multiple interrupts occurring at high frequency. The
implementation of the interrupt service routine used in Example 10.2 is
shown in Listing 10.7.</p>
<p><a name="list10.7" title="Listing 10.7 The implementation of the interrupt service routine used in Example 10.2"></a></p>
<pre><code class="language-c">static uint32_t ulExampleInterruptHandler( void )
{
    BaseType_t xHigherPriorityTaskWoken;

    xHigherPriorityTaskWoken = pdFALSE;

    /* Send a notification to the handler task multiple times. The first
       'give' will unblock the task, the following 'gives' are to demonstrate 
       that the receiving task's notification value is being used to count 
       (latch) events - allowing the task to process each event in turn. */
    vTaskNotifyGiveFromISR( xHandlerTask, &amp;xHigherPriorityTaskWoken );
    vTaskNotifyGiveFromISR( xHandlerTask, &amp;xHigherPriorityTaskWoken );
    vTaskNotifyGiveFromISR( xHandlerTask, &amp;xHigherPriorityTaskWoken );

    portYIELD_FROM_ISR( xHigherPriorityTaskWoken );
}
</code></pre>
<p><em><strong>Listing 10.7</strong></em> <em>The implementation of the interrupt service routine used in Example 10.2</em></p>
<p>The output produced when Example 10.2 is executed is shown in Figure 10.5.
As can be seen, <code>vHandlerTask()</code> processes all three events each time an
interrupt is generated.</p>
<p><a name="fig10.5" title="Figure 10.5 The output produced when Example 10.2 is executed"></a></p>
<hr />
<p><img src="media/image80.jpg" alt="" /><br />
<em><strong>Figure 10.5</strong></em> <em>The output produced when Example 10.2 is executed</em></p>
<hr />
<h3 id="1035-the-xtasknotify-and-xtasknotifyfromisr-api-functions"><a class="header" href="#1035-the-xtasknotify-and-xtasknotifyfromisr-api-functions">10.3.5 The xTaskNotify() and xTaskNotifyFromISR() API Functions</a></h3>
<p><code>xTaskNotify()</code> is a more capable version of <code>xTaskNotifyGive()</code> that can be
used to update the receiving task's notification value in any of the
following ways:</p>
<ul>
<li>
<p>Increment (add one to) the receiving task's notification value, in
which case <code>xTaskNotify()</code> is equivalent to <code>xTaskNotifyGive()</code>.</p>
</li>
<li>
<p>Set one or more bits in the receiving task's notification value.
This allows a task's notification value to be used as a lighter
weight and faster alternative to an event group.</p>
</li>
<li>
<p>Write a completely new number into the receiving task's notification
value, but only if the receiving task has read its notification
value since it was last updated. This allows a task's notification
value to provide similar functionality to that provided by a queue
that has a length of one.</p>
</li>
<li>
<p>Write a completely new number into the receiving task's notification
value, even if the receiving task has not read its notification
value since it was last updated. This allows a task's notification
value to provide similar functionality to that provided by the
<code>xQueueOverwrite()</code> API function. The resultant behavior is sometimes
referred to as a 'mailbox'.</p>
</li>
</ul>
<p><code>xTaskNotify()</code> is more flexible and powerful than <code>xTaskNotifyGive()</code>, and
because of that extra flexibility and power, it is also a little more
complex to use.</p>
<p><code>xTaskNotifyFromISR()</code> is a version of <code>xTaskNotify()</code> that can be used in
an interrupt service routine, and therefore has an additional
<code>pxHigherPriorityTaskWoken</code> parameter.</p>
<p>Calling <code>xTaskNotify()</code> will always set the receiving task's notification
state to pending, if it was not already pending.</p>
<p><a name="list10.8" title="Listing 10.8 Prototypes for the xTaskNotify() and xTaskNotifyFromISR() API functions"></a></p>
<pre><code class="language-c">BaseType_t xTaskNotify( TaskHandle_t xTaskToNotify,
                        uint32_t ulValue,
                        eNotifyAction eAction );

BaseType_t xTaskNotifyFromISR( TaskHandle_t xTaskToNotify,
                               uint32_t ulValue,
                               eNotifyAction eAction,
                               BaseType_t *pxHigherPriorityTaskWoken );
</code></pre>
<p><em><strong>Listing 10.8</strong></em> <em>Prototypes for the xTaskNotify() and xTaskNotifyFromISR() API functions</em></p>
<p><strong>xTaskNotify() parameters and return value</strong></p>
<ul>
<li>
<p><code>xTaskToNotify</code></p>
<p>The handle of the task to which the notification is being sent—see
the <code>pxCreatedTask</code> parameter of the <code>xTaskCreate()</code> API function for
information on obtaining handles to tasks.</p>
</li>
<li>
<p><code>ulValue</code></p>
<p>How ulValue is used is dependent on the eNotifyAction value. See below.</p>
</li>
<li>
<p><code>eNotifyAction</code></p>
<p>An enumerated type that specifies how to update the receiving task's
notification value. See below.</p>
</li>
<li>
<p>Return value</p>
<p><code>xTaskNotify()</code> will return <code>pdPASS</code> <em>except</em> in the one case noted below.</p>
</li>
</ul>
<p><strong>Valid xTaskNotify() eNotifyAction Parameter Values, and Their Resultant
Effect on the Receiving Task's Notification Value</strong></p>
<ul>
<li>
<p><code>eNoAction</code></p>
<p>The receiving task's notification state is set to pending without
it's notification value being updated. The <code>xTaskNotify()</code> <code>ulValue</code>
parameter is not used.</p>
<p>The <code>eNoAction</code> action allows a task notification to be used as a
faster and lighter-weight alternative to a binary semaphore.</p>
</li>
<li>
<p><code>eSetBits</code></p>
<p>The receiving task's notification value is bitwise OR'ed with the
value passed in the <code>xTaskNotify()</code> <code>ulValue</code> parameter. For example, if
<code>ulValue</code> is set to 0x01, then bit 0 will be set in the receiving task's
notification value. As another example, if <code>ulValue</code> is 0x06 (binary 0110)
then bit 1 and bit 2 will be set in the receiving task's notification value.</p>
<p>The <code>eSetBits</code> action allows a task notification to be used as a faster
and lighter-weight alternative to an event group.</p>
</li>
<li>
<p><code>eIncrement</code></p>
<p>The receiving task's notification value is incremented. The
<code>xTaskNotify()</code> <code>ulValue</code> parameter is not used.</p>
<p>The <code>eIncrement</code> action allows a task notification to be used as a
faster and lighter-weight alternative to a binary or counting semaphore,
and is equivalent to the simpler <code>xTaskNotifyGive()</code> API function.</p>
</li>
<li>
<p><code>eSetValueWithoutOverwrite</code></p>
<p>If the receiving task had a notification pending before
<code>xTaskNotify()</code> was called, then no action is taken and <code>xTaskNotify()</code> will
return <code>pdFAIL</code>.</p>
<p>If the receiving task did not have a notification pending before
<code>xTaskNotify()</code> was called, then the receiving task's notification value
is set to the value passed in the <code>xTaskNotify()</code> <code>ulValue</code> parameter.</p>
</li>
<li>
<p><code>eSetValueWithOverwrite</code></p>
<p>The receiving task's notification value is set to the value passed
in the <code>xTaskNotify()</code> <code>ulValue</code> parameter, regardless of whether the
receiving task had a notification pending before <code>xTaskNotify()</code> was
called or not.</p>
</li>
</ul>
<h3 id="1036-the-xtasknotifywait-api-function"><a class="header" href="#1036-the-xtasknotifywait-api-function">10.3.6 The xTaskNotifyWait() API Function</a></h3>
<p><code>xTaskNotifyWait()</code> is a more capable version of <code>ulTaskNotifyTake()</code>. It
allows a task to wait, with an optional timeout, for the calling task's
notification state to become pending, should it not already be pending.
<code>xTaskNotifyWait()</code> provides options for bits to be cleared in the calling
task's notification value both on entry to the function, and on exit
from the function.</p>
<p><a name="list10.9" title="Listing 10.9 The xTaskNotifyWait() API function prototype"></a></p>
<pre><code class="language-c">BaseType_t xTaskNotifyWait( uint32_t   ulBitsToClearOnEntry,
                            uint32_t   ulBitsToClearOnExit,
                            uint32_t   *pulNotificationValue,
                            TickType_t xTicksToWait );
</code></pre>
<p><em><strong>Listing 10.9</strong></em> <em>The xTaskNotifyWait() API function prototype</em></p>
<p><strong>xTaskNotifyWait() parameters and return value</strong></p>
<ul>
<li>
<p><code>ulBitsToClearOnEntry</code></p>
<p>If the calling task did not have a notification pending before it
called <code>xTaskNotifyWait()</code>, then any bits set in <code>ulBitsToClearOnEntry</code> will
be cleared in the task's notification value on entry to the function.</p>
<p>For example, if <code>ulBitsToClearOnEntry</code> is 0x01, then bit 0 of the
task's notification value will be cleared. As another example, setting
<code>ulBitsToClearOnEntry</code> to 0xffffffff (<code>ULONG_MAX</code>) will clear all the bits
in the task's notification value, effectively clearing the value to 0.</p>
</li>
<li>
<p><code>ulBitsToClearOnExit</code></p>
<p>If the calling task exits <code>xTaskNotifyWait()</code> because it received a
notification, or because it already had a notification pending when
<code>xTaskNotifyWait()</code> was called, then any bits set in <code>ulBitsToClearOnExit</code>
will be cleared in the task's notification value before the task exits
the <code>xTaskNotifyWait()</code> function.</p>
<p>The bits are cleared after the task's notification value has been
saved in <code>*pulNotificationValue</code> (see the description of
<code>pulNotificationValue</code> below).</p>
<p>For example, if <code>ulBitsToClearOnExit</code> is 0x03, then bit 0 and bit 1 of
the task's notification value will be cleared before the function
exits.</p>
<p>Setting <code>ulBitsToClearOnExit</code> to 0xffffffff (<code>ULONG_MAX</code>) will clear all
the bits in the task's notification value, effectively clearing the
value to 0.</p>
</li>
<li>
<p><code>pulNotificationValue</code></p>
<p>Used to pass out the task's notification value. The value copied
to <code>*pulNotificationValue</code> is the task's notification value as it was
before any bits were cleared due to the <code>ulBitsToClearOnExit</code> setting.</p>
<p>`pulNotificationValue is an optional parameter and can be set to NULL
if it is not required.</p>
</li>
<li>
<p><code>xTicksToWait</code></p>
<p>The maximum amount of time the calling task should remain in the
Blocked state to wait for its notification state to become pending.</p>
<p>The block time is specified in tick periods, so the absolute time it
represents is dependent on the tick frequency. The macro <code>pdMS_TO_TICKS()</code>
can be used to convert a time specified in milliseconds to a time
specified in ticks.</p>
<p>Setting <code>xTicksToWait</code> to <code>portMAX_DELAY</code> will cause the task to wait
indefinitely (without timing out), provided <code>INCLUDE_vTaskSuspend</code> is set
to 1 in <code>FreeRTOSConfig.h</code>.</p>
</li>
<li>
<p>Return value</p>
<p>There are two possible return values:</p>
<ul>
<li>
<p><code>pdTRUE</code></p>
<p>This indicates <code>xTaskNotifyWait()</code> returned because a notification was
received, or because the calling task already had a notification pending
when <code>xTaskNotifyWait()</code> was called.</p>
<p>If a block time was specified (<code>xTicksToWait</code> was not zero), then it is
possible that the calling task was placed into the Blocked state, to
wait for its notification state to become pending, but its notification
state was set to pending before the block time expired.</p>
</li>
<li>
<p><code>pdFALSE</code></p>
<p>This indicates that <code>xTaskNotifyWait()</code> returned without the calling
task receiving a task notification.</p>
<p>If <code>xTicksToWait</code> was not zero, then the calling task will have been
held in the Blocked state to wait for its notification state to become
pending, but the specified block time expired before that happened.</p>
</li>
</ul>
</li>
</ul>
<h3 id="1037-task-notifications-used-in-peripheral-device-drivers-uart-example"><a class="header" href="#1037-task-notifications-used-in-peripheral-device-drivers-uart-example">10.3.7 Task Notifications Used in Peripheral Device Drivers: UART Example</a></h3>
<p>Peripheral driver libraries provide functions that perform common
operations on hardware interfaces. Examples of peripherals for which
such libraries are often provided include Universal Asynchronous
Receivers and Transmitters (UARTs), Serial Peripheral Interface (SPI)
ports, analog to digital converters (ADCs), and Ethernet ports. Examples
of functions typically provided by such libraries include functions to
initialize a peripheral, send data to a peripheral, and receive data
from a peripheral.</p>
<p>Some operations on peripherals take a relatively long time to complete.
Examples of such operations include a high precision ADC conversion, and
the transmission of a large data packet on a UART. In these cases the
driver library function could be implemented to poll (repeatedly read)
the peripheral's status registers to determine when the operation has
completed. However, polling in this manner is nearly always wasteful as
it utilizes 100% of the processor's time while no productive processing
is being performed. The waste is particularly expensive in a
multi-tasking system, where a task that is polling a peripheral might be
preventing the execution of a lower priority task that does have
productive processing to perform.</p>
<p>To avoid the potential for wasted processing time, an efficient RTOS
aware device driver should be interrupt driven, and give a task that
initiates a lengthy operation the option of waiting in the Blocked state
for the operation to complete. That way, lower priority tasks can
execute while the task performing the lengthy operation is in the
Blocked state, and no tasks use processing time unless they can use it
productively.</p>
<p>It is common practice for RTOS aware driver libraries to use a binary
semaphore to place tasks into the Blocked state. The technique is
demonstrated by the pseudo code shown in Listing 10.10, which provides the
outline of an RTOS aware library function that transmits data on a UART
port. In Listing 10.10:</p>
<ul>
<li>
<p><code>xUART</code> is a structure that describes the UART peripheral, and holds
state information. The <code>xTxSemaphore</code> member of the structure is a
variable of type <code>SemaphoreHandle_t</code>. It is assumed the semaphore has
already been created.</p>
</li>
<li>
<p>The <code>xUART_Send()</code> function does not include any mutual exclusion
logic. If more than one task is going to use the <code>xUART_Send()</code>
function, then the application writer will have to manage mutual
exclusion within the application itself. For example, a task may be
required to obtain a mutex before calling <code>xUART_Send()</code>.</p>
</li>
<li>
<p>The <code>xSemaphoreTake()</code> API function is used to place the calling task
into the Blocked state after the UART transmission has been initiated.</p>
</li>
<li>
<p>The <code>xSemaphoreGiveFromISR()</code> API function is used to remove the task
from the Blocked state after the transmission has completed, which
is when the UART peripheral's transmit end interrupt service routine
executes.</p>
</li>
</ul>
<p><a name="list10.10" title="Listing 10.10 Pseudo code demonstrating how a binary semaphore can be used in a driver library transmit..."></a></p>
<pre><code class="language-c">/* Driver library function to send data to a UART. */

BaseType_t xUART_Send( xUART *pxUARTInstance, 
                       uint8_t *pucDataSource, 
                       size_t uxLength )
{
    BaseType_t xReturn;

    /* Ensure the UART's transmit semaphore is not already available by 
       attempting to take the semaphore without a timeout. */
    xSemaphoreTake( pxUARTInstance-&gt;xTxSemaphore, 0 );

    /* Start the transmission. */
    UART_low_level_send( pxUARTInstance, pucDataSource, uxLength );

    /* Block on the semaphore to wait for the transmission to complete. If 
       the semaphore is obtained then xReturn will get set to pdPASS. If the 
       semaphore take operation times out then xReturn will get set to pdFAIL. 
       Note that, if the interrupt occurs between UART_low_level_send() being 
       called, and xSemaphoreTake() being called, then the event will be 
       latched in the binary semaphore, and the call to xSemaphoreTake() will 
       return immediately. */
    xReturn = xSemaphoreTake( pxUARTInstance-&gt;xTxSemaphore, 
                              pxUARTInstance-&gt;xTxTimeout );

    return xReturn;
}
/*-----------------------------------------------------------*/

/* The service routine for the UART's transmit end interrupt, which executes 
   after the last byte has been sent to the UART. */
void xUART_TransmitEndISR( xUART *pxUARTInstance )
{
    BaseType_t xHigherPriorityTaskWoken = pdFALSE;

    /* Clear the interrupt. */
    UART_low_level_interrupt_clear( pxUARTInstance );

    /* Give the Tx semaphore to signal the end of the transmission. If a task 
       is Blocked waiting for the semaphore then the task will be removed from
       the Blocked state. */
    xSemaphoreGiveFromISR( pxUARTInstance-&gt;xTxSemaphore, 
                           &amp;xHigherPriorityTaskWoken );
    portYIELD_FROM_ISR( xHigherPriorityTaskWoken );
}
</code></pre>
<p><em><strong>Listing 10.10</strong></em> <em>Pseudo code demonstrating how a binary semaphore can be used in a driver library transmit function</em></p>
<p>The technique demonstrated in Listing 10.10 is perfectly workable, and
indeed common practice, but it has some drawbacks:</p>
<ul>
<li>
<p>The library uses multiple semaphores, which increases its RAM
footprint.</p>
</li>
<li>
<p>Semaphores cannot be used until they have been created, so a library
that uses semaphores cannot be used until it has been explicitly
initialized.</p>
</li>
<li>
<p>Semaphores are generic objects that are applicable to a wide range
of use cases; they include logic to allow any number of tasks to
wait in the Blocked state for the semaphore to become available, and
to select (in a deterministic manner) which task to remove from the
Blocked state when the semaphore does become available. Executing
that logic takes a finite time, and that processing overhead is
unnecessary in the scenario shown is Listing 10.10, in which there
cannot be more than one task waiting for the semaphore at any given
time.</p>
</li>
</ul>
<p>Listing 10.11 demonstrates how to avoid these drawbacks by using a task
notification in place of a binary semaphore.</p>
<blockquote>
<p><em>Note: If a library uses task notifications, then the library's
documentation must clearly state that calling a library function can
change the calling task's notification state and notification value.</em></p>
</blockquote>
<p>In Listing 10.11:</p>
<ul>
<li>
<p>The <code>xTxSemaphore</code> member of the <code>xUART</code> structure has been replaced by
the <code>xTaskToNotify</code> member. <code>xTaskToNotify</code> is a variable of type
<code>TaskHandle_t</code>, and is used to hold the handle of the task that is
waiting for the UART operation to complete.</p>
</li>
<li>
<p>The <code>xTaskGetCurrentTaskHandle()</code> FreeRTOS API function is used to
obtain the handle of the task that is in the Running state.</p>
</li>
<li>
<p>The library does not create any FreeRTOS objects, so it does not incur
a RAM overhead, and does not need to be explicitly initialized.</p>
</li>
<li>
<p>The task notification is sent directly to the task that is waiting
for the UART operation to complete, so no unnecessary logic is
executed.</p>
</li>
</ul>
<p>The <code>xTaskToNotify</code> member of the <code>xUART</code> structure is accessed from both a
task and an interrupt service routine, requiring that consideration be
given as to how the processor will update its value:</p>
<ul>
<li>
<p>If <code>xTaskToNotify</code> is updated by a single memory write operation, then
it can be updated outside of a critical section, exactly as shown in
Listing 10.11. This would be the case if <code>xTaskToNotify</code> is a 32-bit
variable (<code>TaskHandle_t</code> was a 32-bit type), and the processor on
which FreeRTOS is running is a 32-bit processor.</p>
</li>
<li>
<p>If more than one memory write operation is required to update
<code>xTaskToNotify</code>, then <code>xTaskToNotify</code> must only be updated from within a
critical section—otherwise the interrupt service routine might
access <code>xTaskToNotify</code> while it is in an inconsistent state. This
would be the case if <code>xTaskToNotify</code> is a 32-bit variable, and the
processor on which FreeRTOS is running is a 16-bit processor, as it
would require two 16-bit memory write operations to update all
32-bits.</p>
</li>
</ul>
<p>Internally, within the FreeRTOS implementation, <code>TaskHandle_t</code> is a
pointer, so <code>sizeof( TaskHandle_t )</code> always equals <code>sizeof( void * )</code>.</p>
<p><a name="list10.11" title="Listing 10.11 Pseudo code demonstrating how a task notification can be used in a driver library transmit..."></a></p>
<pre><code class="language-c">/* Driver library function to send data to a UART. */
BaseType_t xUART_Send( xUART *pxUARTInstance, 
                       uint8_t *pucDataSource, 
                       size_t uxLength )
{
    BaseType_t xReturn;

    /* Save the handle of the task that called this function. The book text
       contains notes as to whether the following line needs to be protected 
       by a critical section or not. */
    pxUARTInstance-&gt;xTaskToNotify = xTaskGetCurrentTaskHandle();

    /* Ensure the calling task does not already have a notification pending by 
       calling ulTaskNotifyTake() with the xClearCountOnExit parameter set to 
       pdTRUE, and a block time of 0 (don't block). */
    ulTaskNotifyTake( pdTRUE, 0 );

    /* Start the transmission. */
    UART_low_level_send( pxUARTInstance, pucDataSource, uxLength );

    /* Block until notified that the transmission is complete. If the 
       notification is received then xReturn will be set to 1 because the ISR 
       will have incremented this task's notification value to 1 (pdTRUE). If 
       the operation times out then xReturn will be 0 (pdFALSE) because this 
       task's notification value will not have been changed since it was 
       cleared to 0 above. Note that, if the ISR executes between the calls to
       UART_low_level_send() and the call to ulTaskNotifyTake(), then the 
       event will be latched in the task's notification value, and the call to 
       ulTaskNotifyTake() will return immediately. */
    xReturn = ( BaseType_t ) ulTaskNotifyTake( pdTRUE, 
                                               pxUARTInstance-&gt;xTxTimeout );

    return xReturn;
}
/*-----------------------------------------------------------*/

/* The ISR that executes after the last byte has been sent to the UART. */
void xUART_TransmitEndISR( xUART *pxUARTInstance )
{
    BaseType_t xHigherPriorityTaskWoken = pdFALSE;

    /* This function should not execute unless there is a task waiting to be 
       notified. Test this condition with an assert. This step is not strictly
       necessary, but will aid debugging. configASSERT() is described in 
       section 12.2. */
    configASSERT( pxUARTInstance-&gt;xTaskToNotify != NULL );

    /* Clear the interrupt. */
    UART_low_level_interrupt_clear( pxUARTInstance );

    /* Send a notification directly to the task that called xUART_Send(). If 
       the task is Blocked waiting for the notification then the task will be 
       removed from the Blocked state. */
    vTaskNotifyGiveFromISR( pxUARTInstance-&gt;xTaskToNotify,
                            &amp;xHigherPriorityTaskWoken );

    /* Now there are no tasks waiting to be notified. Set the xTaskToNotify 
       member of the xUART structure back to NULL. This step is not strictly 
       necessary but will aid debugging. */
    pxUARTInstance-&gt;xTaskToNotify = NULL;
    portYIELD_FROM_ISR( xHigherPriorityTaskWoken );
}
</code></pre>
<p><em><strong>Listing 10.11</strong></em> <em>Pseudo code demonstrating how a task notification can be used in a driver library transmit function</em></p>
<p>Task notifications can also replace semaphores in receive functions, as
demonstrated in pseudo code Listing 10.12, which provides the outline of
an RTOS aware library function that receives data on a UART port.
Referring to Listing 10.12:</p>
<ul>
<li>
<p>The <code>xUART_Receive()</code> function does not include any mutual exclusion
logic. If more than one task is going to use the <code>xUART_Receive()</code>
function, then the application writer will have to manage mutual
exclusion within the application itself. For example, a task may be
required to obtain a mutex before calling <code>xUART_Receive()</code>.</p>
</li>
<li>
<p>The UART's receive interrupt service routine places the characters
that are received by the UART into a RAM buffer. The <code>xUART_Receive()</code>
function returns characters from the RAM buffer.</p>
</li>
<li>
<p>The <code>xUART_Receive()</code> <code>uxWantedBytes</code> parameter is used to specify the
number of characters to receive. If the RAM buffer does not already
contain the requested number characters, then the calling task is
placed into the Blocked state to wait to be notified that the number
of characters in the buffer has increased. The <code>while()</code> loop is used
to repeat this sequence until either the receive buffer contains the
requested number of characters, or a timeout occurs.</p>
</li>
<li>
<p>The calling task may enter the Blocked state more than once. The
block time is therefore adjusted to take into account the amount of
time that has already passed since <code>xUART_Receive()</code> was called. The
adjustments ensure the total time spent inside <code>xUART_Receive()</code> does
not exceed the block time specified by the <code>xRxTimeout</code> member of the
<code>xUART</code> structure. The block time is adjusted using the FreeRTOS
<code>vTaskSetTimeOutState()</code> and <code>xTaskCheckForTimeOut()</code> helper functions.</p>
</li>
</ul>
<p><a name="list10.12" title="Listing 10.12 Pseudo code demonstrating how a task notification can be used in a driver library receive..."></a></p>
<pre><code class="language-c">/* Driver library function to receive data from a UART. */

size_t xUART_Receive( xUART *pxUARTInstance, 
                      uint8_t *pucBuffer,
                      size_t uxWantedBytes )
{
    size_t uxReceived = 0;
    TickType_t xTicksToWait;
    TimeOut_t xTimeOut;

    /* Record the time at which this function was entered. */
    vTaskSetTimeOutState( &amp;xTimeOut );

    /* xTicksToWait is the timeout value - it is initially set to the maximum 
       receive timeout for this UART instance. */
    xTicksToWait = pxUARTInstance-&gt;xRxTimeout;

    /* Save the handle of the task that called this function. The book text 
       contains notes as to whether the following line needs to be protected 
       by a critical section or not. */
    pxUARTInstance-&gt;xTaskToNotify = xTaskGetCurrentTaskHandle();

    /* Loop until the buffer contains the wanted number of bytes, or a
       timeout occurs. */
    while( UART_bytes_in_rx_buffer( pxUARTInstance ) &lt; uxWantedBytes )
    {
        /* Look for a timeout, adjusting xTicksToWait to account for the time
           spent in this function so far. */
        if( xTaskCheckForTimeOut( &amp;xTimeOut, &amp;xTicksToWait ) != pdFALSE )
        {
            /* Timed out before the wanted number of bytes were available, 
               exit the loop. */
            break;
        }

        /* The receive buffer does not yet contain the required amount of 
           bytes. Wait for a maximum of xTicksToWait ticks to be notified that 
           the receive interrupt service routine has placed more data into the 
           buffer. It does not matter if the calling task already had a 
           notification pending when it called this function, if it did, it
           would just iteration around this while loop one extra time. */
        ulTaskNotifyTake( pdTRUE, xTicksToWait );
    }

    /* No tasks are waiting for receive notifications, so set xTaskToNotify
       back to NULL. The book text contains notes as to whether the following 
       line needs to be protected by a critical section or not. */
    pxUARTInstance-&gt;xTaskToNotify = NULL;

    /* Attempt to read uxWantedBytes from the receive buffer into pucBuffer. 
       The actual number of bytes read (which might be less than uxWantedBytes)
       is returned. */
    uxReceived = UART_read_from_receive_buffer( pxUARTInstance, 
                                                pucBuffer,
                                                uxWantedBytes );
    return uxReceived;
}

/*-----------------------------------------------------------*/

/* The interrupt service routine for the UART's receive interrupt */
void xUART_ReceiveISR( xUART *pxUARTInstance )
{
    BaseType_t xHigherPriorityTaskWoken = pdFALSE;

    /* Copy received data into this UART's receive buffer and clear the
       interrupt. */
    UART_low_level_receive( pxUARTInstance );

    /* If a task is waiting to be notified of the new data then notify it now. */
    if( pxUARTInstance-&gt;xTaskToNotify != NULL )
    {
        vTaskNotifyGiveFromISR( pxUARTInstance-&gt;xTaskToNotify,
                                &amp;xHigherPriorityTaskWoken );
        portYIELD_FROM_ISR( xHigherPriorityTaskWoken );
    }
}
</code></pre>
<p><em><strong>Listing 10.12</strong></em> <em>Pseudo code demonstrating how a task notification can be used in a driver library receive function</em></p>
<h3 id="1038-task-notifications-used-in-peripheral-device-drivers-adc-example"><a class="header" href="#1038-task-notifications-used-in-peripheral-device-drivers-adc-example">10.3.8 Task Notifications Used in Peripheral Device Drivers: ADC Example</a></h3>
<p>The previous section demonstrated how to use <code>vTaskNotifyGiveFromISR()</code> to
send a task notification from an interrupt to a task.
<code>vTaskNotifyGiveFromISR()</code> is a simple function to use, but its
capabilities are limited; it can only send a task notification as a
valueless event, it cannot send data. This section demonstrates how to
use <code>xTaskNotifyFromISR()</code> to send data with a task notification event.
The technique is demonstrated by the pseudo code shown in Listing 10.13,
which provides the outline of an RTOS aware interrupt service routine
for an Analog to Digital Converter (ADC). In Listing 10.13:</p>
<ul>
<li>
<p>It is assumed an ADC conversion is started at least every 50
milliseconds.</p>
</li>
<li>
<p><code>ADC_ConversionEndISR()</code> is the interrupt service routine for the
ADC's conversion end interrupt, which is the interrupt that executes
each time a new ADC value is available.</p>
</li>
<li>
<p>The task implemented by <code>vADCTask()</code> processes each value generated by
the ADC. It is assumed the task's handle was stored in
<code>xADCTaskToNotify</code> when the task was created.</p>
</li>
<li>
<p><code>ADC_ConversionEndISR()</code> uses <code>xTaskNotifyFromISR()</code> with the <code>eAction</code>
parameter set to <code>eSetValueWithoutOverwrite</code> to send a task
notification to the <code>vADCTask()</code> task, and write the result of the ADC
conversion into the task's notification value.</p>
</li>
<li>
<p>The <code>vADCTask()</code> task uses <code>xTaskNotifyWait()</code> to wait to be notified
that a new ADC value is available, and to retrieve the result of the
ADC conversion from its notification value.</p>
</li>
</ul>
<p><a name="list10.13" title="Listing 10.13 Pseudo code demonstrating how a task notification can be used to pass a value to a task"></a></p>
<pre><code class="language-c">/* A task that uses an ADC. */
void vADCTask( void *pvParameters )
{
    uint32_t ulADCValue;
    BaseType_t xResult;

    /* The rate at which ADC conversions are triggered. */
    const TickType_t xADCConversionFrequency = pdMS_TO_TICKS( 50 );

    for( ;; )
    {
        /* Wait for the next ADC conversion result. */
        xResult = xTaskNotifyWait(
                    /* The new ADC value will overwrite the old value, so there
                       is no need to clear any bits before waiting for the new 
                       notification value. */
                    0,
                    /* Future ADC values will overwrite the existing value, so
                       there is no need to clear any bits before exiting 
                       xTaskNotifyWait(). */
                    0,
                    /* The address of the variable into which the task's 
                       notification value (which holds the latest ADC 
                       conversion result) will be copied. */
                    &amp;ulADCValue,
                    /* A new ADC value should be received every 
                       xADCConversionFrequency ticks. */
                    xADCConversionFrequency * 2 );

        if( xResult == pdPASS )
        {
            /* A new ADC value was received. Process it now. */
            ProcessADCResult( ulADCValue );
        }
        else
        {
            /* The call to xTaskNotifyWait() did not return within the expected
               time, something must be wrong with the input that triggers the 
               ADC conversion, or with the ADC itself. Handle the error here. */
        }
    }
}

/*-----------------------------------------------------------*/

/* The interrupt service routine that executes each time an ADC conversion 
   completes. */
void ADC_ConversionEndISR( xADC *pxADCInstance )
{
    uint32_t ulConversionResult;
    BaseType_t xHigherPriorityTaskWoken = pdFALSE, xResult;

    /* Read the new ADC value and clear the interrupt. */
    ulConversionResult = ADC_low_level_read( pxADCInstance );

    /* Send a notification, and the ADC conversion result, directly to
       vADCTask(). */
    xResult = xTaskNotifyFromISR( xADCTaskToNotify, /* xTaskToNotify parameter */
                                  ulConversionResult, /* ulValue parameter */
                                  eSetValueWithoutOverwrite, /* eAction parameter. */
                                  &amp;xHigherPriorityTaskWoken );

    /* If the call to xTaskNotifyFromISR() returns pdFAIL then the task is not
       keeping up with the rate at which ADC values are being generated. 
       configASSERT() is described in section 11.2. */
    configASSERT( xResult == pdPASS );
    portYIELD_FROM_ISR( xHigherPriorityTaskWoken );
}
</code></pre>
<p><em><strong>Listing 10.13</strong></em> <em>Pseudo code demonstrating how a task notification can be used to pass a value to a task</em></p>
<h3 id="1039-task-notifications-used-directly-within-an-application"><a class="header" href="#1039-task-notifications-used-directly-within-an-application">10.3.9 Task Notifications Used Directly Within an Application</a></h3>
<p>This section reinforces the power of task notifications by demonstrating
their use in a hypothetical application that includes the following
functionality:</p>
<ul>
<li>
<p>The application communicates across a slow internet connection to
send data to, and request data from, a remote data server. From here
on, the remote data server is referred to as the <em>cloud server</em>.</p>
</li>
<li>
<p>After requesting data from the cloud server, the requesting task
must wait in the Blocked state for the requested data to be
received.</p>
</li>
<li>
<p>After sending data to the cloud server, the sending task must wait
in the Blocked state for an acknowledgement that the cloud server
received the data correctly.</p>
</li>
</ul>
<p>A schematic of the software design is shown in Figure 10.6. In Figure 10.6:</p>
<ul>
<li>
<p>The complexity of handling multiple internet connections to the
cloud server is encapsulated within a single FreeRTOS task. The task
acts as a proxy server within the FreeRTOS application, and is
referred to as the <em>server task</em>.</p>
</li>
<li>
<p>Application tasks read data from the cloud server by calling
<code>CloudRead()</code>. <code>CloudRead()</code> does not communicate with the cloud server
directly, but instead sends the read request to the server task on a
queue, and receives the requested data from the server task as a
task notification.</p>
</li>
<li>
<p>Application tasks write date to the cloud server by calling
<code>CloudWrite()</code>. <code>CloudWrite()</code> does not communicate with the cloud
server directly, but instead sends the write request to the server
task on a queue, and receives the result of the write operation from
the server task as a task notification.</p>
</li>
</ul>
<p>The structure sent to the server task by the <code>CloudRead()</code> and
<code>CloudWrite()</code> functions is shown in Listing 10.14.</p>
<p><a name="fig10.6" title="Figure 10.6 The communication paths from the application tasks to the cloud server, and back again"></a></p>
<hr />
<p><img src="media/image81.png" alt="" /><br />
<em><strong>Figure 10.6</strong></em> <em>The communication paths from the application tasks to the cloud server, and back again</em></p>
<hr />
<p><a name="list10.14" title="Listing 10.14 The structure and data type sent on a queue to the server task"></a></p>
<pre><code class="language-c">typedef enum CloudOperations
{
    eRead, /* Send data to the cloud server. */
    eWrite /* Receive data from the cloud server. */
} Operation_t;

typedef struct CloudCommand
{
    Operation_t eOperation; /* The operation to perform (read or write). */
    uint32_t ulDataID; /* Identifies the data being read or written. */
    uint32_t ulDataValue; /* Only used when writing data to the cloud server. */
    TaskHandle_t xTaskToNotify;/* The handle of the task performing the operation. */
} CloudCommand_t;
</code></pre>
<p><em><strong>Listing 10.14</strong></em> <em>The structure and data type sent on a queue to the server task</em></p>
<p>Pseudo code for <code>CloudRead()</code> is shown in Listing 10.15. The function sends
its request to the server task, then calls <code>xTaskNotifyWait()</code> to wait in
the Blocked state until it is notified that the requested data is
available.</p>
<p>Pseudo code showing how the server task manages a read request is shown
in Listing 10.16. When the data has been received from the cloud server,
the server task unblocks the application task, and sends the received
data to the application task, by calling <code>xTaskNotify()</code> with the <code>eAction</code>
parameter set to <code>eSetValueWithOverwrite</code>.</p>
<p>Listing 10.16 shows a simplified scenario, as it assumes <code>GetCloudData()</code>
does not have to wait to obtain a value from the cloud server.</p>
<p><a name="list10.15" title="Listing 10.15 The Implementation of the Cloud Read API Function"></a></p>
<pre><code class="language-c">/* ulDataID identifies the data to read. pulValue holds the address of the 
   variable into which the data received from the cloud server is to be written. */
BaseType_t CloudRead( uint32_t ulDataID, uint32_t *pulValue )
{
    CloudCommand_t xRequest;
    BaseType_t xReturn;

    /* Set the CloudCommand_t structure members to be correct for this read
       request. */
    xRequest.eOperation = eRead; /* This is a request to read data. */
    xRequest.ulDataID = ulDataID; /* A code that identifies the data to read. */
    xRequest.xTaskToNotify = xTaskGetCurrentTaskHandle(); /* Handle of the
                                                             calling task. */

    /* Ensure there are no notifications already pending by reading the
       notification value with a block time of 0, then send the structure to 
       the server task. */
    xTaskNotifyWait( 0, 0, NULL, 0 );
    xQueueSend( xServerTaskQueue, &amp;xRequest, portMAX_DELAY );

    /* Wait for a notification from the server task. The server task writes
       the value received from the cloud server directly into this task's 
       notification value, so there is no need to clear any bits in the 
       notification value on entry to or exit from the xTaskNotifyWait() 
       function. The received value is written to *pulValue, so pulValue is
       passed as the address to which the notification value is written. */
    xReturn = xTaskNotifyWait( 0, /* No bits cleared on entry */
                               0, /* No bits to clear on exit */
                               pulValue, /* Notification value into *pulValue */
                               pdMS_TO_TICKS( 250 ) ); /* Wait 250ms maximum */

    /* If xReturn is pdPASS, then the value was obtained. If xReturn is pdFAIL,
       then the request timed out. */
    return xReturn;
}
</code></pre>
<p><em><strong>Listing 10.15</strong></em> <em>The Implementation of the Cloud Read API Function</em></p>
<p><a name="list10.16" title="Listing 10.16 The Server Task Processing a Read Request"></a></p>
<pre><code class="language-c">void ServerTask( void *pvParameters )
{
    CloudCommand_t xCommand;
    uint32_t ulReceivedValue;

    for( ;; )
    {
        /* Wait for the next CloudCommand_t structure to be received from a task */
        xQueueReceive( xServerTaskQueue, &amp;xCommand, portMAX_DELAY );

        switch( xCommand.eOperation ) /* Was it a read or write request? */
        {
            case eRead:

                /* Obtain the requested data item from the remote cloud server */
                ulReceivedValue = GetCloudData( xCommand.ulDataID );

                /* Call xTaskNotify() to send both a notification and the value
                   received from the cloud server to the task that made the 
                   request. The handle of the task is obtained from the 
                   CloudCommand_t structure. */
                xTaskNotify( xCommand.xTaskToNotify, /* The task's handle is in
                                                        the structure */
                             ulReceivedValue, /* Cloud data sent as notification 
                                                 value */
                             eSetValueWithOverwrite );
                break;

                /* Other switch cases go here. */
        }
    }
}
</code></pre>
<p><em><strong>Listing 10.16</strong></em> <em>The Server Task Processing a Read Request</em></p>
<p>Pseudo code for <code>CloudWrite()</code> is shown in Listing 10.17. For the purpose of
demonstration, <code>CloudWrite()</code> returns a bitwise status code, where each
bit in the status code is assigned a unique meaning. Four example status
bits are shown by the #define statements at the top of Listing 10.17.</p>
<p>The task clears the four status bits, sends its request to the server
task, then calls <code>xTaskNotifyWait()</code> to wait in the Blocked state for the
status notification.</p>
<p><a name="list10.17" title="Listing 10.17 The Implementation of the Cloud Write API Function"></a></p>
<pre><code class="language-c">/* Status bits used by the cloud write operation. */
#define SEND_SUCCESSFUL_BIT ( 0x01 &lt;&lt; 0 )
#define OPERATION_TIMED_OUT_BIT ( 0x01 &lt;&lt; 1 )
#define NO_INTERNET_CONNECTION_BIT ( 0x01 &lt;&lt; 2 )
#define CANNOT_LOCATE_CLOUD_SERVER_BIT ( 0x01 &lt;&lt; 3 )

/* A mask that has the four status bits set. */
#define CLOUD_WRITE_STATUS_BIT_MASK ( SEND_SUCCESSFUL_BIT |
                                      OPERATION_TIMED_OUT_BIT |
                                      NO_INTERNET_CONNECTION_BIT |
                                      CANNOT_LOCATE_CLOUD_SERVER_BIT )

uint32_t CloudWrite( uint32_t ulDataID, uint32_t ulDataValue )
{
    CloudCommand_t xRequest;
    uint32_t ulNotificationValue;

    /* Set the CloudCommand_t structure members to be correct for this
       write request. */
    xRequest.eOperation = eWrite; /* This is a request to write data */
    xRequest.ulDataID = ulDataID; /* A code that identifies the data being
                                     written */
    xRequest.ulDataValue = ulDataValue; /* Value of the data written to the
                                           cloud server. */
    xRequest.xTaskToNotify = xTaskGetCurrentTaskHandle(); /* Handle of the 
                                                             calling task. */

    /* Clear the three status bits relevant to the write operation by calling
       xTaskNotifyWait() with the ulBitsToClearOnExit parameter set to
       CLOUD_WRITE_STATUS_BIT_MASK, and a block time of 0. The current
       notification value is not required, so the pulNotificationValue 
       parameter is set to NULL. */
    xTaskNotifyWait( 0, CLOUD_WRITE_STATUS_BIT_MASK, NULL, 0 );

    /* Send the request to the server task. */
    xQueueSend( xServerTaskQueue, &amp;xRequest, portMAX_DELAY );

    /* Wait for a notification from the server task. The server task writes
       a bitwise status code into this task's notification value, which is 
       written to ulNotificationValue. */
    xTaskNotifyWait( 0, /* No bits cleared on entry. */
                     CLOUD_WRITE_STATUS_BIT_MASK, /* Clear relevant bits to 0 on exit. */
                     &amp;ulNotificationValue, /* Notified value. */
                     pdMS_TO_TICKS( 250 ) ); /* Wait a maximum of 250ms. */

    /* Return the status code to the calling task. */
    return ( ulNotificationValue &amp; CLOUD_WRITE_STATUS_BIT_MASK );
}
</code></pre>
<p><em><strong>Listing 10.17</strong></em> <em>The Implementation of the Cloud Write API Function</em></p>
<p>Pseudo code demonstrating how the server task manages a write request is
shown in Listing 10.18. When the data has been sent to the cloud server,
the server task unblocks the application task, and sends the bitwise
status code to the application task, by calling <code>xTaskNotify()</code> with the
<code>eAction</code> parameter set to <code>eSetBits</code>. Only the bits defined by the
<code>CLOUD_WRITE_STATUS_BIT_MASK</code> constant can get altered in the receiving
task's notification value, so the receiving task can use other bits in
its notification value for other purposes.</p>
<p>Listing 10.18 shows a simplified scenario, as it assumes <code>SetCloudData()</code>
does not have to wait to obtain an acknowledgement from the remote cloud
server.</p>
<p><a name="list10.18" title="Listing 10.18 The Server Task Processing a Send Request"></a></p>
<pre><code class="language-c">void ServerTask( void *pvParameters )
{
    CloudCommand_t xCommand;
    uint32_t ulBitwiseStatusCode;

    for( ;; )
    {
        /* Wait for the next message. */
        xQueueReceive( xServerTaskQueue, &amp;xCommand, portMAX_DELAY );

        /* Was it a read or write request? */
        switch( xCommand.eOperation )
        {
            case eWrite:

            /* Send the data to the remote cloud server. SetCloudData() returns
               a bitwise status code that only uses the bits defined by the
               CLOUD_WRITE_STATUS_BIT_MASK definition (shown in Listing 10.17). */
            ulBitwiseStatusCode = SetCloudData( xCommand.ulDataID,
                                                xCommand.ulDataValue );

            /* Send a notification to the task that made the write request. 
               The eSetBits action is used so any status bits set in 
               ulBitwiseStatusCode will be set in the notification value of 
               the task being notified. All the other bits remain unchanged. 
               The handle of the task is obtained from the CloudCommand_t
               structure. */
            xTaskNotify( xCommand.xTaskToNotify, /* The task's handle is in 
                                                    the structure. */
                         ulBitwiseStatusCode,    /* Cloud data sent as 
                                                    notification value. */
                         eSetBits );
            break;

            /* Other switch cases go here. */
        }
    }
}
</code></pre>
<p><em><strong>Listing 10.18</strong></em> <em>The Server Task Processing a Send Request</em></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="11-low-power-support-1"><a class="header" href="#11-low-power-support-1">11 Low Power Support</a></h1>
<h2 id="111-power-saving-introduction"><a class="header" href="#111-power-saving-introduction">11.1 Power Saving Introduction</a></h2>
<p>FreeRTOS offers an easy way to tap into low power modes with the IDLE task
hooks and tickless Idle mode.</p>
<p>It is common to reduce the power consumed by the microcontroller on which FreeRTOS is running by using
the IDLE task hook to place the microcontroller into a low power state. The power saving that can be
achieved by this method is limited by the necessity to periodically exit and then re-enter the low power
state to process tick interrupts. Further, if the frequency of the tick interrupt is too high (wake from
idle is too frequent), the energy and time consumed entering and then exiting a low power state for every
tick will outweigh any potential power saving gains for all but the lightest power saving modes.</p>
<p>FreeRTOS supports a low power state that allows the microcontroller to periodically enter and exit low
power consumption. The FreeRTOS tickless idle mode stops the periodic tick interrupt during idle periods
(when there are no application tasks that are able to execute), which allows the MCU to remain in a deep
power saving state until either an interrupt occurs, or it is time for the RTOS kernel to transition a
task into the Ready state. It then makes a correcting adjustment to the RTOS tick count value when the
tick interrupt is restarted. The principle of the FreeRTOS tickless mode is to make the MCU enter the
low-power mode to save system power consumption when the MCU is performing the idle task.</p>
<h2 id="112-freertos-sleep-modes"><a class="header" href="#112-freertos-sleep-modes">11.2 FreeRTOS Sleep Modes</a></h2>
<p>There are three types of sleep modes supported in FreeRTOS:</p>
<ol>
<li>
<p>eAbortSleep - This mode denotes a task has been made ready , a context switch was pended or a tick
interrupt has already occurred but was pended since the scheduler was suspended. It signals the RTOS
to abort entering a sleep mode.</p>
</li>
<li>
<p>eStandardSleep - This mode allows to enter a sleep mode that will not last longer than the expected
idle time.</p>
</li>
<li>
<p>eNoTasksWaitingTimeout - This mode is entered when no tasks are waiting for a timeout so it is safe to
enter a sleep mode that can only be exited by an external interrupt or reset.</p>
</li>
</ol>
<h2 id="113-functions-and-enabling-built-in-tickless-idle-functionality"><a class="header" href="#113-functions-and-enabling-built-in-tickless-idle-functionality">11.3 Functions and Enabling Built-in Tickless Idle Functionality</a></h2>
<p>The Built-in Tickless Idle functionality is enabled by defining <code>configUSE_TICKLESS_IDLE</code> as 1 in FreeRTOSConfig.h
(for ports that support this feature). User defined tickless idle functionality can be provided for any
FreeRTOS port (including those that include a built in implementation) by defining <code>configUSE_TICKLESS_IDLE</code>
to 2 in FreeRTOSConfig.h.</p>
<p>When the tickless idle functionality is enabled, the kernel will call the <code>portSUPPRESS_TICKS_AND_SLEEP()</code>
macro when the following two conditions are satisfied:</p>
<ol>
<li>
<p>The Idle task is the only task able to run because all the application tasks are either in the Blocked
state or in the Suspended state.</p>
</li>
<li>
<p>At least n further complete tick periods will pass before the kernel is due to transition an application
task out of the Blocked state, where n is set by the <code>configEXPECTED_IDLE_TIME_BEFORE_SLEEP</code> definition
in FreeRTOSConfig.h.</p>
</li>
</ol>
<h3 id="1131-the-portsuppress_ticks_and_sleep-macro"><a class="header" href="#1131-the-portsuppress_ticks_and_sleep-macro">11.3.1 The portSUPPRESS_TICKS_AND_SLEEP() Macro</a></h3>
<p><a name="list11.1" title="Listing 11.1 The prototype for the portSUPPRESS\_TICKS\_AND\_SLEEP macro"></a></p>
<pre><code class="language-c">portSUPPRESS_TICKS_AND_SLEEP( xExpectedIdleTime )
</code></pre>
<p><em><strong>Listing 11.1</strong></em> <em>The prototype for the portSUPPRESS_TICKS_AND_SLEEP macro</em></p>
<p>The value of the <code>xExpectedIdleTime</code> parameter in <code>portSUPPRESS_TICKS_AND_SLEEP()</code> equals the total number
of tick periods before a task is due to be moved into the Ready state. The parameter value is therefore the
time the microcontroller can safely remain in a deep sleep state, with the tick interrupt suppressed.</p>
<h3 id="1132-the-vportsuppressticksandsleep-function"><a class="header" href="#1132-the-vportsuppressticksandsleep-function">11.3.2 The vPortSuppressTicksAndSleep Function</a></h3>
<p>The <code>vPortSuppressTicksAndSleep()</code> function is defined in FreeRTOS and it can be used to implement the
tickless mode. This function is weakly defined in the FreeRTOS Cortex-M port layer and can be overridden
by the application writer.</p>
<p><a name="list11.2" title="Listing 11.2 The vPortSuppressTicksAndSleep API function prototype"></a></p>
<pre><code class="language-c">void vPortSuppressTicksAndSleep( TickType_t xExpectedIdleTime );
</code></pre>
<p><em><strong>Listing 11.2</strong></em> <em>The vPortSuppressTicksAndSleep API function prototype</em></p>
<h3 id="1133-the-etaskconfirmsleepmodestatus-function"><a class="header" href="#1133-the-etaskconfirmsleepmodestatus-function">11.3.3 The eTaskConfirmSleepModeStatus Function</a></h3>
<p>The API <em>eTaskConfirmSleepModeStatus</em> returns the sleep mode status to determine if it is ok to proceed
with the sleep and if it is ok to sleep indefinitely. This functionality is only available when <code>configUSE_TICKLESS_IDLE</code>
is set to 1.</p>
<p><a name="list11.3" title="Listing 11.3 The eTaskConfirmSleepModeStatus API function prototype"></a></p>
<pre><code class="language-c">eSleepModeStatus eTaskConfirmSleepModeStatus( void );
</code></pre>
<p><em><strong>Listing 11.3</strong></em> <em>The eTaskConfirmSleepModeStatus API function prototype</em></p>
<p>If <code>eTaskConfirmSleepModeStatus()</code> returns <code>eNoTasksWaitingTimeout</code> when it is called from
within <code>portSUPPRESS_TICKS_AND_SLEEP()</code>, then the microcontroller can remain in a deep sleep state
indefinitely. <code>eTaskConfirmSleepModeStatus()</code> will only return <code>eNoTasksWaitingTimeout</code> when the
following conditions are true:</p>
<ul>
<li>
<p>Software timers are not being used, so the scheduler is not due to execute a timer callback function
at any time in the future.</p>
</li>
<li>
<p>All the application tasks are either in the Suspended state, or in the Blocked state with a timeout value
of <code>portMAX_DELAY</code>, so the scheduler is not due to transition a task out of the Blocked state at any fixed
time in the future.</p>
</li>
</ul>
<p>To avoid race conditions, the FreeRTOS scheduler is suspended before <code>portSUPPRESS_TICKS_AND_SLEEP()</code> is
called, and resumed when <code>portSUPPRESS_TICKS_AND_SLEEP()</code> completes. This ensures application tasks cannot
execute between the microcontroller exiting its low power state and <code>portSUPPRESS_TICKS_AND_SLEEP()</code>
completing its execution. Further, it is necessary for the <code>portSUPPRESS_TICKS_AND_SLEEP()</code> function to
create a small critical section between the timer being stopped and the sleep mode being entered to ensure
it is ok to proceed into the sleep mode. <code>eTaskConfirmSleepModeStatus()</code> should be called from this critical
section.</p>
<p>In addition, FreeRTOS provides users with two other interface functions defined in FreeRTOSConfig.h. These
macros allow the application writer to add additional steps before and after the MCU is placed into the low
power state, respectively.</p>
<h3 id="1134-the-configpre_sleep_processing-configuration"><a class="header" href="#1134-the-configpre_sleep_processing-configuration">11.3.4 The configPRE_SLEEP_PROCESSING configuration</a></h3>
<p><a name="list11.4" title="Listing 11.4 The prototype for the configPRE\_SLEEP\_PROCESSING macro"></a></p>
<pre><code class="language-c">configPRE_SLEEP_PROCESSING( xExpectedIdleTime )
</code></pre>
<p><em><strong>Listing 11.4</strong></em> <em>The prototype for the configPRE_SLEEP_PROCESSING macro</em></p>
<p>Before the user can make the MCU enter the low-power mode, <code>configPRE_SLEEP_PROCESSING()</code> must be called to
configure the system parameters to reduce the system power consumption, such as turning off other peripheral
clocks, reducing the system frequency.</p>
<h3 id="1135-the-configpost_sleep_processing-configuration"><a class="header" href="#1135-the-configpost_sleep_processing-configuration">11.3.5 The configPOST_SLEEP_PROCESSING configuration</a></h3>
<p><a name="list11.5" title="Listing 11.5 The prototype for the configPOST\_SLEEP\_PROCESSING macro"></a></p>
<pre><code class="language-c">configPOST_SLEEP_PROCESSING( xExpectedIdleTime )
</code></pre>
<p><em><strong>Listing 11.5</strong></em> <em>The prototype for the configPOST_SLEEP_PROCESSING macro</em></p>
<p>After exiting the low-power mode, the user should call the <code>configPOST_SLEEP_PROCESSING()</code> function
to restore the system's main frequency and peripheral functions.</p>
<h2 id="114-implementing-portsuppress_ticks_and_sleep-macro"><a class="header" href="#114-implementing-portsuppress_ticks_and_sleep-macro">11.4 Implementing portSUPPRESS_TICKS_AND_SLEEP() Macro</a></h2>
<p>If the FreeRTOS port in use does not provide a default implementation of <code>portSUPPRESS_TICKS_AND_SLEEP()</code>,
then the application writer can provide their own implementation by defining <code>portSUPPRESS_TICKS_AND_SLEEP()</code>
in FreeRTOSConfig.h. If the FreeRTOS port in use does provide a default implementation of <code>portSUPPRESS_TICKS_AND_SLEEP()</code>,
then the application writer can override the default implementation by defining <code>portSUPPRESS_TICKS_AND_SLEEP()</code>
in FreeRTOSConfig.h.</p>
<p>The following source code is an example of how <code>portSUPPRESS_TICKS_AND_SLEEP()</code> might be implemented by an
application writer. The example is basic, and will introduce some slippage between the time maintained by
the kernel and calendar time. Of the function calls shown in the example, only <code>vTaskStepTick()</code>
and <code>eTaskConfirmSleepModeStatus()</code> are part of the FreeRTOS API. The other functions are specific to the
clocks and power saving modes available on the hardware in use, and as such, must be provided by the
application writer.</p>
<p><a name="list11.6" title="Listing 11.6 An example of a user defined implementation of portSUPPRESS\_TICKS\_AND\_SLEEP()"></a></p>
<pre><code class="language-c">/* First define the portSUPPRESS_TICKS_AND_SLEEP() macro.  The parameter is the
   time, in ticks, until the kernel next needs to execute. */

#define portSUPPRESS_TICKS_AND_SLEEP( xIdleTime ) vApplicationSleep( xIdleTime )

/* Define the function that is called by portSUPPRESS_TICKS_AND_SLEEP(). */
void vApplicationSleep( TickType_t xExpectedIdleTime )
{
    unsigned long ulLowPowerTimeBeforeSleep, ulLowPowerTimeAfterSleep;

    eSleepModeStatus eSleepStatus;

    /* Read the current time from a time source that will remain operational
       while the microcontroller is in a low power state. */
    ulLowPowerTimeBeforeSleep = ulGetExternalTime();

    /* Stop the timer that is generating the tick interrupt. */
    prvStopTickInterruptTimer();

    /* Enter a critical section that will not effect interrupts bringing the MCU
       out of sleep mode. */
    disable_interrupts();

    /* Ensure it is still ok to enter the sleep mode. */
    eSleepStatus = eTaskConfirmSleepModeStatus();

    if( eSleepStatus == eAbortSleep )
    {
        /* A task has been moved out of the Blocked state since this macro was
           executed, or a context siwth is being held pending.  Do not enter a
           sleep state.  Restart the tick and exit the critical section. */
        prvStartTickInterruptTimer();
        enable_interrupts();
    }
    else
    {
        if( eSleepStatus == eNoTasksWaitingTimeout )
        {
            /* It is not necessary to configure an interrupt to bring the
               microcontroller out of its low power state at a fixed time in 
               the future. */
            prvSleep();
        }
        else
        {
            /* Configure an interrupt to bring the microcontroller out of its low
               power state at the time the kernel next needs to execute.  The
               interrupt must be generated from a source that remains operational
               when the microcontroller is in a low power state. */
            vSetWakeTimeInterrupt( xExpectedIdleTime );

            /* Enter the low power state. */
            prvSleep();

            /* Determine how long the microcontroller was actually in a low power
               state for, which will be less than xExpectedIdleTime if the
               microcontroller was brought out of low power mode by an interrupt
               other than that configured by the vSetWakeTimeInterrupt() call.
               Note that the scheduler is suspended before
               portSUPPRESS_TICKS_AND_SLEEP() is called, and resumed when
               portSUPPRESS_TICKS_AND_SLEEP() returns.  Therefore no other tasks will
               execute until this function completes. */
            ulLowPowerTimeAfterSleep = ulGetExternalTime();

            /* Correct the kernels tick count to account for the time the
               microcontroller spent in its low power state. */
            vTaskStepTick( ulLowPowerTimeAfterSleep - ulLowPowerTimeBeforeSleep );
        }

        /* Exit the critical section - it might be possible to do this immediately
           after the prvSleep() calls. */
        enable_interrupts();

        /* Restart the timer that is generating the tick interrupt. */
        prvStartTickInterruptTimer();
    }
}
</code></pre>
<p><em><strong>Listing 11.6</strong></em> <em>An example of a user defined implementation of portSUPPRESS_TICKS_AND_SLEEP()</em></p>
<h2 id="115-idle-task-hook-function"><a class="header" href="#115-idle-task-hook-function">11.5 Idle Task Hook Function</a></h2>
<p>The Idle task can optionally call an application defined hook (or callback) function - the idle hook.
The idle task runs at the lowest priority, so such an idle hook function will only get executed when
there are no tasks of higher priority that are able to run. This makes the Idle hook function an ideal
place to put the processor into a low power state - providing an automatic power saving whenever there
is no processing to be performed. The Idle hook will only get called if <code>configUSE_IDLE_HOOK</code> is set
to 1 within FreeRTOSConfig.h.</p>
<p><a name="list11.7" title="Listing 11.7 The vApplicationIdleHook API function prototype"></a></p>
<pre><code class="language-c">void vApplicationIdleHook( void );
</code></pre>
<p><em><strong>Listing 11.7</strong></em> <em>The vApplicationIdleHook API function prototype</em></p>
<p>The idle hook is called repeatedly as long as the idle task is running. It is paramount that the idle
hook function does not call any API functions that could cause it to block. Also, if the application
makes use of the <code>vTaskDelete()</code> API function then the idle task hook must be allowed to periodically
return, since the idle task is responsible for cleaning up the resources that were allocated by the RTOS
kernel to the task that has been deleted.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="12-developer-support-1"><a class="header" href="#12-developer-support-1">12 Developer Support</a></h1>
<h2 id="121-introduction"><a class="header" href="#121-introduction">12.1 Introduction</a></h2>
<p>This chapter highlights a set of features that are included to maximize
productivity by:</p>
<ul>
<li>Providing insight into how an application is behaving.</li>
<li>Highlighting opportunities for optimization.</li>
<li>Trapping errors at the point at which they occur.</li>
</ul>
<h2 id="122-configassert"><a class="header" href="#122-configassert">12.2 configASSERT()</a></h2>
<p>In C, the macro <code>assert()</code> is used to verify an <em>assertion</em> (an
assumption) made by the program. The assertion is written as a C
expression, and if the expression evaluates to false (0), then the
assertion has deemed to have failed. For example, Listing 12.1 tests the
assertion that the pointer <code>pxMyPointer</code> is not NULL.</p>
<p><a name="list12.1" title="Listing 12.1 Using the standard C assert() macro to check pxMyPointer is not NULL"></a></p>
<pre><code class="language-c">/* Test the assertion that pxMyPointer is not NULL */
assert( pxMyPointer != NULL );
</code></pre>
<p><em><strong>Listing 12.1</strong></em> <em>Using the standard C assert() macro to check pxMyPointer is not NULL</em></p>
<p>The application writer specifies the action to take if an assertion
fails by providing an implementation of the <code>assert()</code> macro.</p>
<p>The FreeRTOS source code does not call <code>assert()</code>, because <code>assert()</code> is not
available with all the compilers with which FreeRTOS is compiled.
Instead, the FreeRTOS source code contains lots of calls to a macro
called <code>configASSERT()</code>, which can be defined by the application writer in
<code>FreeRTOSConfig.h</code>, and behaves exactly like the standard C <code>assert()</code>.</p>
<p>A failed assertion must be treated as a fatal error. Do not attempt to
execute past a line that has failed an assertion.</p>
<blockquote>
<p><em>Using <code>configASSERT()</code> improves productivity by immediately trapping and
identifying many of the most common sources of error. It is strongly
advised to have <code>configASSERT()</code> defined while developing or debugging a
FreeRTOS application.</em></p>
</blockquote>
<p>Defining <code>configASSERT()</code> will greatly assist in run-time debugging, but
will also increase the application code size, and therefore slow down
its execution. If a definition of <code>configASSERT()</code> is not provided, then
the default empty definition will be used, and all the calls to
<code>configASSERT()</code> will be completely removed by the C pre-processor.</p>
<h3 id="1221-example-configassert-definitions"><a class="header" href="#1221-example-configassert-definitions">12.2.1 Example configASSERT() definitions</a></h3>
<p>The definition of <code>configASSERT()</code> shown in Listing 12.2 is useful when an
application is being executed under the control of a debugger. It will
halt execution on any line that fails an assertion, so the line that
failed the assertion will be the line displayed by the debugger when the
debug session is paused.</p>
<p><a name="list12.2" title="Listing 12.2 A simple configASSERT() definition useful when executing under the control of a debugger"></a></p>
<pre><code class="language-c">/* Disable interrupts so the tick interrupt stops executing, then sit
   in a loop so execution does not move past the line that failed the
   assertion. If the hardware supports a debug break instruction, then the
   debug break instruction can be used in place of the for() loop. */

#define configASSERT( x ) if( ( x ) == 0 ) { taskDISABLE_INTERRUPTS(); for(;;); }
</code></pre>
<p><em><strong>Listing 12.2</strong></em> <em>A simple configASSERT() definition useful when executing under the control of a debugger</em></p>
<p>The definition of <code>configASSERT()</code> shown in Listing 12.3 is useful when an
application is not being executed under the control of a debugger. It
prints out, or otherwise records, the source code line that failed an
assertion. The line that failed the assertion is identified using the
standard C <code>__FILE__</code> macro to obtain the name of the source file, and
the standard C <code>__LINE__</code> macro to obtain the line number within the
source file.</p>
<p><a name="list12.3" title="Listing 12.3 A configASSERT() definition that records the source code line that failed an assertion"></a></p>
<pre><code class="language-c">/* This function must be defined in a C source file, not the FreeRTOSConfig.h 
   header file. */
void vAssertCalled( const char *pcFile, uint32_t ulLine )
{
    /* Inside this function, pcFile holds the name of the source file that 
       contains the line that detected the error, and ulLine holds the line 
       number in the source file. The pcFile and ulLine values can be printed 
       out, or otherwise recorded, before the following infinite loop is 
       entered. */
    RecordErrorInformationHere( pcFile, ulLine );

    /* Disable interrupts so the tick interrupt stops executing, then sit in a 
       loop so execution does not move past the line that failed the assertion. */
    taskDISABLE_INTERRUPTS();
    for( ;; );
}
/*-----------------------------------------------------------*/

/* These following two lines must be placed in FreeRTOSConfig.h. */
extern void vAssertCalled( const char *pcFile, unsigned long ulLine );
#define configASSERT( x ) if( ( x ) == 0 ) vAssertCalled( __FILE__, __LINE__ )
</code></pre>
<p><em><strong>Listing 12.3</strong></em> <em>A configASSERT() definition that records the source code line that failed an assertion</em></p>
<h2 id="123-tracealyzer-for-freertos"><a class="header" href="#123-tracealyzer-for-freertos">12.3 Tracealyzer for FreeRTOS</a></h2>
<p>Tracealyzer for FreeRTOS is a run-time diagnostic and optimization tool provided
by our partner company, Percepio.</p>
<p>Tracealyzer for FreeRTOS captures valuable dynamic behavior information, then
presents the captured information in interconnected graphical views. The
tool is also capable of displaying multiple synchronized views.</p>
<p>The captured information is invaluable when analyzing, troubleshooting,
or simply optimizing a FreeRTOS application.</p>
<p>Tracealyzer for FreeRTOS can be used side-by-side with a traditional debugger, and
complements the debugger's view with a higher level, time-based
perspective.</p>
<p><a name="fig12.1" title="Figure 12.1 FreeRTOS+Trace includes more than 20 interconnected views"></a>
<a name="fig12.2" title="Figure 12.2 FreeRTOS+Trace main trace view - one of more than 20 interconnected trace views"></a>
<a name="fig12.3" title="Figure 12.3 FreeRTOS+Trace CPU load view - one of more than 20 interconnected trace views"></a>
<a name="fig12.4" title="Figure 12.4 FreeRTOS+Trace response time view - one of more than 20 interconnected trace views"></a>
<a name="fig12.5" title="Figure 12.5 FreeRTOS+Trace user event plot view - one of more than 20 interconnected trace views"></a>
<a name="fig12.6" title="Figure 12.6 FreeRTOS+Trace kernel object history view - one of more than 20 interconnected trace views"></a></p>
<hr />
<p><img src="media/image82.png" alt="" /><br />
<em><strong>Figure 12.1</strong></em> <em>FreeRTOS+Trace includes more than 20 interconnected views</em></p>
<p><img src="media/image83.png" alt="" /><br />
<em><strong>Figure 12.2</strong></em> <em>FreeRTOS+Trace main trace view - one of more than 20 interconnected trace views</em></p>
<p><img src="media/image84.png" alt="" /><br />
<em><strong>Figure 12.3</strong></em> <em>FreeRTOS+Trace CPU load view - one of more than 20 interconnected trace views</em></p>
<p><img src="media/image85.png" alt="" /><br />
<em><strong>Figure 12.4</strong></em> <em>FreeRTOS+Trace response time view - one of more than 20 interconnected trace views</em></p>
<p><img src="media/image86.png" alt="" /><br />
<em><strong>Figure 12.5</strong></em> <em>FreeRTOS+Trace user event plot view - one of more than 20 interconnected trace views</em></p>
<p><img src="media/image87.png" alt="" /><br />
<em><strong>Figure 12.6</strong></em> <em>FreeRTOS+Trace kernel object history view - one of more than 20 interconnected trace views</em></p>
<hr />
<h2 id="124-debug-related-hook-callback-functions"><a class="header" href="#124-debug-related-hook-callback-functions">12.4 Debug Related Hook (Callback) Functions</a></h2>
<h3 id="1241-malloc-failed-hook"><a class="header" href="#1241-malloc-failed-hook">12.4.1 Malloc failed hook</a></h3>
<p>The malloc failed hook (or callback) was described in Chapter 3, Heap
Memory Management.</p>
<p>Defining a malloc failed hook ensures the application developer is
notified immediately if an attempt to create a task, queue, semaphore or
event group fails.</p>
<h3 id="1242-stack-overflow-hook"><a class="header" href="#1242-stack-overflow-hook">12.4.2 Stack overflow hook</a></h3>
<p>Details of the stack overflow hook are provided in section 13.3, Stack
Overflow.</p>
<p>Defining a stack overflow hook ensures the application developer is
notified if the amount of stack used by a task exceeds the stack space
allocated to the task.</p>
<h2 id="125-viewing-run-time-and-task-state-information"><a class="header" href="#125-viewing-run-time-and-task-state-information">12.5 Viewing Run-time and Task State Information</a></h2>
<h3 id="1251-task-run-time-statistics"><a class="header" href="#1251-task-run-time-statistics">12.5.1 Task Run-Time Statistics</a></h3>
<p>Task run-time statistics provide information on the amount of processing
time each task has received. A task's <em>run time</em> is the total time the
task has been in the Running state since the application booted.</p>
<p>Run-time statistics are intended to be used as a profiling and debugging
aid during the development phase of a project. The information they
provide is only valid until the counter used as the run-time statistics
clock overflows. Collecting run-time statistics will increase the task
context switch time.</p>
<p>To obtain binary run-time statistics information, call the
<code>uxTaskGetSystemState()</code> API function. To obtain run-time statistics
information as a human readable ASCII table, call the
<code>vTaskGetRunTimeStatistics()</code> helper function.</p>
<h3 id="1252-the-run-time-statistics-clock"><a class="header" href="#1252-the-run-time-statistics-clock">12.5.2 The Run-Time Statistics Clock</a></h3>
<p>Run-time statistics need to measure fractions of a tick period.
Therefore, the RTOS tick count is not used as the run-time statistics
clock, and the clock is instead provided by the application code. It is
recommended to make the frequency of the run-time statistics clock
between 10 and 100 times faster than the frequency of the tick
interrupt. The faster the run-time statistics clock, the more accurate
the statistics will be, but also the sooner the time value will
overflow.</p>
<p>Ideally, the time value will be generated by a free-running 32-bit
peripheral timer/counter, the value of which can be read with no other
processing overhead. If the available peripherals and clock speeds do
not make that technique possible, then alternative, but less efficient,
techniques include:</p>
<ul>
<li>
<p>Configure a peripheral to generate a periodic interrupt at the
desired run-time statistics clock frequency, and then use a count
of the number of interrupts generated as the run-time statistics clock.</p>
<p>This method is very inefficient if the periodic interrupt is only
used for the purpose of providing a run-time statistics clock.
However, if the application already uses a periodic interrupt with a
suitable frequency, then it is simple and efficient to add a count
of the number of interrupts generated into the existing interrupt
service routine.</p>
</li>
<li>
<p>Generate a 32-bit value by using the current value of a free running
16-bit peripheral timer as the 32-bit value's least significant
16-bits, and the number of times the timer has overflowed as the
32-bit value's most significant 16-bits.</p>
</li>
</ul>
<p>It is possible, with appropriate and somewhat complex manipulation, to
generate a run-time statistics clock by combining the RTOS tick count
with the current value of an ARM Cortex-M SysTick timer. Some of the
demo projects in the FreeRTOS download demonstrate how this is achieved.</p>
<h3 id="1253-configuring-an-application-to-collect-run-time-statistics"><a class="header" href="#1253-configuring-an-application-to-collect-run-time-statistics">12.5.3 Configuring an Application to Collect Run-Time Statistics</a></h3>
<p>Below are details on the macros necessary to collect task run-time
statistics. Originally, the macros were intended to be included in
the RTOS port layer, which is why the macros are prefixed 'port', but it
has proven more practical to define them in <code>FreeRTOSConfig.h</code>.</p>
<p><strong>Macros used in the collection of run-time statistics</strong></p>
<ul>
<li>
<p><code>configGENERATE_RUN_TIME_STATS</code></p>
<p>This macro must be set to 1 in FreeRTOSConfig.h. When this macro is
set to 1 the scheduler will call the other macros detailed in this section
at the appropriate times.</p>
</li>
<li>
<p><code>portCONFIGURE_TIMER_FOR_RUN_TIME_STATS()</code></p>
<p>This macro must be provided to initialize whichever peripheral is
used to provide the run-time statistics clock.</p>
</li>
<li>
<p><code>portGET_RUN_TIME_COUNTER_VALUE()</code>, or <code>portALT_GET_RUN_TIME_COUNTER_VALUE(Time)</code></p>
<p>One of these two macros must be provided to return the current
run-time statistics clock value. This is the total time the application
has been running, in run-time statistics clock units, since the
application first booted.</p>
<p>If the first macro is used, it must be defined to evaluate to the
current clock value. If the second macro is used, it must be defined to
set its 'Time' parameter to the current clock value.</p>
</li>
</ul>
<h3 id="1254-the-uxtaskgetsystemstate-api-function"><a class="header" href="#1254-the-uxtaskgetsystemstate-api-function">12.5.4 The uxTaskGetSystemState() API Function</a></h3>
<p><code>uxTaskGetSystemState()</code> provides a snapshot of status information for
each task under the control of the FreeRTOS scheduler. The information
is provided as an array of <code>TaskStatus_t</code> structures, with one index in
the array for each task. <code>TaskStatus_t</code> is described by Listing 12.5 and
below.</p>
<p><a name="list12.4" title="Listing 12.4 The uxTaskGetSystemState() API function prototype"></a></p>
<pre><code class="language-c">UBaseType_t uxTaskGetSystemState( TaskStatus_t * const pxTaskStatusArray,
                                  const UBaseType_t uxArraySize,
                                  configRUN_TIME_COUNTER_TYPE * const pulTotalRunTime );
</code></pre>
<p><em><strong>Listing 12.4</strong></em> <em>The uxTaskGetSystemState() API function prototype</em></p>
<blockquote>
<p>Note: <code>configRUN_TIME_COUNTER_TYPE</code> defaults to <code>uint32_t</code> for backward compatibility, but can be
overridden in FreeRTOSConfig.h if <code>uint32_t</code> is too restrictive.</p>
</blockquote>
<p><strong>uxTaskGetSystemState() parameters and return value</strong></p>
<ul>
<li>
<p><code>pxTaskStatusArray</code></p>
<p>A pointer to an array of <code>TaskStatus_t</code> structures.</p>
<p>The array must contain at least one <code>TaskStatus_t</code> structure for each
task. The number of tasks can be determined using the
<code>uxTaskGetNumberOfTasks()</code> API function.</p>
<p>The <code>TaskStatus_t</code> structure is shown in Listing 12.5, and the
TaskStatus_t structure members are described in the next list.</p>
</li>
<li>
<p><code>uxArraySize</code></p>
<p>The size of the array pointed to by the <code>pxTaskStatusArray</code> parameter.
The size is specified as the number of indexes in the array (the number
of <code>TaskStatus_t</code> structures contained in the array), not by the number of
bytes in the array.</p>
</li>
<li>
<p><code>pulTotalRunTime</code></p>
<p>If <code>configGENERATE_RUN_TIME_STATS</code> is set to 1 in <code>FreeRTOSConfig.h</code>,
then <code>*pulTotalRunTime</code> is set by <code>uxTaskGetSystemState()</code> to the total run
time (as defined by the run-time statistics clock provided by the
application) since the target booted.</p>
<p><code>pulTotalRunTime</code> is optional, and can be set to NULL if the total run
time is not required.</p>
</li>
<li>
<p>Return value</p>
<p>The number of <code>TaskStatus_t</code> structures that were populated by
<code>uxTaskGetSystemState()</code> is returned.</p>
<p>The returned value should equal the number returned by the
<code>uxTaskGetNumberOfTasks()</code> API function, but will be zero if the value
passed in the <code>uxArraySize</code> parameter was too small.</p>
</li>
</ul>
<p><a name="list12.5" title="Listing 12.5 The TaskStatus\_t structure"></a></p>
<pre><code class="language-c">typedef struct xTASK_STATUS
{
    TaskHandle_t xHandle;
    const char *pcTaskName;
    UBaseType_t xTaskNumber;
    eTaskState eCurrentState;
    UBaseType_t uxCurrentPriority;
    UBaseType_t uxBasePriority;
    configRUN_TIME_COUNTER_TYPE ulRunTimeCounter;
    StackType_t * pxStackBase;
    #if ( ( portSTACK_GROWTH &gt; 0 ) || ( configRECORD_STACK_HIGH_ADDRESS == 1 ) )
        StackType_t * pxTopOfStack;
        StackType_t * pxEndOfStack;
    #endif
    uint16_t usStackHighWaterMark;
    #if ( ( configUSE_CORE_AFFINITY == 1 ) &amp;&amp; ( configNUMBER_OF_CORES &gt; 1 ) )
        UBaseType_t uxCoreAffinityMask;
    #endif
} TaskStatus_t;
</code></pre>
<p><em><strong>Listing 12.5</strong></em> <em>The TaskStatus_t structure</em></p>
<p><strong>TaskStatus_t structure members</strong></p>
<ul>
<li>
<p><code>xHandle</code></p>
<p>The handle of the task to which the information in the structure relates.</p>
</li>
<li>
<p><code>pcTaskName</code></p>
<p>The human readable text name of the task.</p>
</li>
<li>
<p><code>xTaskNumber</code></p>
<p>Each task has a unique <code>xTaskNumber</code> value.</p>
<p>If an application creates and deletes tasks at run time then it is
possible that a task will have the same handle as a task that was
previously deleted. <code>xTaskNumber</code> is provided to allow application code,
and kernel aware debuggers, to distinguish between a task that is still
valid, and a deleted task that had the same handle as the valid
task.</p>
</li>
<li>
<p><code>eCurrentState</code></p>
<p>An enumerated type that holds the state of the task.
<code>eCurrentState</code> can be one of the following values:</p>
<ul>
<li><code>eRunning</code></li>
<li><code>eReady</code></li>
<li><code>eBlocked</code></li>
<li><code>eSuspended</code></li>
<li><code>eDeleted</code></li>
</ul>
<p>A task will only be reported as being in the <code>eDeleted</code> state for the
short period between the time the task was deleted by a call to
<code>vTaskDelete()</code>, and the time the Idle task frees the memory that was
allocated to the deleted task's internal data structures and stack.
After that time, the task will no longer exist in any way, and it is
invalid to attempt to use its handle.</p>
</li>
<li>
<p><code>uxCurrentPriority</code></p>
<p>The priority at which the task was running at the time
<code>uxTaskGetSystemState()</code> was called. <code>uxCurrentPriority</code> will only be higher
than the priority assigned to the task by the application writer if the
task has temporarily been assigned a higher priority in accordance with
the priority inheritance mechanism described in section
<a href="ch08.html#83-mutexes-and-binary-semaphores">8.3 Mutexes (and Binary Semaphores)</a>.</p>
</li>
<li>
<p><code>uxBasePriority</code></p>
<p>The priority assigned to the task by the application writer.
<code>uxBasePriority</code> is only valid if <code>configUSE_MUTEXES</code> is set to 1 in
FreeRTOSConfig.h.</p>
</li>
<li>
<p><code>ulRunTimeCounter</code></p>
<p>The total run time used by the task since the task was created. The
total run time is provided as an absolute time that uses the clock
provided by the application writer for the collection of run-time
statistics. <code>ulRunTimeCounter</code> is only valid if
<code>configGENERATE_RUN_TIME_STATS</code> is set to 1 in FreeRTOSConfig.h.</p>
</li>
<li>
<p><code>pxStackBase</code></p>
<p>Points to the base address of the stack region allotted to this task.</p>
</li>
<li>
<p><code>pxTopOfStack</code></p>
<p>Points to the current top address of the stack region allotted to this task.
The field <code>pxTopOfStack</code> is only valid if either the stack grows upwards (i.e.
<code>portSTACK_GROWTH</code> is greater than zero) or <code>configRECORD_STACK_HIGH_ADDRESS</code>
is set to 1 in FreeRTOSConfig.h.</p>
</li>
<li>
<p><code>pxEndOfStack</code></p>
<p>Points to the end address of the of the stack region allotted to this task.
The field <code>pxEndOfStack</code> is only valid if either the stack grows upwards (i.e.
<code>portSTACK_GROWTH</code> is greater than zero) or <code>configRECORD_STACK_HIGH_ADDRESS</code>
is set to 1 in FreeRTOSConfig.h.</p>
</li>
<li>
<p><code>usStackHighWaterMark</code></p>
<p>The task's stack high water mark. This is the minimum amount of
stack space that has remained for the task since the task was created.
It is an indication of how close the task has come to overflowing its
stack; the closer this value is to zero, the closer the task has come to
overflowing its stack. <code>usStackHighWaterMark</code> is specified in bytes.</p>
</li>
<li>
<p><code>uxCoreAffinityMask</code></p>
<p>A bitwise value that indicates the cores on which the task can run.
Cores are numbered from 0 to <code>configNUMBER_OF_CORES</code> - 1. For example, a
task that can run on core 0 and core 1 will have its <code>uxCoreAffinityMask</code>
set to 0x03. The field <code>uxCoreAffinityMask</code> is only available if both
<code>configUSE_CORE_AFFINITY</code> is set to 1 and <code>configNUMBER_OF_CORES</code>
is set to greater than 1 in FreeRTOSConfig.h.</p>
</li>
</ul>
<h3 id="1255-the-vtasklisttasks-helper-function"><a class="header" href="#1255-the-vtasklisttasks-helper-function">12.5.5 The vTaskListTasks() Helper Function</a></h3>
<p><code>vTaskListTasks()</code> provides similar task status information to that provided by
<code>uxTaskGetSystemState()</code>, but it presents the information as a human
readable ASCII table, rather than an array of binary values.</p>
<p><code>vTaskListTasks()</code> is a very processor intensive function, and leaves the
scheduler suspended for an extended period. Therefore, it is recommended
to use the function for debug purposes only, and not in a production
real-time system.</p>
<p><code>vTaskListTasks()</code> is available if <code>configUSE_TRACE_FACILITY</code> is set to 1 and
<code>configUSE_STATS_FORMATTING_FUNCTIONS</code> is set to greater than 0 in
FreeRTOSConfig.h.</p>
<p><a name="list12.6" title="Listing 12.6 The vTaskListTasks() API function prototype"></a></p>
<pre><code class="language-c">void vTaskListTasks( char * pcWriteBuffer, size_t uxBufferLength );
</code></pre>
<p><em><strong>Listing 12.6</strong></em> <em>The vTaskListTasks() API function prototype</em></p>
<p><strong>vTaskListTasks() parameters</strong></p>
<ul>
<li>
<p><code>pcWriteBuffer</code></p>
<p>A pointer to a character buffer into which the formatted and human readable table is written.
This buffer is assumed to be large enough to contain the generated report.<br />
Approximately 40 bytes per task should be sufficient.</p>
</li>
<li>
<p><code>uxBufferLength</code></p>
<p>Length of the <code>pcWriteBuffer</code>.</p>
</li>
</ul>
<p>An example of the output generated by <code>vTaskListTasks()</code> is shown in Figure 12.7.
In the output:</p>
<ul>
<li>
<p>Each row provides information on a single task.</p>
</li>
<li>
<p>The first column is the task's name.</p>
</li>
<li>
<p>The second column is the task's state, where 'X' means Running, 'R' means Ready, 'B'
means Blocked, 'S' means Suspended, and 'D' means the task has been
deleted. A task will only be reported as being in the deleted state
for the short period between the time the task was deleted by a call
to <code>vTaskDelete()</code>, and the time the Idle task frees the memory that
was allocated to the deleted task's internal data structures and
stack. After that time, the task will no longer exist in any way,
and it is invalid to attempt to use its handle.</p>
</li>
<li>
<p>The third column is the task's priority.</p>
</li>
<li>
<p>The fourth column is the task's stack high water mark. See the
description of <code>usStackHighWaterMark</code>.</p>
</li>
<li>
<p>The fifth column is the unique number allocated to the task. See the
description of <code>xTaskNumber</code>.</p>
</li>
</ul>
<p><a name="fig12.7" title="Figure 12.7 Example output generated by vTaskListTasks()"></a></p>
<hr />
<p><img src="media/image88.png" alt="" /><br />
<em><strong>Figure 12.7</strong></em> <em>Example output generated by vTaskListTasks()</em></p>
<hr />
<blockquote>
<p>Note:<br />
The older version of <code>vTaskListTasks</code> is <code>vTaskList</code>. <code>vTaskList</code> assumes that the
<code>pcWriteBuffer</code> is of length <code>configSTATS_BUFFER_MAX_LENGTH</code>. This function is there only for
backward compatibility. New applications are recommended to use <code>vTaskListTasks</code> and
supply the length of the <code>pcWriteBuffer</code> explicitly.</p>
</blockquote>
<p><a name="list12.7" title="Listing 12.7 The vTaskList() API function prototype"></a></p>
<pre><code class="language-c">void vTaskList( signed char *pcWriteBuffer );
</code></pre>
<p><em><strong>Listing 12.7</strong></em> <em>The vTaskList() API function prototype</em></p>
<p><strong>vTaskList() parameters</strong></p>
<ul>
<li>
<p><code>pcWriteBuffer</code></p>
<p>A pointer to a character buffer into which the formatted and human readable table is written.
The buffer must be large enough to hold the entire table, as no boundary checking is performed.</p>
</li>
</ul>
<h3 id="1256-the-vtaskgetruntimestatistics-helper-function"><a class="header" href="#1256-the-vtaskgetruntimestatistics-helper-function">12.5.6 The vTaskGetRunTimeStatistics() Helper Function</a></h3>
<p><code>vTaskGetRunTimeStatistics()</code> formats collected run-time statistics into a
human readable ASCII table.</p>
<p><code>vTaskGetRunTimeStatistics()</code> is a very processor intensive function and leaves
the scheduler suspended for an extended period. Therefore, it is
recommended to use the function for debug purposes only, and not in a
production real-time system.</p>
<p><code>vTaskGetRunTimeStatistics()</code> is available when <code>configGENERATE_RUN_TIME_STATS</code> is set to
1, <code>configUSE_STATS_FORMATTING_FUNCTIONS</code> is set greater than 0, and
<code>configUSE_TRACE_FACILITY</code> is set to 1 in FreeRTOSConfig.h.</p>
<p><a name="list12.8" title="Listing 12.8 The vTaskGetRunTimeStatistics() API function prototype"></a></p>
<pre><code class="language-c">void vTaskGetRunTimeStatistics( char * pcWriteBuffer, size_t uxBufferLength );
</code></pre>
<p><em><strong>Listing 12.8</strong></em> <em>The vTaskGetRunTimeStatistics() API function prototype</em></p>
<p><strong>vTaskGetRunTimeStatistics() parameters</strong></p>
<ul>
<li>
<p><code>pcWriteBuffer</code></p>
<p>A pointer to a character buffer into which the formatted and human readable table is written.
This buffer is assumed to be large enough to contain the generated report.<br />
Approximately 40 bytes per task should be sufficient.</p>
</li>
<li>
<p><code>uxBufferLength</code></p>
<p>Length of the <code>pcWriteBuffer</code>.</p>
</li>
</ul>
<p>An example of the output generated by <code>vTaskGetRunTimeStatistics()</code> is shown in
Figure 12.8. In the output:</p>
<ul>
<li>
<p>Each row provides information on a single task.</p>
</li>
<li>
<p>The first column is the task name.</p>
</li>
<li>
<p>The second column is the amount of time the task has spent in the
Running state as an absolute value. See the description of
<code>ulRunTimeCounter</code>.</p>
</li>
<li>
<p>The third column is the amount of time the task has spent in the
Running state as a percentage of the total time since the target was
booted. The total of the displayed percentage times will normally be
less than the expected 100% because statistics are collected and
calculated using integer calculations that round down to the nearest
integer value.</p>
</li>
</ul>
<p><a name="fig12.8" title="Figure 12.8 Example output generated by vTaskGetRunTimeStatistics()"></a></p>
<hr />
<p><img src="media/image89.png" alt="" /><br />
<em><strong>Figure 12.8</strong></em> <em>Example output generated by vTaskGetRunTimeStatistics()</em></p>
<hr />
<blockquote>
<p>Note:<br />
The older version of <code>vTaskGetRunTimeStatistics</code> is <code>vTaskGetRunTimeStats</code>.
<code>vTaskGetRunTimeStats</code> assumes that the pcWriteBuffer is of length
<code>configSTATS_BUFFER_MAX_LENGTH</code>. This function is there only for backward compatiblity.
New applications are recommended to use <code>vTaskGetRunTimeStatistics</code> and supply the length
of the pcWriteBuffer explicitly.</p>
</blockquote>
<p><a name="list12.9" title="Listing 12.9 The vTaskGetRunTimeStats() API function prototype"></a></p>
<pre><code class="language-c">void vTaskGetRunTimeStats( signed char *pcWriteBuffer );
</code></pre>
<p><em><strong>Listing 12.9</strong></em> <em>The vTaskGetRunTimeStats() API function prototype</em></p>
<p><strong>vTaskGetRunTimeStats() parameters</strong></p>
<ul>
<li>
<p><code>pcWriteBuffer</code></p>
<p>A pointer to a character buffer into which the formatted and human readable table is written. The
buffer must be large enough to hold the entire table, as no boundary checking is performed.</p>
</li>
</ul>
<h3 id="1257-generating-and-displaying-run-time-statistics-a-worked-example"><a class="header" href="#1257-generating-and-displaying-run-time-statistics-a-worked-example">12.5.7 Generating and Displaying Run-Time Statistics, a Worked Example</a></h3>
<p>This example uses a hypothetical 16-bit timer to generate a 32-bit
run-time statistics clock. The counter is configured to generate an
interrupt each time the 16-bit value reaches its maximum
value—effectively creating an overflow interrupt. The interrupt service
routine counts the number of overflow occurrences.</p>
<p>The 32-bit value is created by using the count of overflow occurrences
as the two most significant bytes of the 32-bit value, and the current
16-bit counter value as the two least significant bytes of the 32-bit
value. Pseudo code for the interrupt service routine is shown in Listing
12.10.</p>
<p><a name="list12.10" title="Listing 12.10 16-bit timer overflow interrupt handler used to count timer overflows"></a></p>
<pre><code class="language-c">void TimerOverflowInterruptHandler( void )
{
    /* Just count the number of interrupts. */
    ulOverflowCount++;

    /* Clear the interrupt. */
    ClearTimerInterrupt();
}
</code></pre>
<p><em><strong>Listing 12.10</strong></em> <em>16-bit timer overflow interrupt handler used to count timer overflows</em></p>
<p>Listing 12.11 shows the lines added to FreeRTOSConfig.h to enable the
collection of run-time statistics.</p>
<p><a name="list12.11" title="Listing 12.11 Macros added to FreeRTOSConfig.h to enable the collection of run-time statistics"></a></p>
<pre><code class="language-c">/* Set configGENERATE_RUN_TIME_STATS to 1 to enable collection of run-time 
   statistics. When this is done, both portCONFIGURE_TIMER_FOR_RUN_TIME_STATS()
   and portGET_RUN_TIME_COUNTER_VALUE() or 
   portALT_GET_RUN_TIME_COUNTER_VALUE(x) must also be defined. */
#define configGENERATE_RUN_TIME_STATS 1

/* portCONFIGURE_TIMER_FOR_RUN_TIME_STATS() is defined to call the function 
   that sets up the hypothetical 16-bit timer (the function's implementation 
   is not shown). */
void vSetupTimerForRunTimeStats( void );
#define portCONFIGURE_TIMER_FOR_RUN_TIME_STATS()  vSetupTimerForRunTimeStats()

/* portALT_GET_RUN_TIME_COUNTER_VALUE() is defined to set its parameter to the
   current run-time counter/time value. The returned time value is 32-bits 
   long, and is formed by shifting the count of 16-bit timer overflows into 
   the top two bytes of a 32-bit number, then bitwise ORing the result with 
   the current 16-bit counter value. */
#define portALT_GET_RUN_TIME_COUNTER_VALUE( ulCountValue )                  \
{                                                                           \
    extern volatile unsigned long ulOverflowCount;                          \
                                                                            \
    /* Disconnect the clock from the counter so it does not change          \
       while its value is being used. */                                    \
    PauseTimer();                                                           \
                                                                            \
    /* The number of overflows is shifted into the most significant         \
       two bytes of the returned 32-bit value. */                           \
    ulCountValue = ( ulOverflowCount &lt;&lt; 16UL );                             \
                                                                            \
    /* The current counter value is used as the two least significant       \
       bytes of the returned 32-bit value. */                               \
    ulCountValue |= ( unsigned long ) ReadTimerCount();                     \
                                                                            \
    /* Reconnect the clock to the counter. */                               \
    ResumeTimer();                                                          \
}
</code></pre>
<p><em><strong>Listing 12.11</strong></em> <em>Macros added to FreeRTOSConfig.h to enable the collection of run-time statistics</em></p>
<p>The task shown in Listing 12.12 prints out the collected run-time statistics every 5 seconds.</p>
<p><a name="list12.12" title="Listing 12.12 The task that prints out the collected run-time statistics"></a></p>
<pre><code class="language-c">#define RUN_TIME_STATS_STRING_BUFFER_LENGTH       512

/* For clarity, calls to fflush() have been omitted from this code listing. */
static void prvStatsTask( void *pvParameters )
{
    TickType_t xLastExecutionTime;

    /* The buffer used to hold the formatted run-time statistics text needs to
       be quite large. It is therefore declared static to ensure it is not
       allocated on the task stack. This makes this function non re-entrant. */
    static signed char cStringBuffer[ RUN_TIME_STATS_STRING_BUFFER_LENGTH ];

    /* The task will run every 5 seconds. */
    const TickType_t xBlockPeriod = pdMS_TO_TICKS( 5000 );

    /* Initialize xLastExecutionTime to the current time. This is the only
       time this variable needs to be written to explicitly. Afterwards it is 
       updated internally within the vTaskDelayUntil() API function. */
    xLastExecutionTime = xTaskGetTickCount();

    /* As per most tasks, this task is implemented in an infinite loop. */
    for( ;; )
    {
        /* Wait until it is time to run this task again. */
        xTaskDelayUntil( &amp;xLastExecutionTime, xBlockPeriod );

        /* Generate a text table from the run-time stats. This must fit into
           the cStringBuffer array. */
        vTaskGetRunTimeStatistics( cStringBuffer, RUN_TIME_STATS_STRING_BUFFER_LENGTH );

        /* Print out column headings for the run-time stats table. */
        printf( "\nTask\t\tAbs\t\t\t%%\n" );
        printf( "-------------------------------------------------------------\n" );

        /* Print out the run-time stats themselves. The table of data contains
           multiple lines, so the vPrintMultipleLines() function is called 
           instead of calling printf() directly. vPrintMultipleLines() simply 
           calls printf() on each line individually, to ensure the line 
           buffering works as expected. */ 
        vPrintMultipleLines( cStringBuffer );
    }
}
</code></pre>
<p><em><strong>Listing 12.12</strong></em> <em>The task that prints out the collected run-time statistics</em></p>
<h2 id="126-trace-hook-macros"><a class="header" href="#126-trace-hook-macros">12.6 Trace Hook Macros</a></h2>
<p>Trace macros are macros that have been placed at key points within the
FreeRTOS source code. By default, the macros are empty, and so do not
generate any code, and have no run time overhead. By overriding the
default empty implementations, an application writer can:</p>
<ul>
<li>
<p>Insert code into FreeRTOS without modifying the FreeRTOS source
files.</p>
</li>
<li>
<p>Output detailed execution sequencing information by any means
available on the target hardware. Trace macros appear in enough
places in the FreeRTOS source code to allow them to be used to
create a full and detailed scheduler activity trace and profiling
log.</p>
</li>
</ul>
<h3 id="1261-available-trace-hook-macros"><a class="header" href="#1261-available-trace-hook-macros">12.6.1 Available Trace Hook Macros</a></h3>
<p>It would take too much space to detail every macro here. The list below
details the subset of macros deemed to be most useful to an application
writer.</p>
<p>Many of the descriptions in the list below refer to a variable called
<code>pxCurrentTCB</code>. <code>pxCurrentTCB</code> is a FreeRTOS private variable that holds the
handle of the task in the Running state, and is available to any macro
that is called from the FreeRTOS/Source/tasks.c source file.</p>
<p><strong>A selection of the most commonly used trace hook macros</strong></p>
<ul>
<li>
<p><code>traceTASK_INCREMENT_TICK(xTickCount)</code></p>
<p>Called during the tick interrupt, before the tick count is incremented. The <code>xTickCount</code> parameter
passes the new tick count value into the macro.</p>
</li>
<li>
<p><code>traceTASK_SWITCHED_OUT()</code></p>
<p>Called before a new task is selected to run. At this point, <code>pxCurrentTCB</code> contains the handle of
the task about to leave the Running state.</p>
</li>
<li>
<p><code>traceTASK_SWITCHED_IN()</code></p>
<p>Called after a task is selected to run. At this point, <code>pxCurrentTCB</code> contains the handle of the
task about to enter the Running state.</p>
</li>
<li>
<p><code>traceBLOCKING_ON_QUEUE_RECEIVE(pxQueue)</code></p>
<p>Called immediately before the currently executing task enters the Blocked state following an attempt
to read from an empty queue, or an attempt to 'take' an empty semaphore or mutex. The <code>pxQueue</code> parameter
passes the handle of the target queue or semaphore into the macro.</p>
</li>
<li>
<p><code>traceBLOCKING_ON_QUEUE_SEND(pxQueue)</code></p>
<p>Called immediately before the currently executing task enters the Blocked state following an attempt
to write to a queue that is full. The <code>pxQueue</code> parameter passes the handle of the target queue into
the macro.</p>
</li>
<li>
<p><code>traceQUEUE_SEND(pxQueue)</code></p>
<p>Called from within <code>xQueueSend()</code>, <code>xQueueSendToFront()</code>, <code>xQueueSendToBack()</code>, or any of the semaphore
'give' functions, when the queue send or semaphore 'give' is successful. The <code>pxQueue</code> parameter passes
the handle of the target queue or semaphore into the macro.</p>
</li>
<li>
<p><code>traceQUEUE_SEND_FAILED(pxQueue)</code></p>
<p>Called from within <code>xQueueSend()</code>, <code>xQueueSendToFront()</code>, <code>xQueueSendToBack()</code>, or any of the semaphore
'give' functions, when the queue send or semaphore 'give' operation fails. A queue send or semaphore
'give' will fail if the queue is full and remains full for the duration of any block time specified.
The <code>pxQueue</code> parameter passes the handle of the target queue or semaphore into the macro.</p>
</li>
<li>
<p><code>traceQUEUE_RECEIVE(pxQueue)</code></p>
<p>Called from within <code>xQueueReceive()</code> or any of the semaphore 'take' functions when the queue receive or
semaphore 'take' is successful. The <code>pxQueue</code> parameter passes the handle of the target queue or semaphore
into the macro.</p>
</li>
<li>
<p><code>traceQUEUE_RECEIVE_FAILED(pxQueue)</code></p>
<p>Called from within <code>xQueueReceive()</code> or any of the semaphore 'take' functions when the queue or semaphore
receive operation fails. A queue receive or semaphore 'take' operation will fail if the queue or semaphore
is empty and remains empty for the duration of any block time specified. The <code>pxQueue</code> parameter passes the
handle of the target queue or semaphore into the macro.</p>
</li>
<li>
<p><code>traceQUEUE_SEND_FROM_ISR(pxQueue)</code></p>
<p>Called from within <code>xQueueSendFromISR()</code> when the send operation is successful. The <code>pxQueue</code> parameter
passes the handle of the target queue into the macro.</p>
</li>
<li>
<p><code>traceQUEUE_SEND_FROM_ISR_FAILED(pxQueue)</code></p>
<p>Called from within <code>xQueueSendFromISR()</code> when the send operation fails. A send operation will fail
if the queue is already full. The <code>pxQueue</code> parameter passes the handle of the target queue into the
macro.</p>
</li>
<li>
<p><code>traceQUEUE_RECEIVE_FROM_ISR(pxQueue)</code></p>
<p>Called from within <code>xQueueReceiveFromISR()</code> when the receive operation is successful. The <code>pxQueue</code>
parameter passes the handle of the target queue into the macro.</p>
</li>
<li>
<p><code>traceQUEUE_RECEIVE_FROM_ISR_FAILED(pxQueue)</code></p>
<p>Called from within <code>xQueueReceiveFromISR()</code> when the receive operation fails due to the queue already
being empty. The <code>pxQueue</code> parameter passes the handle of the target queue into the macro.</p>
</li>
<li>
<p><code>traceTASK_DELAY_UNTIL( xTimeToWake )</code></p>
<p>Called from within <code>xTaskDelayUntil()</code> immediately before the calling task enters the Blocked state.</p>
</li>
<li>
<p><code>traceTASK_DELAY()</code></p>
<p>Called from within <code>vTaskDelay()</code> immediately before the calling task enters the Blocked state.</p>
</li>
</ul>
<h3 id="1262-defining-trace-hook-macros"><a class="header" href="#1262-defining-trace-hook-macros">12.6.2 Defining Trace Hook Macros</a></h3>
<p>Each trace macro has a default empty definition. The default definition
can be overridden by providing a new macro definition in
FreeRTOSConfig.h. If trace macro definitions become long or complex,
then they can be implemented in a new header file that is then itself
included from FreeRTOSConfig.h.</p>
<p>In accordance with software engineering best practice, FreeRTOS
maintains a strict data hiding policy. Trace macros allow user code to
be added to the FreeRTOS source files, so the data types visible to the
trace macros will be different to those visible to application code:</p>
<ul>
<li>
<p>Inside the FreeRTOS/Source/tasks.c source file, a task handle is a
pointer to the data structure that describes a task (the task's
<em>Task Control Block</em>, or <em>TCB</em>). Outside of the
FreeRTOS/Source/tasks.c source file a task handle is a pointer to
void.</p>
</li>
<li>
<p>Inside the FreeRTOS/Source/queue.c source file, a queue handle is a
pointer to the data structure that describes a queue. Outside of the
FreeRTOS/Source/queue.c source file a queue handle is a pointer to
void.</p>
</li>
</ul>
<blockquote>
<p><em>Extreme caution is required if a normally private FreeRTOS data
structure is accessed directly by a trace macro, as private data
structures might change between FreeRTOS versions.</em></p>
</blockquote>
<h3 id="1263-freertos-aware-debugger-plug-ins"><a class="header" href="#1263-freertos-aware-debugger-plug-ins">12.6.3 FreeRTOS Aware Debugger Plug-ins</a></h3>
<p>Plug-ins that provide some FreeRTOS awareness are available for the
following IDEs. This list may not be an exhaustive:</p>
<p><img src="media/image90.png" alt="" /></p>
<ul>
<li>
<p>Eclipse (StateViewer)</p>
</li>
<li>
<p>Eclipse (ThreadSpy)</p>
</li>
<li>
<p>IAR</p>
</li>
<li>
<p>ARM DS-5</p>
</li>
<li>
<p>Atollic TrueStudio</p>
</li>
<li>
<p>Microchip MPLAB</p>
</li>
<li>
<p>iSYSTEM WinIDEA</p>
</li>
<li>
<p>STM32CubeIDE</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="13-troubleshooting-1"><a class="header" href="#13-troubleshooting-1">13 Troubleshooting</a></h1>
<h2 id="131-chapter-introduction-and-scope"><a class="header" href="#131-chapter-introduction-and-scope">13.1 Chapter Introduction and Scope</a></h2>
<p>This chapter highlights the most common issues encountered by users who
are new to FreeRTOS. First, it focuses on three issues that have proven
to be the most frequent source of support requests over the years:
incorrect interrupt priority assignment, stack overflow, and
inappropriate use of printf(). It then briefly, and in an FAQ style,
touches on other common errors, their possible causes, and their
solutions.</p>
<blockquote>
<p><em>Using <code>configASSERT()</code> improves productivity by immediately trapping and
identifying many of the most common sources of error. It is strongly
advised to have <code>configASSERT()</code> defined while developing or debugging a
FreeRTOS application. <code>configASSERT()</code> is described in section 12.2.</em></p>
</blockquote>
<h2 id="132-interrupt-priorities"><a class="header" href="#132-interrupt-priorities">13.2 Interrupt Priorities</a></h2>
<blockquote>
<p><em>Note: This is the number one cause of support requests, and in most
ports defining <code>configASSERT()</code> will trap the error immediately!</em></p>
</blockquote>
<p>If the FreeRTOS port in use supports interrupt nesting, and the service
routine for an interrupt makes use of the FreeRTOS API, then it is
<em>essential</em> the interrupt's priority is set at or below
<code>configMAX_SYSCALL_INTERRUPT_PRIORITY</code>, as described in section 7.8,
Interrupt Nesting. Failure to do this will result in ineffective
critical sections, which in turn will result in intermittent failures.</p>
<p>Take particular care if running FreeRTOS on a processor where:</p>
<ul>
<li>
<p>Interrupt priorities default to having the highest possible
priority, which is the case on some ARM Cortex processors, and
possibly others. On such processors, the priority of an interrupt
that uses the FreeRTOS API cannot be left uninitialized.</p>
</li>
<li>
<p>Numerically high priority numbers represent logically low interrupt
priorities, which may seem counterintuitive, and therefore cause
confusion. Again this is the case on ARM Cortex processors, and
possibly others.</p>
</li>
<li>
<p>For example, on such a processor an interrupt that is executing at
priority 5 can itself be interrupted by an interrupt that has a
priority of 4. Therefore, if <code>configMAX_SYSCALL_INTERRUPT_PRIORITY</code> is
set to 5, any interrupt that uses the FreeRTOS API can only be
assigned a priority numerically higher than or equal to 5. In that
case, interrupt priorities of 5 or 6 would be valid, but an
interrupt priority of 3 is definitely invalid.</p>
<p><img src="media/image91.png" alt="" /></p>
</li>
<li>
<p>Different library implementations expect the priority of an
interrupt to be specified in a different way. Again, this is particularly
relevant to libraries that target ARM Cortex processors, where
interrupt priorities are bit shifted before being written to the
hardware registers. Some libraries will perform the bit shift
themselves, whereas others expect the bit shift to be performed
before the priority is passed into the library function.</p>
</li>
<li>
<p>Different implementations of the same architecture implement a
different number of interrupt priority bits. For example, a Cortex-M
processor from one manufacturer may implement 3 priority bits, while
a Cortex-M processor from another manufacturer may implement 4
priority bits.</p>
</li>
<li>
<p>The bits that define the priority of an interrupt can be split
between bits that define a pre-emption priority, and bits that
define a sub-priority. Ensure all the bits are assigned to
specifying a pre-emption priority, so that sub-priorities are not used.</p>
</li>
</ul>
<p>In some FreeRTOS ports, <code>configMAX_SYSCALL_INTERRUPT_PRIORITY</code> has the
alternative name <code>configMAX_API_CALL_INTERRUPT_PRIORITY</code>.</p>
<h2 id="133-stack-overflow"><a class="header" href="#133-stack-overflow">13.3 Stack Overflow</a></h2>
<p>Stack overflow is the second most common source of support requests.
FreeRTOS provides several features to assist trapping and debugging
stack related issues<sup class="footnote-reference"><a href="#28">1</a></sup>.</p>
<div class="footnote-definition" id="28"><sup class="footnote-definition-label">1</sup>
<p>These features are not available in the FreeRTOS Windows port.</p>
</div>
<h3 id="1331-the-uxtaskgetstackhighwatermark-api-function"><a class="header" href="#1331-the-uxtaskgetstackhighwatermark-api-function">13.3.1 The uxTaskGetStackHighWaterMark() API Function</a></h3>
<p>Each task maintains its own stack, the total size of which is specified
when the task is created. <code>uxTaskGetStackHighWaterMark()</code> is used to query
how close a task has come to overflowing the stack space allocated to
it. This value is called the stack 'high water mark'.</p>
<p><a name="list13.1" title="Listing 13.1 The uxTaskGetStackHighWaterMark() API function prototype"></a></p>
<pre><code class="language-c">UBaseType_t uxTaskGetStackHighWaterMark( TaskHandle_t xTask );
</code></pre>
<p><em><strong>Listing 13.1</strong></em> <em>The uxTaskGetStackHighWaterMark() API function prototype</em></p>
<p><strong>uxTaskGetStackHighWaterMark() parameters and return value</strong></p>
<ul>
<li>
<p><code>xTask</code></p>
<p>The handle of the task whose stack high water mark is being
queried (the subject task)—see the pxCreatedTask parameter of the
<code>xTaskCreate()</code> API function for information on obtaining handles to
tasks.</p>
<p>A task can query its own stack high water mark by passing NULL in
place of a valid task handle.</p>
</li>
<li>
<p>Return value</p>
<p>The amount of stack used by the task grows and shrinks as the task
executes and interrupts are processed. <code>uxTaskGetStackHighWaterMark()</code>
returns the minimum amount of remaining stack space that has been
available since the task started executing. This is the amount of stack
that remains unused when stack usage is at its greatest (or deepest)
value. The closer the high water mark is to zero, the closer the task
has come to overflowing its stack.</p>
</li>
</ul>
<p><code>uxTaskGetStackHighWaterMark2()</code> API can be used instead of
<code>uxTaskGetStackHighWaterMark()</code> which only differs in the return type.</p>
<p><a name="list13.2" title="Listing 13.2 The uxTaskGetStackHighWaterMark2() API function prototype"></a></p>
<pre><code class="language-c">configSTACK_DEPTH_TYPE uxTaskGetStackHighWaterMark2( TaskHandle_t xTask );
</code></pre>
<p><em><strong>Listing 13.2</strong></em> <em>The uxTaskGetStackHighWaterMark2() API function prototype</em></p>
<p>Using <code>configSTACK_DEPTH_TYPE</code> allows the application writer to control the type
used for stack depth.</p>
<h3 id="1332-run-time-stack-checkingoverview"><a class="header" href="#1332-run-time-stack-checkingoverview">13.3.2 Run Time Stack Checking—Overview</a></h3>
<p>FreeRTOS includes three optional run time stack checking mechanisms. These
are controlled by the <code>configCHECK_FOR_STACK_OVERFLOW</code> compile time
configuration constant within FreeRTOSConfig.h. Both methods increase
the time it takes to perform a context switch.</p>
<p>The stack overflow hook (or stack overflow callback) is a function that
is called by the kernel when it detects a stack overflow. To use a stack
overflow hook function:</p>
<ol>
<li>
<p>Set <code>configCHECK_FOR_STACK_OVERFLOW</code> to either 1 , 2 or 3 in
FreeRTOSConfig.h, as described in the following sub-sections.</p>
</li>
<li>
<p>Provide the implementation of the hook function, using the exact
function name and prototype shown in Listing 13.3.</p>
</li>
</ol>
<p><a name="list13.3" title="Listing 13.3 The stack overflow hook function prototype"></a></p>
<pre><code class="language-c">void vApplicationStackOverflowHook( TaskHandle_t *pxTask, signed char *pcTaskName );
</code></pre>
<p><em><strong>Listing 13.3</strong></em> <em>The stack overflow hook function prototype</em></p>
<p>The stack overflow hook is provided to make trapping and debugging stack
errors easier, but there is no real way to recover from a stack overflow
when it occurs. The function's parameters pass the handle and name of
the task that has overflowed its stack into the hook function.</p>
<p>The stack overflow hook gets called from the context of an interrupt.</p>
<p>Some microcontrollers generate a fault exception when they detect an
incorrect memory access, and it is possible for a fault to be triggered
before the kernel has a chance to call the stack overflow hook function.</p>
<h3 id="1333-run-time-stack-checkingmethod-1"><a class="header" href="#1333-run-time-stack-checkingmethod-1">13.3.3 Run Time Stack Checking—Method 1</a></h3>
<p>Method 1 is selected when <code>configCHECK_FOR_STACK_OVERFLOW</code> is set to 1.</p>
<p>A task's entire execution context is saved onto its stack each time it
gets swapped out. It is likely that this will be the time at which stack
usage reaches its peak. When <code>configCHECK_FOR_STACK_OVERFLOW</code> is set to 1,
the kernel checks that the stack pointer remains within the valid stack
space after the context has been saved. The stack overflow hook is
called if the stack pointer is found to be outside its valid range.</p>
<p>Method 1 is quick to execute, but can miss stack overflows that occur
between context switches.</p>
<h3 id="1334-run-time-stack-checkingmethod-2"><a class="header" href="#1334-run-time-stack-checkingmethod-2">13.3.4 Run Time Stack Checking—Method 2</a></h3>
<p>Method 2 performs additional checks to those already described for
method 1. It is selected when <code>configCHECK_FOR_STACK_OVERFLOW</code> is set to 2.</p>
<p>When a task is created, its stack is filled with a known pattern. Method
2 tests the last valid 20 bytes of the task stack space to verify that
this pattern has not been overwritten. The stack overflow hook function
is called if any of the 20 bytes have changed from their expected
values.</p>
<p>Method 2 is not as quick to execute as method 1, but is still relatively
fast, as only 20 bytes are tested. Most likely, it will catch all stack
overflows; however, it is possible (but highly improbable) that some
overflows will be missed.</p>
<h3 id="1334-run-time-stack-checkingmethod-3"><a class="header" href="#1334-run-time-stack-checkingmethod-3">13.3.4 Run Time Stack Checking—Method 3</a></h3>
<p>Method 3 is selected when <code>configCHECK_FOR_STACK_OVERFLOW</code> is set to 3.</p>
<p>This method is available only for selected ports. When available, this method
enables ISR stack checking. When an ISR stack overflow is detected, an
assert is triggered. Note that the stack overflow hook function is not called in
this case because it is specific to a task stack and not the ISR stack.</p>
<h2 id="134-use-of-printf-and-sprintf"><a class="header" href="#134-use-of-printf-and-sprintf">13.4 Use of printf() and sprintf()</a></h2>
<p>Logging via <code>printf()</code> is a common source of error, and,
unaware of this, it is common for application developers to then add
further calls to <code>printf()</code> to aid debugging, and in-so-doing, exacerbate
the problem.</p>
<p>Many cross compiler vendors will provide a <code>printf()</code> implementation that
is suitable for use in small embedded systems. Even when that is the
case, the implementation may not be thread safe, probably won't be
suitable for use inside an interrupt service routine, and depending on
where the output is directed, take a relatively long time to execute.</p>
<p>Particular care must be taken if a <code>printf()</code> implementation that is
specifically designed for small embedded systems is not available, and a
generic <code>printf()</code> implementation is used instead, as:</p>
<ul>
<li>
<p>Just including a call to <code>printf()</code> or <code>sprintf()</code> can massively
increase the size of the application's executable.</p>
</li>
<li>
<p><code>printf()</code> and <code>sprintf()</code> may call <code>malloc()</code>, which might be invalid if
a memory allocation scheme other than heap_3 is in use. See section
3.2, Example Memory Allocation Schemes, for more information.</p>
</li>
<li>
<p><code>printf()</code> and <code>sprintf()</code> may require a stack that is many times bigger
than would otherwise be required.</p>
</li>
</ul>
<h3 id="1341-printf-stdargc"><a class="header" href="#1341-printf-stdargc">13.4.1 Printf-stdarg.c</a></h3>
<p>Many of the FreeRTOS demonstration projects use a file called
printf-stdarg.c, which provides a minimal and stack-efficient
implementation of <code>sprintf()</code> that can be used in place of the standard
library version. In most cases, this will permit a much smaller stack to
be allocated to each task that calls <code>sprintf()</code> and related functions.</p>
<p>printf-stdarg.c also provides a mechanism for directing the <code>printf()</code>
output to a port character by character which, while slow, allows stack
usage to be decreased even further.</p>
<p>Note that not all copies of <code>printf-stdarg.c</code> included in the FreeRTOS
download implement <code>snprintf()</code>. Copies that do not implement <code>snprintf()</code>
simply ignore the buffer size parameter, as they map directly to
<code>sprintf()</code>.</p>
<p>printf-stdarg.c is open source, but is owned by a third party, and
therefore licensed separately from FreeRTOS. The license terms are
contained at the top of the source file.</p>
<h2 id="135-other-common-sources-of-error"><a class="header" href="#135-other-common-sources-of-error">13.5 Other Common Sources of Error</a></h2>
<h3 id="1351-symptom-adding-a-simple-task-to-a-demo-causes-the-demo-to-crash"><a class="header" href="#1351-symptom-adding-a-simple-task-to-a-demo-causes-the-demo-to-crash">13.5.1 Symptom: Adding a simple task to a demo causes the demo to crash</a></h3>
<p>Creating a task requires memory to be obtained from the heap. Many of
the demo application projects dimension the heap to be exactly big
enough to create the demo tasks—so, after the tasks are created, there
will be insufficient heap remaining for any further tasks, queues, event
groups, or semaphores to be added.</p>
<p>The idle task, and possibly also the RTOS daemon task, are created
automatically when <code>vTaskStartScheduler()</code> is called.
<code>vTaskStartScheduler()</code> will return only if there is not enough heap
memory remaining for these tasks to be created. Including a null loop <code>[ for(;;); ]</code>
after the call to <code>vTaskStartScheduler()</code> can make this error easier to debug.</p>
<p>To be able to add more tasks, you must either increase the heap size, or remove
some of the existing demo tasks. The increase in heap size will always be
limited by the amount of RAM available. See section 3.2, Example Memory
Allocation Schemes, for more information.</p>
<h3 id="1352-symptom-using-an-api-function-within-an-interrupt-causes-the-application-to-crash"><a class="header" href="#1352-symptom-using-an-api-function-within-an-interrupt-causes-the-application-to-crash">13.5.2 Symptom: Using an API function within an interrupt causes the application to crash</a></h3>
<p>Do not use API functions within interrupt service routines, unless the
name of the API function ends with '...FromISR()'. In particular, do not
create a critical section within an interrupt unless using the interrupt
safe macros. See section 7.2, Using the FreeRTOS API from an ISR, for
more information.</p>
<p>In FreeRTOS ports that support interrupt nesting, do not use any API
functions in an interrupt that has been assigned an interrupt priority
above <code>configMAX_SYSCALL_INTERRUPT_PRIORITY</code>. See section 7.8, Interrupt
Nesting, for more information.</p>
<h3 id="1353-symptom-sometimes-the-application-crashes-within-an-interrupt-service-routine"><a class="header" href="#1353-symptom-sometimes-the-application-crashes-within-an-interrupt-service-routine">13.5.3 Symptom: Sometimes the application crashes within an interrupt service routine</a></h3>
<p>The first thing to check is that the interrupt is not causing a stack
overflow. Some ports only check for stack overflow within tasks, and not
within interrupts.</p>
<p>The way interrupts are defined and used differs between ports and
between compilers. Therefore, the second thing to check is that the
syntax, macros, and calling conventions used in the interrupt service
routine are exactly as described on the documentation page provided for
the port being used, and exactly as demonstrated in the demo application
provided with the port.</p>
<p>If the application is running on a processor that uses numerically low
priority numbers to represent logically high priorities, then ensure the
priority assigned to each interrupt takes that into account, as it can
seem counter-intuitive. If the application is running on a processor
that defaults the priority of each interrupt to the maximum possible
priority, then ensure the priority of each interrupt is not left at its
default value. See section 7.8, Interrupt Nesting, and section 13.2,
Interrupt Priorities, for more information.</p>
<h3 id="1354-symptom-the-scheduler-crashes-when-attempting-to-start-the-first-task"><a class="header" href="#1354-symptom-the-scheduler-crashes-when-attempting-to-start-the-first-task">13.5.4 Symptom: The scheduler crashes when attempting to start the first task</a></h3>
<p>Ensure the FreeRTOS interrupt handlers have been installed. Refer to the
documentation page for the FreeRTOS port in use for information, and the
demo application provided for the port for an example.</p>
<p>Some processors must be in a privileged mode before the scheduler can be
started. The easiest way to achieve this is to place the processor into
a privileged mode within the C startup code, before main() is called.</p>
<h3 id="1355-symptom-interrupts-are-unexpectedly-left-disabled-or-critical-sections-do-not-nest-correctly"><a class="header" href="#1355-symptom-interrupts-are-unexpectedly-left-disabled-or-critical-sections-do-not-nest-correctly">13.5.5 Symptom: Interrupts are unexpectedly left disabled, or critical sections do not nest correctly</a></h3>
<p>If a FreeRTOS API function is called before the scheduler has been
started then interrupts will deliberately be left disabled, and not
re-enabled again until the first task starts to execute. This is done to
protect the system from crashes caused by interrupts that attempt to use
FreeRTOS API functions during system initialization, before the
scheduler has been started, and while the scheduler may be in an
inconsistent state.</p>
<p>Do not alter the microcontroller interrupt enable bits or priority flags
using any method other than calls to <code>taskENTER_CRITICAL()</code> and
<code>taskEXIT_CRITICAL()</code>. These macros keep a count of their call nesting
depth to ensure interrupts become enabled again only when the call
nesting has unwound completely to zero. Be aware that some library
functions may themselves enable and disable interrupts.</p>
<h3 id="1356-symptom-the-application-crashes-even-before-the-scheduler-is-started"><a class="header" href="#1356-symptom-the-application-crashes-even-before-the-scheduler-is-started">13.5.6 Symptom: The application crashes even before the scheduler is started</a></h3>
<p>An interrupt service routine that could potentially cause a context
switch must not be permitted to execute before the scheduler has been
started. The same applies to any interrupt service routine that attempts
to send to or receive from a FreeRTOS object, such as a queue or
semaphore. A context switch cannot occur until after the scheduler has
started.</p>
<p>Many API functions cannot be called until after the scheduler has been
started. It is best to restrict API usage to the creation of objects
such as tasks, queues, and semaphores, rather than the use of these
objects, until after <code>vTaskStartScheduler()</code> has been called.</p>
<h3 id="1357-symptom-calling-api-functions-while-the-scheduler-is-suspended-or-from-inside-a-critical-section-causes-the-application-to-crash"><a class="header" href="#1357-symptom-calling-api-functions-while-the-scheduler-is-suspended-or-from-inside-a-critical-section-causes-the-application-to-crash">13.5.7 Symptom: Calling API functions while the scheduler is suspended, or from inside a critical section, causes the application to crash</a></h3>
<p>The scheduler is suspended by calling <code>vTaskSuspendAll()</code> and resumed
(unsuspended) by calling <code>xTaskResumeAll()</code>. A critical section is entered
by calling <code>taskENTER_CRITICAL()</code>, and exited by calling
<code>taskEXIT_CRITICAL()</code>.</p>
<p>Do not call API functions while the scheduler is suspended, or from
inside a critical section.</p>
<h2 id="136-additional-debugging-steps"><a class="header" href="#136-additional-debugging-steps">13.6 Additional Debugging Steps</a></h2>
<p>If you encounter an issue not covered in the common causes described above,
you can try to use some of the following debugging steps.</p>
<ul>
<li>Define <code>configASSERT()</code>, enable malloc failed checking and stack overflow
checking in the application's FreeRTOSConfig file.</li>
<li>Check the return values of the FreeRTOS APIs to make sure those were
successful.</li>
<li>Check that the secheduler related configuration, like <code>configUSE_TIME_SLICING</code>, and
<code>configUSE_PREEMPTION</code> are set correctly as per the application requirements.</li>
<li><a href="https://www.freertos.org/Debugging-Hard-Faults-On-Cortex-M-Microcontrollers.html">This page</a>
provides details about debugging hard faults on Cortex-M microcontrollers.</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
